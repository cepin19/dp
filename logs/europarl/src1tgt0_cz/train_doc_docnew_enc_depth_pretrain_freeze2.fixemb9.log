[2019-03-31 20:21:32] [marian] Marian v1.7.8 acb2c2e 2019-03-31 15:01:15 +0200
[2019-03-31 20:21:32] [marian] Running on pcknot5 as process 18920 with command line:
[2019-03-31 20:21:32] [marian] /mnt/minerva1/nlp/projects/nmt/doc-marian/build/marian --model model/model.src1tgt0.docnew.enc_depth.pretrained.frozen2.fix_emb9.npz --pretrained-model ../src0tgt0/model/model.src0tgt0_to_tgt0.newbase.160.npz.best-perplexity.npz --type transformer-context --train-sets corp/europarl.cs-en.docs.train.en.bpe.src_prev corp/europarl.cs-en.docs.train.en.bpe.src corp/europarl.cs-en.docs.train.cz.bpe --max-length 160 --dim-vocabs 30000 30000 --embedding-fix-src --embedding-fix-trg --vocabs corp/vocab.encz.opensub.new.yml corp/vocab.encz.opensub.new.yml corp/vocab.encz.opensub.new.yml --mini-batch-fit -w 7800 --mini-batch 1000 --maxi-batch 1000 --early-stopping 10 --freeze --valid-freq 10000 --save-freq 10000 --disp-freq 1000 --valid-metrics cross-entropy perplexity translation --valid-sets corp/europarl.cs-en.docs.dev.en.bpe.src_prev corp/europarl.cs-en.docs.dev.en.bpe.src corp/europarl.cs-en.docs.dev.cz.bpe --valid-script-path ./val.sh --valid-translation-output data/valid.bpe.en.output --quiet-translation --valid-mini-batch 16 --keep-best --beam-size 6 --normalize 0.6 --log model/train_trans.gate.log --valid-log model/valid_trans.gate.log --enc-depth 6 --dec-depth 6 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0002 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --optimizer-delay 4 --devices 0 --no-nccl --sync-sgd --seed 1111 --exponential-smoothing --no-restore-corpus
[2019-03-31 20:21:32] [config] after-batches: 0
[2019-03-31 20:21:32] [config] after-epochs: 0
[2019-03-31 20:21:32] [config] allow-unk: false
[2019-03-31 20:21:32] [config] beam-size: 6
[2019-03-31 20:21:32] [config] bert-class-symbol: "[CLS]"
[2019-03-31 20:21:32] [config] bert-mask-symbol: "[MASK]"
[2019-03-31 20:21:32] [config] bert-masking-fraction: 0.15
[2019-03-31 20:21:32] [config] bert-sep-symbol: "[SEP]"
[2019-03-31 20:21:32] [config] bert-train-type-embeddings: true
[2019-03-31 20:21:32] [config] bert-type-vocab-size: 2
[2019-03-31 20:21:32] [config] best-deep: false
[2019-03-31 20:21:32] [config] clip-gemm: 0
[2019-03-31 20:21:32] [config] clip-norm: 5
[2019-03-31 20:21:32] [config] context-enc-depth: 1
[2019-03-31 20:21:32] [config] cost-type: ce-mean
[2019-03-31 20:21:32] [config] cpu-threads: 0
[2019-03-31 20:21:32] [config] data-weighting: ""
[2019-03-31 20:21:32] [config] data-weighting-type: sentence
[2019-03-31 20:21:32] [config] dec-cell: gru
[2019-03-31 20:21:32] [config] dec-cell-base-depth: 2
[2019-03-31 20:21:32] [config] dec-cell-high-depth: 1
[2019-03-31 20:21:32] [config] dec-depth: 6
[2019-03-31 20:21:32] [config] devices:
[2019-03-31 20:21:32] [config]   - 0
[2019-03-31 20:21:32] [config] dim-emb: 512
[2019-03-31 20:21:32] [config] dim-rnn: 1024
[2019-03-31 20:21:32] [config] dim-vocabs:
[2019-03-31 20:21:32] [config]   - 30000
[2019-03-31 20:21:32] [config]   - 30000
[2019-03-31 20:21:32] [config] disp-first: 0
[2019-03-31 20:21:32] [config] disp-freq: 1000
[2019-03-31 20:21:32] [config] disp-label-counts: false
[2019-03-31 20:21:32] [config] dropout-rnn: 0
[2019-03-31 20:21:32] [config] dropout-src: 0
[2019-03-31 20:21:32] [config] dropout-trg: 0
[2019-03-31 20:21:32] [config] dump-config: ""
[2019-03-31 20:21:32] [config] early-stopping: 10
[2019-03-31 20:21:32] [config] embedding-fix-src: true
[2019-03-31 20:21:32] [config] embedding-fix-trg: true
[2019-03-31 20:21:32] [config] embedding-normalization: false
[2019-03-31 20:21:32] [config] embedding-vectors:
[2019-03-31 20:21:32] [config]   []
[2019-03-31 20:21:32] [config] enc-cell: gru
[2019-03-31 20:21:32] [config] enc-cell-depth: 1
[2019-03-31 20:21:32] [config] enc-depth: 6
[2019-03-31 20:21:32] [config] enc-type: bidirectional
[2019-03-31 20:21:32] [config] exponential-smoothing: 0.0001
[2019-03-31 20:21:32] [config] freeze: true
[2019-03-31 20:21:32] [config] grad-dropping-momentum: 0
[2019-03-31 20:21:32] [config] grad-dropping-rate: 0
[2019-03-31 20:21:32] [config] grad-dropping-warmup: 100
[2019-03-31 20:21:32] [config] guided-alignment: none
[2019-03-31 20:21:32] [config] guided-alignment-cost: mse
[2019-03-31 20:21:32] [config] guided-alignment-weight: 0.1
[2019-03-31 20:21:32] [config] hier-att: false
[2019-03-31 20:21:32] [config] ignore-model-config: false
[2019-03-31 20:21:32] [config] input-types:
[2019-03-31 20:21:32] [config]   []
[2019-03-31 20:21:32] [config] interpolate-env-vars: false
[2019-03-31 20:21:32] [config] keep-best: true
[2019-03-31 20:21:32] [config] label-smoothing: 0.1
[2019-03-31 20:21:32] [config] layer-normalization: false
[2019-03-31 20:21:32] [config] learn-rate: 0.0002
[2019-03-31 20:21:32] [config] log: model/train_trans.gate.log
[2019-03-31 20:21:32] [config] log-level: info
[2019-03-31 20:21:32] [config] log-time-zone: ""
[2019-03-31 20:21:32] [config] lr-decay: 0
[2019-03-31 20:21:32] [config] lr-decay-freq: 50000
[2019-03-31 20:21:32] [config] lr-decay-inv-sqrt:
[2019-03-31 20:21:32] [config]   - 16000
[2019-03-31 20:21:32] [config] lr-decay-repeat-warmup: false
[2019-03-31 20:21:32] [config] lr-decay-reset-optimizer: false
[2019-03-31 20:21:32] [config] lr-decay-start:
[2019-03-31 20:21:32] [config]   - 10
[2019-03-31 20:21:32] [config]   - 1
[2019-03-31 20:21:32] [config] lr-decay-strategy: epoch+stalled
[2019-03-31 20:21:32] [config] lr-report: true
[2019-03-31 20:21:32] [config] lr-warmup: 16000
[2019-03-31 20:21:32] [config] lr-warmup-at-reload: false
[2019-03-31 20:21:32] [config] lr-warmup-cycle: false
[2019-03-31 20:21:32] [config] lr-warmup-start-rate: 0
[2019-03-31 20:21:32] [config] max-length: 160
[2019-03-31 20:21:32] [config] max-length-crop: false
[2019-03-31 20:21:32] [config] max-length-factor: 3
[2019-03-31 20:21:32] [config] maxi-batch: 1000
[2019-03-31 20:21:32] [config] maxi-batch-sort: trg
[2019-03-31 20:21:32] [config] mini-batch: 1000
[2019-03-31 20:21:32] [config] mini-batch-fit: true
[2019-03-31 20:21:32] [config] mini-batch-fit-step: 10
[2019-03-31 20:21:32] [config] mini-batch-overstuff: 1
[2019-03-31 20:21:32] [config] mini-batch-track-lr: false
[2019-03-31 20:21:32] [config] mini-batch-understuff: 1
[2019-03-31 20:21:32] [config] mini-batch-warmup: 0
[2019-03-31 20:21:32] [config] mini-batch-words: 0
[2019-03-31 20:21:32] [config] mini-batch-words-ref: 0
[2019-03-31 20:21:32] [config] model: model/model.src1tgt0.docnew.enc_depth.pretrained.frozen2.fix_emb9.npz
[2019-03-31 20:21:32] [config] multi-loss-type: sum
[2019-03-31 20:21:32] [config] multi-node: false
[2019-03-31 20:21:32] [config] multi-node-overlap: true
[2019-03-31 20:21:32] [config] n-best: false
[2019-03-31 20:21:32] [config] no-nccl: true
[2019-03-31 20:21:32] [config] no-reload: false
[2019-03-31 20:21:32] [config] no-restore-corpus: true
[2019-03-31 20:21:32] [config] no-shuffle: false
[2019-03-31 20:21:32] [config] normalize: 0.6
[2019-03-31 20:21:32] [config] num-devices: 0
[2019-03-31 20:21:32] [config] optimizer: adam
[2019-03-31 20:21:32] [config] optimizer-delay: 4
[2019-03-31 20:21:32] [config] optimizer-params:
[2019-03-31 20:21:32] [config]   - 0.9
[2019-03-31 20:21:32] [config]   - 0.98
[2019-03-31 20:21:32] [config]   - 1e-09
[2019-03-31 20:21:32] [config] overwrite: false
[2019-03-31 20:21:32] [config] pretrained-model: ../src0tgt0/model/model.src0tgt0_to_tgt0.newbase.160.npz.best-perplexity.npz
[2019-03-31 20:21:32] [config] quiet: false
[2019-03-31 20:21:32] [config] quiet-translation: true
[2019-03-31 20:21:32] [config] relative-paths: false
[2019-03-31 20:21:32] [config] right-left: false
[2019-03-31 20:21:32] [config] save-freq: 10000
[2019-03-31 20:21:32] [config] seed: 1111
[2019-03-31 20:21:32] [config] shuffle-in-ram: false
[2019-03-31 20:21:32] [config] skip: false
[2019-03-31 20:21:32] [config] sqlite: ""
[2019-03-31 20:21:32] [config] sqlite-drop: false
[2019-03-31 20:21:32] [config] sync-sgd: true
[2019-03-31 20:21:32] [config] tempdir: /tmp
[2019-03-31 20:21:32] [config] tied-embeddings: false
[2019-03-31 20:21:32] [config] tied-embeddings-all: true
[2019-03-31 20:21:32] [config] tied-embeddings-src: false
[2019-03-31 20:21:32] [config] train-sets:
[2019-03-31 20:21:32] [config]   - corp/europarl.cs-en.docs.train.en.bpe.src_prev
[2019-03-31 20:21:32] [config]   - corp/europarl.cs-en.docs.train.en.bpe.src
[2019-03-31 20:21:32] [config]   - corp/europarl.cs-en.docs.train.cz.bpe
[2019-03-31 20:21:32] [config] transformer-aan-activation: swish
[2019-03-31 20:21:32] [config] transformer-aan-depth: 2
[2019-03-31 20:21:32] [config] transformer-aan-nogate: false
[2019-03-31 20:21:32] [config] transformer-decoder-autoreg: self-attention
[2019-03-31 20:21:32] [config] transformer-dim-aan: 2048
[2019-03-31 20:21:32] [config] transformer-dim-ffn: 2048
[2019-03-31 20:21:32] [config] transformer-dropout: 0.1
[2019-03-31 20:21:32] [config] transformer-dropout-attention: 0
[2019-03-31 20:21:32] [config] transformer-dropout-ffn: 0
[2019-03-31 20:21:32] [config] transformer-ffn-activation: swish
[2019-03-31 20:21:32] [config] transformer-ffn-depth: 2
[2019-03-31 20:21:32] [config] transformer-guided-alignment-layer: last
[2019-03-31 20:21:32] [config] transformer-heads: 8
[2019-03-31 20:21:32] [config] transformer-no-projection: false
[2019-03-31 20:21:32] [config] transformer-postprocess: dan
[2019-03-31 20:21:32] [config] transformer-postprocess-emb: d
[2019-03-31 20:21:32] [config] transformer-preprocess: ""
[2019-03-31 20:21:32] [config] transformer-tied-layers:
[2019-03-31 20:21:32] [config]   []
[2019-03-31 20:21:32] [config] transformer-train-position-embeddings: false
[2019-03-31 20:21:32] [config] type: transformer-context
[2019-03-31 20:21:32] [config] ulr: false
[2019-03-31 20:21:32] [config] ulr-dim-emb: 0
[2019-03-31 20:21:32] [config] ulr-dropout: 0
[2019-03-31 20:21:32] [config] ulr-keys-vectors: ""
[2019-03-31 20:21:32] [config] ulr-query-vectors: ""
[2019-03-31 20:21:32] [config] ulr-softmax-temperature: 1
[2019-03-31 20:21:32] [config] ulr-trainable-transformation: false
[2019-03-31 20:21:32] [config] valid-freq: 10000
[2019-03-31 20:21:32] [config] valid-log: model/valid_trans.gate.log
[2019-03-31 20:21:32] [config] valid-max-length: 1000
[2019-03-31 20:21:32] [config] valid-metrics:
[2019-03-31 20:21:32] [config]   - cross-entropy
[2019-03-31 20:21:32] [config]   - perplexity
[2019-03-31 20:21:32] [config]   - translation
[2019-03-31 20:21:32] [config] valid-mini-batch: 16
[2019-03-31 20:21:32] [config] valid-script-path: ./val.sh
[2019-03-31 20:21:32] [config] valid-sets:
[2019-03-31 20:21:32] [config]   - corp/europarl.cs-en.docs.dev.en.bpe.src_prev
[2019-03-31 20:21:32] [config]   - corp/europarl.cs-en.docs.dev.en.bpe.src
[2019-03-31 20:21:32] [config]   - corp/europarl.cs-en.docs.dev.cz.bpe
[2019-03-31 20:21:32] [config] valid-translation-output: data/valid.bpe.en.output
[2019-03-31 20:21:32] [config] vocabs:
[2019-03-31 20:21:32] [config]   - corp/vocab.encz.opensub.new.yml
[2019-03-31 20:21:32] [config]   - corp/vocab.encz.opensub.new.yml
[2019-03-31 20:21:32] [config]   - corp/vocab.encz.opensub.new.yml
[2019-03-31 20:21:32] [config] word-penalty: 0
[2019-03-31 20:21:32] [config] workspace: 7800
[2019-03-31 20:21:32] [config] Model is being created with Marian v1.7.8 acb2c2e 2019-03-31 15:01:15 +0200
[2019-03-31 20:21:32] Using synchronous training
[2019-03-31 20:21:32] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encz.opensub.new.yml
[2019-03-31 20:21:32] [data] Setting vocabulary size for input 0 to 30000
[2019-03-31 20:21:32] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encz.opensub.new.yml
[2019-03-31 20:21:32] [data] Setting vocabulary size for input 1 to 30000
[2019-03-31 20:21:32] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encz.opensub.new.yml
[2019-03-31 20:21:32] [data] Setting vocabulary size for input 2 to 30000
[2019-03-31 20:21:32] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-03-31 20:21:32] [batching] Collecting statistics for batch fitting with step size 10
[2019-03-31 20:21:33] [memory] Extending reserved space to 7808 MB (device gpu0)
[2019-03-31 20:21:33] [comm] NCCL communicator overridden
[2019-03-31 20:21:33] [training] Using 1 GPUs
[2019-03-31 20:21:33] [memory] Reserving 311 MB, device gpu0
[2019-03-31 20:21:33] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-03-31 20:21:33] [memory] Reserving 311 MB, device gpu0
[2019-03-31 20:21:39] [batching] Done. Typical MB size is 10685 target words
[2019-03-31 20:21:39] [memory] Extending reserved space to 7808 MB (device gpu0)
[2019-03-31 20:21:39] [comm] NCCL communicator overridden
[2019-03-31 20:21:39] [training] Using 1 GPUs
[2019-03-31 20:21:39] [training] Initializing model weights with the pre-trained model ../src0tgt0/model/model.src0tgt0_to_tgt0.newbase.160.npz.best-perplexity.npz
[2019-03-31 20:21:39] Loading model from ../src0tgt0/model/model.src0tgt0_to_tgt0.newbase.160.npz.best-perplexity.npz
[2019-03-31 20:21:40] Training started
[2019-03-31 20:21:40] [data] Shuffling data
[2019-03-31 20:21:40] [data] Done reading 620637 sentences
[2019-03-31 20:21:42] [data] Done shuffling 620637 sentences to temp files
[2019-03-31 20:22:04] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-03-31 20:22:04] [memory] Reserving 311 MB, device gpu0
[2019-03-31 20:22:04] [memory] Reserving 311 MB, device gpu0
[2019-03-31 20:22:04] [memory] Reserving 311 MB, device gpu0
[2019-03-31 20:22:05] [memory] Reserving 311 MB, device gpu0
[2019-03-31 20:22:05] [memory] Reserving 622 MB, device gpu0
[2019-03-31 20:27:30] Ep. 1 : Up. 1000 : Sen. 164,505 : Cost 272.53314209 : Time 357.51s : 14135.20 words/s : L.r. 1.2500e-05
[2019-03-31 20:33:05] Ep. 1 : Up. 2000 : Sen. 334,195 : Cost 257.24264526 : Time 335.29s : 15669.13 words/s : L.r. 2.5000e-05
[2019-03-31 20:38:36] Ep. 1 : Up. 3000 : Sen. 505,507 : Cost 242.54386902 : Time 331.21s : 15433.33 words/s : L.r. 3.7500e-05
[2019-03-31 20:42:26] Seen 620307 samples
[2019-03-31 20:42:26] Starting epoch 2
[2019-03-31 20:42:26] [data] Shuffling data
[2019-03-31 20:42:27] [data] Done reading 620637 sentences
[2019-03-31 20:42:29] [data] Done shuffling 620637 sentences to temp files
[2019-03-31 20:44:34] Ep. 2 : Up. 4000 : Sen. 51,969 : Cost 243.64683533 : Time 357.68s : 14373.09 words/s : L.r. 5.0000e-05
[2019-03-31 20:50:12] Ep. 2 : Up. 5000 : Sen. 223,074 : Cost 237.13415527 : Time 337.54s : 15646.81 words/s : L.r. 6.2500e-05
[2019-03-31 20:55:43] Ep. 2 : Up. 6000 : Sen. 388,765 : Cost 232.35975647 : Time 330.94s : 15504.17 words/s : L.r. 7.5000e-05
[2019-03-31 21:01:14] Ep. 2 : Up. 7000 : Sen. 557,397 : Cost 224.14730835 : Time 331.22s : 15580.35 words/s : L.r. 8.7500e-05
[2019-03-31 21:03:14] Seen 620307 samples
[2019-03-31 21:03:14] Starting epoch 3
[2019-03-31 21:03:14] [data] Shuffling data
[2019-03-31 21:03:15] [data] Done reading 620637 sentences
[2019-03-31 21:03:17] [data] Done shuffling 620637 sentences to temp files
[2019-03-31 21:07:09] Ep. 3 : Up. 8000 : Sen. 110,521 : Cost 210.73263550 : Time 355.69s : 14355.04 words/s : L.r. 1.0000e-04
[2019-03-31 21:12:47] Ep. 3 : Up. 9000 : Sen. 281,544 : Cost 217.19792175 : Time 337.51s : 15630.89 words/s : L.r. 1.1250e-04
[2019-03-31 21:18:18] Ep. 3 : Up. 10000 : Sen. 447,429 : Cost 213.78010559 : Time 330.89s : 15447.73 words/s : L.r. 1.2500e-04
[2019-03-31 21:18:18] Saving model weights and runtime parameters to model/model.src1tgt0.docnew.enc_depth.pretrained.frozen2.fix_emb9.npz.orig.npz
[2019-03-31 21:18:22] Saving model weights and runtime parameters to model/model.src1tgt0.docnew.enc_depth.pretrained.frozen2.fix_emb9.iter10000.npz
[2019-03-31 21:18:26] Saving model weights and runtime parameters to model/model.src1tgt0.docnew.enc_depth.pretrained.frozen2.fix_emb9.npz
[2019-03-31 21:18:31] Saving Adam parameters to model/model.src1tgt0.docnew.enc_depth.pretrained.frozen2.fix_emb9.npz.optimizer.npz
[2019-03-31 21:18:50] Saving model weights and runtime parameters to model/model.src1tgt0.docnew.enc_depth.pretrained.frozen2.fix_emb9.npz.best-cross-entropy.npz
[2019-03-31 21:18:54] [valid] Ep. 3 : Up. 10000 : cross-entropy : 197.283 : new best
[2019-03-31 21:19:04] Saving model weights and runtime parameters to model/model.src1tgt0.docnew.enc_depth.pretrained.frozen2.fix_emb9.npz.best-perplexity.npz
[2019-03-31 21:19:08] [valid] Ep. 3 : Up. 10000 : perplexity : 585.82 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-03-31 21:24:00] Saving model weights and runtime parameters to model/model.src1tgt0.docnew.enc_depth.pretrained.frozen2.fix_emb9.npz.best-translation.npz
[2019-03-31 21:24:04] [valid] Ep. 3 : Up. 10000 : translation : 4 : new best
[2019-03-31 21:29:35] Ep. 3 : Up. 11000 : Sen. 612,963 : Cost 209.82263184 : Time 676.92s : 7520.40 words/s : L.r. 1.3750e-04
[2019-03-31 21:29:51] Seen 620307 samples
[2019-03-31 21:29:51] Starting epoch 4
[2019-03-31 21:29:51] [data] Shuffling data
[2019-03-31 21:29:52] [data] Done reading 620637 sentences
[2019-03-31 21:29:54] [data] Done shuffling 620637 sentences to temp files
[2019-03-31 21:35:36] Ep. 4 : Up. 12000 : Sen. 161,830 : Cost 207.97305298 : Time 361.28s : 14492.50 words/s : L.r. 1.5000e-04
[2019-03-31 21:41:05] Ep. 4 : Up. 13000 : Sen. 326,051 : Cost 205.80610657 : Time 329.12s : 15459.38 words/s : L.r. 1.6250e-04
[2019-03-31 21:46:41] Ep. 4 : Up. 14000 : Sen. 498,172 : Cost 198.16885376 : Time 335.54s : 15496.12 words/s : L.r. 1.7500e-04
[2019-03-31 21:50:43] Seen 620307 samples
[2019-03-31 21:50:43] Starting epoch 5
[2019-03-31 21:50:43] [data] Shuffling data
[2019-03-31 21:50:44] [data] Done reading 620637 sentences
[2019-03-31 21:50:46] [data] Done shuffling 620637 sentences to temp files
[2019-03-31 21:52:31] Ep. 5 : Up. 15000 : Sen. 40,168 : Cost 198.16273499 : Time 350.57s : 14150.74 words/s : L.r. 1.8750e-04
[2019-03-31 21:58:07] Ep. 5 : Up. 16000 : Sen. 217,403 : Cost 190.25738525 : Time 335.80s : 15713.92 words/s : L.r. 2.0000e-04
[2019-03-31 22:03:42] Ep. 5 : Up. 17000 : Sen. 385,308 : Cost 197.09550476 : Time 334.88s : 15555.87 words/s : L.r. 1.9403e-04
[2019-03-31 22:09:14] Ep. 5 : Up. 18000 : Sen. 551,656 : Cost 194.17239380 : Time 332.12s : 15474.69 words/s : L.r. 1.8856e-04
[2019-03-31 22:11:32] Seen 620307 samples
[2019-03-31 22:11:32] Starting epoch 6
[2019-03-31 22:11:32] [data] Shuffling data
[2019-03-31 22:11:32] [data] Done reading 620637 sentences
[2019-03-31 22:11:34] [data] Done shuffling 620637 sentences to temp files
[2019-03-31 22:15:01] Ep. 6 : Up. 19000 : Sen. 93,998 : Cost 188.86149597 : Time 347.25s : 14212.02 words/s : L.r. 1.8353e-04
[2019-03-31 22:20:36] Ep. 6 : Up. 20000 : Sen. 269,432 : Cost 181.74993896 : Time 334.84s : 15489.37 words/s : L.r. 1.7889e-04
[2019-03-31 22:20:36] Saving model weights and runtime parameters to model/model.src1tgt0.docnew.enc_depth.pretrained.frozen2.fix_emb9.npz.orig.npz
[2019-03-31 22:20:40] Saving model weights and runtime parameters to model/model.src1tgt0.docnew.enc_depth.pretrained.frozen2.fix_emb9.iter20000.npz
[2019-03-31 22:20:45] Saving model weights and runtime parameters to model/model.src1tgt0.docnew.enc_depth.pretrained.frozen2.fix_emb9.npz
[2019-03-31 22:20:49] Saving Adam parameters to model/model.src1tgt0.docnew.enc_depth.pretrained.frozen2.fix_emb9.npz.optimizer.npz
[2019-03-31 22:21:08] Saving model weights and runtime parameters to model/model.src1tgt0.docnew.enc_depth.pretrained.frozen2.fix_emb9.npz.best-cross-entropy.npz
[2019-03-31 22:21:13] [valid] Ep. 6 : Up. 20000 : cross-entropy : 171.694 : new best
[2019-03-31 22:21:22] Saving model weights and runtime parameters to model/model.src1tgt0.docnew.enc_depth.pretrained.frozen2.fix_emb9.npz.best-perplexity.npz
[2019-03-31 22:21:26] [valid] Ep. 6 : Up. 20000 : perplexity : 256.304 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-03-31 22:25:31] Saving model weights and runtime parameters to model/model.src1tgt0.docnew.enc_depth.pretrained.frozen2.fix_emb9.npz.best-translation.npz
[2019-03-31 22:25:35] [valid] Ep. 6 : Up. 20000 : translation : 5.3 : new best
[2019-03-31 22:31:11] Ep. 6 : Up. 21000 : Sen. 438,805 : Cost 190.73504639 : Time 634.35s : 8289.62 words/s : L.r. 1.7457e-04
[2019-03-31 22:36:46] Ep. 6 : Up. 22000 : Sen. 605,892 : Cost 190.27485657 : Time 335.15s : 15559.33 words/s : L.r. 1.7056e-04
[2019-03-31 22:37:19] Seen 620307 samples
[2019-03-31 22:37:19] Starting epoch 7
[2019-03-31 22:37:19] [data] Shuffling data
[2019-03-31 22:37:20] [data] Done reading 620637 sentences
[2019-03-31 22:37:22] [data] Done shuffling 620637 sentences to temp files
[2019-03-31 22:42:46] Ep. 7 : Up. 23000 : Sen. 154,904 : Cost 187.07043457 : Time 360.08s : 14562.88 words/s : L.r. 1.6681e-04
[2019-03-31 22:48:06] Ep. 7 : Up. 24000 : Sen. 312,218 : Cost 185.72068787 : Time 320.40s : 15141.89 words/s : L.r. 1.6330e-04
[2019-03-31 22:53:46] Ep. 7 : Up. 25000 : Sen. 483,052 : Cost 187.66166687 : Time 339.60s : 15742.99 words/s : L.r. 1.6000e-04
[2019-03-31 22:58:07] Seen 620307 samples
[2019-03-31 22:58:07] Starting epoch 8
[2019-03-31 22:58:07] [data] Shuffling data
[2019-03-31 22:58:08] [data] Done reading 620637 sentences
[2019-03-31 22:58:10] [data] Done shuffling 620637 sentences to temp files
[2019-03-31 22:59:42] Ep. 8 : Up. 26000 : Sen. 33,395 : Cost 179.26573181 : Time 356.60s : 14413.48 words/s : L.r. 1.5689e-04
[2019-03-31 23:05:10] Ep. 8 : Up. 27000 : Sen. 197,925 : Cost 181.46981812 : Time 327.30s : 15395.18 words/s : L.r. 1.5396e-04
[2019-03-31 23:10:49] Ep. 8 : Up. 28000 : Sen. 374,940 : Cost 177.10556030 : Time 339.58s : 15670.27 words/s : L.r. 1.5119e-04
[2019-03-31 23:16:19] Ep. 8 : Up. 29000 : Sen. 539,324 : Cost 182.68330383 : Time 329.45s : 15465.08 words/s : L.r. 1.4856e-04
[2019-03-31 23:18:57] Seen 620307 samples
[2019-03-31 23:18:57] Starting epoch 9
[2019-03-31 23:18:57] [data] Shuffling data
[2019-03-31 23:18:58] [data] Done reading 620637 sentences
[2019-03-31 23:19:00] [data] Done shuffling 620637 sentences to temp files
[2019-03-31 23:22:20] Ep. 9 : Up. 30000 : Sen. 90,533 : Cost 178.65534973 : Time 361.03s : 14506.27 words/s : L.r. 1.4606e-04
[2019-03-31 23:22:20] Saving model weights and runtime parameters to model/model.src1tgt0.docnew.enc_depth.pretrained.frozen2.fix_emb9.npz.orig.npz
[2019-03-31 23:22:24] Saving model weights and runtime parameters to model/model.src1tgt0.docnew.enc_depth.pretrained.frozen2.fix_emb9.iter30000.npz
[2019-03-31 23:22:29] Saving model weights and runtime parameters to model/model.src1tgt0.docnew.enc_depth.pretrained.frozen2.fix_emb9.npz
[2019-03-31 23:22:34] Saving Adam parameters to model/model.src1tgt0.docnew.enc_depth.pretrained.frozen2.fix_emb9.npz.optimizer.npz
[2019-03-31 23:22:53] Saving model weights and runtime parameters to model/model.src1tgt0.docnew.enc_depth.pretrained.frozen2.fix_emb9.npz.best-cross-entropy.npz
[2019-03-31 23:22:58] [valid] Ep. 9 : Up. 30000 : cross-entropy : 160.87 : new best
[2019-03-31 23:23:07] Saving model weights and runtime parameters to model/model.src1tgt0.docnew.enc_depth.pretrained.frozen2.fix_emb9.npz.best-perplexity.npz
[2019-03-31 23:23:11] [valid] Ep. 9 : Up. 30000 : perplexity : 180.681 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-03-31 23:27:09] Saving model weights and runtime parameters to model/model.src1tgt0.docnew.enc_depth.pretrained.frozen2.fix_emb9.npz.best-translation.npz
[2019-03-31 23:27:13] [valid] Ep. 9 : Up. 30000 : translation : 6.2 : new best
[2019-03-31 23:32:47] Ep. 9 : Up. 31000 : Sen. 258,874 : Cost 180.69165039 : Time 627.08s : 8306.25 words/s : L.r. 1.4368e-04
[2019-03-31 23:38:20] Ep. 9 : Up. 32000 : Sen. 427,060 : Cost 179.19731140 : Time 332.71s : 15550.28 words/s : L.r. 1.4142e-04
[2019-03-31 23:43:43] Ep. 9 : Up. 33000 : Sen. 591,639 : Cost 174.12602234 : Time 323.29s : 15282.37 words/s : L.r. 1.3926e-04
[2019-03-31 23:44:39] Seen 620307 samples
[2019-03-31 23:44:39] Starting epoch 10
[2019-03-31 23:44:39] [data] Shuffling data
[2019-03-31 23:44:39] [data] Done reading 620637 sentences
[2019-03-31 23:44:41] [data] Done shuffling 620637 sentences to temp files
[2019-03-31 23:49:44] Ep. 10 : Up. 34000 : Sen. 141,801 : Cost 179.06701660 : Time 361.62s : 14589.53 words/s : L.r. 1.3720e-04
[2019-03-31 23:55:12] Ep. 10 : Up. 35000 : Sen. 305,476 : Cost 176.95506287 : Time 327.12s : 15346.82 words/s : L.r. 1.3522e-04
[2019-04-01 00:00:47] Ep. 10 : Up. 36000 : Sen. 476,325 : Cost 177.29872131 : Time 335.55s : 15679.64 words/s : L.r. 1.3333e-04
train_doc_docnew_enc_depth_pretrain_freeze2.sh: řádek 29: 18920 Ukončen (SIGTERM)      $marian_home/marian --model model/model.src1tgt0.docnew.enc_depth.pretrained.frozen2.fix_emb9.npz --pretrained-model ../src0tgt0/model/model.src0tgt0_to_tgt0.newbase.160.npz.best-perplexity.npz --type transformer-context --train-sets corp/europarl.cs-en.docs.train.en.bpe.src_prev corp/europarl.cs-en.docs.train.en.bpe.src corp/europarl.cs-en.docs.train.cz.bpe --max-length 160 --dim-vocabs 30000 30000 --embedding-fix-src --embedding-fix-trg --vocabs corp/vocab.encz.opensub.new.yml corp/vocab.encz.opensub.new.yml corp/vocab.encz.opensub.new.yml --mini-batch-fit -w 7800 --mini-batch 1000 --maxi-batch 1000 --early-stopping 10 --freeze --valid-freq 10000 --save-freq 10000 --disp-freq 1000 --valid-metrics cross-entropy perplexity translation --valid-sets corp/europarl.cs-en.docs.dev.en.bpe.src_prev corp/europarl.cs-en.docs.dev.en.bpe.src corp/europarl.cs-en.docs.dev.cz.bpe --valid-script-path ./val.sh --valid-translation-output data/valid.bpe.en.output --quiet-translation --valid-mini-batch 16 --keep-best --beam-size 6 --normalize 0.6 --log model/train_trans.gate.log --valid-log model/valid_trans.gate.log --enc-depth 6 --dec-depth 6 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0002 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --optimizer-delay 4 --devices 0 --no-nccl --sync-sgd --seed 1111 --exponential-smoothing --no-restore-corpus
