[2018-11-26 02:49:03] [config] after-batches: 0
[2018-11-26 02:49:03] [config] after-epochs: 0
[2018-11-26 02:49:03] [config] allow-unk: false
[2018-11-26 02:49:03] [config] beam-size: 6
[2018-11-26 02:49:03] [config] best-deep: false
[2018-11-26 02:49:03] [config] clip-gemm: 0
[2018-11-26 02:49:03] [config] clip-norm: 5
[2018-11-26 02:49:03] [config] cost-type: ce-mean
[2018-11-26 02:49:03] [config] cpu-threads: 0
[2018-11-26 02:49:03] [config] data-weighting-type: sentence
[2018-11-26 02:49:03] [config] dec-cell: gru
[2018-11-26 02:49:03] [config] dec-cell-base-depth: 2
[2018-11-26 02:49:03] [config] dec-cell-high-depth: 1
[2018-11-26 02:49:03] [config] dec-depth: 6
[2018-11-26 02:49:03] [config] devices:
[2018-11-26 02:49:03] [config]   - 2
[2018-11-26 02:49:03] [config] dim-emb: 512
[2018-11-26 02:49:03] [config] dim-rnn: 1024
[2018-11-26 02:49:03] [config] dim-vocabs:
[2018-11-26 02:49:03] [config]   - 0
[2018-11-26 02:49:03] [config]   - 0
[2018-11-26 02:49:03] [config] disp-freq: 500
[2018-11-26 02:49:03] [config] disp-label-counts: false
[2018-11-26 02:49:03] [config] dropout-rnn: 0
[2018-11-26 02:49:03] [config] dropout-src: 0
[2018-11-26 02:49:03] [config] dropout-trg: 0
[2018-11-26 02:49:03] [config] dump-config: false
[2018-11-26 02:49:03] [config] early-stopping: 15
[2018-11-26 02:49:03] [config] embedding-fix-src: false
[2018-11-26 02:49:03] [config] embedding-fix-trg: false
[2018-11-26 02:49:03] [config] embedding-normalization: false
[2018-11-26 02:49:03] [config] enc-cell: gru
[2018-11-26 02:49:03] [config] enc-cell-depth: 1
[2018-11-26 02:49:03] [config] enc-depth: 6
[2018-11-26 02:49:03] [config] enc-type: bidirectional
[2018-11-26 02:49:03] [config] exponential-smoothing: 0.0001
[2018-11-26 02:49:03] [config] grad-dropping-momentum: 0
[2018-11-26 02:49:03] [config] grad-dropping-rate: 0
[2018-11-26 02:49:03] [config] grad-dropping-warmup: 100
[2018-11-26 02:49:03] [config] guided-alignment-cost: ce
[2018-11-26 02:49:03] [config] guided-alignment-weight: 1
[2018-11-26 02:49:03] [config] ignore-model-config: false
[2018-11-26 02:49:03] [config] interpolate-env-vars: false
[2018-11-26 02:49:03] [config] keep-best: false
[2018-11-26 02:49:03] [config] label-smoothing: 0.1
[2018-11-26 02:49:03] [config] layer-normalization: false
[2018-11-26 02:49:03] [config] learn-rate: 0.0003
[2018-11-26 02:49:03] [config] log: model/train_trans.log
[2018-11-26 02:49:03] [config] log-level: info
[2018-11-26 02:49:03] [config] lr-decay: 0
[2018-11-26 02:49:03] [config] lr-decay-freq: 50000
[2018-11-26 02:49:03] [config] lr-decay-inv-sqrt: 16000
[2018-11-26 02:49:03] [config] lr-decay-repeat-warmup: false
[2018-11-26 02:49:03] [config] lr-decay-reset-optimizer: false
[2018-11-26 02:49:03] [config] lr-decay-start:
[2018-11-26 02:49:03] [config]   - 10
[2018-11-26 02:49:03] [config]   - 1
[2018-11-26 02:49:03] [config] lr-decay-strategy: epoch+stalled
[2018-11-26 02:49:03] [config] lr-report: true
[2018-11-26 02:49:03] [config] lr-warmup: 16000
[2018-11-26 02:49:03] [config] lr-warmup-at-reload: false
[2018-11-26 02:49:03] [config] lr-warmup-cycle: false
[2018-11-26 02:49:03] [config] lr-warmup-start-rate: 0
[2018-11-26 02:49:03] [config] max-length: 160
[2018-11-26 02:49:03] [config] max-length-crop: false
[2018-11-26 02:49:03] [config] max-length-factor: 3
[2018-11-26 02:49:03] [config] maxi-batch: 1000
[2018-11-26 02:49:03] [config] maxi-batch-sort: trg
[2018-11-26 02:49:03] [config] mini-batch: 60
[2018-11-26 02:49:03] [config] mini-batch-fit: false
[2018-11-26 02:49:03] [config] mini-batch-fit-step: 10
[2018-11-26 02:49:03] [config] mini-batch-words: 0
[2018-11-26 02:49:03] [config] model: model/model.src1tgt0.trans3.fixed.batch.65.opt32.npz
[2018-11-26 02:49:03] [config] multi-node: false
[2018-11-26 02:49:03] [config] multi-node-overlap: true
[2018-11-26 02:49:03] [config] n-best: false
[2018-11-26 02:49:03] [config] no-nccl: false
[2018-11-26 02:49:03] [config] no-reload: false
[2018-11-26 02:49:03] [config] no-restore-corpus: false
[2018-11-26 02:49:03] [config] no-shuffle: false
[2018-11-26 02:49:03] [config] normalize: 0.6
[2018-11-26 02:49:03] [config] optimizer: adam
[2018-11-26 02:49:03] [config] optimizer-delay: 32
[2018-11-26 02:49:03] [config] optimizer-params:
[2018-11-26 02:49:03] [config]   - 0.9
[2018-11-26 02:49:03] [config]   - 0.98
[2018-11-26 02:49:03] [config]   - 1e-09
[2018-11-26 02:49:03] [config] overwrite: false
[2018-11-26 02:49:03] [config] quiet: false
[2018-11-26 02:49:03] [config] quiet-translation: true
[2018-11-26 02:49:03] [config] relative-paths: false
[2018-11-26 02:49:03] [config] right-left: false
[2018-11-26 02:49:03] [config] save-freq: 5000
[2018-11-26 02:49:03] [config] seed: 1111
[2018-11-26 02:49:03] [config] skip: false
[2018-11-26 02:49:03] [config] sqlite: ""
[2018-11-26 02:49:03] [config] sqlite-drop: false
[2018-11-26 02:49:03] [config] sync-sgd: true
[2018-11-26 02:49:03] [config] tempdir: /tmp
[2018-11-26 02:49:03] [config] tied-embeddings: false
[2018-11-26 02:49:03] [config] tied-embeddings-all: true
[2018-11-26 02:49:03] [config] tied-embeddings-src: false
[2018-11-26 02:49:03] [config] train-sets:
[2018-11-26 02:49:03] [config]   - corp/europarl.cs-en.docs.train.en.bpe
[2018-11-26 02:49:03] [config]   - corp/europarl.cs-en.docs.train.cz.bpe
[2018-11-26 02:49:03] [config] transformer-aan-activation: swish
[2018-11-26 02:49:03] [config] transformer-aan-depth: 2
[2018-11-26 02:49:03] [config] transformer-aan-nogate: false
[2018-11-26 02:49:03] [config] transformer-decoder-autoreg: self-attention
[2018-11-26 02:49:03] [config] transformer-dim-aan: 2048
[2018-11-26 02:49:03] [config] transformer-dim-ffn: 2048
[2018-11-26 02:49:03] [config] transformer-dropout: 0.1
[2018-11-26 02:49:03] [config] transformer-dropout-attention: 0
[2018-11-26 02:49:03] [config] transformer-dropout-ffn: 0
[2018-11-26 02:49:03] [config] transformer-ffn-activation: swish
[2018-11-26 02:49:03] [config] transformer-ffn-depth: 2
[2018-11-26 02:49:03] [config] transformer-guided-alignment-layer: last
[2018-11-26 02:49:03] [config] transformer-heads: 8
[2018-11-26 02:49:03] [config] transformer-no-projection: false
[2018-11-26 02:49:03] [config] transformer-postprocess: dan
[2018-11-26 02:49:03] [config] transformer-postprocess-emb: d
[2018-11-26 02:49:03] [config] transformer-preprocess: ""
[2018-11-26 02:49:03] [config] transformer-tied-layers:
[2018-11-26 02:49:03] [config]   []
[2018-11-26 02:49:03] [config] type: transformer
[2018-11-26 02:49:03] [config] valid-freq: 5000
[2018-11-26 02:49:03] [config] valid-log: model/valid_trans.log
[2018-11-26 02:49:03] [config] valid-max-length: 1000
[2018-11-26 02:49:03] [config] valid-metrics:
[2018-11-26 02:49:03] [config]   - cross-entropy
[2018-11-26 02:49:03] [config]   - perplexity
[2018-11-26 02:49:03] [config]   - translation
[2018-11-26 02:49:03] [config] valid-mini-batch: 16
[2018-11-26 02:49:03] [config] valid-script-path: ./val.sh
[2018-11-26 02:49:03] [config] valid-sets:
[2018-11-26 02:49:03] [config]   - corp/europarl.cs-en.docs.dev.en.bpe
[2018-11-26 02:49:03] [config]   - corp/europarl.cs-en.docs.dev.cz.bpe
[2018-11-26 02:49:03] [config] valid-translation-output: data/valid.bpe.en.output
[2018-11-26 02:49:03] [config] vocabs:
[2018-11-26 02:49:03] [config]   - corp/vocab.encs.europarl.yml
[2018-11-26 02:49:03] [config]   - corp/vocab.encs.europarl.yml
[2018-11-26 02:49:03] [config] word-penalty: 0
[2018-11-26 02:49:03] [config] workspace: 2048
[2018-11-26 02:49:03] [config] Model is being created with Marian v1.6.0+59e69a8
[2018-11-26 02:49:03] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.europarl.yml
[2018-11-26 02:49:03] [data] Setting vocabulary size for input 0 to 32000
[2018-11-26 02:49:03] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.europarl.yml
[2018-11-26 02:49:03] [data] Setting vocabulary size for input 1 to 32000
[2018-11-26 02:49:04] [memory] Extending reserved space to 2048 MB (device gpu2)
[2018-11-26 02:49:04] Training started
[2018-11-26 02:49:04] [data] Shuffling files
[2018-11-26 02:49:06] [data] Done
[2018-11-26 02:49:08] [memory] Reserving 230 MB, device gpu2
tcmalloc: large alloc 2147483648 bytes == 0x24a9e000 @ 
tcmalloc: large alloc 2281701376 bytes == 0x24a9e000 @ 
tcmalloc: large alloc 2415919104 bytes == 0x24a9e000 @ 
tcmalloc: large alloc 2550136832 bytes == 0x24a9e000 @ 
tcmalloc: large alloc 2684354560 bytes == 0x24a9e000 @ 
tcmalloc: large alloc 2818572288 bytes == 0x24a9e000 @ 
tcmalloc: large alloc 2952790016 bytes == 0x24a9e000 @ 
tcmalloc: large alloc 3087007744 bytes == 0x24a9e000 @ 
[2018-11-26 02:49:25] [memory] Reserving 230 MB, device gpu2
tcmalloc: large alloc 3221225472 bytes == 0x24a9e000 @ 
tcmalloc: large alloc 3355443200 bytes == 0x24a9e000 @ 
tcmalloc: large alloc 3489660928 bytes == 0x24a9e000 @ 
[2018-11-26 02:49:30] [memory] Reserving 461 MB, device gpu2
[2018-11-26 02:49:30] [memory] Reserving 230 MB, device gpu2
tcmalloc: large alloc 4026531840 bytes == 0x24a9e000 @ 
tcmalloc: large alloc 4429185024 bytes == 0x24a9e000 @ 
tcmalloc: large alloc 4966055936 bytes == 0x7efcf4000000 @ 
tcmalloc: large alloc 5637144576 bytes == 0x7ef074000000 @ 
tcmalloc: large alloc 6308233216 bytes == 0x7ee264000000 @ 
tcmalloc: large alloc 7113539584 bytes == 0x7ecf74000000 @ 
tcmalloc: large alloc 8053063680 bytes == 0x7eb684000000 @ 
tcmalloc: large alloc 8589934592 bytes == 0x7ea6e4000000 @ 
tcmalloc: large alloc 8724152320 bytes == 0x7ea2d4000000 @ 
tcmalloc: large alloc 8858370048 bytes == 0x7e9eb4000000 @ 
tcmalloc: large alloc 8992587776 bytes == 0x7e9a84000000 @ 
tcmalloc: large alloc 9126805504 bytes == 0x7e9644000000 @ 
tcmalloc: large alloc 9261023232 bytes == 0x7e91f4000000 @ 
tcmalloc: large alloc 9395240960 bytes == 0x7e8d94000000 @ 
tcmalloc: large alloc 9529458688 bytes == 0x7e8924000000 @ 
tcmalloc: large alloc 9663676416 bytes == 0x7e84a4000000 @ 
tcmalloc: large alloc 9797894144 bytes == 0x7e8014000000 @ 
tcmalloc: large alloc 9932111872 bytes == 0x7e7b74000000 @ 
tcmalloc: large alloc 10066329600 bytes == 0x7e76c4000000 @ 
tcmalloc: large alloc 10200547328 bytes == 0x7e7204000000 @ 
[2018-11-26 03:04:41] Error: out of memory - /home/big_maggie/usr/marian_cosmas/marian_1.6.0/marian-dev/src/tensors/gpu/device.cu:30
train_trans.sh: line 26: 100363 Aborted                 (core dumped) $marian_home/marian --model model/model.src1tgt0.trans3.fixed.batch.65.opt32.npz --type transformer --train-sets corp/europarl.cs-en.docs.train.en.bpe corp/europarl.cs-en.docs.train.cz.bpe --max-length 160 --vocabs corp/vocab.encs.europarl.yml corp/vocab.encs.europarl.yml --mini-batch 60 --maxi-batch 1000 --early-stopping 15 --valid-freq 5000 --save-freq 5000 --disp-freq 500 --valid-metrics cross-entropy perplexity translation --valid-sets corp/europarl.cs-en.docs.dev.en.bpe corp/europarl.cs-en.docs.dev.cz.bpe --valid-script-path ./val.sh --valid-translation-output data/valid.bpe.en.output --quiet-translation --valid-mini-batch 16 --beam-size 6 --normalize 0.6 --log model/train_trans.log --valid-log model/valid_trans.log --enc-depth 6 --dec-depth 6 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --optimizer-delay 32 --devices 2 --sync-sgd --seed 1111 --exponential-smoothing
