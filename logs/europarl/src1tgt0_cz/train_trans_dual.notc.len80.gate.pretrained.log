[2019-03-05 13:37:04] [marian] Marian v1.7.8 63e1cfe4 2019-02-11 21:04:00 -0800
[2019-03-05 13:37:04] [marian] Running on pcknot4 as process 29606 with command line:
[2019-03-05 13:37:04] [marian] /mnt/minerva1/nlp/projects/nmt/marian-doc-gated4/doc-marian/build/marian --model model/model.src1tgt0.dual.doc.same_embedding.gate_really.notc.pretrained.len80.npz --pretrained-model ../src0tgt0/model.src0tgt0.trans3.iter110000.npz --type transformer-context --train-sets corp/europarl.cs-en.docs.train.en.bpe.src_prev corp/europarl.cs-en.docs.train.en.bpe.src corp/europarl.cs-en.docs.train.cz.bpe --max-length 80 --dim-vocabs 32000 32000 --vocabs ../src0tgt0/corp/vocab.encs.europarl.yml ../src0tgt0/corp/vocab.encs.europarl.yml ../src0tgt0/corp/vocab.encs.europarl.yml --mini-batch-fit -w 8500 --mini-batch 1000 --maxi-batch 1000 --early-stopping 10 --valid-freq 5000 --save-freq 5000 --disp-freq 500 --valid-metrics cross-entropy perplexity translation --valid-sets corp/europarl.cs-en.docs.dev.en.bpe.src_prev corp/europarl.cs-en.docs.dev.en.bpe.src corp/europarl.cs-en.docs.dev.cz.bpe --valid-script-path ./val.sh --valid-translation-output data/valid.bpe.en.output --quiet-translation --valid-mini-batch 16 --beam-size 6 --normalize 0.6 --log model/train_trans.doc.log --valid-log model/valid_trans.doc.log --enc-depth 6 --dec-depth 6 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --optimizer-delay 8 --devices 0 --sync-sgd --seed 1111 --exponential-smoothing --no-restore-corpus --keep-best --overwrite
[2019-03-05 13:37:04] [config] after-batches: 0
[2019-03-05 13:37:04] [config] after-epochs: 0
[2019-03-05 13:37:04] [config] allow-unk: false
[2019-03-05 13:37:04] [config] beam-size: 6
[2019-03-05 13:37:04] [config] bert-class-symbol: "[CLS]"
[2019-03-05 13:37:04] [config] bert-mask-symbol: "[MASK]"
[2019-03-05 13:37:04] [config] bert-masking-fraction: 0.15
[2019-03-05 13:37:04] [config] bert-sep-symbol: "[SEP]"
[2019-03-05 13:37:04] [config] bert-train-type-embeddings: true
[2019-03-05 13:37:04] [config] bert-type-vocab-size: 2
[2019-03-05 13:37:04] [config] best-deep: false
[2019-03-05 13:37:04] [config] clip-gemm: 0
[2019-03-05 13:37:04] [config] clip-norm: 5
[2019-03-05 13:37:04] [config] cost-type: ce-mean
[2019-03-05 13:37:04] [config] cpu-threads: 0
[2019-03-05 13:37:04] [config] data-weighting: ""
[2019-03-05 13:37:04] [config] data-weighting-type: sentence
[2019-03-05 13:37:04] [config] dec-cell: gru
[2019-03-05 13:37:04] [config] dec-cell-base-depth: 2
[2019-03-05 13:37:04] [config] dec-cell-high-depth: 1
[2019-03-05 13:37:04] [config] dec-depth: 6
[2019-03-05 13:37:04] [config] devices:
[2019-03-05 13:37:04] [config]   - 0
[2019-03-05 13:37:04] [config] dim-emb: 512
[2019-03-05 13:37:04] [config] dim-rnn: 1024
[2019-03-05 13:37:04] [config] dim-vocabs:
[2019-03-05 13:37:04] [config]   - 32000
[2019-03-05 13:37:04] [config]   - 32000
[2019-03-05 13:37:04] [config] disp-first: 0
[2019-03-05 13:37:04] [config] disp-freq: 500
[2019-03-05 13:37:04] [config] disp-label-counts: false
[2019-03-05 13:37:04] [config] dropout-rnn: 0
[2019-03-05 13:37:04] [config] dropout-src: 0
[2019-03-05 13:37:04] [config] dropout-trg: 0
[2019-03-05 13:37:04] [config] dump-config: ""
[2019-03-05 13:37:04] [config] early-stopping: 10
[2019-03-05 13:37:04] [config] embedding-fix-src: false
[2019-03-05 13:37:04] [config] embedding-fix-trg: false
[2019-03-05 13:37:04] [config] embedding-normalization: false
[2019-03-05 13:37:04] [config] embedding-vectors:
[2019-03-05 13:37:04] [config]   []
[2019-03-05 13:37:04] [config] enc-cell: gru
[2019-03-05 13:37:04] [config] enc-cell-depth: 1
[2019-03-05 13:37:04] [config] enc-depth: 6
[2019-03-05 13:37:04] [config] enc-type: bidirectional
[2019-03-05 13:37:04] [config] exponential-smoothing: 0.0001
[2019-03-05 13:37:04] [config] grad-dropping-momentum: 0
[2019-03-05 13:37:04] [config] grad-dropping-rate: 0
[2019-03-05 13:37:04] [config] grad-dropping-warmup: 100
[2019-03-05 13:37:04] [config] guided-alignment: none
[2019-03-05 13:37:04] [config] guided-alignment-cost: mse
[2019-03-05 13:37:04] [config] guided-alignment-weight: 0.1
[2019-03-05 13:37:04] [config] ignore-model-config: false
[2019-03-05 13:37:04] [config] input-types:
[2019-03-05 13:37:04] [config]   []
[2019-03-05 13:37:04] [config] interpolate-env-vars: false
[2019-03-05 13:37:04] [config] keep-best: true
[2019-03-05 13:37:04] [config] label-smoothing: 0.1
[2019-03-05 13:37:04] [config] layer-normalization: false
[2019-03-05 13:37:04] [config] learn-rate: 0.0003
[2019-03-05 13:37:04] [config] log: model/train_trans.doc.log
[2019-03-05 13:37:04] [config] log-level: info
[2019-03-05 13:37:04] [config] log-time-zone: ""
[2019-03-05 13:37:04] [config] lr-decay: 0
[2019-03-05 13:37:04] [config] lr-decay-freq: 50000
[2019-03-05 13:37:04] [config] lr-decay-inv-sqrt:
[2019-03-05 13:37:04] [config]   - 16000
[2019-03-05 13:37:04] [config] lr-decay-repeat-warmup: false
[2019-03-05 13:37:04] [config] lr-decay-reset-optimizer: false
[2019-03-05 13:37:04] [config] lr-decay-start:
[2019-03-05 13:37:04] [config]   - 10
[2019-03-05 13:37:04] [config]   - 1
[2019-03-05 13:37:04] [config] lr-decay-strategy: epoch+stalled
[2019-03-05 13:37:04] [config] lr-report: true
[2019-03-05 13:37:04] [config] lr-warmup: 16000
[2019-03-05 13:37:04] [config] lr-warmup-at-reload: false
[2019-03-05 13:37:04] [config] lr-warmup-cycle: false
[2019-03-05 13:37:04] [config] lr-warmup-start-rate: 0
[2019-03-05 13:37:04] [config] max-length: 80
[2019-03-05 13:37:04] [config] max-length-crop: false
[2019-03-05 13:37:04] [config] max-length-factor: 3
[2019-03-05 13:37:04] [config] maxi-batch: 1000
[2019-03-05 13:37:04] [config] maxi-batch-sort: trg
[2019-03-05 13:37:04] [config] mini-batch: 1000
[2019-03-05 13:37:04] [config] mini-batch-fit: true
[2019-03-05 13:37:04] [config] mini-batch-fit-step: 10
[2019-03-05 13:37:04] [config] mini-batch-overstuff: 1
[2019-03-05 13:37:04] [config] mini-batch-track-lr: false
[2019-03-05 13:37:04] [config] mini-batch-understuff: 1
[2019-03-05 13:37:04] [config] mini-batch-warmup: 0
[2019-03-05 13:37:04] [config] mini-batch-words: 0
[2019-03-05 13:37:04] [config] mini-batch-words-ref: 0
[2019-03-05 13:37:04] [config] model: model/model.src1tgt0.dual.doc.same_embedding.gate_really.notc.pretrained.len80.npz
[2019-03-05 13:37:04] [config] multi-loss-type: sum
[2019-03-05 13:37:04] [config] multi-node: false
[2019-03-05 13:37:04] [config] multi-node-overlap: true
[2019-03-05 13:37:04] [config] n-best: false
[2019-03-05 13:37:04] [config] no-nccl: false
[2019-03-05 13:37:04] [config] no-reload: false
[2019-03-05 13:37:04] [config] no-restore-corpus: true
[2019-03-05 13:37:04] [config] no-shuffle: false
[2019-03-05 13:37:04] [config] normalize: 0.6
[2019-03-05 13:37:04] [config] num-devices: 0
[2019-03-05 13:37:04] [config] optimizer: adam
[2019-03-05 13:37:04] [config] optimizer-delay: 8
[2019-03-05 13:37:04] [config] optimizer-params:
[2019-03-05 13:37:04] [config]   - 0.9
[2019-03-05 13:37:04] [config]   - 0.98
[2019-03-05 13:37:04] [config]   - 1e-09
[2019-03-05 13:37:04] [config] overwrite: true
[2019-03-05 13:37:04] [config] pretrained-model: ../src0tgt0/model.src0tgt0.trans3.iter110000.npz
[2019-03-05 13:37:04] [config] quiet: false
[2019-03-05 13:37:04] [config] quiet-translation: true
[2019-03-05 13:37:04] [config] relative-paths: false
[2019-03-05 13:37:04] [config] right-left: false
[2019-03-05 13:37:04] [config] save-freq: 5000
[2019-03-05 13:37:04] [config] seed: 1111
[2019-03-05 13:37:04] [config] shuffle-in-ram: false
[2019-03-05 13:37:04] [config] skip: false
[2019-03-05 13:37:04] [config] sqlite: ""
[2019-03-05 13:37:04] [config] sqlite-drop: false
[2019-03-05 13:37:04] [config] sync-sgd: true
[2019-03-05 13:37:04] [config] tempdir: /tmp
[2019-03-05 13:37:04] [config] tied-embeddings: false
[2019-03-05 13:37:04] [config] tied-embeddings-all: true
[2019-03-05 13:37:04] [config] tied-embeddings-src: false
[2019-03-05 13:37:04] [config] train-sets:
[2019-03-05 13:37:04] [config]   - corp/europarl.cs-en.docs.train.en.bpe.src_prev
[2019-03-05 13:37:04] [config]   - corp/europarl.cs-en.docs.train.en.bpe.src
[2019-03-05 13:37:04] [config]   - corp/europarl.cs-en.docs.train.cz.bpe
[2019-03-05 13:37:04] [config] transformer-aan-activation: swish
[2019-03-05 13:37:04] [config] transformer-aan-depth: 2
[2019-03-05 13:37:04] [config] transformer-aan-nogate: false
[2019-03-05 13:37:04] [config] transformer-decoder-autoreg: self-attention
[2019-03-05 13:37:04] [config] transformer-dim-aan: 2048
[2019-03-05 13:37:04] [config] transformer-dim-ffn: 2048
[2019-03-05 13:37:04] [config] transformer-dropout: 0.1
[2019-03-05 13:37:04] [config] transformer-dropout-attention: 0
[2019-03-05 13:37:04] [config] transformer-dropout-ffn: 0
[2019-03-05 13:37:04] [config] transformer-ffn-activation: swish
[2019-03-05 13:37:04] [config] transformer-ffn-depth: 2
[2019-03-05 13:37:04] [config] transformer-guided-alignment-layer: last
[2019-03-05 13:37:04] [config] transformer-heads: 8
[2019-03-05 13:37:04] [config] transformer-no-projection: false
[2019-03-05 13:37:04] [config] transformer-postprocess: dan
[2019-03-05 13:37:04] [config] transformer-postprocess-emb: d
[2019-03-05 13:37:04] [config] transformer-preprocess: ""
[2019-03-05 13:37:04] [config] transformer-tied-layers:
[2019-03-05 13:37:04] [config]   []
[2019-03-05 13:37:04] [config] transformer-train-position-embeddings: false
[2019-03-05 13:37:04] [config] type: transformer-context
[2019-03-05 13:37:04] [config] ulr: false
[2019-03-05 13:37:04] [config] ulr-dim-emb: 0
[2019-03-05 13:37:04] [config] ulr-dropout: 0
[2019-03-05 13:37:04] [config] ulr-keys-vectors: ""
[2019-03-05 13:37:04] [config] ulr-query-vectors: ""
[2019-03-05 13:37:04] [config] ulr-softmax-temperature: 1
[2019-03-05 13:37:04] [config] ulr-trainable-transformation: false
[2019-03-05 13:37:04] [config] valid-freq: 5000
[2019-03-05 13:37:04] [config] valid-log: model/valid_trans.doc.log
[2019-03-05 13:37:04] [config] valid-max-length: 1000
[2019-03-05 13:37:04] [config] valid-metrics:
[2019-03-05 13:37:04] [config]   - cross-entropy
[2019-03-05 13:37:04] [config]   - perplexity
[2019-03-05 13:37:04] [config]   - translation
[2019-03-05 13:37:04] [config] valid-mini-batch: 16
[2019-03-05 13:37:04] [config] valid-script-path: ./val.sh
[2019-03-05 13:37:04] [config] valid-sets:
[2019-03-05 13:37:04] [config]   - corp/europarl.cs-en.docs.dev.en.bpe.src_prev
[2019-03-05 13:37:04] [config]   - corp/europarl.cs-en.docs.dev.en.bpe.src
[2019-03-05 13:37:04] [config]   - corp/europarl.cs-en.docs.dev.cz.bpe
[2019-03-05 13:37:04] [config] valid-translation-output: data/valid.bpe.en.output
[2019-03-05 13:37:04] [config] vocabs:
[2019-03-05 13:37:04] [config]   - ../src0tgt0/corp/vocab.encs.europarl.yml
[2019-03-05 13:37:04] [config]   - ../src0tgt0/corp/vocab.encs.europarl.yml
[2019-03-05 13:37:04] [config]   - ../src0tgt0/corp/vocab.encs.europarl.yml
[2019-03-05 13:37:04] [config] word-penalty: 0
[2019-03-05 13:37:04] [config] workspace: 8500
[2019-03-05 13:37:04] [config] Model is being created with Marian v1.7.8 63e1cfe4 2019-02-11 21:04:00 -0800
[2019-03-05 13:37:04] Using synchronous training
[2019-03-05 13:37:04] [data] Loading vocabulary from JSON/Yaml file ../src0tgt0/corp/vocab.encs.europarl.yml
[2019-03-05 13:37:04] [data] Setting vocabulary size for input 0 to 32000
[2019-03-05 13:37:04] [data] Loading vocabulary from JSON/Yaml file ../src0tgt0/corp/vocab.encs.europarl.yml
[2019-03-05 13:37:04] [data] Setting vocabulary size for input 1 to 32000
[2019-03-05 13:37:04] [data] Loading vocabulary from JSON/Yaml file ../src0tgt0/corp/vocab.encs.europarl.yml
[2019-03-05 13:37:04] [data] Setting vocabulary size for input 2 to 32000
[2019-03-05 13:37:04] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-03-05 13:37:04] [batching] Collecting statistics for batch fitting with step size 10
[2019-03-05 13:37:05] [memory] Extending reserved space to 8576 MB (device gpu0)
[2019-03-05 13:37:06] [comm] Using NCCL 2.4.2 for GPU communication
[2019-03-05 13:37:06] [comm] NCCLCommunicator constructed successfully.
[2019-03-05 13:37:06] [training] Using 1 GPUs
[2019-03-05 13:37:06] [memory] Reserving 315 MB, device gpu0
[2019-03-05 13:37:07] [memory] Reserving 315 MB, device gpu0
[2019-03-05 13:37:15] [batching] Done. Typical MB size is 33230 target words
[2019-03-05 13:37:15] [memory] Extending reserved space to 8576 MB (device gpu0)
[2019-03-05 13:37:15] [comm] Using NCCL 2.4.2 for GPU communication
[2019-03-05 13:37:15] [comm] NCCLCommunicator constructed successfully.
[2019-03-05 13:37:15] [training] Using 1 GPUs
[2019-03-05 13:37:15] [training] Initializing model weights with the pre-trained model ../src0tgt0/model.src0tgt0.trans3.iter110000.npz
[2019-03-05 13:37:15] Loading model from ../src0tgt0/model.src0tgt0.trans3.iter110000.npz
[2019-03-05 13:37:17] Training started
[2019-03-05 13:37:17] [data] Shuffling data
[2019-03-05 13:37:17] [data] Done reading 620637 sentences
[2019-03-05 13:37:20] [data] Done shuffling 620637 sentences to temp files
[2019-03-05 13:37:41] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-03-05 13:37:41] [memory] Reserving 387 MB, device gpu0
[2019-03-05 13:37:41] [memory] Reserving 387 MB, device gpu0
[2019-03-05 13:37:41] [memory] Reserving 387 MB, device gpu0
[2019-03-05 13:37:43] [memory] Reserving 774 MB, device gpu0
[2019-03-05 13:48:54] Ep. 1 : Up. 500 : Sen. 239,689 : Cost 263.20169067 : Time 709.74s : 10178.06 words/s : L.r. 9.3750e-06
[2019-03-05 13:59:46] Ep. 1 : Up. 1000 : Sen. 482,796 : Cost 228.20341492 : Time 651.94s : 10575.61 words/s : L.r. 1.8750e-05
[2019-03-05 14:05:21] Seen 601324 samples
[2019-03-05 14:05:21] Starting epoch 2
[2019-03-05 14:05:21] [data] Shuffling data
[2019-03-05 14:05:21] [data] Done reading 620637 sentences
[2019-03-05 14:05:23] [data] Done shuffling 620637 sentences to temp files
[2019-03-05 14:11:26] Ep. 2 : Up. 1500 : Sen. 126,326 : Cost 235.10241699 : Time 700.20s : 10300.62 words/s : L.r. 2.8125e-05
[2019-03-05 14:22:37] Ep. 2 : Up. 2000 : Sen. 369,195 : Cost 233.42561340 : Time 670.43s : 10650.10 words/s : L.r. 3.7500e-05
[2019-03-05 14:33:32] Seen 601324 samples
[2019-03-05 14:33:32] Starting epoch 3
[2019-03-05 14:33:32] [data] Shuffling data
[2019-03-05 14:33:32] [data] Done reading 620637 sentences
[2019-03-05 14:33:35] [data] Done shuffling 620637 sentences to temp files
[2019-03-05 14:34:16] Ep. 3 : Up. 2500 : Sen. 7,742 : Cost 238.06616211 : Time 699.84s : 10299.25 words/s : L.r. 4.6875e-05
[2019-03-05 14:45:14] Ep. 3 : Up. 3000 : Sen. 254,267 : Cost 222.01771545 : Time 657.99s : 10575.42 words/s : L.r. 5.6250e-05
[2019-03-05 14:56:39] Ep. 3 : Up. 3500 : Sen. 491,247 : Cost 242.83401489 : Time 684.05s : 10712.79 words/s : L.r. 6.5625e-05
[2019-03-05 15:01:44] Seen 601324 samples
[2019-03-05 15:01:44] Starting epoch 4
[2019-03-05 15:01:44] [data] Shuffling data
[2019-03-05 15:01:44] [data] Done reading 620637 sentences
[2019-03-05 15:01:47] [data] Done shuffling 620637 sentences to temp files
[2019-03-05 15:08:01] Ep. 4 : Up. 4000 : Sen. 133,154 : Cost 223.51423645 : Time 682.45s : 10202.94 words/s : L.r. 7.5000e-05
[2019-03-05 15:19:26] Ep. 4 : Up. 4500 : Sen. 376,884 : Cost 235.00393677 : Time 685.37s : 10714.38 words/s : L.r. 8.4375e-05
[2019-03-05 15:29:55] Seen 601324 samples
[2019-03-05 15:29:55] Starting epoch 5
[2019-03-05 15:29:55] [data] Shuffling data
[2019-03-05 15:29:55] [data] Done reading 620637 sentences
[2019-03-05 15:29:58] [data] Done shuffling 620637 sentences to temp files
[2019-03-05 15:31:02] Ep. 5 : Up. 5000 : Sen. 15,395 : Cost 230.84965515 : Time 695.71s : 10227.25 words/s : L.r. 9.3750e-05
[2019-03-05 15:31:02] Saving model weights and runtime parameters to model/model.src1tgt0.dual.doc.same_embedding.gate_really.notc.pretrained.len80.npz.orig.npz
[2019-03-05 15:31:09] Saving model weights and runtime parameters to model/model.src1tgt0.dual.doc.same_embedding.gate_really.notc.pretrained.len80.npz
[2019-03-05 15:31:16] Saving Adam parameters to model/model.src1tgt0.dual.doc.same_embedding.gate_really.notc.pretrained.len80.npz.optimizer.npz
[2019-03-05 15:31:40] Saving model weights and runtime parameters to model/model.src1tgt0.dual.doc.same_embedding.gate_really.notc.pretrained.len80.npz.best-cross-entropy.npz
[2019-03-05 15:31:46] [valid] Ep. 5 : Up. 5000 : cross-entropy : 273.809 : new best
[2019-03-05 15:31:57] Saving model weights and runtime parameters to model/model.src1tgt0.dual.doc.same_embedding.gate_really.notc.pretrained.len80.npz.best-perplexity.npz
[2019-03-05 15:32:03] [valid] Ep. 5 : Up. 5000 : perplexity : 6940.23 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-03-05 16:00:42] Saving model weights and runtime parameters to model/model.src1tgt0.dual.doc.same_embedding.gate_really.notc.pretrained.len80.npz.best-translation.npz
[2019-03-05 16:00:51] [valid] Ep. 5 : Up. 5000 : translation : 0 : new best
[2019-03-05 16:12:10] Ep. 5 : Up. 5500 : Sen. 259,684 : Cost 229.87379456 : Time 2467.67s : 2932.48 words/s : L.r. 1.0313e-04
[2019-03-05 16:23:19] Ep. 5 : Up. 6000 : Sen. 500,213 : Cost 228.85408020 : Time 669.65s : 10613.53 words/s : L.r. 1.1250e-04
[2019-03-05 16:27:57] Seen 601324 samples
[2019-03-05 16:27:57] Starting epoch 6
[2019-03-05 16:27:57] [data] Shuffling data
[2019-03-05 16:27:58] [data] Done reading 620637 sentences
[2019-03-05 16:28:00] [data] Done shuffling 620637 sentences to temp files
[2019-03-05 16:34:59] Ep. 6 : Up. 6500 : Sen. 139,318 : Cost 232.35685730 : Time 699.83s : 10310.67 words/s : L.r. 1.2188e-04
[2019-03-05 16:45:56] Ep. 6 : Up. 7000 : Sen. 380,672 : Cost 221.58897400 : Time 656.44s : 10553.51 words/s : L.r. 1.3125e-04
[2019-03-05 16:56:08] Seen 601324 samples
[2019-03-05 16:56:08] Starting epoch 7
[2019-03-05 16:56:08] [data] Shuffling data
[2019-03-05 16:56:09] [data] Done reading 620637 sentences
[2019-03-05 16:56:11] [data] Done shuffling 620637 sentences to temp files
[2019-03-05 16:57:35] Ep. 7 : Up. 7500 : Sen. 21,723 : Cost 229.22224426 : Time 699.30s : 10287.84 words/s : L.r. 1.4063e-04
[2019-03-05 17:08:44] Ep. 7 : Up. 8000 : Sen. 267,047 : Cost 222.71624756 : Time 668.58s : 10615.40 words/s : L.r. 1.5000e-04
[2019-03-05 17:19:46] Ep. 7 : Up. 8500 : Sen. 504,565 : Cost 228.79450989 : Time 662.43s : 10643.72 words/s : L.r. 1.5938e-04
[2019-03-05 17:24:19] Seen 601324 samples
[2019-03-05 17:24:19] Starting epoch 8
[2019-03-05 17:24:19] [data] Shuffling data
[2019-03-05 17:24:19] [data] Done reading 620637 sentences
[2019-03-05 17:24:21] [data] Done shuffling 620637 sentences to temp files
[2019-03-05 17:31:35] Ep. 8 : Up. 9000 : Sen. 145,611 : Cost 231.90908813 : Time 708.81s : 10307.22 words/s : L.r. 1.6875e-04
[2019-03-05 17:42:38] Ep. 8 : Up. 9500 : Sen. 386,949 : Cost 224.06109619 : Time 663.48s : 10603.08 words/s : L.r. 1.7813e-04
[2019-03-05 17:52:31] Seen 601324 samples
[2019-03-05 17:52:31] Starting epoch 9
[2019-03-05 17:52:31] [data] Shuffling data
[2019-03-05 17:52:32] [data] Done reading 620637 sentences
[2019-03-05 17:52:34] [data] Done shuffling 620637 sentences to temp files
[2019-03-05 17:54:24] Ep. 9 : Up. 10000 : Sen. 29,316 : Cost 229.33230591 : Time 705.84s : 10315.00 words/s : L.r. 1.8750e-04
[2019-03-05 17:54:24] Saving model weights and runtime parameters to model/model.src1tgt0.dual.doc.same_embedding.gate_really.notc.pretrained.len80.npz.orig.npz
[2019-03-05 17:54:30] Saving model weights and runtime parameters to model/model.src1tgt0.dual.doc.same_embedding.gate_really.notc.pretrained.len80.npz
[2019-03-05 17:54:37] Saving Adam parameters to model/model.src1tgt0.dual.doc.same_embedding.gate_really.notc.pretrained.len80.npz.optimizer.npz
[2019-03-05 17:55:00] Saving model weights and runtime parameters to model/model.src1tgt0.dual.doc.same_embedding.gate_really.notc.pretrained.len80.npz.best-cross-entropy.npz
[2019-03-05 17:55:06] [valid] Ep. 9 : Up. 10000 : cross-entropy : 269.306 : new best
[2019-03-05 17:55:18] Saving model weights and runtime parameters to model/model.src1tgt0.dual.doc.same_embedding.gate_really.notc.pretrained.len80.npz.best-perplexity.npz
[2019-03-05 17:55:24] [valid] Ep. 9 : Up. 10000 : perplexity : 6000.59 : new best
train_trans_dual_doc_gate_pretrained.sh: řádek 27: 29606 Ukončen (SIGTERM)      $marian_home/marian --model model/model.src1tgt0.dual.doc.same_embedding.gate_really.notc.pretrained.len80.npz --pretrained-model ../src0tgt0/model.src0tgt0.trans3.iter110000.npz --type transformer-context --train-sets corp/europarl.cs-en.docs.train.en.bpe.src_prev corp/europarl.cs-en.docs.train.en.bpe.src corp/europarl.cs-en.docs.train.cz.bpe --max-length 80 --dim-vocabs 32000 32000 --vocabs ../src0tgt0/corp/vocab.encs.europarl.yml ../src0tgt0/corp/vocab.encs.europarl.yml ../src0tgt0/corp/vocab.encs.europarl.yml --mini-batch-fit -w 8500 --mini-batch 1000 --maxi-batch 1000 --early-stopping 10 --valid-freq 5000 --save-freq 5000 --disp-freq 500 --valid-metrics cross-entropy perplexity translation --valid-sets corp/europarl.cs-en.docs.dev.en.bpe.src_prev corp/europarl.cs-en.docs.dev.en.bpe.src corp/europarl.cs-en.docs.dev.cz.bpe --valid-script-path ./val.sh --valid-translation-output data/valid.bpe.en.output --quiet-translation --valid-mini-batch 16 --beam-size 6 --normalize 0.6 --log model/train_trans.doc.log --valid-log model/valid_trans.doc.log --enc-depth 6 --dec-depth 6 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --optimizer-delay 8 --devices 0 --sync-sgd --seed 1111 --exponential-smoothing --no-restore-corpus --keep-best --overwrite
