[2019-02-27 15:57:24] [marian] Marian v1.7.8 63e1cfe4 2019-02-11 21:04:00 -0800
[2019-02-27 15:57:24] [marian] Running on cosmas.lingea.cz as process 58709 with command line:
[2019-02-27 15:57:24] [marian] /home/large/data/models/marian/marian-doc/marian-dev/build/marian --model model/model.src1tgt0.doc.gate2.npz --type transformer-context --train-sets corp/europarl.cs-en.docs.train.en.bpe.src_prev corp/europarl.cs-en.docs.train.en.bpe.src corp/europarl.cs-en.docs.train.cz.bpe --max-length 55 --dim-vocabs 30000 30000 --vocabs corp/vocab.encs.europarl.yml corp/vocab.encs.europarl.yml corp/vocab.encs.europarl.yml --mini-batch-fit -w 8900 --mini-batch 1000 --maxi-batch 1000 --early-stopping 10 --valid-freq 5000 --save-freq 5000 --disp-freq 500 --valid-metrics cross-entropy perplexity translation --valid-sets corp/europarl.cs-en.docs.dev.en.bpe.src_prev corp/europarl.cs-en.docs.dev.en.bpe.src corp/europarl.cs-en.docs.dev.cz.bpe --valid-script-path ./val.sh --valid-translation-output data/valid.bpe.en.output --quiet-translation --valid-mini-batch 16 --beam-size 6 --normalize 0.6 --log model/train_trans.doc.log --valid-log model/valid_trans.doc.log --enc-depth 6 --dec-depth 6 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --optimizer-delay 2 --devices 0 --sync-sgd --seed 1111 --exponential-smoothing --no-restore-corpus --no-nccl
[2019-02-27 15:57:24] [config] after-batches: 0
[2019-02-27 15:57:24] [config] after-epochs: 0
[2019-02-27 15:57:24] [config] allow-unk: false
[2019-02-27 15:57:24] [config] beam-size: 6
[2019-02-27 15:57:24] [config] bert-class-symbol: "[CLS]"
[2019-02-27 15:57:24] [config] bert-mask-symbol: "[MASK]"
[2019-02-27 15:57:24] [config] bert-masking-fraction: 0.15
[2019-02-27 15:57:24] [config] bert-sep-symbol: "[SEP]"
[2019-02-27 15:57:24] [config] bert-train-type-embeddings: true
[2019-02-27 15:57:24] [config] bert-type-vocab-size: 2
[2019-02-27 15:57:24] [config] best-deep: false
[2019-02-27 15:57:24] [config] clip-gemm: 0
[2019-02-27 15:57:24] [config] clip-norm: 5
[2019-02-27 15:57:24] [config] cost-type: ce-mean
[2019-02-27 15:57:24] [config] cpu-threads: 0
[2019-02-27 15:57:24] [config] data-weighting: ""
[2019-02-27 15:57:24] [config] data-weighting-type: sentence
[2019-02-27 15:57:24] [config] dec-cell: gru
[2019-02-27 15:57:24] [config] dec-cell-base-depth: 2
[2019-02-27 15:57:24] [config] dec-cell-high-depth: 1
[2019-02-27 15:57:24] [config] dec-depth: 6
[2019-02-27 15:57:24] [config] devices:
[2019-02-27 15:57:24] [config]   - 0
[2019-02-27 15:57:24] [config] dim-emb: 512
[2019-02-27 15:57:24] [config] dim-rnn: 1024
[2019-02-27 15:57:24] [config] dim-vocabs:
[2019-02-27 15:57:24] [config]   - 30000
[2019-02-27 15:57:24] [config]   - 30000
[2019-02-27 15:57:24] [config] disp-first: 0
[2019-02-27 15:57:24] [config] disp-freq: 500
[2019-02-27 15:57:24] [config] disp-label-counts: false
[2019-02-27 15:57:24] [config] dropout-rnn: 0
[2019-02-27 15:57:24] [config] dropout-src: 0
[2019-02-27 15:57:24] [config] dropout-trg: 0
[2019-02-27 15:57:24] [config] dump-config: ""
[2019-02-27 15:57:24] [config] early-stopping: 10
[2019-02-27 15:57:24] [config] embedding-fix-src: false
[2019-02-27 15:57:24] [config] embedding-fix-trg: false
[2019-02-27 15:57:24] [config] embedding-normalization: false
[2019-02-27 15:57:24] [config] embedding-vectors:
[2019-02-27 15:57:24] [config]   []
[2019-02-27 15:57:24] [config] enc-cell: gru
[2019-02-27 15:57:24] [config] enc-cell-depth: 1
[2019-02-27 15:57:24] [config] enc-depth: 6
[2019-02-27 15:57:24] [config] enc-type: bidirectional
[2019-02-27 15:57:24] [config] exponential-smoothing: 0.0001
[2019-02-27 15:57:24] [config] grad-dropping-momentum: 0
[2019-02-27 15:57:24] [config] grad-dropping-rate: 0
[2019-02-27 15:57:24] [config] grad-dropping-warmup: 100
[2019-02-27 15:57:24] [config] guided-alignment: none
[2019-02-27 15:57:24] [config] guided-alignment-cost: mse
[2019-02-27 15:57:24] [config] guided-alignment-weight: 0.1
[2019-02-27 15:57:24] [config] ignore-model-config: false
[2019-02-27 15:57:24] [config] input-types:
[2019-02-27 15:57:24] [config]   []
[2019-02-27 15:57:24] [config] interpolate-env-vars: false
[2019-02-27 15:57:24] [config] keep-best: false
[2019-02-27 15:57:24] [config] label-smoothing: 0.1
[2019-02-27 15:57:24] [config] layer-normalization: false
[2019-02-27 15:57:24] [config] learn-rate: 0.0003
[2019-02-27 15:57:24] [config] log: model/train_trans.doc.log
[2019-02-27 15:57:24] [config] log-level: info
[2019-02-27 15:57:24] [config] log-time-zone: ""
[2019-02-27 15:57:24] [config] lr-decay: 0
[2019-02-27 15:57:24] [config] lr-decay-freq: 50000
[2019-02-27 15:57:24] [config] lr-decay-inv-sqrt:
[2019-02-27 15:57:24] [config]   - 16000
[2019-02-27 15:57:24] [config] lr-decay-repeat-warmup: false
[2019-02-27 15:57:24] [config] lr-decay-reset-optimizer: false
[2019-02-27 15:57:24] [config] lr-decay-start:
[2019-02-27 15:57:24] [config]   - 10
[2019-02-27 15:57:24] [config]   - 1
[2019-02-27 15:57:24] [config] lr-decay-strategy: epoch+stalled
[2019-02-27 15:57:24] [config] lr-report: true
[2019-02-27 15:57:24] [config] lr-warmup: 16000
[2019-02-27 15:57:24] [config] lr-warmup-at-reload: false
[2019-02-27 15:57:24] [config] lr-warmup-cycle: false
[2019-02-27 15:57:24] [config] lr-warmup-start-rate: 0
[2019-02-27 15:57:24] [config] max-length: 55
[2019-02-27 15:57:24] [config] max-length-crop: false
[2019-02-27 15:57:24] [config] max-length-factor: 3
[2019-02-27 15:57:24] [config] maxi-batch: 1000
[2019-02-27 15:57:24] [config] maxi-batch-sort: trg
[2019-02-27 15:57:24] [config] mini-batch: 1000
[2019-02-27 15:57:24] [config] mini-batch-fit: true
[2019-02-27 15:57:24] [config] mini-batch-fit-step: 10
[2019-02-27 15:57:24] [config] mini-batch-overstuff: 1
[2019-02-27 15:57:24] [config] mini-batch-track-lr: false
[2019-02-27 15:57:24] [config] mini-batch-understuff: 1
[2019-02-27 15:57:24] [config] mini-batch-warmup: 0
[2019-02-27 15:57:24] [config] mini-batch-words: 0
[2019-02-27 15:57:24] [config] mini-batch-words-ref: 0
[2019-02-27 15:57:24] [config] model: model/model.src1tgt0.doc.gate2.npz
[2019-02-27 15:57:24] [config] multi-loss-type: sum
[2019-02-27 15:57:24] [config] multi-node: false
[2019-02-27 15:57:24] [config] multi-node-overlap: true
[2019-02-27 15:57:24] [config] n-best: false
[2019-02-27 15:57:24] [config] no-nccl: true
[2019-02-27 15:57:24] [config] no-reload: false
[2019-02-27 15:57:24] [config] no-restore-corpus: true
[2019-02-27 15:57:24] [config] no-shuffle: false
[2019-02-27 15:57:24] [config] normalize: 0.6
[2019-02-27 15:57:24] [config] num-devices: 0
[2019-02-27 15:57:24] [config] optimizer: adam
[2019-02-27 15:57:24] [config] optimizer-delay: 2
[2019-02-27 15:57:24] [config] optimizer-params:
[2019-02-27 15:57:24] [config]   - 0.9
[2019-02-27 15:57:24] [config]   - 0.98
[2019-02-27 15:57:24] [config]   - 1e-09
[2019-02-27 15:57:24] [config] overwrite: false
[2019-02-27 15:57:24] [config] pretrained-model: ""
[2019-02-27 15:57:24] [config] quiet: false
[2019-02-27 15:57:24] [config] quiet-translation: true
[2019-02-27 15:57:24] [config] relative-paths: false
[2019-02-27 15:57:24] [config] right-left: false
[2019-02-27 15:57:24] [config] save-freq: 5000
[2019-02-27 15:57:24] [config] seed: 1111
[2019-02-27 15:57:24] [config] shuffle-in-ram: false
[2019-02-27 15:57:24] [config] skip: false
[2019-02-27 15:57:24] [config] sqlite: ""
[2019-02-27 15:57:24] [config] sqlite-drop: false
[2019-02-27 15:57:24] [config] sync-sgd: true
[2019-02-27 15:57:24] [config] tempdir: /tmp
[2019-02-27 15:57:24] [config] tied-embeddings: false
[2019-02-27 15:57:24] [config] tied-embeddings-all: true
[2019-02-27 15:57:24] [config] tied-embeddings-src: false
[2019-02-27 15:57:24] [config] train-sets:
[2019-02-27 15:57:24] [config]   - corp/europarl.cs-en.docs.train.en.bpe.src_prev
[2019-02-27 15:57:24] [config]   - corp/europarl.cs-en.docs.train.en.bpe.src
[2019-02-27 15:57:24] [config]   - corp/europarl.cs-en.docs.train.cz.bpe
[2019-02-27 15:57:24] [config] transformer-aan-activation: swish
[2019-02-27 15:57:24] [config] transformer-aan-depth: 2
[2019-02-27 15:57:24] [config] transformer-aan-nogate: false
[2019-02-27 15:57:24] [config] transformer-decoder-autoreg: self-attention
[2019-02-27 15:57:24] [config] transformer-dim-aan: 2048
[2019-02-27 15:57:24] [config] transformer-dim-ffn: 2048
[2019-02-27 15:57:24] [config] transformer-dropout: 0.1
[2019-02-27 15:57:24] [config] transformer-dropout-attention: 0
[2019-02-27 15:57:24] [config] transformer-dropout-ffn: 0
[2019-02-27 15:57:24] [config] transformer-ffn-activation: swish
[2019-02-27 15:57:24] [config] transformer-ffn-depth: 2
[2019-02-27 15:57:24] [config] transformer-guided-alignment-layer: last
[2019-02-27 15:57:24] [config] transformer-heads: 8
[2019-02-27 15:57:24] [config] transformer-no-projection: false
[2019-02-27 15:57:24] [config] transformer-postprocess: dan
[2019-02-27 15:57:24] [config] transformer-postprocess-emb: d
[2019-02-27 15:57:24] [config] transformer-preprocess: ""
[2019-02-27 15:57:24] [config] transformer-tied-layers:
[2019-02-27 15:57:24] [config]   []
[2019-02-27 15:57:24] [config] transformer-train-position-embeddings: false
[2019-02-27 15:57:24] [config] type: transformer-context
[2019-02-27 15:57:24] [config] ulr: false
[2019-02-27 15:57:24] [config] ulr-dim-emb: 0
[2019-02-27 15:57:24] [config] ulr-dropout: 0
[2019-02-27 15:57:24] [config] ulr-keys-vectors: ""
[2019-02-27 15:57:24] [config] ulr-query-vectors: ""
[2019-02-27 15:57:24] [config] ulr-softmax-temperature: 1
[2019-02-27 15:57:24] [config] ulr-trainable-transformation: false
[2019-02-27 15:57:24] [config] valid-freq: 5000
[2019-02-27 15:57:24] [config] valid-log: model/valid_trans.doc.log
[2019-02-27 15:57:24] [config] valid-max-length: 1000
[2019-02-27 15:57:24] [config] valid-metrics:
[2019-02-27 15:57:24] [config]   - cross-entropy
[2019-02-27 15:57:24] [config]   - perplexity
[2019-02-27 15:57:24] [config]   - translation
[2019-02-27 15:57:24] [config] valid-mini-batch: 16
[2019-02-27 15:57:24] [config] valid-script-path: ./val.sh
[2019-02-27 15:57:24] [config] valid-sets:
[2019-02-27 15:57:24] [config]   - corp/europarl.cs-en.docs.dev.en.bpe.src_prev
[2019-02-27 15:57:24] [config]   - corp/europarl.cs-en.docs.dev.en.bpe.src
[2019-02-27 15:57:24] [config]   - corp/europarl.cs-en.docs.dev.cz.bpe
[2019-02-27 15:57:24] [config] valid-translation-output: data/valid.bpe.en.output
[2019-02-27 15:57:24] [config] vocabs:
[2019-02-27 15:57:24] [config]   - corp/vocab.encs.europarl.yml
[2019-02-27 15:57:24] [config]   - corp/vocab.encs.europarl.yml
[2019-02-27 15:57:24] [config]   - corp/vocab.encs.europarl.yml
[2019-02-27 15:57:24] [config] word-penalty: 0
[2019-02-27 15:57:24] [config] workspace: 8900
[2019-02-27 15:57:24] [config] Model is being created with Marian v1.7.8 63e1cfe4 2019-02-11 21:04:00 -0800
[2019-02-27 15:57:24] Using synchronous training
[2019-02-27 15:57:24] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.europarl.yml
[2019-02-27 15:57:24] [data] Setting vocabulary size for input 0 to 30000
[2019-02-27 15:57:24] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.europarl.yml
[2019-02-27 15:57:24] [data] Setting vocabulary size for input 1 to 30000
[2019-02-27 15:57:24] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.europarl.yml
[2019-02-27 15:57:24] [data] Setting vocabulary size for input 2 to 30000
[2019-02-27 15:57:24] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-02-27 15:57:24] [batching] Collecting statistics for batch fitting with step size 10
[2019-02-27 15:57:26] [memory] Extending reserved space to 8960 MB (device gpu0)
[2019-02-27 15:57:26] [comm] NCCL communicator overridden
[2019-02-27 15:57:26] [training] Using 1 GPUs
[2019-02-27 15:57:26] [memory] Reserving 313 MB, device gpu0
[2019-02-27 15:57:26] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-02-27 15:57:26] [memory] Reserving 313 MB, device gpu0
[2019-02-27 15:57:36] [batching] Done. Typical MB size is 9203 target words
[2019-02-27 15:57:36] [memory] Extending reserved space to 8960 MB (device gpu0)
[2019-02-27 15:57:37] [comm] NCCL communicator overridden
[2019-02-27 15:57:37] [training] Using 1 GPUs
[2019-02-27 15:57:37] Training started
[2019-02-27 15:57:37] [data] Shuffling data
[2019-02-27 15:57:37] [data] Done reading 620637 sentences
[2019-02-27 15:57:39] [data] Done shuffling 620637 sentences to temp files
[2019-02-27 15:57:59] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-02-27 15:57:59] [memory] Reserving 313 MB, device gpu0
[2019-02-27 15:57:59] [memory] Reserving 313 MB, device gpu0
[2019-02-27 15:57:59] [memory] Reserving 313 MB, device gpu0
[2019-02-27 15:58:00] [memory] Reserving 313 MB, device gpu0
[2019-02-27 15:58:00] [memory] Reserving 626 MB, device gpu0
[2019-02-27 16:03:03] Ep. 1 : Up. 500 : Sen. 98,087 : Cost 253.66064453 : Time 339.02s : 7685.97 words/s : L.r. 9.3750e-06
[2019-02-27 16:07:57] Ep. 1 : Up. 1000 : Sen. 195,070 : Cost 213.98233032 : Time 294.06s : 8620.63 words/s : L.r. 1.8750e-05
[2019-02-27 16:12:54] Ep. 1 : Up. 1500 : Sen. 290,735 : Cost 213.82510376 : Time 296.69s : 8679.43 words/s : L.r. 2.8125e-05
[2019-02-27 16:17:54] Ep. 1 : Up. 2000 : Sen. 388,158 : Cost 213.26751709 : Time 299.50s : 8737.56 words/s : L.r. 3.7500e-05
[2019-02-27 16:22:49] Ep. 1 : Up. 2500 : Sen. 487,096 : Cost 205.40878296 : Time 295.06s : 8682.80 words/s : L.r. 4.6875e-05
[2019-02-27 16:24:14] Seen 515211 samples
[2019-02-27 16:24:14] Starting epoch 2
[2019-02-27 16:24:14] [data] Shuffling data
[2019-02-27 16:24:15] [data] Done reading 620637 sentences
[2019-02-27 16:24:17] [data] Done shuffling 620637 sentences to temp files
[2019-02-27 16:28:08] Ep. 2 : Up. 3000 : Sen. 69,386 : Cost 209.82528687 : Time 319.55s : 8072.64 words/s : L.r. 5.6250e-05
[2019-02-27 16:33:06] Ep. 2 : Up. 3500 : Sen. 166,009 : Cost 211.49482727 : Time 298.23s : 8645.84 words/s : L.r. 6.5625e-05
[2019-02-27 16:37:59] Ep. 2 : Up. 4000 : Sen. 264,279 : Cost 203.39517212 : Time 292.43s : 8649.92 words/s : L.r. 7.5000e-05
[2019-02-27 16:43:03] Ep. 2 : Up. 4500 : Sen. 360,826 : Cost 218.17945862 : Time 304.02s : 8792.34 words/s : L.r. 8.4375e-05
[2019-02-27 16:47:59] Ep. 2 : Up. 5000 : Sen. 459,144 : Cost 204.81315613 : Time 296.02s : 8673.98 words/s : L.r. 9.3750e-05
[2019-02-27 16:47:59] Saving model weights and runtime parameters to model/model.src1tgt0.doc.gate2.npz.orig.npz
[2019-02-27 16:48:00] Saving model weights and runtime parameters to model/model.src1tgt0.doc.gate2.iter5000.npz
[2019-02-27 16:48:01] Saving model weights and runtime parameters to model/model.src1tgt0.doc.gate2.npz
[2019-02-27 16:48:02] Saving Adam parameters to model/model.src1tgt0.doc.gate2.npz.optimizer.npz
[2019-02-27 16:48:18] [valid] Ep. 2 : Up. 5000 : cross-entropy : 244.212 : new best
[2019-02-27 16:48:32] [valid] Ep. 2 : Up. 5000 : perplexity : 2667.75 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-02-27 17:18:11] [valid] Ep. 2 : Up. 5000 : translation : 0 : new best
[2019-02-27 17:21:00] Seen 515211 samples
[2019-02-27 17:21:00] Starting epoch 3
[2019-02-27 17:21:00] [data] Shuffling data
[2019-02-27 17:21:00] [data] Done reading 620637 sentences
[2019-02-27 17:21:02] [data] Done shuffling 620637 sentences to temp files
[2019-02-27 17:23:28] Ep. 3 : Up. 5500 : Sen. 41,375 : Cost 206.91690063 : Time 2129.55s : 1209.96 words/s : L.r. 1.0313e-04
[2019-02-27 17:28:31] Ep. 3 : Up. 6000 : Sen. 141,453 : Cost 205.39497375 : Time 302.98s : 8695.22 words/s : L.r. 1.1250e-04
[2019-02-27 17:33:28] Ep. 3 : Up. 6500 : Sen. 239,247 : Cost 205.75616455 : Time 296.60s : 8708.36 words/s : L.r. 1.2188e-04
[2019-02-27 17:38:21] Ep. 3 : Up. 7000 : Sen. 336,631 : Cost 203.57888794 : Time 292.86s : 8698.19 words/s : L.r. 1.3125e-04
[2019-02-27 17:43:13] Ep. 3 : Up. 7500 : Sen. 433,159 : Cost 204.21327209 : Time 292.30s : 8676.89 words/s : L.r. 1.4063e-04
[2019-02-27 17:47:28] Seen 515211 samples
[2019-02-27 17:47:28] Starting epoch 4
[2019-02-27 17:47:28] [data] Shuffling data
[2019-02-27 17:47:28] [data] Done reading 620637 sentences
[2019-02-27 17:47:30] [data] Done shuffling 620637 sentences to temp files
[2019-02-27 17:48:30] Ep. 4 : Up. 8000 : Sen. 13,694 : Cost 209.98744202 : Time 316.73s : 8172.76 words/s : L.r. 1.5000e-04
[2019-02-27 17:53:35] Ep. 4 : Up. 8500 : Sen. 110,758 : Cost 211.21308899 : Time 304.97s : 8669.22 words/s : L.r. 1.5938e-04
[2019-02-27 17:58:29] Ep. 4 : Up. 9000 : Sen. 207,744 : Cost 205.06924438 : Time 294.52s : 8719.28 words/s : L.r. 1.6875e-04
[2019-02-27 18:03:24] Ep. 4 : Up. 9500 : Sen. 307,128 : Cost 199.75340271 : Time 294.44s : 8728.43 words/s : L.r. 1.7813e-04
[2019-02-27 18:08:14] Ep. 4 : Up. 10000 : Sen. 403,276 : Cost 202.20758057 : Time 289.68s : 8697.81 words/s : L.r. 1.8750e-04
[2019-02-27 18:08:14] Saving model weights and runtime parameters to model/model.src1tgt0.doc.gate2.npz.orig.npz
[2019-02-27 18:08:15] Saving model weights and runtime parameters to model/model.src1tgt0.doc.gate2.iter10000.npz
[2019-02-27 18:08:16] Saving model weights and runtime parameters to model/model.src1tgt0.doc.gate2.npz
[2019-02-27 18:08:18] Saving Adam parameters to model/model.src1tgt0.doc.gate2.npz.optimizer.npz
[2019-02-27 18:08:35] [valid] Ep. 4 : Up. 10000 : cross-entropy : 272.739 : stalled 1 times (last best: 244.212)
[2019-02-27 18:08:49] [valid] Ep. 4 : Up. 10000 : perplexity : 6704.49 : stalled 1 times (last best: 2667.75)
Detokenizer Version $Revision: 4134 $
Language: en
[2019-02-27 18:38:28] [valid] Ep. 4 : Up. 10000 : translation : 0 : stalled 1 times (last best: 0)
[2019-02-27 18:43:28] Ep. 4 : Up. 10500 : Sen. 501,926 : Cost 203.59683228 : Time 2114.51s : 1230.77 words/s : L.r. 1.9688e-04
[2019-02-27 18:44:12] Seen 515211 samples
[2019-02-27 18:44:12] Starting epoch 5
[2019-02-27 18:44:12] [data] Shuffling data
[2019-02-27 18:44:13] [data] Done reading 620637 sentences
[2019-02-27 18:44:15] [data] Done shuffling 620637 sentences to temp files
[2019-02-27 18:48:51] Ep. 5 : Up. 11000 : Sen. 85,899 : Cost 202.00120544 : Time 322.85s : 8059.93 words/s : L.r. 2.0625e-04
[2019-02-27 18:53:44] Ep. 5 : Up. 11500 : Sen. 184,878 : Cost 197.85305786 : Time 293.48s : 8684.57 words/s : L.r. 2.1563e-04
[2019-02-27 18:58:40] Ep. 5 : Up. 12000 : Sen. 281,393 : Cost 206.37034607 : Time 295.69s : 8753.57 words/s : L.r. 2.2500e-04
[2019-02-27 19:03:39] Ep. 5 : Up. 12500 : Sen. 377,565 : Cost 209.43191528 : Time 298.54s : 8764.09 words/s : L.r. 2.3438e-04
[2019-02-27 19:08:29] Ep. 5 : Up. 13000 : Sen. 473,206 : Cost 203.06359863 : Time 290.62s : 8692.55 words/s : L.r. 2.4375e-04
[2019-02-27 19:10:39] Seen 515211 samples
[2019-02-27 19:10:39] Starting epoch 6
[2019-02-27 19:10:39] [data] Shuffling data
[2019-02-27 19:10:40] [data] Done reading 620637 sentences
[2019-02-27 19:10:42] [data] Done shuffling 620637 sentences to temp files
[2019-02-27 19:13:47] Ep. 6 : Up. 13500 : Sen. 54,080 : Cost 204.94544983 : Time 317.44s : 8078.11 words/s : L.r. 2.5313e-04
[2019-02-27 19:18:49] Ep. 6 : Up. 14000 : Sen. 148,890 : Cost 213.19294739 : Time 301.80s : 8726.69 words/s : L.r. 2.6250e-04
[2019-02-27 19:23:48] Ep. 6 : Up. 14500 : Sen. 248,611 : Cost 202.86566162 : Time 299.67s : 8795.99 words/s : L.r. 2.7188e-04
[2019-02-27 19:28:47] Ep. 6 : Up. 15000 : Sen. 350,672 : Cost 195.95596313 : Time 298.98s : 8734.52 words/s : L.r. 2.8125e-04
[2019-02-27 19:28:47] Saving model weights and runtime parameters to model/model.src1tgt0.doc.gate2.npz.orig.npz
[2019-02-27 19:28:49] Saving model weights and runtime parameters to model/model.src1tgt0.doc.gate2.iter15000.npz
[2019-02-27 19:28:50] Saving model weights and runtime parameters to model/model.src1tgt0.doc.gate2.npz
[2019-02-27 19:28:51] Saving Adam parameters to model/model.src1tgt0.doc.gate2.npz.optimizer.npz
[2019-02-27 19:29:08] [valid] Ep. 6 : Up. 15000 : cross-entropy : 266.065 : stalled 2 times (last best: 244.212)
[2019-02-27 19:29:22] [valid] Ep. 6 : Up. 15000 : perplexity : 5404.1 : stalled 2 times (last best: 2667.75)
Detokenizer Version $Revision: 4134 $
Language: en
[2019-02-27 19:58:59] [valid] Ep. 6 : Up. 15000 : translation : 0 : stalled 2 times (last best: 0)
[2019-02-27 20:03:51] Ep. 6 : Up. 15500 : Sen. 445,652 : Cost 204.47906494 : Time 2104.05s : 1203.99 words/s : L.r. 2.9063e-04
[2019-02-27 20:07:20] Seen 515211 samples
[2019-02-27 20:07:20] Starting epoch 7
[2019-02-27 20:07:20] [data] Shuffling data
[2019-02-27 20:07:21] [data] Done reading 620637 sentences
[2019-02-27 20:07:23] [data] Done shuffling 620637 sentences to temp files
[2019-02-27 20:09:06] Ep. 7 : Up. 16000 : Sen. 26,339 : Cost 202.90736389 : Time 314.30s : 8079.91 words/s : L.r. 3.0000e-04
[2019-02-27 20:14:00] Ep. 7 : Up. 16500 : Sen. 122,180 : Cost 201.75137329 : Time 294.00s : 8609.41 words/s : L.r. 2.9542e-04
[2019-02-27 20:18:54] Ep. 7 : Up. 17000 : Sen. 222,472 : Cost 195.43426514 : Time 294.82s : 8703.10 words/s : L.r. 2.9104e-04
[2019-02-27 20:23:47] Ep. 7 : Up. 17500 : Sen. 320,295 : Cost 199.67584229 : Time 293.08s : 8719.23 words/s : L.r. 2.8685e-04
[2019-02-27 20:28:48] Ep. 7 : Up. 18000 : Sen. 419,000 : Cost 204.65957642 : Time 300.15s : 8800.95 words/s : L.r. 2.8284e-04
[2019-02-27 20:33:45] Ep. 7 : Up. 18500 : Sen. 515,073 : Cost 208.84735107 : Time 297.71s : 8805.11 words/s : L.r. 2.7899e-04
[2019-02-27 20:33:46] Seen 515211 samples
[2019-02-27 20:33:46] Starting epoch 8
[2019-02-27 20:33:46] [data] Shuffling data
[2019-02-27 20:33:46] [data] Done reading 620637 sentences
[2019-02-27 20:33:48] [data] Done shuffling 620637 sentences to temp files
[2019-02-27 20:39:09] Ep. 8 : Up. 19000 : Sen. 99,345 : Cost 199.70344543 : Time 324.03s : 8052.71 words/s : L.r. 2.7530e-04
[2019-02-27 20:44:00] Ep. 8 : Up. 19500 : Sen. 191,783 : Cost 207.72380066 : Time 290.61s : 8675.85 words/s : L.r. 2.7175e-04
[2019-02-27 20:48:56] Ep. 8 : Up. 20000 : Sen. 289,411 : Cost 203.40930176 : Time 296.47s : 8786.73 words/s : L.r. 2.6833e-04
[2019-02-27 20:48:56] Saving model weights and runtime parameters to model/model.src1tgt0.doc.gate2.npz.orig.npz
[2019-02-27 20:48:58] Saving model weights and runtime parameters to model/model.src1tgt0.doc.gate2.iter20000.npz
[2019-02-27 20:48:59] Saving model weights and runtime parameters to model/model.src1tgt0.doc.gate2.npz
[2019-02-27 20:49:01] Saving Adam parameters to model/model.src1tgt0.doc.gate2.npz.optimizer.npz
[2019-02-27 20:49:18] [valid] Ep. 8 : Up. 20000 : cross-entropy : 269.373 : stalled 3 times (last best: 244.212)
[2019-02-27 20:49:31] [valid] Ep. 8 : Up. 20000 : perplexity : 6013.66 : stalled 3 times (last best: 2667.75)
Detokenizer Version $Revision: 4134 $
Language: en
[2019-02-27 21:19:29] [valid] Ep. 8 : Up. 20000 : translation : 0 : stalled 3 times (last best: 0)
[2019-02-27 21:24:34] Ep. 8 : Up. 20500 : Sen. 385,468 : Cost 199.71502686 : Time 2137.59s : 1177.98 words/s : L.r. 2.6504e-04
[2019-02-27 21:29:53] Ep. 8 : Up. 21000 : Sen. 485,734 : Cost 201.73400879 : Time 318.63s : 8331.92 words/s : L.r. 2.6186e-04
[2019-02-27 21:31:23] Seen 515211 samples
[2019-02-27 21:31:23] Starting epoch 9
[2019-02-27 21:31:23] [data] Shuffling data
[2019-02-27 21:31:23] [data] Done reading 620637 sentences
[2019-02-27 21:31:25] [data] Done shuffling 620637 sentences to temp files
[2019-02-27 21:35:28] Ep. 9 : Up. 21500 : Sen. 69,729 : Cost 197.50567627 : Time 335.85s : 7685.47 words/s : L.r. 2.5880e-04
[2019-02-27 21:40:43] Ep. 9 : Up. 22000 : Sen. 168,464 : Cost 199.03472900 : Time 314.66s : 8234.21 words/s : L.r. 2.5584e-04
[2019-02-27 21:45:53] Ep. 9 : Up. 22500 : Sen. 262,688 : Cost 205.05715942 : Time 310.18s : 8203.09 words/s : L.r. 2.5298e-04
[2019-02-27 21:51:11] Ep. 9 : Up. 23000 : Sen. 362,065 : Cost 199.18553162 : Time 317.37s : 8209.54 words/s : L.r. 2.5022e-04
[2019-02-27 21:56:27] Ep. 9 : Up. 23500 : Sen. 461,406 : Cost 199.02293396 : Time 316.13s : 8232.15 words/s : L.r. 2.4754e-04
[2019-02-27 21:59:24] Seen 515211 samples
[2019-02-27 21:59:24] Starting epoch 10
[2019-02-27 21:59:24] [data] Shuffling data
[2019-02-27 21:59:24] [data] Done reading 620637 sentences
[2019-02-27 21:59:27] [data] Done shuffling 620637 sentences to temp files
[2019-02-27 22:02:01] Ep. 10 : Up. 24000 : Sen. 41,651 : Cost 204.04393005 : Time 334.50s : 7674.56 words/s : L.r. 2.4495e-04
train_dual_doc.single.gpu.sh: line 27: 58709 Terminated              $marian_home/marian --model model/model.src1tgt0.doc.gate2.npz --type transformer-context --train-sets corp/europarl.cs-en.docs.train.en.bpe.src_prev corp/europarl.cs-en.docs.train.en.bpe.src corp/europarl.cs-en.docs.train.cz.bpe --max-length 55 --dim-vocabs 30000 30000 --vocabs corp/vocab.encs.europarl.yml corp/vocab.encs.europarl.yml corp/vocab.encs.europarl.yml --mini-batch-fit -w 8900 --mini-batch 1000 --maxi-batch 1000 --early-stopping 10 --valid-freq 5000 --save-freq 5000 --disp-freq 500 --valid-metrics cross-entropy perplexity translation --valid-sets corp/europarl.cs-en.docs.dev.en.bpe.src_prev corp/europarl.cs-en.docs.dev.en.bpe.src corp/europarl.cs-en.docs.dev.cz.bpe --valid-script-path ./val.sh --valid-translation-output data/valid.bpe.en.output --quiet-translation --valid-mini-batch 16 --beam-size 6 --normalize 0.6 --log model/train_trans.doc.log --valid-log model/valid_trans.doc.log --enc-depth 6 --dec-depth 6 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --optimizer-delay 2 --devices 0 --sync-sgd --seed 1111 --exponential-smoothing --no-restore-corpus --no-nccl
train_dual_doc.single.gpu.sh: line 29: /home/pepa: Is a directory
train_dual_doc.single.gpu.sh: line 30: /home/pepa: Is a directory
train_dual_doc.single.gpu.sh: line 31: /home/pepa: Is a directory
train_dual_doc.single.gpu.sh: line 32: /home/pepa: Is a directory
