[2019-05-05 12:15:28] [marian] Marian v1.7.8 1fcb013 2019-05-03 03:15:04 +0200
[2019-05-05 12:15:28] [marian] Running on pcknot5 as process 23939 with command line:
[2019-05-05 12:15:28] [marian] /mnt/minerva1/nlp/projects/nmt/doc-marian-new2/doc-marian/build/marian --model model/model.src1tgt0.voita.new.npz --pretrained-model model/model.src1tgt0.docnew.enc_depth.test_base.npz.best-perplexity.npz --type transformer-voita --train-sets corp/europarl.cs-en.docs.train.en.bpe.src_prev corp/europarl.cs-en.docs.train.en.bpe.src corp/europarl.cs-en.docs.train.cz.bpe --max-length 160 --dim-vocabs 30000 30000 --embedding-fix-src --embedding-fix-trg --vocabs corp/vocab.encz.opensub.new.yml corp/vocab.encz.opensub.new.yml corp/vocab.encz.opensub.new.yml --mini-batch-fit -w 7800 --mini-batch 1000 --maxi-batch 1000 --early-stopping 10 --freeze --context-enc-depth 1 --valid-freq 5000 --save-freq 5000 --disp-freq 1000 --valid-metrics cross-entropy perplexity translation --valid-sets corp/europarl.cs-en.docs.dev.en.bpe.src_prev corp/europarl.cs-en.docs.dev.en.bpe.src corp/europarl.cs-en.docs.dev.cz.bpe --valid-script-path ./val.sh --valid-translation-output data/valid.bpe.en.output --quiet-translation --valid-mini-batch 16 --keep-best --beam-size 6 --normalize 0.6 --log model/train_trans.gate.log --valid-log model/valid_trans.gate.log --enc-depth 6 --dec-depth 6 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0001 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --optimizer-delay 4 --devices 0 --no-nccl --sync-sgd --seed 1111 --exponential-smoothing --no-restore-corpus
[2019-05-05 12:15:28] [config] after-batches: 0
[2019-05-05 12:15:28] [config] after-epochs: 0
[2019-05-05 12:15:28] [config] allow-unk: false
[2019-05-05 12:15:28] [config] beam-size: 6
[2019-05-05 12:15:28] [config] bert-class-symbol: "[CLS]"
[2019-05-05 12:15:28] [config] bert-mask-symbol: "[MASK]"
[2019-05-05 12:15:28] [config] bert-masking-fraction: 0.15
[2019-05-05 12:15:28] [config] bert-sep-symbol: "[SEP]"
[2019-05-05 12:15:28] [config] bert-train-type-embeddings: true
[2019-05-05 12:15:28] [config] bert-type-vocab-size: 2
[2019-05-05 12:15:28] [config] best-deep: false
[2019-05-05 12:15:28] [config] clip-gemm: 0
[2019-05-05 12:15:28] [config] clip-norm: 5
[2019-05-05 12:15:28] [config] context-enc-depth: 1
[2019-05-05 12:15:28] [config] cost-type: ce-mean
[2019-05-05 12:15:28] [config] cpu-threads: 0
[2019-05-05 12:15:28] [config] data-weighting: ""
[2019-05-05 12:15:28] [config] data-weighting-type: sentence
[2019-05-05 12:15:28] [config] dec-cell: gru
[2019-05-05 12:15:28] [config] dec-cell-base-depth: 2
[2019-05-05 12:15:28] [config] dec-cell-high-depth: 1
[2019-05-05 12:15:28] [config] dec-depth: 6
[2019-05-05 12:15:28] [config] devices:
[2019-05-05 12:15:28] [config]   - 0
[2019-05-05 12:15:28] [config] dim-emb: 512
[2019-05-05 12:15:28] [config] dim-rnn: 1024
[2019-05-05 12:15:28] [config] dim-vocabs:
[2019-05-05 12:15:28] [config]   - 30000
[2019-05-05 12:15:28] [config]   - 30000
[2019-05-05 12:15:28] [config] disp-first: 0
[2019-05-05 12:15:28] [config] disp-freq: 1000
[2019-05-05 12:15:28] [config] disp-label-counts: false
[2019-05-05 12:15:28] [config] dropout-rnn: 0
[2019-05-05 12:15:28] [config] dropout-src: 0
[2019-05-05 12:15:28] [config] dropout-trg: 0
[2019-05-05 12:15:28] [config] dump-config: ""
[2019-05-05 12:15:28] [config] early-stopping: 10
[2019-05-05 12:15:28] [config] embedding-fix-src: true
[2019-05-05 12:15:28] [config] embedding-fix-trg: true
[2019-05-05 12:15:28] [config] embedding-normalization: false
[2019-05-05 12:15:28] [config] embedding-vectors:
[2019-05-05 12:15:28] [config]   []
[2019-05-05 12:15:28] [config] enc-cell: gru
[2019-05-05 12:15:28] [config] enc-cell-depth: 1
[2019-05-05 12:15:28] [config] enc-depth: 6
[2019-05-05 12:15:28] [config] enc-type: bidirectional
[2019-05-05 12:15:28] [config] exponential-smoothing: 0.0001
[2019-05-05 12:15:28] [config] freeze: true
[2019-05-05 12:15:28] [config] grad-dropping-momentum: 0
[2019-05-05 12:15:28] [config] grad-dropping-rate: 0
[2019-05-05 12:15:28] [config] grad-dropping-warmup: 100
[2019-05-05 12:15:28] [config] guided-alignment: none
[2019-05-05 12:15:28] [config] guided-alignment-cost: mse
[2019-05-05 12:15:28] [config] guided-alignment-weight: 0.1
[2019-05-05 12:15:28] [config] ignore-model-config: false
[2019-05-05 12:15:28] [config] input-types:
[2019-05-05 12:15:28] [config]   []
[2019-05-05 12:15:28] [config] interpolate-env-vars: false
[2019-05-05 12:15:28] [config] keep-best: true
[2019-05-05 12:15:28] [config] label-smoothing: 0.1
[2019-05-05 12:15:28] [config] layer-normalization: false
[2019-05-05 12:15:28] [config] learn-rate: 0.0001
[2019-05-05 12:15:28] [config] log: model/train_trans.gate.log
[2019-05-05 12:15:28] [config] log-level: info
[2019-05-05 12:15:28] [config] log-time-zone: ""
[2019-05-05 12:15:28] [config] lr-decay: 0
[2019-05-05 12:15:28] [config] lr-decay-freq: 50000
[2019-05-05 12:15:28] [config] lr-decay-inv-sqrt:
[2019-05-05 12:15:28] [config]   - 16000
[2019-05-05 12:15:28] [config] lr-decay-repeat-warmup: false
[2019-05-05 12:15:28] [config] lr-decay-reset-optimizer: false
[2019-05-05 12:15:28] [config] lr-decay-start:
[2019-05-05 12:15:28] [config]   - 10
[2019-05-05 12:15:28] [config]   - 1
[2019-05-05 12:15:28] [config] lr-decay-strategy: epoch+stalled
[2019-05-05 12:15:28] [config] lr-report: true
[2019-05-05 12:15:28] [config] lr-warmup: 16000
[2019-05-05 12:15:28] [config] lr-warmup-at-reload: false
[2019-05-05 12:15:28] [config] lr-warmup-cycle: false
[2019-05-05 12:15:28] [config] lr-warmup-start-rate: 0
[2019-05-05 12:15:28] [config] max-length: 160
[2019-05-05 12:15:28] [config] max-length-crop: false
[2019-05-05 12:15:28] [config] max-length-factor: 3
[2019-05-05 12:15:28] [config] maxi-batch: 1000
[2019-05-05 12:15:28] [config] maxi-batch-sort: trg
[2019-05-05 12:15:28] [config] mini-batch: 1000
[2019-05-05 12:15:28] [config] mini-batch-fit: true
[2019-05-05 12:15:28] [config] mini-batch-fit-step: 10
[2019-05-05 12:15:28] [config] mini-batch-overstuff: 1
[2019-05-05 12:15:28] [config] mini-batch-track-lr: false
[2019-05-05 12:15:28] [config] mini-batch-understuff: 1
[2019-05-05 12:15:28] [config] mini-batch-warmup: 0
[2019-05-05 12:15:28] [config] mini-batch-words: 0
[2019-05-05 12:15:28] [config] mini-batch-words-ref: 0
[2019-05-05 12:15:28] [config] model: model/model.src1tgt0.voita.new.npz
[2019-05-05 12:15:28] [config] multi-loss-type: sum
[2019-05-05 12:15:28] [config] multi-node: false
[2019-05-05 12:15:28] [config] multi-node-overlap: true
[2019-05-05 12:15:28] [config] n-best: false
[2019-05-05 12:15:28] [config] no-nccl: true
[2019-05-05 12:15:28] [config] no-reload: false
[2019-05-05 12:15:28] [config] no-restore-corpus: true
[2019-05-05 12:15:28] [config] no-shuffle: false
[2019-05-05 12:15:28] [config] normalize: 0.6
[2019-05-05 12:15:28] [config] num-devices: 0
[2019-05-05 12:15:28] [config] optimizer: adam
[2019-05-05 12:15:28] [config] optimizer-delay: 4
[2019-05-05 12:15:28] [config] optimizer-params:
[2019-05-05 12:15:28] [config]   - 0.9
[2019-05-05 12:15:28] [config]   - 0.98
[2019-05-05 12:15:28] [config]   - 1e-09
[2019-05-05 12:15:28] [config] overwrite: false
[2019-05-05 12:15:28] [config] pretrained-model: model/model.src1tgt0.docnew.enc_depth.test_base.npz.best-perplexity.npz
[2019-05-05 12:15:28] [config] quiet: false
[2019-05-05 12:15:28] [config] quiet-translation: true
[2019-05-05 12:15:28] [config] relative-paths: false
[2019-05-05 12:15:28] [config] right-left: false
[2019-05-05 12:15:28] [config] save-freq: 5000
[2019-05-05 12:15:28] [config] seed: 1111
[2019-05-05 12:15:28] [config] shuffle-in-ram: false
[2019-05-05 12:15:28] [config] skip: false
[2019-05-05 12:15:28] [config] sqlite: ""
[2019-05-05 12:15:28] [config] sqlite-drop: false
[2019-05-05 12:15:28] [config] sync-sgd: true
[2019-05-05 12:15:28] [config] tempdir: /tmp
[2019-05-05 12:15:28] [config] tied-embeddings: false
[2019-05-05 12:15:28] [config] tied-embeddings-all: true
[2019-05-05 12:15:28] [config] tied-embeddings-src: false
[2019-05-05 12:15:28] [config] train-sets:
[2019-05-05 12:15:28] [config]   - corp/europarl.cs-en.docs.train.en.bpe.src_prev
[2019-05-05 12:15:28] [config]   - corp/europarl.cs-en.docs.train.en.bpe.src
[2019-05-05 12:15:28] [config]   - corp/europarl.cs-en.docs.train.cz.bpe
[2019-05-05 12:15:28] [config] transformer-aan-activation: swish
[2019-05-05 12:15:28] [config] transformer-aan-depth: 2
[2019-05-05 12:15:28] [config] transformer-aan-nogate: false
[2019-05-05 12:15:28] [config] transformer-decoder-autoreg: self-attention
[2019-05-05 12:15:28] [config] transformer-dim-aan: 2048
[2019-05-05 12:15:28] [config] transformer-dim-ffn: 2048
[2019-05-05 12:15:28] [config] transformer-dropout: 0.1
[2019-05-05 12:15:28] [config] transformer-dropout-attention: 0
[2019-05-05 12:15:28] [config] transformer-dropout-ffn: 0
[2019-05-05 12:15:28] [config] transformer-ffn-activation: swish
[2019-05-05 12:15:28] [config] transformer-ffn-depth: 2
[2019-05-05 12:15:28] [config] transformer-guided-alignment-layer: last
[2019-05-05 12:15:28] [config] transformer-heads: 8
[2019-05-05 12:15:28] [config] transformer-no-projection: false
[2019-05-05 12:15:28] [config] transformer-postprocess: dan
[2019-05-05 12:15:28] [config] transformer-postprocess-emb: d
[2019-05-05 12:15:28] [config] transformer-preprocess: ""
[2019-05-05 12:15:28] [config] transformer-tied-layers:
[2019-05-05 12:15:28] [config]   []
[2019-05-05 12:15:28] [config] transformer-train-position-embeddings: false
[2019-05-05 12:15:28] [config] type: transformer-voita
[2019-05-05 12:15:28] [config] ulr: false
[2019-05-05 12:15:28] [config] ulr-dim-emb: 0
[2019-05-05 12:15:28] [config] ulr-dropout: 0
[2019-05-05 12:15:28] [config] ulr-keys-vectors: ""
[2019-05-05 12:15:28] [config] ulr-query-vectors: ""
[2019-05-05 12:15:28] [config] ulr-softmax-temperature: 1
[2019-05-05 12:15:28] [config] ulr-trainable-transformation: false
[2019-05-05 12:15:28] [config] valid-freq: 5000
[2019-05-05 12:15:28] [config] valid-log: model/valid_trans.gate.log
[2019-05-05 12:15:28] [config] valid-max-length: 1000
[2019-05-05 12:15:28] [config] valid-metrics:
[2019-05-05 12:15:28] [config]   - cross-entropy
[2019-05-05 12:15:28] [config]   - perplexity
[2019-05-05 12:15:28] [config]   - translation
[2019-05-05 12:15:28] [config] valid-mini-batch: 16
[2019-05-05 12:15:28] [config] valid-script-path: ./val.sh
[2019-05-05 12:15:28] [config] valid-sets:
[2019-05-05 12:15:28] [config]   - corp/europarl.cs-en.docs.dev.en.bpe.src_prev
[2019-05-05 12:15:28] [config]   - corp/europarl.cs-en.docs.dev.en.bpe.src
[2019-05-05 12:15:28] [config]   - corp/europarl.cs-en.docs.dev.cz.bpe
[2019-05-05 12:15:28] [config] valid-translation-output: data/valid.bpe.en.output
[2019-05-05 12:15:28] [config] vocabs:
[2019-05-05 12:15:28] [config]   - corp/vocab.encz.opensub.new.yml
[2019-05-05 12:15:28] [config]   - corp/vocab.encz.opensub.new.yml
[2019-05-05 12:15:28] [config]   - corp/vocab.encz.opensub.new.yml
[2019-05-05 12:15:28] [config] word-penalty: 0
[2019-05-05 12:15:28] [config] workspace: 7800
[2019-05-05 12:15:28] [config] Model is being created with Marian v1.7.8 1fcb013 2019-05-03 03:15:04 +0200
[2019-05-05 12:15:28] Using synchronous training
[2019-05-05 12:15:28] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encz.opensub.new.yml
[2019-05-05 12:15:28] [data] Setting vocabulary size for input 0 to 30000
[2019-05-05 12:15:28] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encz.opensub.new.yml
[2019-05-05 12:15:29] [data] Setting vocabulary size for input 1 to 30000
[2019-05-05 12:15:29] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encz.opensub.new.yml
[2019-05-05 12:15:29] [data] Setting vocabulary size for input 2 to 30000
[2019-05-05 12:15:29] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-05-05 12:15:29] [batching] Collecting statistics for batch fitting with step size 10
[2019-05-05 12:15:29] [memory] Extending reserved space to 7808 MB (device gpu0)
[2019-05-05 12:15:29] [comm] NCCL communicator overridden
[2019-05-05 12:15:29] [training] Using 1 GPUs
[2019-05-05 12:15:29] [memory] Reserving 237 MB, device gpu0
[2019-05-05 12:15:29] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-05-05 12:15:30] [memory] Reserving 237 MB, device gpu0
[2019-05-05 12:15:37] [batching] Done. Typical MB size is 12860 target words
[2019-05-05 12:15:37] [memory] Extending reserved space to 7808 MB (device gpu0)
[2019-05-05 12:15:37] [comm] NCCL communicator overridden
[2019-05-05 12:15:37] [training] Using 1 GPUs
[2019-05-05 12:15:37] [training] Initializing model weights with the pre-trained model model/model.src1tgt0.docnew.enc_depth.test_base.npz.best-perplexity.npz
[2019-05-05 12:15:37] Loading model from model/model.src1tgt0.docnew.enc_depth.test_base.npz.best-perplexity.npz
[2019-05-05 12:15:37] Training started
[2019-05-05 12:15:37] [data] Shuffling data
[2019-05-05 12:15:37] [data] Done reading 620637 sentences
[2019-05-05 12:15:40] [data] Done shuffling 620637 sentences to temp files
[2019-05-05 12:16:02] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-05-05 12:16:02] [memory] Reserving 249 MB, device gpu0
[2019-05-05 12:16:02] [memory] Reserving 249 MB, device gpu0
[2019-05-05 12:16:02] [memory] Reserving 249 MB, device gpu0
[2019-05-05 12:16:03] [memory] Reserving 249 MB, device gpu0
[2019-05-05 12:16:03] [memory] Reserving 498 MB, device gpu0
[2019-05-05 12:22:31] Ep. 1 : Up. 1000 : Sen. 189,337 : Cost 82.13272095 : Time 421.97s : 14051.43 words/s : L.r. 6.2500e-06
[2019-05-05 12:28:58] Ep. 1 : Up. 2000 : Sen. 381,286 : Cost 67.17240143 : Time 386.91s : 15227.15 words/s : L.r. 1.2500e-05
[2019-05-05 12:35:24] Ep. 1 : Up. 3000 : Sen. 572,645 : Cost 65.67128754 : Time 386.13s : 15007.25 words/s : L.r. 1.8750e-05
[2019-05-05 12:36:52] Seen 620307 samples
[2019-05-05 12:36:52] Starting epoch 2
[2019-05-05 12:36:52] [data] Shuffling data
[2019-05-05 12:36:53] [data] Done reading 620637 sentences
[2019-05-05 12:36:55] [data] Done shuffling 620637 sentences to temp files
[2019-05-05 12:42:23] Ep. 2 : Up. 4000 : Sen. 149,151 : Cost 66.42899323 : Time 419.46s : 14450.51 words/s : L.r. 2.5000e-05
[2019-05-05 12:48:54] Ep. 2 : Up. 5000 : Sen. 348,058 : Cost 63.74060059 : Time 391.02s : 15056.25 words/s : L.r. 3.1250e-05
[2019-05-05 12:48:54] Saving model weights and runtime parameters to model/model.src1tgt0.voita.new.npz.orig.npz
[2019-05-05 12:48:58] Saving model weights and runtime parameters to model/model.src1tgt0.voita.new.iter5000.npz
[2019-05-05 12:49:01] Saving model weights and runtime parameters to model/model.src1tgt0.voita.new.npz
[2019-05-05 12:49:05] Saving Adam parameters to model/model.src1tgt0.voita.new.npz.optimizer.npz
[2019-05-05 12:49:20] Saving model weights and runtime parameters to model/model.src1tgt0.voita.new.npz.best-cross-entropy.npz
[2019-05-05 12:49:23] [valid] Ep. 2 : Up. 5000 : cross-entropy : 42.4724 : new best
[2019-05-05 12:49:32] Saving model weights and runtime parameters to model/model.src1tgt0.voita.new.npz.best-perplexity.npz
[2019-05-05 12:49:36] [valid] Ep. 2 : Up. 5000 : perplexity : 3.94331 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-05-05 12:52:09] Saving model weights and runtime parameters to model/model.src1tgt0.voita.new.npz.best-translation.npz
[2019-05-05 12:52:13] [valid] Ep. 2 : Up. 5000 : translation : 30.1 : new best
[2019-05-05 12:58:45] Ep. 2 : Up. 6000 : Sen. 540,814 : Cost 66.87390137 : Time 590.90s : 10117.98 words/s : L.r. 3.7500e-05
[2019-05-05 13:01:29] Seen 620307 samples
[2019-05-05 13:01:29] Starting epoch 3
[2019-05-05 13:01:29] [data] Shuffling data
[2019-05-05 13:01:29] [data] Done reading 620637 sentences
[2019-05-05 13:01:31] [data] Done shuffling 620637 sentences to temp files
[2019-05-05 13:05:28] Ep. 3 : Up. 7000 : Sen. 101,692 : Cost 67.15959930 : Time 402.61s : 14063.44 words/s : L.r. 4.3750e-05
[2019-05-05 13:11:59] Ep. 3 : Up. 8000 : Sen. 297,099 : Cost 65.08827972 : Time 391.02s : 15153.27 words/s : L.r. 5.0000e-05
[2019-05-05 13:18:28] Ep. 3 : Up. 9000 : Sen. 488,324 : Cost 66.45337677 : Time 389.46s : 15122.89 words/s : L.r. 5.6250e-05
[2019-05-05 13:22:46] Seen 620307 samples
[2019-05-05 13:22:46] Starting epoch 4
[2019-05-05 13:22:46] [data] Shuffling data
[2019-05-05 13:22:47] [data] Done reading 620637 sentences
[2019-05-05 13:22:49] [data] Done shuffling 620637 sentences to temp files
[2019-05-05 13:25:24] Ep. 4 : Up. 10000 : Sen. 66,569 : Cost 64.72165680 : Time 415.75s : 14368.36 words/s : L.r. 6.2500e-05
[2019-05-05 13:25:24] Saving model weights and runtime parameters to model/model.src1tgt0.voita.new.npz.orig.npz
[2019-05-05 13:25:28] Saving model weights and runtime parameters to model/model.src1tgt0.voita.new.iter10000.npz
[2019-05-05 13:25:31] Saving model weights and runtime parameters to model/model.src1tgt0.voita.new.npz
[2019-05-05 13:25:36] Saving Adam parameters to model/model.src1tgt0.voita.new.npz.optimizer.npz
[2019-05-05 13:25:51] Saving model weights and runtime parameters to model/model.src1tgt0.voita.new.npz.best-cross-entropy.npz
[2019-05-05 13:25:55] [valid] Ep. 4 : Up. 10000 : cross-entropy : 42.3594 : new best
[2019-05-05 13:26:04] Saving model weights and runtime parameters to model/model.src1tgt0.voita.new.npz.best-perplexity.npz
[2019-05-05 13:26:07] [valid] Ep. 4 : Up. 10000 : perplexity : 3.92895 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-05-05 13:28:41] [valid] Ep. 4 : Up. 10000 : translation : 29.9 : stalled 1 times (last best: 30.1)
[2019-05-05 13:35:08] Ep. 4 : Up. 11000 : Sen. 253,249 : Cost 67.64700317 : Time 584.59s : 10049.58 words/s : L.r. 6.8750e-05
[2019-05-05 13:41:34] Ep. 4 : Up. 12000 : Sen. 441,032 : Cost 66.84646606 : Time 385.15s : 15093.51 words/s : L.r. 7.5000e-05
[2019-05-05 13:47:20] Seen 620307 samples
[2019-05-05 13:47:20] Starting epoch 5
[2019-05-05 13:47:20] [data] Shuffling data
[2019-05-05 13:47:21] [data] Done reading 620637 sentences
[2019-05-05 13:47:23] [data] Done shuffling 620637 sentences to temp files
[2019-05-05 13:48:31] Ep. 5 : Up. 13000 : Sen. 21,587 : Cost 64.00310516 : Time 417.48s : 14265.01 words/s : L.r. 8.1250e-05
[2019-05-05 13:55:00] Ep. 5 : Up. 14000 : Sen. 211,312 : Cost 67.25227356 : Time 389.02s : 15263.56 words/s : L.r. 8.7500e-05
[2019-05-05 14:01:32] Ep. 5 : Up. 15000 : Sen. 406,936 : Cost 65.60198975 : Time 391.53s : 15182.31 words/s : L.r. 9.3750e-05
[2019-05-05 14:01:32] Saving model weights and runtime parameters to model/model.src1tgt0.voita.new.npz.orig.npz
[2019-05-05 14:01:35] Saving model weights and runtime parameters to model/model.src1tgt0.voita.new.iter15000.npz
[2019-05-05 14:01:39] Saving model weights and runtime parameters to model/model.src1tgt0.voita.new.npz
[2019-05-05 14:01:43] Saving Adam parameters to model/model.src1tgt0.voita.new.npz.optimizer.npz
[2019-05-05 14:01:58] [valid] Ep. 5 : Up. 15000 : cross-entropy : 42.3996 : stalled 1 times (last best: 42.3594)
[2019-05-05 14:02:06] [valid] Ep. 5 : Up. 15000 : perplexity : 3.93406 : stalled 1 times (last best: 3.92895)
Detokenizer Version $Revision: 4134 $
Language: en
[2019-05-05 14:04:40] [valid] Ep. 5 : Up. 15000 : translation : 30.1 : stalled 2 times (last best: 30.1)
[2019-05-05 14:11:06] Ep. 5 : Up. 16000 : Sen. 599,425 : Cost 65.82811737 : Time 574.12s : 10170.79 words/s : L.r. 1.0000e-04
[2019-05-05 14:11:45] Seen 620307 samples
[2019-05-05 14:11:45] Starting epoch 6
[2019-05-05 14:11:45] [data] Shuffling data
[2019-05-05 14:11:45] [data] Done reading 620637 sentences
[2019-05-05 14:11:48] [data] Done shuffling 620637 sentences to temp files
[2019-05-05 14:18:05] Ep. 6 : Up. 17000 : Sen. 179,798 : Cost 64.47135925 : Time 419.57s : 14339.55 words/s : L.r. 9.7014e-05
[2019-05-05 14:24:29] Ep. 6 : Up. 18000 : Sen. 367,657 : Cost 66.74490356 : Time 383.61s : 15158.76 words/s : L.r. 9.4281e-05
[2019-05-05 14:30:55] Ep. 6 : Up. 19000 : Sen. 556,579 : Cost 66.46063995 : Time 385.80s : 15042.58 words/s : L.r. 9.1766e-05
[2019-05-05 14:33:01] Seen 620307 samples
[2019-05-05 14:33:01] Starting epoch 7
[2019-05-05 14:33:01] [data] Shuffling data
[2019-05-05 14:33:01] [data] Done reading 620637 sentences
[2019-05-05 14:33:03] [data] Done shuffling 620637 sentences to temp files
[2019-05-05 14:37:51] Ep. 7 : Up. 20000 : Sen. 134,100 : Cost 64.88957214 : Time 416.08s : 14401.85 words/s : L.r. 8.9443e-05
[2019-05-05 14:37:51] Saving model weights and runtime parameters to model/model.src1tgt0.voita.new.npz.orig.npz
[2019-05-05 14:37:55] Saving model weights and runtime parameters to model/model.src1tgt0.voita.new.iter20000.npz
[2019-05-05 14:37:58] Saving model weights and runtime parameters to model/model.src1tgt0.voita.new.npz
[2019-05-05 14:38:02] Saving Adam parameters to model/model.src1tgt0.voita.new.npz.optimizer.npz
[2019-05-05 14:38:17] [valid] Ep. 7 : Up. 20000 : cross-entropy : 42.4488 : stalled 2 times (last best: 42.3594)
[2019-05-05 14:38:25] [valid] Ep. 7 : Up. 20000 : perplexity : 3.94031 : stalled 2 times (last best: 3.92895)
Detokenizer Version $Revision: 4134 $
Language: en
[2019-05-05 14:40:59] Saving model weights and runtime parameters to model/model.src1tgt0.voita.new.npz.best-translation.npz
[2019-05-05 14:41:03] [valid] Ep. 7 : Up. 20000 : translation : 30.2 : new best
[2019-05-05 14:47:35] Ep. 7 : Up. 21000 : Sen. 323,310 : Cost 67.81696320 : Time 584.25s : 10232.73 words/s : L.r. 8.7287e-05
[2019-05-05 14:54:00] Ep. 7 : Up. 22000 : Sen. 515,250 : Cost 64.98590088 : Time 384.58s : 15106.40 words/s : L.r. 8.5280e-05
[2019-05-05 14:57:29] Seen 620307 samples
[2019-05-05 14:57:29] Starting epoch 8
[2019-05-05 14:57:29] [data] Shuffling data
[2019-05-05 14:57:29] [data] Done reading 620637 sentences
[2019-05-05 14:57:32] [data] Done shuffling 620637 sentences to temp files
[2019-05-05 15:00:53] Ep. 8 : Up. 23000 : Sen. 84,892 : Cost 66.42124176 : Time 413.65s : 14254.94 words/s : L.r. 8.3406e-05
[2019-05-05 15:07:14] Ep. 8 : Up. 24000 : Sen. 274,089 : Cost 64.06402588 : Time 380.99s : 14985.95 words/s : L.r. 8.1650e-05
[2019-05-05 15:13:44] Ep. 8 : Up. 25000 : Sen. 465,559 : Cost 65.87877655 : Time 389.42s : 15164.86 words/s : L.r. 8.0000e-05
[2019-05-05 15:13:44] Saving model weights and runtime parameters to model/model.src1tgt0.voita.new.npz.orig.npz
[2019-05-05 15:13:48] Saving model weights and runtime parameters to model/model.src1tgt0.voita.new.iter25000.npz
[2019-05-05 15:13:51] Saving model weights and runtime parameters to model/model.src1tgt0.voita.new.npz
[2019-05-05 15:13:55] Saving Adam parameters to model/model.src1tgt0.voita.new.npz.optimizer.npz
[2019-05-05 15:14:10] [valid] Ep. 8 : Up. 25000 : cross-entropy : 42.5676 : stalled 3 times (last best: 42.3594)
[2019-05-05 15:14:19] [valid] Ep. 8 : Up. 25000 : perplexity : 3.95547 : stalled 3 times (last best: 3.92895)
Detokenizer Version $Revision: 4134 $
Language: en
[2019-05-05 15:16:52] [valid] Ep. 8 : Up. 25000 : translation : 30 : stalled 1 times (last best: 30.2)
[2019-05-05 15:21:55] Seen 620307 samples
[2019-05-05 15:21:55] Starting epoch 9
[2019-05-05 15:21:55] [data] Shuffling data
[2019-05-05 15:21:56] [data] Done reading 620637 sentences
[2019-05-05 15:21:58] [data] Done shuffling 620637 sentences to temp files
[2019-05-05 15:23:56] Ep. 9 : Up. 26000 : Sen. 47,916 : Cost 63.93486786 : Time 611.95s : 9943.88 words/s : L.r. 7.8446e-05
[2019-05-05 15:30:21] Ep. 9 : Up. 27000 : Sen. 236,359 : Cost 65.25831604 : Time 385.71s : 15084.82 words/s : L.r. 7.6980e-05
[2019-05-05 15:36:55] Ep. 9 : Up. 28000 : Sen. 436,484 : Cost 63.92220306 : Time 393.77s : 15314.59 words/s : L.r. 7.5593e-05
[2019-05-05 15:43:13] Seen 620307 samples
[2019-05-05 15:43:13] Starting epoch 10
[2019-05-05 15:43:13] [data] Shuffling data
[2019-05-05 15:43:13] [data] Done reading 620637 sentences
[2019-05-05 15:43:15] [data] Done shuffling 620637 sentences to temp files
[2019-05-05 15:43:44] Ep. 10 : Up. 29000 : Sen. 2,850 : Cost 66.04842377 : Time 409.11s : 14151.49 words/s : L.r. 7.4278e-05
[2019-05-05 15:50:14] Ep. 10 : Up. 30000 : Sen. 192,982 : Cost 65.39609528 : Time 389.60s : 15164.24 words/s : L.r. 7.3030e-05
[2019-05-05 15:50:14] Saving model weights and runtime parameters to model/model.src1tgt0.voita.new.npz.orig.npz
[2019-05-05 15:50:17] Saving model weights and runtime parameters to model/model.src1tgt0.voita.new.iter30000.npz
[2019-05-05 15:50:21] Saving model weights and runtime parameters to model/model.src1tgt0.voita.new.npz
[2019-05-05 15:50:25] Saving Adam parameters to model/model.src1tgt0.voita.new.npz.optimizer.npz
[2019-05-05 15:50:40] [valid] Ep. 10 : Up. 30000 : cross-entropy : 42.7142 : stalled 4 times (last best: 42.3594)
[2019-05-05 15:50:48] [valid] Ep. 10 : Up. 30000 : perplexity : 3.97424 : stalled 4 times (last best: 3.92895)
Detokenizer Version $Revision: 4134 $
Language: en
[2019-05-05 15:53:22] [valid] Ep. 10 : Up. 30000 : translation : 30 : stalled 2 times (last best: 30.2)
[2019-05-05 15:59:52] Ep. 10 : Up. 31000 : Sen. 391,204 : Cost 63.96504593 : Time 578.44s : 10381.40 words/s : L.r. 7.1842e-05
[2019-05-05 16:06:21] Ep. 10 : Up. 32000 : Sen. 583,913 : Cost 64.08891296 : Time 388.21s : 15055.78 words/s : L.r. 7.0711e-05
[2019-05-05 16:07:37] Seen 620307 samples
[2019-05-05 16:07:37] Starting epoch 11
[2019-05-05 16:07:37] [data] Shuffling data
[2019-05-05 16:07:37] [data] Done reading 620637 sentences
[2019-05-05 16:07:39] [data] Done shuffling 620637 sentences to temp files
[2019-05-05 16:13:18] Ep. 11 : Up. 33000 : Sen. 153,413 : Cost 66.17120361 : Time 417.09s : 14342.69 words/s : L.r. 6.9631e-05
[2019-05-05 16:19:41] Ep. 11 : Up. 34000 : Sen. 340,789 : Cost 64.32093811 : Time 383.46s : 14996.88 words/s : L.r. 6.8599e-05
[2019-05-05 16:26:11] Ep. 11 : Up. 35000 : Sen. 537,930 : Cost 63.34615326 : Time 389.72s : 15221.21 words/s : L.r. 6.7612e-05
[2019-05-05 16:26:11] Saving model weights and runtime parameters to model/model.src1tgt0.voita.new.npz.orig.npz
[2019-05-05 16:26:15] Saving model weights and runtime parameters to model/model.src1tgt0.voita.new.iter35000.npz
[2019-05-05 16:26:18] Saving model weights and runtime parameters to model/model.src1tgt0.voita.new.npz
[2019-05-05 16:26:22] Saving Adam parameters to model/model.src1tgt0.voita.new.npz.optimizer.npz
[2019-05-05 16:26:37] [valid] Ep. 11 : Up. 35000 : cross-entropy : 42.864 : stalled 5 times (last best: 42.3594)
[2019-05-05 16:26:45] [valid] Ep. 11 : Up. 35000 : perplexity : 3.99351 : stalled 5 times (last best: 3.92895)
Detokenizer Version $Revision: 4134 $
Language: en
[2019-05-05 16:29:19] [valid] Ep. 11 : Up. 35000 : translation : 30.2 : stalled 3 times (last best: 30.2)
[2019-05-05 16:32:01] Seen 620307 samples
[2019-05-05 16:32:01] Starting epoch 12
[2019-05-05 16:32:01] [data] Shuffling data
[2019-05-05 16:32:01] [data] Done reading 620637 sentences
[2019-05-05 16:32:04] [data] Done shuffling 620637 sentences to temp files
[2019-05-05 16:36:11] Ep. 12 : Up. 36000 : Sen. 111,609 : Cost 63.65216064 : Time 599.79s : 9821.58 words/s : L.r. 6.6667e-05
[2019-05-05 16:42:42] Ep. 12 : Up. 37000 : Sen. 308,511 : Cost 62.80424118 : Time 391.49s : 15124.33 words/s : L.r. 6.5760e-05
[2019-05-05 16:49:06] Ep. 12 : Up. 38000 : Sen. 497,363 : Cost 64.13279724 : Time 384.07s : 15038.09 words/s : L.r. 6.4889e-05
[2019-05-05 16:53:17] Seen 620307 samples
[2019-05-05 16:53:17] Starting epoch 13
[2019-05-05 16:53:17] [data] Shuffling data
[2019-05-05 16:53:18] [data] Done reading 620637 sentences
[2019-05-05 16:53:20] [data] Done shuffling 620637 sentences to temp files
[2019-05-05 16:56:00] Ep. 13 : Up. 39000 : Sen. 67,830 : Cost 65.21334839 : Time 413.74s : 14357.34 words/s : L.r. 6.4051e-05
[2019-05-05 17:02:30] Ep. 13 : Up. 40000 : Sen. 258,324 : Cost 64.66561127 : Time 390.06s : 15185.70 words/s : L.r. 6.3246e-05
[2019-05-05 17:02:30] Saving model weights and runtime parameters to model/model.src1tgt0.voita.new.npz.orig.npz
[2019-05-05 17:02:34] Saving model weights and runtime parameters to model/model.src1tgt0.voita.new.iter40000.npz
[2019-05-05 17:02:37] Saving model weights and runtime parameters to model/model.src1tgt0.voita.new.npz
[2019-05-05 17:02:41] Saving Adam parameters to model/model.src1tgt0.voita.new.npz.optimizer.npz
[2019-05-05 17:02:56] [valid] Ep. 13 : Up. 40000 : cross-entropy : 43.038 : stalled 6 times (last best: 42.3594)
[2019-05-05 17:03:05] [valid] Ep. 13 : Up. 40000 : perplexity : 4.01603 : stalled 6 times (last best: 3.92895)
Detokenizer Version $Revision: 4134 $
Language: en
[2019-05-05 17:05:38] [valid] Ep. 13 : Up. 40000 : translation : 30.1 : stalled 4 times (last best: 30.2)
[2019-05-05 17:12:05] Ep. 13 : Up. 41000 : Sen. 452,505 : Cost 63.16761780 : Time 574.92s : 10209.70 words/s : L.r. 6.2470e-05
[2019-05-05 17:17:42] Seen 620307 samples
[2019-05-05 17:17:42] Starting epoch 14
[2019-05-05 17:17:42] [data] Shuffling data
[2019-05-05 17:17:42] [data] Done reading 620637 sentences
[2019-05-05 17:17:44] [data] Done shuffling 620637 sentences to temp files
[2019-05-05 17:19:04] Ep. 14 : Up. 42000 : Sen. 28,222 : Cost 64.00428772 : Time 418.90s : 14340.74 words/s : L.r. 6.1721e-05
[2019-05-05 17:25:30] Ep. 14 : Up. 43000 : Sen. 217,077 : Cost 64.31671906 : Time 386.42s : 15164.14 words/s : L.r. 6.0999e-05
[2019-05-05 17:31:54] Ep. 14 : Up. 44000 : Sen. 405,691 : Cost 64.51102448 : Time 384.22s : 15228.86 words/s : L.r. 6.0302e-05
[2019-05-05 17:38:28] Ep. 14 : Up. 45000 : Sen. 604,909 : Cost 62.20384216 : Time 393.78s : 15100.47 words/s : L.r. 5.9628e-05
[2019-05-05 17:38:28] Saving model weights and runtime parameters to model/model.src1tgt0.voita.new.npz.orig.npz
[2019-05-05 17:38:32] Saving model weights and runtime parameters to model/model.src1tgt0.voita.new.iter45000.npz
[2019-05-05 17:38:35] Saving model weights and runtime parameters to model/model.src1tgt0.voita.new.npz
[2019-05-05 17:38:39] Saving Adam parameters to model/model.src1tgt0.voita.new.npz.optimizer.npz
[2019-05-05 17:38:54] [valid] Ep. 14 : Up. 45000 : cross-entropy : 43.176 : stalled 7 times (last best: 42.3594)
[2019-05-05 17:39:03] [valid] Ep. 14 : Up. 45000 : perplexity : 4.03396 : stalled 7 times (last best: 3.92895)
Detokenizer Version $Revision: 4134 $
Language: en
[2019-05-05 17:41:36] [valid] Ep. 14 : Up. 45000 : translation : 30 : stalled 5 times (last best: 30.2)
[2019-05-05 17:42:06] Seen 620307 samples
[2019-05-05 17:42:06] Starting epoch 15
[2019-05-05 17:42:06] [data] Shuffling data
[2019-05-05 17:42:06] [data] Done reading 620637 sentences
[2019-05-05 17:42:09] [data] Done shuffling 620637 sentences to temp files
[2019-05-05 17:48:26] Ep. 15 : Up. 46000 : Sen. 169,910 : Cost 64.95518494 : Time 597.73s : 9748.89 words/s : L.r. 5.8977e-05
[2019-05-05 17:55:04] Ep. 15 : Up. 47000 : Sen. 369,503 : Cost 63.87154388 : Time 398.39s : 15429.41 words/s : L.r. 5.8346e-05
[2019-05-05 18:01:26] Ep. 15 : Up. 48000 : Sen. 562,464 : Cost 61.38080597 : Time 381.65s : 14952.08 words/s : L.r. 5.7735e-05
[2019-05-05 18:03:23] Seen 620307 samples
[2019-05-05 18:03:23] Starting epoch 16
[2019-05-05 18:03:23] [data] Shuffling data
[2019-05-05 18:03:23] [data] Done reading 620637 sentences
[2019-05-05 18:03:25] [data] Done shuffling 620637 sentences to temp files
[2019-05-05 18:08:13] Ep. 16 : Up. 49000 : Sen. 129,017 : Cost 63.19620132 : Time 407.03s : 14075.60 words/s : L.r. 5.7143e-05
[2019-05-05 18:14:44] Ep. 16 : Up. 50000 : Sen. 322,493 : Cost 63.79148483 : Time 391.25s : 15286.40 words/s : L.r. 5.6569e-05
[2019-05-05 18:14:44] Saving model weights and runtime parameters to model/model.src1tgt0.voita.new.npz.orig.npz
[2019-05-05 18:14:48] Saving model weights and runtime parameters to model/model.src1tgt0.voita.new.iter50000.npz
[2019-05-05 18:14:51] Saving model weights and runtime parameters to model/model.src1tgt0.voita.new.npz
[2019-05-05 18:14:55] Saving Adam parameters to model/model.src1tgt0.voita.new.npz.optimizer.npz
[2019-05-05 18:15:10] [valid] Ep. 16 : Up. 50000 : cross-entropy : 43.3533 : stalled 8 times (last best: 42.3594)
[2019-05-05 18:15:19] [valid] Ep. 16 : Up. 50000 : perplexity : 4.05713 : stalled 8 times (last best: 3.92895)
Detokenizer Version $Revision: 4134 $
Language: en
[2019-05-05 18:17:52] [valid] Ep. 16 : Up. 50000 : translation : 30 : stalled 6 times (last best: 30.2)
[2019-05-05 18:24:27] Ep. 16 : Up. 51000 : Sen. 518,545 : Cost 64.20275879 : Time 582.73s : 10419.54 words/s : L.r. 5.6011e-05
[2019-05-05 18:27:47] Seen 620307 samples
[2019-05-05 18:27:47] Starting epoch 17
[2019-05-05 18:27:47] [data] Shuffling data
[2019-05-05 18:27:47] [data] Done reading 620637 sentences
[2019-05-05 18:27:50] [data] Done shuffling 620637 sentences to temp files
[2019-05-05 18:31:20] Ep. 17 : Up. 52000 : Sen. 92,141 : Cost 62.03173065 : Time 413.38s : 14109.04 words/s : L.r. 5.5470e-05
[2019-05-05 18:37:50] Ep. 17 : Up. 53000 : Sen. 285,725 : Cost 63.29555511 : Time 389.99s : 15261.14 words/s : L.r. 5.4944e-05
[2019-05-05 18:44:18] Ep. 17 : Up. 54000 : Sen. 477,449 : Cost 62.82495499 : Time 387.74s : 15068.27 words/s : L.r. 5.4433e-05
[2019-05-05 18:49:05] Seen 620307 samples
[2019-05-05 18:49:05] Starting epoch 18
[2019-05-05 18:49:05] [data] Shuffling data
[2019-05-05 18:49:05] [data] Done reading 620637 sentences
[2019-05-05 18:49:08] [data] Done shuffling 620637 sentences to temp files
[2019-05-05 18:51:13] Ep. 18 : Up. 55000 : Sen. 51,207 : Cost 62.19648743 : Time 414.37s : 14144.17 words/s : L.r. 5.3936e-05
[2019-05-05 18:51:13] Saving model weights and runtime parameters to model/model.src1tgt0.voita.new.npz.orig.npz
[2019-05-05 18:51:16] Saving model weights and runtime parameters to model/model.src1tgt0.voita.new.iter55000.npz
[2019-05-05 18:51:20] Saving model weights and runtime parameters to model/model.src1tgt0.voita.new.npz
[2019-05-05 18:51:24] Saving Adam parameters to model/model.src1tgt0.voita.new.npz.optimizer.npz
[2019-05-05 18:51:39] [valid] Ep. 18 : Up. 55000 : cross-entropy : 43.4841 : stalled 9 times (last best: 42.3594)
[2019-05-05 18:51:47] [valid] Ep. 18 : Up. 55000 : perplexity : 4.07431 : stalled 9 times (last best: 3.92895)
Detokenizer Version $Revision: 4134 $
Language: en
[2019-05-05 18:54:20] [valid] Ep. 18 : Up. 55000 : translation : 30 : stalled 7 times (last best: 30.2)
[2019-05-05 19:00:54] Ep. 18 : Up. 56000 : Sen. 247,030 : Cost 62.76238251 : Time 581.68s : 10305.74 words/s : L.r. 5.3452e-05
[2019-05-05 19:07:29] Ep. 18 : Up. 57000 : Sen. 438,965 : Cost 64.78114319 : Time 394.46s : 15301.16 words/s : L.r. 5.2981e-05
[2019-05-05 19:13:30] Seen 620307 samples
[2019-05-05 19:13:30] Starting epoch 19
[2019-05-05 19:13:30] [data] Shuffling data
[2019-05-05 19:13:31] [data] Done reading 620637 sentences
[2019-05-05 19:13:33] [data] Done shuffling 620637 sentences to temp files
[2019-05-05 19:14:12] Ep. 19 : Up. 58000 : Sen. 9,047 : Cost 61.48907852 : Time 403.83s : 14098.40 words/s : L.r. 5.2523e-05
train_voita_new.sh: řádek 29: 23939 Ukončen (SIGTERM)      $marian_home/marian --model model/model.src1tgt0.voita.new.npz --pretrained-model model/model.src1tgt0.docnew.enc_depth.test_base.npz.best-perplexity.npz --type transformer-voita --train-sets corp/europarl.cs-en.docs.train.en.bpe.src_prev corp/europarl.cs-en.docs.train.en.bpe.src corp/europarl.cs-en.docs.train.cz.bpe --max-length 160 --dim-vocabs 30000 30000 --embedding-fix-src --embedding-fix-trg --vocabs corp/vocab.encz.opensub.new.yml corp/vocab.encz.opensub.new.yml corp/vocab.encz.opensub.new.yml --mini-batch-fit -w 7800 --mini-batch 1000 --maxi-batch 1000 --early-stopping 10 --freeze --context-enc-depth 1 --valid-freq 5000 --save-freq 5000 --disp-freq 1000 --valid-metrics cross-entropy perplexity translation --valid-sets corp/europarl.cs-en.docs.dev.en.bpe.src_prev corp/europarl.cs-en.docs.dev.en.bpe.src corp/europarl.cs-en.docs.dev.cz.bpe --valid-script-path ./val.sh --valid-translation-output data/valid.bpe.en.output --quiet-translation --valid-mini-batch 16 --keep-best --beam-size 6 --normalize 0.6 --log model/train_trans.gate.log --valid-log model/valid_trans.gate.log --enc-depth 6 --dec-depth 6 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0001 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --optimizer-delay 4 --devices 0 --no-nccl --sync-sgd --seed 1111 --exponential-smoothing --no-restore-corpus
