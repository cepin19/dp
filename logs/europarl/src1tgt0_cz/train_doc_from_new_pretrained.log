[2019-04-02 04:06:07] [marian] Marian v1.7.8 b59f01a 2019-04-02 03:22:27 +0200
[2019-04-02 04:06:07] [marian] Running on pcknot5 as process 942 with command line:
[2019-04-02 04:06:07] [marian] /mnt/minerva1/nlp/projects/nmt/doc-marian/build/marian --model model/model.src1tgt0.from_new_pretrained.npz --pretrained-model model/model.src1tgt0.docnew.enc_depth.test_base.npz.best-perplexity.npz --type transformer-context --train-sets corp/europarl.cs-en.docs.train.en.bpe.src_prev corp/europarl.cs-en.docs.train.en.bpe.src corp/europarl.cs-en.docs.train.cz.bpe --max-length 160 --dim-vocabs 30000 30000 --embedding-fix-src --embedding-fix-trg --vocabs corp/vocab.encz.opensub.new.yml corp/vocab.encz.opensub.new.yml corp/vocab.encz.opensub.new.yml --mini-batch-fit -w 7800 --mini-batch 1000 --maxi-batch 1000 --early-stopping 10 --freeze --valid-freq 5000 --save-freq 5000 --disp-freq 1000 --valid-metrics cross-entropy perplexity translation --valid-sets corp/europarl.cs-en.docs.dev.en.bpe.src_prev corp/europarl.cs-en.docs.dev.en.bpe.src corp/europarl.cs-en.docs.dev.cz.bpe --valid-script-path ./val.sh --valid-translation-output data/valid.bpe.en.output --quiet-translation --valid-mini-batch 16 --keep-best --beam-size 6 --normalize 0.6 --log model/train_trans.gate.log --valid-log model/valid_trans.gate.log --enc-depth 6 --dec-depth 6 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0001 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --optimizer-delay 4 --devices 0 --no-nccl --sync-sgd --seed 1111 --exponential-smoothing --no-restore-corpus
[2019-04-02 04:06:07] [config] after-batches: 0
[2019-04-02 04:06:07] [config] after-epochs: 0
[2019-04-02 04:06:07] [config] allow-unk: false
[2019-04-02 04:06:07] [config] beam-size: 6
[2019-04-02 04:06:07] [config] bert-class-symbol: "[CLS]"
[2019-04-02 04:06:07] [config] bert-mask-symbol: "[MASK]"
[2019-04-02 04:06:07] [config] bert-masking-fraction: 0.15
[2019-04-02 04:06:07] [config] bert-sep-symbol: "[SEP]"
[2019-04-02 04:06:07] [config] bert-train-type-embeddings: true
[2019-04-02 04:06:07] [config] bert-type-vocab-size: 2
[2019-04-02 04:06:07] [config] best-deep: false
[2019-04-02 04:06:07] [config] clip-gemm: 0
[2019-04-02 04:06:07] [config] clip-norm: 5
[2019-04-02 04:06:07] [config] context-enc-depth: 1
[2019-04-02 04:06:07] [config] cost-type: ce-mean
[2019-04-02 04:06:07] [config] cpu-threads: 0
[2019-04-02 04:06:07] [config] data-weighting: ""
[2019-04-02 04:06:07] [config] data-weighting-type: sentence
[2019-04-02 04:06:07] [config] dec-cell: gru
[2019-04-02 04:06:07] [config] dec-cell-base-depth: 2
[2019-04-02 04:06:07] [config] dec-cell-high-depth: 1
[2019-04-02 04:06:07] [config] dec-depth: 6
[2019-04-02 04:06:07] [config] devices:
[2019-04-02 04:06:07] [config]   - 0
[2019-04-02 04:06:07] [config] dim-emb: 512
[2019-04-02 04:06:07] [config] dim-rnn: 1024
[2019-04-02 04:06:07] [config] dim-vocabs:
[2019-04-02 04:06:07] [config]   - 30000
[2019-04-02 04:06:07] [config]   - 30000
[2019-04-02 04:06:07] [config]   - 30000
[2019-04-02 04:06:07] [config] disp-first: 0
[2019-04-02 04:06:07] [config] disp-freq: 1000
[2019-04-02 04:06:07] [config] disp-label-counts: false
[2019-04-02 04:06:07] [config] dropout-rnn: 0
[2019-04-02 04:06:07] [config] dropout-src: 0
[2019-04-02 04:06:07] [config] dropout-trg: 0
[2019-04-02 04:06:07] [config] dump-config: ""
[2019-04-02 04:06:07] [config] early-stopping: 10
[2019-04-02 04:06:07] [config] embedding-fix-src: true
[2019-04-02 04:06:07] [config] embedding-fix-trg: true
[2019-04-02 04:06:07] [config] embedding-normalization: false
[2019-04-02 04:06:07] [config] embedding-vectors:
[2019-04-02 04:06:07] [config]   []
[2019-04-02 04:06:07] [config] enc-cell: gru
[2019-04-02 04:06:07] [config] enc-cell-depth: 1
[2019-04-02 04:06:07] [config] enc-depth: 6
[2019-04-02 04:06:07] [config] enc-type: bidirectional
[2019-04-02 04:06:07] [config] exponential-smoothing: 0.0001
[2019-04-02 04:06:07] [config] freeze: true
[2019-04-02 04:06:07] [config] grad-dropping-momentum: 0
[2019-04-02 04:06:07] [config] grad-dropping-rate: 0
[2019-04-02 04:06:07] [config] grad-dropping-warmup: 100
[2019-04-02 04:06:07] [config] guided-alignment: none
[2019-04-02 04:06:07] [config] guided-alignment-cost: mse
[2019-04-02 04:06:07] [config] guided-alignment-weight: 0.1
[2019-04-02 04:06:07] [config] hier-att: false
[2019-04-02 04:06:07] [config] ignore-model-config: false
[2019-04-02 04:06:07] [config] input-types:
[2019-04-02 04:06:07] [config]   []
[2019-04-02 04:06:07] [config] interpolate-env-vars: false
[2019-04-02 04:06:07] [config] keep-best: true
[2019-04-02 04:06:07] [config] label-smoothing: 0.1
[2019-04-02 04:06:07] [config] layer-normalization: false
[2019-04-02 04:06:07] [config] learn-rate: 0.0001
[2019-04-02 04:06:07] [config] log: model/train_trans.gate.log
[2019-04-02 04:06:07] [config] log-level: info
[2019-04-02 04:06:07] [config] log-time-zone: ""
[2019-04-02 04:06:07] [config] lr-decay: 0
[2019-04-02 04:06:07] [config] lr-decay-freq: 50000
[2019-04-02 04:06:07] [config] lr-decay-inv-sqrt:
[2019-04-02 04:06:07] [config]   - 16000
[2019-04-02 04:06:07] [config] lr-decay-repeat-warmup: false
[2019-04-02 04:06:07] [config] lr-decay-reset-optimizer: false
[2019-04-02 04:06:07] [config] lr-decay-start:
[2019-04-02 04:06:07] [config]   - 10
[2019-04-02 04:06:07] [config]   - 1
[2019-04-02 04:06:07] [config] lr-decay-strategy: epoch+stalled
[2019-04-02 04:06:07] [config] lr-report: true
[2019-04-02 04:06:07] [config] lr-warmup: 16000
[2019-04-02 04:06:07] [config] lr-warmup-at-reload: false
[2019-04-02 04:06:07] [config] lr-warmup-cycle: false
[2019-04-02 04:06:07] [config] lr-warmup-start-rate: 0
[2019-04-02 04:06:07] [config] max-length: 160
[2019-04-02 04:06:07] [config] max-length-crop: false
[2019-04-02 04:06:07] [config] max-length-factor: 3
[2019-04-02 04:06:07] [config] maxi-batch: 1000
[2019-04-02 04:06:07] [config] maxi-batch-sort: trg
[2019-04-02 04:06:07] [config] mini-batch: 1000
[2019-04-02 04:06:07] [config] mini-batch-fit: true
[2019-04-02 04:06:07] [config] mini-batch-fit-step: 10
[2019-04-02 04:06:07] [config] mini-batch-overstuff: 1
[2019-04-02 04:06:07] [config] mini-batch-track-lr: false
[2019-04-02 04:06:07] [config] mini-batch-understuff: 1
[2019-04-02 04:06:07] [config] mini-batch-warmup: 0
[2019-04-02 04:06:07] [config] mini-batch-words: 0
[2019-04-02 04:06:07] [config] mini-batch-words-ref: 0
[2019-04-02 04:06:07] [config] model: model/model.src1tgt0.from_new_pretrained.npz
[2019-04-02 04:06:07] [config] multi-loss-type: sum
[2019-04-02 04:06:07] [config] multi-node: false
[2019-04-02 04:06:07] [config] multi-node-overlap: true
[2019-04-02 04:06:07] [config] n-best: false
[2019-04-02 04:06:07] [config] no-nccl: true
[2019-04-02 04:06:07] [config] no-reload: false
[2019-04-02 04:06:07] [config] no-restore-corpus: true
[2019-04-02 04:06:07] [config] no-shuffle: false
[2019-04-02 04:06:07] [config] normalize: 0.6
[2019-04-02 04:06:07] [config] num-devices: 0
[2019-04-02 04:06:07] [config] optimizer: adam
[2019-04-02 04:06:07] [config] optimizer-delay: 4
[2019-04-02 04:06:07] [config] optimizer-params:
[2019-04-02 04:06:07] [config]   - 0.9
[2019-04-02 04:06:07] [config]   - 0.98
[2019-04-02 04:06:07] [config]   - 1e-09
[2019-04-02 04:06:07] [config] overwrite: false
[2019-04-02 04:06:07] [config] pretrained-model: model/model.src1tgt0.docnew.enc_depth.test_base.npz.best-perplexity.npz
[2019-04-02 04:06:07] [config] quiet: false
[2019-04-02 04:06:07] [config] quiet-translation: true
[2019-04-02 04:06:07] [config] relative-paths: false
[2019-04-02 04:06:07] [config] right-left: false
[2019-04-02 04:06:07] [config] save-freq: 5000
[2019-04-02 04:06:07] [config] seed: 1111
[2019-04-02 04:06:07] [config] shuffle-in-ram: false
[2019-04-02 04:06:07] [config] skip: false
[2019-04-02 04:06:07] [config] sqlite: ""
[2019-04-02 04:06:07] [config] sqlite-drop: false
[2019-04-02 04:06:07] [config] sync-sgd: true
[2019-04-02 04:06:07] [config] tempdir: /tmp
[2019-04-02 04:06:07] [config] tied-embeddings: false
[2019-04-02 04:06:07] [config] tied-embeddings-all: true
[2019-04-02 04:06:07] [config] tied-embeddings-src: false
[2019-04-02 04:06:07] [config] train-sets:
[2019-04-02 04:06:07] [config]   - corp/europarl.cs-en.docs.train.en.bpe.src_prev
[2019-04-02 04:06:07] [config]   - corp/europarl.cs-en.docs.train.en.bpe.src
[2019-04-02 04:06:07] [config]   - corp/europarl.cs-en.docs.train.cz.bpe
[2019-04-02 04:06:07] [config] transformer-aan-activation: swish
[2019-04-02 04:06:07] [config] transformer-aan-depth: 2
[2019-04-02 04:06:07] [config] transformer-aan-nogate: false
[2019-04-02 04:06:07] [config] transformer-decoder-autoreg: self-attention
[2019-04-02 04:06:07] [config] transformer-dim-aan: 2048
[2019-04-02 04:06:07] [config] transformer-dim-ffn: 2048
[2019-04-02 04:06:07] [config] transformer-dropout: 0.1
[2019-04-02 04:06:07] [config] transformer-dropout-attention: 0
[2019-04-02 04:06:07] [config] transformer-dropout-ffn: 0
[2019-04-02 04:06:07] [config] transformer-ffn-activation: swish
[2019-04-02 04:06:07] [config] transformer-ffn-depth: 2
[2019-04-02 04:06:07] [config] transformer-guided-alignment-layer: last
[2019-04-02 04:06:07] [config] transformer-heads: 8
[2019-04-02 04:06:07] [config] transformer-no-projection: false
[2019-04-02 04:06:07] [config] transformer-postprocess: dan
[2019-04-02 04:06:07] [config] transformer-postprocess-emb: d
[2019-04-02 04:06:07] [config] transformer-preprocess: ""
[2019-04-02 04:06:07] [config] transformer-tied-layers:
[2019-04-02 04:06:07] [config]   []
[2019-04-02 04:06:07] [config] transformer-train-position-embeddings: false
[2019-04-02 04:06:07] [config] type: transformer-context
[2019-04-02 04:06:07] [config] ulr: false
[2019-04-02 04:06:07] [config] ulr-dim-emb: 0
[2019-04-02 04:06:07] [config] ulr-dropout: 0
[2019-04-02 04:06:07] [config] ulr-keys-vectors: ""
[2019-04-02 04:06:07] [config] ulr-query-vectors: ""
[2019-04-02 04:06:07] [config] ulr-softmax-temperature: 1
[2019-04-02 04:06:07] [config] ulr-trainable-transformation: false
[2019-04-02 04:06:07] [config] valid-freq: 5000
[2019-04-02 04:06:07] [config] valid-log: model/valid_trans.gate.log
[2019-04-02 04:06:07] [config] valid-max-length: 1000
[2019-04-02 04:06:07] [config] valid-metrics:
[2019-04-02 04:06:07] [config]   - cross-entropy
[2019-04-02 04:06:07] [config]   - perplexity
[2019-04-02 04:06:07] [config]   - translation
[2019-04-02 04:06:07] [config] valid-mini-batch: 16
[2019-04-02 04:06:07] [config] valid-script-path: ./val.sh
[2019-04-02 04:06:07] [config] valid-sets:
[2019-04-02 04:06:07] [config]   - corp/europarl.cs-en.docs.dev.en.bpe.src_prev
[2019-04-02 04:06:07] [config]   - corp/europarl.cs-en.docs.dev.en.bpe.src
[2019-04-02 04:06:07] [config]   - corp/europarl.cs-en.docs.dev.cz.bpe
[2019-04-02 04:06:07] [config] valid-translation-output: data/valid.bpe.en.output
[2019-04-02 04:06:07] [config] version: v1.7.8 b59f01a 2019-04-02 03:22:27 +0200
[2019-04-02 04:06:07] [config] vocabs:
[2019-04-02 04:06:07] [config]   - corp/vocab.encz.opensub.new.yml
[2019-04-02 04:06:07] [config]   - corp/vocab.encz.opensub.new.yml
[2019-04-02 04:06:07] [config]   - corp/vocab.encz.opensub.new.yml
[2019-04-02 04:06:07] [config] word-penalty: 0
[2019-04-02 04:06:07] [config] workspace: 7800
[2019-04-02 04:06:07] [config] Loaded model has been created with Marian v1.7.8 b59f01a 2019-04-02 03:22:27 +0200
[2019-04-02 04:06:07] Using synchronous training
[2019-04-02 04:06:07] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encz.opensub.new.yml
[2019-04-02 04:06:08] [data] Setting vocabulary size for input 0 to 30000
[2019-04-02 04:06:08] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encz.opensub.new.yml
[2019-04-02 04:06:08] [data] Setting vocabulary size for input 1 to 30000
[2019-04-02 04:06:08] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encz.opensub.new.yml
[2019-04-02 04:06:08] [data] Setting vocabulary size for input 2 to 30000
[2019-04-02 04:06:08] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-04-02 04:06:08] [batching] Collecting statistics for batch fitting with step size 10
[2019-04-02 04:06:08] [memory] Extending reserved space to 7808 MB (device gpu0)
[2019-04-02 04:06:09] [comm] NCCL communicator overridden
[2019-04-02 04:06:09] [training] Using 1 GPUs
[2019-04-02 04:06:09] [memory] Reserving 311 MB, device gpu0
[2019-04-02 04:06:09] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-04-02 04:06:09] [memory] Reserving 311 MB, device gpu0
[2019-04-02 04:06:15] [batching] Done. Typical MB size is 10685 target words
[2019-04-02 04:06:15] [memory] Extending reserved space to 7808 MB (device gpu0)
[2019-04-02 04:06:15] [comm] NCCL communicator overridden
[2019-04-02 04:06:15] [training] Using 1 GPUs
[2019-04-02 04:06:15] Loading model from model/model.src1tgt0.from_new_pretrained.npz.orig.npz
[2019-04-02 04:06:18] Loading Adam parameters from model/model.src1tgt0.from_new_pretrained.npz.optimizer.npz
[2019-04-02 04:06:24] [memory] Reserving 622 MB, device gpu0
[2019-04-02 04:06:25] [training] Model reloaded from model/model.src1tgt0.from_new_pretrained.npz
[2019-04-02 04:06:25] Training started
[2019-04-02 04:06:25] [data] Shuffling data
[2019-04-02 04:06:25] [data] Done reading 620637 sentences
[2019-04-02 04:06:27] [data] Done shuffling 620637 sentences to temp files
[2019-04-02 04:06:51] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-04-02 04:06:51] [memory] Reserving 311 MB, device gpu0
[2019-04-02 04:06:51] [memory] Reserving 311 MB, device gpu0
[2019-04-02 04:06:51] Loading model from model/model.src1tgt0.from_new_pretrained.npz
[2019-04-02 04:06:54] [memory] Reserving 311 MB, device cpu0
[2019-04-02 04:06:54] [memory] Reserving 311 MB, device gpu0
[2019-04-02 04:06:54] [memory] Reserving 311 MB, device gpu0
[2019-04-02 04:12:22] Ep. 1 : Up. 3000 : Sen. 164,505 : Cost 65.01369476 : Time 373.73s : 13521.69 words/s : L.r. 1.8750e-05
[2019-04-02 04:17:59] Ep. 1 : Up. 4000 : Sen. 334,195 : Cost 65.26861572 : Time 337.23s : 15579.26 words/s : L.r. 2.5000e-05
[2019-04-02 04:23:32] Ep. 1 : Up. 5000 : Sen. 505,507 : Cost 62.69984055 : Time 332.90s : 15354.83 words/s : L.r. 3.1250e-05
[2019-04-02 04:23:32] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.npz.orig.npz
[2019-04-02 04:23:36] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.iter5000.npz
[2019-04-02 04:23:40] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.npz
[2019-04-02 04:23:45] Saving Adam parameters to model/model.src1tgt0.from_new_pretrained.npz.optimizer.npz
[2019-04-02 04:24:03] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.npz.best-cross-entropy.npz
[2019-04-02 04:24:07] [valid] Ep. 1 : Up. 5000 : cross-entropy : 41.9072 : new best
[2019-04-02 04:24:16] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.npz.best-perplexity.npz
[2019-04-02 04:24:21] [valid] Ep. 1 : Up. 5000 : perplexity : 3.87197 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-02 04:27:37] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.npz.best-translation.npz
[2019-04-02 04:27:42] [valid] Ep. 1 : Up. 5000 : translation : 30.5 : new best
[2019-04-02 04:31:33] Seen 620307 samples
[2019-04-02 04:31:33] Starting epoch 2
[2019-04-02 04:31:33] [data] Shuffling data
[2019-04-02 04:31:33] [data] Done reading 620637 sentences
[2019-04-02 04:31:35] [data] Done shuffling 620637 sentences to temp files
[2019-04-02 04:33:42] Ep. 2 : Up. 6000 : Sen. 51,969 : Cost 64.89832306 : Time 610.59s : 8419.69 words/s : L.r. 3.7500e-05
[2019-04-02 04:39:21] Ep. 2 : Up. 7000 : Sen. 223,074 : Cost 64.93989563 : Time 338.80s : 15588.96 words/s : L.r. 4.3750e-05
[2019-04-02 04:44:54] Ep. 2 : Up. 8000 : Sen. 388,765 : Cost 65.20484924 : Time 332.61s : 15426.28 words/s : L.r. 5.0000e-05
[2019-04-02 04:50:27] Ep. 2 : Up. 9000 : Sen. 557,397 : Cost 64.40704346 : Time 332.90s : 15501.44 words/s : L.r. 5.6250e-05
[2019-04-02 04:52:28] Seen 620307 samples
[2019-04-02 04:52:28] Starting epoch 3
[2019-04-02 04:52:28] [data] Shuffling data
[2019-04-02 04:52:28] [data] Done reading 620637 sentences
[2019-04-02 04:52:31] [data] Done shuffling 620637 sentences to temp files
[2019-04-02 04:56:25] Ep. 3 : Up. 10000 : Sen. 110,521 : Cost 61.88358307 : Time 358.14s : 14256.88 words/s : L.r. 6.2500e-05
[2019-04-02 04:56:25] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.npz.orig.npz
[2019-04-02 04:56:29] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.iter10000.npz
[2019-04-02 04:56:33] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.npz
[2019-04-02 04:56:38] Saving Adam parameters to model/model.src1tgt0.from_new_pretrained.npz.optimizer.npz
[2019-04-02 04:56:56] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.npz.best-cross-entropy.npz
[2019-04-02 04:57:00] [valid] Ep. 3 : Up. 10000 : cross-entropy : 41.7827 : new best
[2019-04-02 04:57:10] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.npz.best-perplexity.npz
[2019-04-02 04:57:14] [valid] Ep. 3 : Up. 10000 : perplexity : 3.85643 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-02 05:00:31] [valid] Ep. 3 : Up. 10000 : translation : 30.4 : stalled 1 times (last best: 30.5)
[2019-04-02 05:06:10] Ep. 3 : Up. 11000 : Sen. 281,544 : Cost 64.90319061 : Time 584.98s : 9018.25 words/s : L.r. 6.8750e-05
[2019-04-02 05:11:41] Ep. 3 : Up. 12000 : Sen. 447,429 : Cost 64.90328217 : Time 331.52s : 15418.47 words/s : L.r. 7.5000e-05
[2019-04-02 05:17:12] Ep. 3 : Up. 13000 : Sen. 612,963 : Cost 64.63767242 : Time 330.85s : 15386.83 words/s : L.r. 8.1250e-05
[2019-04-02 05:17:29] Seen 620307 samples
[2019-04-02 05:17:29] Starting epoch 4
[2019-04-02 05:17:29] [data] Shuffling data
[2019-04-02 05:17:29] [data] Done reading 620637 sentences
[2019-04-02 05:17:31] [data] Done shuffling 620637 sentences to temp files
[2019-04-02 05:23:15] Ep. 4 : Up. 14000 : Sen. 161,830 : Cost 65.03027344 : Time 362.48s : 14444.65 words/s : L.r. 8.7500e-05
[2019-04-02 05:28:44] Ep. 4 : Up. 15000 : Sen. 326,051 : Cost 65.38690186 : Time 329.42s : 15445.38 words/s : L.r. 9.3750e-05
[2019-04-02 05:28:44] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.npz.orig.npz
[2019-04-02 05:28:48] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.iter15000.npz
[2019-04-02 05:28:53] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.npz
[2019-04-02 05:28:57] Saving Adam parameters to model/model.src1tgt0.from_new_pretrained.npz.optimizer.npz
[2019-04-02 05:29:18] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.npz.best-cross-entropy.npz
[2019-04-02 05:29:22] [valid] Ep. 4 : Up. 15000 : cross-entropy : 41.7667 : new best
[2019-04-02 05:29:31] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.npz.best-perplexity.npz
[2019-04-02 05:29:36] [valid] Ep. 4 : Up. 15000 : perplexity : 3.85444 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-02 05:32:55] [valid] Ep. 4 : Up. 15000 : translation : 30.5 : stalled 2 times (last best: 30.5)
[2019-04-02 05:38:30] Ep. 4 : Up. 16000 : Sen. 498,172 : Cost 63.44222260 : Time 585.94s : 8873.95 words/s : L.r. 1.0000e-04
[2019-04-02 05:42:33] Seen 620307 samples
[2019-04-02 05:42:33] Starting epoch 5
[2019-04-02 05:42:33] [data] Shuffling data
[2019-04-02 05:42:33] [data] Done reading 620637 sentences
[2019-04-02 05:42:35] [data] Done shuffling 620637 sentences to temp files
[2019-04-02 05:44:22] Ep. 5 : Up. 17000 : Sen. 40,168 : Cost 64.25688934 : Time 351.88s : 14097.80 words/s : L.r. 9.7014e-05
[2019-04-02 05:49:58] Ep. 5 : Up. 18000 : Sen. 217,403 : Cost 62.60813141 : Time 336.46s : 15682.82 words/s : L.r. 9.4281e-05
[2019-04-02 05:55:34] Ep. 5 : Up. 19000 : Sen. 385,308 : Cost 65.16823578 : Time 335.57s : 15523.63 words/s : L.r. 9.1766e-05
[2019-04-02 06:01:07] Ep. 5 : Up. 20000 : Sen. 551,656 : Cost 64.92190552 : Time 332.87s : 15439.85 words/s : L.r. 8.9443e-05
[2019-04-02 06:01:07] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.npz.orig.npz
[2019-04-02 06:01:11] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.iter20000.npz
[2019-04-02 06:01:15] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.npz
[2019-04-02 06:01:20] Saving Adam parameters to model/model.src1tgt0.from_new_pretrained.npz.optimizer.npz
[2019-04-02 06:01:38] [valid] Ep. 5 : Up. 20000 : cross-entropy : 41.788 : stalled 1 times (last best: 41.7667)
[2019-04-02 06:01:48] [valid] Ep. 5 : Up. 20000 : perplexity : 3.85709 : stalled 1 times (last best: 3.85444)
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-02 06:05:05] [valid] Ep. 5 : Up. 20000 : translation : 30.5 : stalled 3 times (last best: 30.5)
[2019-04-02 06:07:23] Seen 620307 samples
[2019-04-02 06:07:23] Starting epoch 6
[2019-04-02 06:07:23] [data] Shuffling data
[2019-04-02 06:07:23] [data] Done reading 620637 sentences
[2019-04-02 06:07:25] [data] Done shuffling 620637 sentences to temp files
[2019-04-02 06:10:53] Ep. 6 : Up. 21000 : Sen. 93,998 : Cost 63.94733429 : Time 586.57s : 8413.42 words/s : L.r. 8.7287e-05
[2019-04-02 06:16:29] Ep. 6 : Up. 22000 : Sen. 269,432 : Cost 62.04050446 : Time 335.61s : 15454.15 words/s : L.r. 8.5280e-05
[2019-04-02 06:22:06] Ep. 6 : Up. 23000 : Sen. 438,805 : Cost 65.37220764 : Time 336.73s : 15616.45 words/s : L.r. 8.3406e-05
[2019-04-02 06:27:42] Ep. 6 : Up. 24000 : Sen. 605,892 : Cost 65.60636139 : Time 336.13s : 15514.11 words/s : L.r. 8.1650e-05
[2019-04-02 06:28:16] Seen 620307 samples
[2019-04-02 06:28:16] Starting epoch 7
[2019-04-02 06:28:16] [data] Shuffling data
[2019-04-02 06:28:16] [data] Done reading 620637 sentences
[2019-04-02 06:28:18] [data] Done shuffling 620637 sentences to temp files
[2019-04-02 06:33:44] Ep. 7 : Up. 25000 : Sen. 154,904 : Cost 65.20640564 : Time 362.41s : 14469.24 words/s : L.r. 8.0000e-05
[2019-04-02 06:33:44] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.npz.orig.npz
[2019-04-02 06:33:49] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.iter25000.npz
[2019-04-02 06:33:53] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.npz
[2019-04-02 06:33:57] Saving Adam parameters to model/model.src1tgt0.from_new_pretrained.npz.optimizer.npz
[2019-04-02 06:34:16] [valid] Ep. 7 : Up. 25000 : cross-entropy : 41.7905 : stalled 2 times (last best: 41.7667)
[2019-04-02 06:34:25] [valid] Ep. 7 : Up. 25000 : perplexity : 3.8574 : stalled 2 times (last best: 3.85444)
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-02 06:37:42] [valid] Ep. 7 : Up. 25000 : translation : 30.5 : stalled 4 times (last best: 30.5)
[2019-04-02 06:43:04] Ep. 7 : Up. 26000 : Sen. 312,218 : Cost 64.88562012 : Time 559.94s : 8664.33 words/s : L.r. 7.8446e-05
[2019-04-02 06:48:46] Ep. 7 : Up. 27000 : Sen. 483,052 : Cost 65.75013733 : Time 341.27s : 15665.70 words/s : L.r. 7.6980e-05
[2019-04-02 06:53:08] Seen 620307 samples
[2019-04-02 06:53:08] Starting epoch 8
[2019-04-02 06:53:08] [data] Shuffling data
[2019-04-02 06:53:09] [data] Done reading 620637 sentences
[2019-04-02 06:53:11] [data] Done shuffling 620637 sentences to temp files
[2019-04-02 06:54:45] Ep. 8 : Up. 28000 : Sen. 33,395 : Cost 63.33627319 : Time 358.99s : 14317.83 words/s : L.r. 7.5593e-05
[2019-04-02 07:00:13] Ep. 8 : Up. 29000 : Sen. 197,925 : Cost 64.40833282 : Time 328.42s : 15342.91 words/s : L.r. 7.4278e-05
[2019-04-02 07:05:54] Ep. 8 : Up. 30000 : Sen. 374,940 : Cost 63.13810730 : Time 340.65s : 15621.05 words/s : L.r. 7.3030e-05
[2019-04-02 07:05:54] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.npz.orig.npz
[2019-04-02 07:05:58] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.iter30000.npz
[2019-04-02 07:06:02] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.npz
[2019-04-02 07:06:07] Saving Adam parameters to model/model.src1tgt0.from_new_pretrained.npz.optimizer.npz
[2019-04-02 07:06:25] [valid] Ep. 8 : Up. 30000 : cross-entropy : 41.7875 : stalled 3 times (last best: 41.7667)
[2019-04-02 07:06:34] [valid] Ep. 8 : Up. 30000 : perplexity : 3.85703 : stalled 3 times (last best: 3.85444)
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-02 07:09:52] [valid] Ep. 8 : Up. 30000 : translation : 30.4 : stalled 5 times (last best: 30.5)
[2019-04-02 07:15:22] Ep. 8 : Up. 31000 : Sen. 539,324 : Cost 65.21996307 : Time 568.38s : 8964.02 words/s : L.r. 7.1842e-05
[2019-04-02 07:18:01] Seen 620307 samples
[2019-04-02 07:18:01] Starting epoch 9
[2019-04-02 07:18:01] [data] Shuffling data
[2019-04-02 07:18:02] [data] Done reading 620637 sentences
[2019-04-02 07:18:04] [data] Done shuffling 620637 sentences to temp files
[2019-04-02 07:21:26] Ep. 9 : Up. 32000 : Sen. 90,533 : Cost 64.11723328 : Time 363.54s : 14406.02 words/s : L.r. 7.0711e-05
[2019-04-02 07:27:01] Ep. 9 : Up. 33000 : Sen. 258,874 : Cost 65.04425049 : Time 335.33s : 15533.31 words/s : L.r. 6.9631e-05
[2019-04-02 07:32:35] Ep. 9 : Up. 34000 : Sen. 427,060 : Cost 64.71855927 : Time 334.22s : 15480.08 words/s : L.r. 6.8599e-05
[2019-04-02 07:38:00] Ep. 9 : Up. 35000 : Sen. 591,639 : Cost 63.10416794 : Time 324.76s : 15213.06 words/s : L.r. 6.7612e-05
[2019-04-02 07:38:00] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.npz.orig.npz
[2019-04-02 07:38:04] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.iter35000.npz
[2019-04-02 07:38:09] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.npz
[2019-04-02 07:38:13] Saving Adam parameters to model/model.src1tgt0.from_new_pretrained.npz.optimizer.npz
[2019-04-02 07:38:31] [valid] Ep. 9 : Up. 35000 : cross-entropy : 41.7944 : stalled 4 times (last best: 41.7667)
[2019-04-02 07:38:40] [valid] Ep. 9 : Up. 35000 : perplexity : 3.85788 : stalled 4 times (last best: 3.85444)
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-02 07:41:58] [valid] Ep. 9 : Up. 35000 : translation : 30.4 : stalled 6 times (last best: 30.5)
[2019-04-02 07:42:54] Seen 620307 samples
[2019-04-02 07:42:54] Starting epoch 10
[2019-04-02 07:42:54] [data] Shuffling data
[2019-04-02 07:42:54] [data] Done reading 620637 sentences
[2019-04-02 07:42:56] [data] Done shuffling 620637 sentences to temp files
[2019-04-02 07:48:01] Ep. 10 : Up. 36000 : Sen. 141,801 : Cost 65.11058807 : Time 601.43s : 8772.16 words/s : L.r. 6.6667e-05
[2019-04-02 07:53:30] Ep. 10 : Up. 37000 : Sen. 305,476 : Cost 64.42938232 : Time 328.81s : 15268.15 words/s : L.r. 6.5760e-05
[2019-04-02 07:59:07] Ep. 10 : Up. 38000 : Sen. 476,325 : Cost 64.75074768 : Time 337.32s : 15597.31 words/s : L.r. 6.4889e-05
[2019-04-02 08:03:48] Seen 620307 samples
[2019-04-02 08:03:48] Starting epoch 11
[2019-04-02 08:03:48] [data] Shuffling data
[2019-04-02 08:03:49] [data] Done reading 620637 sentences
[2019-04-02 08:03:51] [data] Done shuffling 620637 sentences to temp files
[2019-04-02 08:05:08] Ep. 11 : Up. 39000 : Sen. 27,885 : Cost 63.05529785 : Time 360.78s : 14303.27 words/s : L.r. 6.4051e-05
[2019-04-02 08:10:41] Ep. 11 : Up. 40000 : Sen. 192,021 : Cost 65.97824097 : Time 332.89s : 15467.59 words/s : L.r. 6.3246e-05
[2019-04-02 08:10:41] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.npz.orig.npz
[2019-04-02 08:10:46] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.iter40000.npz
[2019-04-02 08:10:50] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.npz
[2019-04-02 08:10:55] Saving Adam parameters to model/model.src1tgt0.from_new_pretrained.npz.optimizer.npz
[2019-04-02 08:11:13] [valid] Ep. 11 : Up. 40000 : cross-entropy : 41.812 : stalled 5 times (last best: 41.7667)
[2019-04-02 08:11:22] [valid] Ep. 11 : Up. 40000 : perplexity : 3.86008 : stalled 5 times (last best: 3.85444)
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-02 08:14:39] [valid] Ep. 11 : Up. 40000 : translation : 30.4 : stalled 7 times (last best: 30.5)
[2019-04-02 08:20:08] Ep. 11 : Up. 41000 : Sen. 357,526 : Cost 64.72159576 : Time 566.80s : 8986.47 words/s : L.r. 6.2470e-05
[2019-04-02 08:25:41] Ep. 11 : Up. 42000 : Sen. 532,888 : Cost 61.49188614 : Time 333.28s : 15438.82 words/s : L.r. 6.1721e-05
[2019-04-02 08:28:38] Seen 620307 samples
[2019-04-02 08:28:38] Starting epoch 12
[2019-04-02 08:28:38] [data] Shuffling data
[2019-04-02 08:28:39] [data] Done reading 620637 sentences
[2019-04-02 08:28:41] [data] Done shuffling 620637 sentences to temp files
[2019-04-02 08:31:46] Ep. 12 : Up. 43000 : Sen. 84,953 : Cost 65.01306152 : Time 365.18s : 14566.71 words/s : L.r. 6.0999e-05
[2019-04-02 08:37:18] Ep. 12 : Up. 44000 : Sen. 254,548 : Cost 63.27114487 : Time 331.80s : 15408.22 words/s : L.r. 6.0302e-05
[2019-04-02 08:42:48] Ep. 12 : Up. 45000 : Sen. 417,763 : Cost 65.55599976 : Time 329.75s : 15438.26 words/s : L.r. 5.9628e-05
[2019-04-02 08:42:48] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.npz.orig.npz
[2019-04-02 08:42:52] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.iter45000.npz
[2019-04-02 08:42:56] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.npz
[2019-04-02 08:43:01] Saving Adam parameters to model/model.src1tgt0.from_new_pretrained.npz.optimizer.npz
[2019-04-02 08:43:19] [valid] Ep. 12 : Up. 45000 : cross-entropy : 41.8112 : stalled 6 times (last best: 41.7667)
[2019-04-02 08:43:28] [valid] Ep. 12 : Up. 45000 : perplexity : 3.85999 : stalled 6 times (last best: 3.85444)
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-02 08:46:45] [valid] Ep. 12 : Up. 45000 : translation : 30.4 : stalled 8 times (last best: 30.5)
[2019-04-02 08:52:17] Ep. 12 : Up. 46000 : Sen. 582,979 : Cost 65.79704285 : Time 569.01s : 9076.18 words/s : L.r. 5.8977e-05
[2019-04-02 08:53:26] Seen 620307 samples
[2019-04-02 08:53:26] Starting epoch 13
[2019-04-02 08:53:26] [data] Shuffling data
[2019-04-02 08:53:27] [data] Done reading 620637 sentences
[2019-04-02 08:53:29] [data] Done shuffling 620637 sentences to temp files
[2019-04-02 08:58:12] Ep. 13 : Up. 47000 : Sen. 132,120 : Cost 63.03436279 : Time 355.59s : 14292.66 words/s : L.r. 5.8346e-05
[2019-04-02 09:03:41] Ep. 13 : Up. 48000 : Sen. 296,135 : Cost 64.71561432 : Time 328.24s : 15393.13 words/s : L.r. 5.7735e-05
[2019-04-02 09:09:16] Ep. 13 : Up. 49000 : Sen. 468,934 : Cost 63.36901855 : Time 335.67s : 15545.20 words/s : L.r. 5.7143e-05
[2019-04-02 09:14:18] Seen 620307 samples
[2019-04-02 09:14:18] Starting epoch 14
[2019-04-02 09:14:18] [data] Shuffling data
[2019-04-02 09:14:19] [data] Done reading 620637 sentences
[2019-04-02 09:14:21] [data] Done shuffling 620637 sentences to temp files
[2019-04-02 09:15:21] Ep. 14 : Up. 50000 : Sen. 18,745 : Cost 65.28731537 : Time 364.16s : 14487.22 words/s : L.r. 5.6569e-05
[2019-04-02 09:15:21] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.npz.orig.npz
[2019-04-02 09:15:25] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.iter50000.npz
[2019-04-02 09:15:29] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.npz
[2019-04-02 09:15:34] Saving Adam parameters to model/model.src1tgt0.from_new_pretrained.npz.optimizer.npz
[2019-04-02 09:15:52] [valid] Ep. 14 : Up. 50000 : cross-entropy : 41.8088 : stalled 7 times (last best: 41.7667)
[2019-04-02 09:16:01] [valid] Ep. 14 : Up. 50000 : perplexity : 3.85969 : stalled 7 times (last best: 3.85444)
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-02 09:19:19] [valid] Ep. 14 : Up. 50000 : translation : 30.4 : stalled 9 times (last best: 30.5)
[2019-04-02 09:24:42] Ep. 14 : Up. 51000 : Sen. 181,018 : Cost 63.79658890 : Time 561.88s : 8766.69 words/s : L.r. 5.6011e-05
[2019-04-02 09:30:22] Ep. 14 : Up. 52000 : Sen. 353,814 : Cost 64.51197815 : Time 339.62s : 15612.14 words/s : L.r. 5.5470e-05
[2019-04-02 09:36:00] Ep. 14 : Up. 53000 : Sen. 524,149 : Cost 65.00610352 : Time 337.97s : 15575.67 words/s : L.r. 5.4944e-05
[2019-04-02 09:39:11] Seen 620307 samples
[2019-04-02 09:39:11] Starting epoch 15
[2019-04-02 09:39:11] [data] Shuffling data
[2019-04-02 09:39:11] [data] Done reading 620637 sentences
[2019-04-02 09:39:13] [data] Done shuffling 620637 sentences to temp files
[2019-04-02 09:41:59] Ep. 15 : Up. 54000 : Sen. 69,039 : Cost 65.42375183 : Time 358.79s : 14345.77 words/s : L.r. 5.4433e-05
[2019-04-02 09:47:29] Ep. 15 : Up. 55000 : Sen. 235,223 : Cost 64.29202271 : Time 329.78s : 15420.89 words/s : L.r. 5.3936e-05
[2019-04-02 09:47:29] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.npz.orig.npz
[2019-04-02 09:47:33] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.iter55000.npz
[2019-04-02 09:47:37] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.npz
[2019-04-02 09:47:41] Saving Adam parameters to model/model.src1tgt0.from_new_pretrained.npz.optimizer.npz
[2019-04-02 09:48:00] [valid] Ep. 15 : Up. 55000 : cross-entropy : 41.8079 : stalled 8 times (last best: 41.7667)
[2019-04-02 09:48:09] [valid] Ep. 15 : Up. 55000 : perplexity : 3.85956 : stalled 8 times (last best: 3.85444)
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-02 09:51:26] [valid] Ep. 15 : Up. 55000 : translation : 30.4 : stalled 10 times (last best: 30.5)
[2019-04-02 09:56:58] Ep. 15 : Up. 56000 : Sen. 402,677 : Cost 64.42239380 : Time 569.77s : 9008.61 words/s : L.r. 5.3452e-05
[2019-04-02 10:02:32] Ep. 15 : Up. 57000 : Sen. 572,002 : Cost 64.10008240 : Time 333.62s : 15475.90 words/s : L.r. 5.2981e-05
[2019-04-02 10:04:01] Seen 620307 samples
[2019-04-02 10:04:01] Starting epoch 16
[2019-04-02 10:04:01] [data] Shuffling data
[2019-04-02 10:04:01] [data] Done reading 620637 sentences
[2019-04-02 10:04:03] [data] Done shuffling 620637 sentences to temp files
[2019-04-02 10:08:39] Ep. 16 : Up. 58000 : Sen. 129,771 : Cost 63.28935242 : Time 367.40s : 14592.37 words/s : L.r. 5.2523e-05
[2019-04-02 10:14:08] Ep. 16 : Up. 59000 : Sen. 295,461 : Cost 64.49733734 : Time 328.77s : 15437.07 words/s : L.r. 5.2076e-05
[2019-04-02 10:19:34] Ep. 16 : Up. 60000 : Sen. 458,846 : Cost 63.42300797 : Time 326.23s : 15154.95 words/s : L.r. 5.1640e-05
[2019-04-02 10:19:34] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.npz.orig.npz
[2019-04-02 10:19:39] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.iter60000.npz
[2019-04-02 10:19:43] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.npz
[2019-04-02 10:19:47] Saving Adam parameters to model/model.src1tgt0.from_new_pretrained.npz.optimizer.npz
[2019-04-02 10:20:06] [valid] Ep. 16 : Up. 60000 : cross-entropy : 41.8072 : stalled 9 times (last best: 41.7667)
[2019-04-02 10:20:15] [valid] Ep. 16 : Up. 60000 : perplexity : 3.85949 : stalled 9 times (last best: 3.85444)
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-02 10:23:34] [valid] Ep. 16 : Up. 60000 : translation : 30.4 : stalled 11 times (last best: 30.5)
[2019-04-02 10:28:54] Seen 620307 samples
[2019-04-02 10:28:54] Starting epoch 17
[2019-04-02 10:28:54] [data] Shuffling data
[2019-04-02 10:28:54] [data] Done reading 620637 sentences
[2019-04-02 10:28:56] [data] Done shuffling 620637 sentences to temp files
[2019-04-02 10:29:37] Ep. 17 : Up. 61000 : Sen. 8,862 : Cost 65.10742950 : Time 603.13s : 8752.02 words/s : L.r. 5.1215e-05
[2019-04-02 10:35:14] Ep. 17 : Up. 62000 : Sen. 178,936 : Cost 64.88813782 : Time 336.10s : 15607.13 words/s : L.r. 5.0800e-05
[2019-04-02 10:40:46] Ep. 17 : Up. 63000 : Sen. 348,006 : Cost 63.79521561 : Time 332.48s : 15411.85 words/s : L.r. 5.0395e-05
[2019-04-02 10:46:20] Ep. 17 : Up. 64000 : Sen. 517,630 : Cost 63.62725067 : Time 334.15s : 15381.89 words/s : L.r. 5.0000e-05
[2019-04-02 10:49:50] Seen 620307 samples
[2019-04-02 10:49:50] Starting epoch 18
[2019-04-02 10:49:50] [data] Shuffling data
[2019-04-02 10:49:50] [data] Done reading 620637 sentences
[2019-04-02 10:49:52] [data] Done shuffling 620637 sentences to temp files
[2019-04-02 10:52:18] Ep. 18 : Up. 65000 : Sen. 60,170 : Cost 65.76989746 : Time 358.26s : 14241.67 words/s : L.r. 4.9614e-05
[2019-04-02 10:52:18] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.npz.orig.npz
[2019-04-02 10:52:23] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.iter65000.npz
[2019-04-02 10:52:27] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.npz
[2019-04-02 10:52:31] Saving Adam parameters to model/model.src1tgt0.from_new_pretrained.npz.optimizer.npz
[2019-04-02 10:52:50] [valid] Ep. 18 : Up. 65000 : cross-entropy : 41.8049 : stalled 10 times (last best: 41.7667)
[2019-04-02 10:52:59] [valid] Ep. 18 : Up. 65000 : perplexity : 3.8592 : stalled 10 times (last best: 3.85444)
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-02 10:56:19] [valid] Ep. 18 : Up. 65000 : translation : 30.4 : stalled 12 times (last best: 30.5)
[2019-04-02 10:56:19] Training finished
[2019-04-02 10:56:19] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.npz.orig.npz
[2019-04-02 10:56:23] Saving model weights and runtime parameters to model/model.src1tgt0.from_new_pretrained.npz
[2019-04-02 10:56:29] Saving Adam parameters to model/model.src1tgt0.from_new_pretrained.npz.optimizer.npz
