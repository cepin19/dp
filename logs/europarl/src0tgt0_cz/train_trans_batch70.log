[2018-11-23 11:27:48] [config] after-batches: 0
[2018-11-23 11:27:48] [config] after-epochs: 0
[2018-11-23 11:27:48] [config] allow-unk: false
[2018-11-23 11:27:48] [config] batch-flexible-lr: false
[2018-11-23 11:27:48] [config] batch-normal-words: 1920
[2018-11-23 11:27:48] [config] beam-size: 6
[2018-11-23 11:27:48] [config] best-deep: false
[2018-11-23 11:27:48] [config] clip-gemm: 0
[2018-11-23 11:27:48] [config] clip-norm: 5
[2018-11-23 11:27:48] [config] cost-type: ce-mean
[2018-11-23 11:27:48] [config] cpu-threads: 0
[2018-11-23 11:27:48] [config] data-weighting-type: sentence
[2018-11-23 11:27:48] [config] dec-cell: gru
[2018-11-23 11:27:48] [config] dec-cell-base-depth: 2
[2018-11-23 11:27:48] [config] dec-cell-high-depth: 1
[2018-11-23 11:27:48] [config] dec-depth: 6
[2018-11-23 11:27:48] [config] devices:
[2018-11-23 11:27:48] [config]   - 0
[2018-11-23 11:27:48] [config] dim-emb: 512
[2018-11-23 11:27:48] [config] dim-rnn: 1024
[2018-11-23 11:27:48] [config] dim-vocabs:
[2018-11-23 11:27:48] [config]   - 0
[2018-11-23 11:27:48] [config]   - 0
[2018-11-23 11:27:48] [config] disp-freq: 500
[2018-11-23 11:27:48] [config] disp-label-counts: false
[2018-11-23 11:27:48] [config] dropout-rnn: 0
[2018-11-23 11:27:48] [config] dropout-src: 0
[2018-11-23 11:27:48] [config] dropout-trg: 0
[2018-11-23 11:27:48] [config] dump-config: false
[2018-11-23 11:27:48] [config] early-stopping: 10
[2018-11-23 11:27:48] [config] embedding-fix-src: false
[2018-11-23 11:27:48] [config] embedding-fix-trg: false
[2018-11-23 11:27:48] [config] embedding-normalization: false
[2018-11-23 11:27:48] [config] enc-cell: gru
[2018-11-23 11:27:48] [config] enc-cell-depth: 1
[2018-11-23 11:27:48] [config] enc-depth: 6
[2018-11-23 11:27:48] [config] enc-type: bidirectional
[2018-11-23 11:27:48] [config] exponential-smoothing: 0.0001
[2018-11-23 11:27:48] [config] grad-dropping-momentum: 0
[2018-11-23 11:27:48] [config] grad-dropping-rate: 0
[2018-11-23 11:27:48] [config] grad-dropping-warmup: 100
[2018-11-23 11:27:48] [config] guided-alignment-cost: ce
[2018-11-23 11:27:48] [config] guided-alignment-weight: 1
[2018-11-23 11:27:48] [config] ignore-model-config: false
[2018-11-23 11:27:48] [config] interpolate-env-vars: false
[2018-11-23 11:27:48] [config] keep-best: false
[2018-11-23 11:27:48] [config] label-smoothing: 0.1
[2018-11-23 11:27:48] [config] layer-normalization: false
[2018-11-23 11:27:48] [config] learn-rate: 0.0003
[2018-11-23 11:27:48] [config] log: model/train_trans.log
[2018-11-23 11:27:48] [config] log-level: info
[2018-11-23 11:27:48] [config] lr-decay: 0
[2018-11-23 11:27:48] [config] lr-decay-freq: 50000
[2018-11-23 11:27:48] [config] lr-decay-inv-sqrt: 16000
[2018-11-23 11:27:48] [config] lr-decay-repeat-warmup: false
[2018-11-23 11:27:48] [config] lr-decay-reset-optimizer: false
[2018-11-23 11:27:48] [config] lr-decay-start:
[2018-11-23 11:27:48] [config]   - 10
[2018-11-23 11:27:48] [config]   - 1
[2018-11-23 11:27:48] [config] lr-decay-strategy: epoch+stalled
[2018-11-23 11:27:48] [config] lr-report: true
[2018-11-23 11:27:48] [config] lr-warmup: 16000
[2018-11-23 11:27:48] [config] lr-warmup-at-reload: false
[2018-11-23 11:27:48] [config] lr-warmup-cycle: false
[2018-11-23 11:27:48] [config] lr-warmup-start-rate: 0
[2018-11-23 11:27:48] [config] max-length: 80
[2018-11-23 11:27:48] [config] max-length-crop: false
[2018-11-23 11:27:48] [config] max-length-factor: 3
[2018-11-23 11:27:48] [config] maxi-batch: 1000
[2018-11-23 11:27:48] [config] maxi-batch-sort: trg
[2018-11-23 11:27:48] [config] mini-batch: 70
[2018-11-23 11:27:48] [config] mini-batch-fit: false
[2018-11-23 11:27:48] [config] mini-batch-fit-step: 10
[2018-11-23 11:27:48] [config] mini-batch-words: 0
[2018-11-23 11:27:48] [config] model: model/model.src0tgt0.trans.batch70.npz
[2018-11-23 11:27:48] [config] multi-node: false
[2018-11-23 11:27:48] [config] multi-node-overlap: true
[2018-11-23 11:27:48] [config] n-best: false
[2018-11-23 11:27:48] [config] no-reload: false
[2018-11-23 11:27:48] [config] no-restore-corpus: false
[2018-11-23 11:27:48] [config] no-shuffle: false
[2018-11-23 11:27:48] [config] normalize: 0.6
[2018-11-23 11:27:48] [config] optimizer: adam
[2018-11-23 11:27:48] [config] optimizer-delay: 4
[2018-11-23 11:27:48] [config] optimizer-params:
[2018-11-23 11:27:48] [config]   - 0.9
[2018-11-23 11:27:48] [config]   - 0.98
[2018-11-23 11:27:48] [config]   - 1e-09
[2018-11-23 11:27:48] [config] overwrite: false
[2018-11-23 11:27:48] [config] quiet: false
[2018-11-23 11:27:48] [config] quiet-translation: true
[2018-11-23 11:27:48] [config] relative-paths: false
[2018-11-23 11:27:48] [config] right-left: false
[2018-11-23 11:27:48] [config] save-freq: 5000
[2018-11-23 11:27:48] [config] seed: 1111
[2018-11-23 11:27:48] [config] skip: false
[2018-11-23 11:27:48] [config] sqlite: ""
[2018-11-23 11:27:48] [config] sqlite-drop: false
[2018-11-23 11:27:48] [config] sync-sgd: true
[2018-11-23 11:27:48] [config] tempdir: /tmp
[2018-11-23 11:27:48] [config] tied-embeddings: false
[2018-11-23 11:27:48] [config] tied-embeddings-all: true
[2018-11-23 11:27:48] [config] tied-embeddings-src: false
[2018-11-23 11:27:48] [config] train-sets:
[2018-11-23 11:27:48] [config]   - corp/europarl.cs-en.docs.train.en.bpe
[2018-11-23 11:27:48] [config]   - corp/europarl.cs-en.docs.train.cz.bpe
[2018-11-23 11:27:48] [config] transformer-aan-activation: swish
[2018-11-23 11:27:48] [config] transformer-aan-depth: 2
[2018-11-23 11:27:48] [config] transformer-aan-nogate: false
[2018-11-23 11:27:48] [config] transformer-decoder-autoreg: self-attention
[2018-11-23 11:27:48] [config] transformer-dim-aan: 2048
[2018-11-23 11:27:48] [config] transformer-dim-ffn: 2048
[2018-11-23 11:27:48] [config] transformer-dropout: 0.1
[2018-11-23 11:27:48] [config] transformer-dropout-attention: 0
[2018-11-23 11:27:48] [config] transformer-dropout-ffn: 0
[2018-11-23 11:27:48] [config] transformer-ffn-activation: swish
[2018-11-23 11:27:48] [config] transformer-ffn-depth: 2
[2018-11-23 11:27:48] [config] transformer-guided-alignment-layer: last
[2018-11-23 11:27:48] [config] transformer-heads: 8
[2018-11-23 11:27:48] [config] transformer-no-projection: false
[2018-11-23 11:27:48] [config] transformer-postprocess: dan
[2018-11-23 11:27:48] [config] transformer-postprocess-emb: d
[2018-11-23 11:27:48] [config] transformer-preprocess: ""
[2018-11-23 11:27:48] [config] transformer-tied-layers:
[2018-11-23 11:27:48] [config]   []
[2018-11-23 11:27:48] [config] type: transformer
[2018-11-23 11:27:48] [config] valid-freq: 5000
[2018-11-23 11:27:48] [config] valid-log: model/valid_trans.log
[2018-11-23 11:27:48] [config] valid-max-length: 1000
[2018-11-23 11:27:48] [config] valid-metrics:
[2018-11-23 11:27:48] [config]   - cross-entropy
[2018-11-23 11:27:48] [config]   - perplexity
[2018-11-23 11:27:48] [config]   - translation
[2018-11-23 11:27:48] [config] valid-mini-batch: 64
[2018-11-23 11:27:48] [config] valid-script-path: ./val.sh
[2018-11-23 11:27:48] [config] valid-sets:
[2018-11-23 11:27:48] [config]   - corp/europarl.cs-en.docs.dev.en.bpe
[2018-11-23 11:27:48] [config]   - corp/europarl.cs-en.docs.dev.cz.bpe
[2018-11-23 11:27:48] [config] valid-translation-output: data/valid.bpe.en.output
[2018-11-23 11:27:48] [config] version: false
[2018-11-23 11:27:48] [config] vocabs:
[2018-11-23 11:27:48] [config]   - corp/vocab.encs.europarl.yml
[2018-11-23 11:27:48] [config]   - corp/vocab.encs.europarl.yml
[2018-11-23 11:27:48] [config] word-penalty: 0
[2018-11-23 11:27:48] [config] workspace: 2048
[2018-11-23 11:27:48] [config] Model created with Marian false
[2018-11-23 11:27:48] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.europarl.yml
[2018-11-23 11:27:49] [data] Setting vocabulary size for input 0 to 32000
[2018-11-23 11:27:49] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.europarl.yml
[2018-11-23 11:27:49] [data] Setting vocabulary size for input 1 to 32000
[2018-11-23 11:27:50] [memory] Extending reserved space to 2048 MB (device gpu0)
[2018-11-23 11:27:50] Training started
[2018-11-23 11:27:50] [data] Shuffling files
[2018-11-23 11:27:52] [data] Done
[2018-11-23 11:27:57] [memory] Reserving 230 MB, device gpu0
[2018-11-23 11:27:59] [memory] Reserving 230 MB, device gpu0
[2018-11-23 11:28:05] [memory] Reserving 461 MB, device gpu0
[2018-11-23 11:28:05] [memory] Reserving 230 MB, device gpu0
[2018-11-23 11:31:38] Ep. 1 : Up. 500 : Sen. 35000 : Cost 287.03 : Time 228.39s : 4467.30 words/s : L.r. 9.3750e-06
[2018-11-23 11:33:18] Ep. 1 : Up. 1000 : Sen. 70000 : Cost 252.24 : Time 100.28s : 10444.57 words/s : L.r. 1.8750e-05
[2018-11-23 11:34:52] Ep. 1 : Up. 1500 : Sen. 105000 : Cost 231.27 : Time 94.30s : 10921.43 words/s : L.r. 2.8125e-05
[2018-11-23 11:36:26] Ep. 1 : Up. 2000 : Sen. 140000 : Cost 228.94 : Time 94.15s : 11040.97 words/s : L.r. 3.7500e-05
[2018-11-23 11:38:00] Ep. 1 : Up. 2500 : Sen. 175000 : Cost 218.14 : Time 93.26s : 10961.45 words/s : L.r. 4.6875e-05
[2018-11-23 11:39:33] Ep. 1 : Up. 3000 : Sen. 210000 : Cost 212.73 : Time 93.47s : 11137.24 words/s : L.r. 5.6250e-05
[2018-11-23 11:41:10] Ep. 1 : Up. 3500 : Sen. 245000 : Cost 211.50 : Time 96.70s : 11117.05 words/s : L.r. 6.5625e-05
[2018-11-23 11:42:40] Ep. 1 : Up. 4000 : Sen. 280000 : Cost 188.59 : Time 90.76s : 10960.71 words/s : L.r. 7.5000e-05
[2018-11-23 11:44:14] Ep. 1 : Up. 4500 : Sen. 315000 : Cost 190.41 : Time 93.46s : 11089.77 words/s : L.r. 8.4375e-05
[2018-11-23 11:45:48] Ep. 1 : Up. 5000 : Sen. 350000 : Cost 183.46 : Time 94.04s : 10981.26 words/s : L.r. 9.3750e-05
[2018-11-23 11:45:55] [valid] Ep. 1 : Up. 5000 : cross-entropy : 174.85 : new best
[2018-11-23 11:46:02] [valid] Ep. 1 : Up. 5000 : perplexity : 283.82 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2018-11-23 12:03:02] [valid] Ep. 1 : Up. 5000 : translation : 1.18 : new best
[2018-11-23 12:03:02] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-23 12:03:06] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.iter5000.npz
[2018-11-23 12:03:10] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz
[2018-11-23 12:03:14] Saving Adam parameters to model/model.src0tgt0.trans.batch70.npz.optimizer.npz
[2018-11-23 12:04:55] Ep. 1 : Up. 5500 : Sen. 385000 : Cost 179.77 : Time 1147.28s : 910.00 words/s : L.r. 1.0313e-04
[2018-11-23 12:06:29] Ep. 1 : Up. 6000 : Sen. 420000 : Cost 172.06 : Time 93.99s : 10968.59 words/s : L.r. 1.1250e-04
[2018-11-23 12:08:02] Ep. 1 : Up. 6500 : Sen. 455000 : Cost 165.91 : Time 93.23s : 10987.68 words/s : L.r. 1.2188e-04
[2018-11-23 12:09:37] Ep. 1 : Up. 7000 : Sen. 490000 : Cost 163.88 : Time 94.63s : 10997.63 words/s : L.r. 1.3125e-04
[2018-11-23 12:11:13] Ep. 1 : Up. 7500 : Sen. 525000 : Cost 161.88 : Time 95.74s : 11060.08 words/s : L.r. 1.4063e-04
[2018-11-23 12:12:45] Ep. 1 : Up. 8000 : Sen. 560000 : Cost 149.47 : Time 92.23s : 10963.75 words/s : L.r. 1.5000e-04
[2018-11-23 12:14:21] Ep. 1 : Up. 8500 : Sen. 594964 : Cost 149.79 : Time 95.86s : 10962.86 words/s : L.r. 1.5938e-04
[2018-11-23 12:14:59] Seen 609664 samples
[2018-11-23 12:14:59] Starting epoch 2
[2018-11-23 12:14:59] [data] Shuffling files
[2018-11-23 12:15:01] [data] Done
[2018-11-23 12:16:00] Ep. 2 : Up. 9000 : Sen. 20300 : Cost 138.81 : Time 99.57s : 10275.08 words/s : L.r. 1.6875e-04
[2018-11-23 12:17:35] Ep. 2 : Up. 9500 : Sen. 55300 : Cost 133.82 : Time 94.23s : 10913.95 words/s : L.r. 1.7813e-04
[2018-11-23 12:19:09] Ep. 2 : Up. 10000 : Sen. 90300 : Cost 127.60 : Time 94.07s : 10816.52 words/s : L.r. 1.8750e-04
[2018-11-23 12:19:16] [valid] Ep. 2 : Up. 10000 : cross-entropy : 113.859 : new best
[2018-11-23 12:19:23] [valid] Ep. 2 : Up. 10000 : perplexity : 39.5703 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2018-11-23 12:29:52] [valid] Ep. 2 : Up. 10000 : translation : 7.79 : new best
[2018-11-23 12:29:52] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-23 12:29:56] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.iter10000.npz
[2018-11-23 12:30:00] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz
[2018-11-23 12:30:04] Saving Adam parameters to model/model.src0tgt0.trans.batch70.npz.optimizer.npz
[2018-11-23 12:31:47] Ep. 2 : Up. 10500 : Sen. 125300 : Cost 126.22 : Time 758.20s : 1378.24 words/s : L.r. 1.9688e-04
[2018-11-23 12:33:23] Ep. 2 : Up. 11000 : Sen. 160300 : Cost 121.66 : Time 95.56s : 10952.23 words/s : L.r. 2.0625e-04
[2018-11-23 12:34:56] Ep. 2 : Up. 11500 : Sen. 195300 : Cost 116.12 : Time 93.49s : 11047.36 words/s : L.r. 2.1563e-04
[2018-11-23 12:36:31] Ep. 2 : Up. 12000 : Sen. 230300 : Cost 114.45 : Time 95.04s : 10971.74 words/s : L.r. 2.2500e-04
[2018-11-23 12:38:03] Ep. 2 : Up. 12500 : Sen. 265300 : Cost 107.63 : Time 91.75s : 10978.83 words/s : L.r. 2.3438e-04
[2018-11-23 12:39:38] Ep. 2 : Up. 13000 : Sen. 300300 : Cost 110.18 : Time 95.01s : 11025.72 words/s : L.r. 2.4375e-04
[2018-11-23 12:41:14] Ep. 2 : Up. 13500 : Sen. 335300 : Cost 109.27 : Time 95.88s : 11050.67 words/s : L.r. 2.5313e-04
[2018-11-23 12:42:46] Ep. 2 : Up. 14000 : Sen. 370300 : Cost 101.62 : Time 91.84s : 10899.39 words/s : L.r. 2.6250e-04
[2018-11-23 12:44:19] Ep. 2 : Up. 14500 : Sen. 405300 : Cost 102.85 : Time 93.57s : 10963.02 words/s : L.r. 2.7188e-04
[2018-11-23 12:45:55] Ep. 2 : Up. 15000 : Sen. 440300 : Cost 105.01 : Time 96.21s : 10994.54 words/s : L.r. 2.8125e-04
[2018-11-23 12:46:02] [valid] Ep. 2 : Up. 15000 : cross-entropy : 75.5813 : new best
[2018-11-23 12:46:09] [valid] Ep. 2 : Up. 15000 : perplexity : 11.491 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2018-11-23 12:50:53] [valid] Ep. 2 : Up. 15000 : translation : 19.23 : new best
[2018-11-23 12:50:53] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-23 12:50:57] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.iter15000.npz
[2018-11-23 12:51:01] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz
[2018-11-23 12:51:05] Saving Adam parameters to model/model.src0tgt0.trans.batch70.npz.optimizer.npz
[2018-11-23 12:52:43] Ep. 2 : Up. 15500 : Sen. 475300 : Cost 98.04 : Time 408.13s : 2451.89 words/s : L.r. 2.9063e-04
[2018-11-23 12:54:20] Ep. 2 : Up. 16000 : Sen. 510300 : Cost 104.14 : Time 96.21s : 11067.38 words/s : L.r. 3.0000e-04
[2018-11-23 12:55:53] Ep. 2 : Up. 16500 : Sen. 545300 : Cost 99.87 : Time 93.68s : 11015.73 words/s : L.r. 2.9542e-04
[2018-11-23 12:57:28] Ep. 2 : Up. 17000 : Sen. 580264 : Cost 98.63 : Time 94.33s : 10912.32 words/s : L.r. 2.9104e-04
[2018-11-23 12:58:47] Seen 609664 samples
[2018-11-23 12:58:47] Starting epoch 3
[2018-11-23 12:58:47] [data] Shuffling files
[2018-11-23 12:58:50] [data] Done
[2018-11-23 12:59:11] Ep. 3 : Up. 17500 : Sen. 5600 : Cost 99.76 : Time 103.09s : 10266.19 words/s : L.r. 2.8685e-04
[2018-11-23 13:00:45] Ep. 3 : Up. 18000 : Sen. 40600 : Cost 94.80 : Time 94.47s : 10868.29 words/s : L.r. 2.8284e-04
[2018-11-23 13:02:20] Ep. 3 : Up. 18500 : Sen. 75600 : Cost 94.85 : Time 94.48s : 10931.31 words/s : L.r. 2.7899e-04
[2018-11-23 13:03:53] Ep. 3 : Up. 19000 : Sen. 110600 : Cost 92.92 : Time 93.55s : 10894.54 words/s : L.r. 2.7530e-04
[2018-11-23 13:05:28] Ep. 3 : Up. 19500 : Sen. 145600 : Cost 94.28 : Time 94.39s : 10993.17 words/s : L.r. 2.7175e-04
[2018-11-23 13:07:03] Ep. 3 : Up. 20000 : Sen. 180600 : Cost 94.71 : Time 95.52s : 10996.92 words/s : L.r. 2.6833e-04
[2018-11-23 13:07:10] [valid] Ep. 3 : Up. 20000 : cross-entropy : 64.7294 : new best
[2018-11-23 13:07:17] [valid] Ep. 3 : Up. 20000 : perplexity : 8.09307 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2018-11-23 13:10:53] [valid] Ep. 3 : Up. 20000 : translation : 23.01 : new best
[2018-11-23 13:10:53] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-23 13:10:57] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.iter20000.npz
[2018-11-23 13:11:01] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz
[2018-11-23 13:11:05] Saving Adam parameters to model/model.src0tgt0.trans.batch70.npz.optimizer.npz
[2018-11-23 13:12:48] Ep. 3 : Up. 20500 : Sen. 215600 : Cost 92.05 : Time 344.33s : 2987.10 words/s : L.r. 2.6504e-04
[2018-11-23 13:14:22] Ep. 3 : Up. 21000 : Sen. 250600 : Cost 91.89 : Time 94.82s : 10874.83 words/s : L.r. 2.6186e-04
[2018-11-23 13:15:58] Ep. 3 : Up. 21500 : Sen. 285600 : Cost 91.86 : Time 95.18s : 10913.52 words/s : L.r. 2.5880e-04
[2018-11-23 13:17:34] Ep. 3 : Up. 22000 : Sen. 320600 : Cost 93.53 : Time 96.09s : 11022.96 words/s : L.r. 2.5584e-04
[2018-11-23 13:19:05] Ep. 3 : Up. 22500 : Sen. 355600 : Cost 86.37 : Time 91.17s : 10880.29 words/s : L.r. 2.5298e-04
[2018-11-23 13:20:39] Ep. 3 : Up. 23000 : Sen. 390600 : Cost 90.47 : Time 94.47s : 10959.66 words/s : L.r. 2.5022e-04
[2018-11-23 13:22:13] Ep. 3 : Up. 23500 : Sen. 425600 : Cost 89.73 : Time 94.08s : 11003.07 words/s : L.r. 2.4754e-04
[2018-11-23 13:23:48] Ep. 3 : Up. 24000 : Sen. 460600 : Cost 89.75 : Time 94.97s : 10976.16 words/s : L.r. 2.4495e-04
[2018-11-23 13:25:22] Ep. 3 : Up. 24500 : Sen. 495600 : Cost 88.10 : Time 93.30s : 10989.83 words/s : L.r. 2.4244e-04
[2018-11-23 13:26:55] Ep. 3 : Up. 25000 : Sen. 530600 : Cost 87.71 : Time 93.56s : 10949.62 words/s : L.r. 2.4000e-04
[2018-11-23 13:27:02] [valid] Ep. 3 : Up. 25000 : cross-entropy : 59.5179 : new best
[2018-11-23 13:27:09] [valid] Ep. 3 : Up. 25000 : perplexity : 6.83911 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2018-11-23 13:31:07] [valid] Ep. 3 : Up. 25000 : translation : 24.67 : new best
[2018-11-23 13:31:07] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-23 13:31:11] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.iter25000.npz
[2018-11-23 13:31:15] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz
[2018-11-23 13:31:19] Saving Adam parameters to model/model.src0tgt0.trans.batch70.npz.optimizer.npz
[2018-11-23 13:33:03] Ep. 3 : Up. 25500 : Sen. 565564 : Cost 90.20 : Time 367.84s : 2868.53 words/s : L.r. 2.3764e-04
[2018-11-23 13:34:38] Ep. 3 : Up. 26000 : Sen. 600564 : Cost 86.76 : Time 94.94s : 10736.41 words/s : L.r. 2.3534e-04
[2018-11-23 13:35:03] Seen 609664 samples
[2018-11-23 13:35:03] Starting epoch 4
[2018-11-23 13:35:03] [data] Shuffling files
[2018-11-23 13:35:06] [data] Done
[2018-11-23 13:36:20] Ep. 4 : Up. 26500 : Sen. 25900 : Cost 86.93 : Time 102.00s : 10204.54 words/s : L.r. 2.3311e-04
[2018-11-23 13:37:53] Ep. 4 : Up. 27000 : Sen. 60900 : Cost 83.86 : Time 93.09s : 10852.69 words/s : L.r. 2.3094e-04
[2018-11-23 13:39:30] Ep. 4 : Up. 27500 : Sen. 95900 : Cost 89.20 : Time 97.29s : 11008.65 words/s : L.r. 2.2883e-04
[2018-11-23 13:41:03] Ep. 4 : Up. 28000 : Sen. 130900 : Cost 83.62 : Time 92.72s : 10907.87 words/s : L.r. 2.2678e-04
[2018-11-23 13:42:39] Ep. 4 : Up. 28500 : Sen. 165900 : Cost 87.96 : Time 96.41s : 10982.39 words/s : L.r. 2.2478e-04
[2018-11-23 13:44:13] Ep. 4 : Up. 29000 : Sen. 200900 : Cost 84.67 : Time 93.89s : 10926.69 words/s : L.r. 2.2283e-04
[2018-11-23 13:45:47] Ep. 4 : Up. 29500 : Sen. 235900 : Cost 83.47 : Time 93.53s : 10836.28 words/s : L.r. 2.2094e-04
[2018-11-23 13:47:22] Ep. 4 : Up. 30000 : Sen. 270900 : Cost 86.35 : Time 95.54s : 10977.59 words/s : L.r. 2.1909e-04
[2018-11-23 13:47:29] [valid] Ep. 4 : Up. 30000 : cross-entropy : 56.5898 : new best
[2018-11-23 13:47:36] [valid] Ep. 4 : Up. 30000 : perplexity : 6.22185 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2018-11-23 13:50:43] [valid] Ep. 4 : Up. 30000 : translation : 25.71 : new best
[2018-11-23 13:50:43] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-23 13:50:47] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.iter30000.npz
[2018-11-23 13:50:51] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz
[2018-11-23 13:50:56] Saving Adam parameters to model/model.src0tgt0.trans.batch70.npz.optimizer.npz
[2018-11-23 13:52:41] Ep. 4 : Up. 30500 : Sen. 305900 : Cost 85.99 : Time 318.11s : 3299.62 words/s : L.r. 2.1729e-04
[2018-11-23 13:54:16] Ep. 4 : Up. 31000 : Sen. 340900 : Cost 84.35 : Time 95.31s : 10809.22 words/s : L.r. 2.1553e-04
[2018-11-23 13:55:47] Ep. 4 : Up. 31500 : Sen. 375900 : Cost 80.05 : Time 90.90s : 10794.57 words/s : L.r. 2.1381e-04
[2018-11-23 13:57:24] Ep. 4 : Up. 32000 : Sen. 410900 : Cost 86.99 : Time 97.29s : 10938.07 words/s : L.r. 2.1213e-04
[2018-11-23 13:58:58] Ep. 4 : Up. 32500 : Sen. 445900 : Cost 84.24 : Time 94.34s : 10991.61 words/s : L.r. 2.1049e-04
[2018-11-23 14:00:34] Ep. 4 : Up. 33000 : Sen. 480900 : Cost 85.37 : Time 95.41s : 10977.98 words/s : L.r. 2.0889e-04
[2018-11-23 14:02:09] Ep. 4 : Up. 33500 : Sen. 515900 : Cost 84.46 : Time 95.62s : 10920.10 words/s : L.r. 2.0733e-04
[2018-11-23 14:03:44] Ep. 4 : Up. 34000 : Sen. 550900 : Cost 83.39 : Time 94.20s : 10948.44 words/s : L.r. 2.0580e-04
[2018-11-23 14:05:16] Ep. 4 : Up. 34500 : Sen. 585864 : Cost 81.45 : Time 92.50s : 10861.57 words/s : L.r. 2.0430e-04
[2018-11-23 14:06:22] Seen 609664 samples
[2018-11-23 14:06:22] Starting epoch 5
[2018-11-23 14:06:22] [data] Shuffling files
[2018-11-23 14:06:24] [data] Done
[2018-11-23 14:06:59] Ep. 5 : Up. 35000 : Sen. 11200 : Cost 85.01 : Time 103.12s : 10290.85 words/s : L.r. 2.0284e-04
[2018-11-23 14:07:06] [valid] Ep. 5 : Up. 35000 : cross-entropy : 54.596 : new best
[2018-11-23 14:07:13] [valid] Ep. 5 : Up. 35000 : perplexity : 5.83375 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2018-11-23 14:10:42] [valid] Ep. 5 : Up. 35000 : translation : 26.37 : new best
[2018-11-23 14:10:42] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-23 14:10:47] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.iter35000.npz
[2018-11-23 14:10:51] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz
[2018-11-23 14:10:55] Saving Adam parameters to model/model.src0tgt0.trans.batch70.npz.optimizer.npz
[2018-11-23 14:12:38] Ep. 5 : Up. 35500 : Sen. 46200 : Cost 82.11 : Time 339.11s : 3069.95 words/s : L.r. 2.0140e-04
[2018-11-23 14:14:13] Ep. 5 : Up. 36000 : Sen. 81200 : Cost 82.32 : Time 94.79s : 10958.89 words/s : L.r. 2.0000e-04
[2018-11-23 14:15:48] Ep. 5 : Up. 36500 : Sen. 116200 : Cost 81.32 : Time 94.67s : 10900.31 words/s : L.r. 1.9863e-04
[2018-11-23 14:17:20] Ep. 5 : Up. 37000 : Sen. 151200 : Cost 79.57 : Time 92.44s : 10845.54 words/s : L.r. 1.9728e-04
[2018-11-23 14:18:56] Ep. 5 : Up. 37500 : Sen. 186200 : Cost 83.49 : Time 95.72s : 11061.20 words/s : L.r. 1.9596e-04
[2018-11-23 14:20:30] Ep. 5 : Up. 38000 : Sen. 221200 : Cost 81.69 : Time 94.44s : 10945.98 words/s : L.r. 1.9467e-04
[2018-11-23 14:22:04] Ep. 5 : Up. 38500 : Sen. 256200 : Cost 80.56 : Time 93.72s : 10928.21 words/s : L.r. 1.9340e-04
[2018-11-23 14:23:38] Ep. 5 : Up. 39000 : Sen. 291200 : Cost 82.08 : Time 94.12s : 11047.99 words/s : L.r. 1.9215e-04
[2018-11-23 14:25:14] Ep. 5 : Up. 39500 : Sen. 326200 : Cost 82.35 : Time 95.32s : 10975.88 words/s : L.r. 1.9093e-04
[2018-11-23 14:26:46] Ep. 5 : Up. 40000 : Sen. 361200 : Cost 78.65 : Time 91.93s : 10892.54 words/s : L.r. 1.8974e-04
[2018-11-23 14:26:52] [valid] Ep. 5 : Up. 40000 : cross-entropy : 53.2525 : new best
[2018-11-23 14:27:00] [valid] Ep. 5 : Up. 40000 : perplexity : 5.58598 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2018-11-23 14:30:34] [valid] Ep. 5 : Up. 40000 : translation : 26.88 : new best
[2018-11-23 14:30:34] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-23 14:30:38] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.iter40000.npz
[2018-11-23 14:30:42] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz
[2018-11-23 14:30:46] Saving Adam parameters to model/model.src0tgt0.trans.batch70.npz.optimizer.npz
[2018-11-23 14:32:31] Ep. 5 : Up. 40500 : Sen. 396200 : Cost 82.86 : Time 345.31s : 3040.34 words/s : L.r. 1.8856e-04
[2018-11-23 14:34:06] Ep. 5 : Up. 41000 : Sen. 431200 : Cost 80.61 : Time 95.15s : 10793.58 words/s : L.r. 1.8741e-04
[2018-11-23 14:35:43] Ep. 5 : Up. 41500 : Sen. 466200 : Cost 83.74 : Time 97.22s : 10911.59 words/s : L.r. 1.8628e-04
[2018-11-23 14:37:17] Ep. 5 : Up. 42000 : Sen. 501200 : Cost 79.39 : Time 93.56s : 10857.53 words/s : L.r. 1.8516e-04
[2018-11-23 14:38:54] Ep. 5 : Up. 42500 : Sen. 536200 : Cost 83.39 : Time 96.90s : 10965.28 words/s : L.r. 1.8407e-04
[2018-11-23 14:40:24] Ep. 5 : Up. 43000 : Sen. 571200 : Cost 77.11 : Time 90.75s : 10868.06 words/s : L.r. 1.8300e-04
[2018-11-23 14:42:02] Ep. 5 : Up. 43500 : Sen. 606164 : Cost 83.45 : Time 97.17s : 10932.45 words/s : L.r. 1.8194e-04
[2018-11-23 14:42:11] Seen 609664 samples
[2018-11-23 14:42:11] Starting epoch 6
[2018-11-23 14:42:11] [data] Shuffling files
[2018-11-23 14:42:13] [data] Done
[2018-11-23 14:43:41] Ep. 6 : Up. 44000 : Sen. 31500 : Cost 77.48 : Time 99.78s : 10162.45 words/s : L.r. 1.8091e-04
[2018-11-23 14:45:17] Ep. 6 : Up. 44500 : Sen. 66500 : Cost 79.24 : Time 95.40s : 10855.58 words/s : L.r. 1.7989e-04
[2018-11-23 14:46:53] Ep. 6 : Up. 45000 : Sen. 101500 : Cost 81.49 : Time 96.50s : 11012.34 words/s : L.r. 1.7889e-04
[2018-11-23 14:47:00] [valid] Ep. 6 : Up. 45000 : cross-entropy : 52.1024 : new best
[2018-11-23 14:47:07] [valid] Ep. 6 : Up. 45000 : perplexity : 5.38225 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2018-11-23 14:50:48] [valid] Ep. 6 : Up. 45000 : translation : 27.24 : new best
[2018-11-23 14:50:48] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-23 14:50:52] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.iter45000.npz
[2018-11-23 14:50:56] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz
[2018-11-23 14:51:00] Saving Adam parameters to model/model.src0tgt0.trans.batch70.npz.optimizer.npz
[2018-11-23 14:52:41] Ep. 6 : Up. 45500 : Sen. 136500 : Cost 77.40 : Time 347.41s : 2902.95 words/s : L.r. 1.7790e-04
[2018-11-23 14:54:14] Ep. 6 : Up. 46000 : Sen. 171500 : Cost 77.55 : Time 93.33s : 10847.16 words/s : L.r. 1.7693e-04
[2018-11-23 14:55:50] Ep. 6 : Up. 46500 : Sen. 206500 : Cost 82.08 : Time 96.49s : 11060.51 words/s : L.r. 1.7598e-04
[2018-11-23 14:57:24] Ep. 6 : Up. 47000 : Sen. 241500 : Cost 77.85 : Time 93.17s : 10903.10 words/s : L.r. 1.7504e-04
[2018-11-23 14:58:59] Ep. 6 : Up. 47500 : Sen. 276500 : Cost 80.77 : Time 95.28s : 11005.78 words/s : L.r. 1.7411e-04
[2018-11-23 15:00:32] Ep. 6 : Up. 48000 : Sen. 311500 : Cost 78.20 : Time 93.32s : 10925.86 words/s : L.r. 1.7321e-04
[2018-11-23 15:02:09] Ep. 6 : Up. 48500 : Sen. 346500 : Cost 81.84 : Time 96.30s : 11045.04 words/s : L.r. 1.7231e-04
[2018-11-23 15:03:42] Ep. 6 : Up. 49000 : Sen. 381500 : Cost 78.59 : Time 93.74s : 10907.63 words/s : L.r. 1.7143e-04
[2018-11-23 15:05:18] Ep. 6 : Up. 49500 : Sen. 416500 : Cost 79.78 : Time 95.29s : 10929.95 words/s : L.r. 1.7056e-04
[2018-11-23 15:06:50] Ep. 6 : Up. 50000 : Sen. 451500 : Cost 77.71 : Time 92.71s : 10935.36 words/s : L.r. 1.6971e-04
[2018-11-23 15:06:57] [valid] Ep. 6 : Up. 50000 : cross-entropy : 51.2128 : new best
[2018-11-23 15:07:04] [valid] Ep. 6 : Up. 50000 : perplexity : 5.22979 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2018-11-23 15:10:12] [valid] Ep. 6 : Up. 50000 : translation : 27.45 : new best
[2018-11-23 15:10:12] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-23 15:10:15] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.iter50000.npz
[2018-11-23 15:10:20] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz
[2018-11-23 15:10:24] Saving Adam parameters to model/model.src0tgt0.trans.batch70.npz.optimizer.npz
[2018-11-23 15:12:09] Ep. 6 : Up. 50500 : Sen. 486500 : Cost 79.68 : Time 318.28s : 3266.13 words/s : L.r. 1.6886e-04
[2018-11-23 15:13:44] Ep. 6 : Up. 51000 : Sen. 521500 : Cost 78.46 : Time 95.32s : 10756.00 words/s : L.r. 1.6803e-04
[2018-11-23 15:15:20] Ep. 6 : Up. 51500 : Sen. 556500 : Cost 79.80 : Time 95.74s : 10872.10 words/s : L.r. 1.6722e-04
[2018-11-23 15:16:55] Ep. 6 : Up. 52000 : Sen. 591464 : Cost 79.72 : Time 95.62s : 10882.23 words/s : L.r. 1.6641e-04
[2018-11-23 15:17:45] Seen 609664 samples
[2018-11-23 15:17:45] Starting epoch 7
[2018-11-23 15:17:45] [data] Shuffling files
[2018-11-23 15:17:47] [data] Done
[2018-11-23 15:18:37] Ep. 7 : Up. 52500 : Sen. 16800 : Cost 78.23 : Time 101.45s : 10223.95 words/s : L.r. 1.6562e-04
[2018-11-23 15:20:13] Ep. 7 : Up. 53000 : Sen. 51800 : Cost 79.53 : Time 96.77s : 10993.58 words/s : L.r. 1.6483e-04
[2018-11-23 15:21:45] Ep. 7 : Up. 53500 : Sen. 86800 : Cost 73.69 : Time 91.40s : 10811.65 words/s : L.r. 1.6406e-04
[2018-11-23 15:23:18] Ep. 7 : Up. 54000 : Sen. 121800 : Cost 77.29 : Time 93.55s : 10991.71 words/s : L.r. 1.6330e-04
[2018-11-23 15:24:52] Ep. 7 : Up. 54500 : Sen. 156800 : Cost 77.53 : Time 93.92s : 10959.13 words/s : L.r. 1.6255e-04
[2018-11-23 15:26:27] Ep. 7 : Up. 55000 : Sen. 191800 : Cost 78.34 : Time 94.84s : 10957.42 words/s : L.r. 1.6181e-04
[2018-11-23 15:26:34] [valid] Ep. 7 : Up. 55000 : cross-entropy : 50.4655 : new best
[2018-11-23 15:26:41] [valid] Ep. 7 : Up. 55000 : perplexity : 5.10505 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2018-11-23 15:30:05] [valid] Ep. 7 : Up. 55000 : translation : 27.67 : new best
[2018-11-23 15:30:05] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-23 15:30:09] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.iter55000.npz
[2018-11-23 15:30:13] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz
[2018-11-23 15:30:18] Saving Adam parameters to model/model.src0tgt0.trans.batch70.npz.optimizer.npz
[2018-11-23 15:32:03] Ep. 7 : Up. 55500 : Sen. 226800 : Cost 79.09 : Time 335.41s : 3131.79 words/s : L.r. 1.6108e-04
[2018-11-23 15:33:40] Ep. 7 : Up. 56000 : Sen. 261800 : Cost 78.43 : Time 97.03s : 10771.36 words/s : L.r. 1.6036e-04
[2018-11-23 15:35:12] Ep. 7 : Up. 56500 : Sen. 296800 : Cost 74.56 : Time 91.95s : 10782.97 words/s : L.r. 1.5965e-04
[2018-11-23 15:36:48] Ep. 7 : Up. 57000 : Sen. 331800 : Cost 79.41 : Time 96.15s : 10940.11 words/s : L.r. 1.5894e-04
[2018-11-23 15:38:24] Ep. 7 : Up. 57500 : Sen. 366800 : Cost 80.14 : Time 96.69s : 11014.40 words/s : L.r. 1.5825e-04
[2018-11-23 15:39:58] Ep. 7 : Up. 58000 : Sen. 401800 : Cost 76.97 : Time 93.67s : 10955.98 words/s : L.r. 1.5757e-04
[2018-11-23 15:41:32] Ep. 7 : Up. 58500 : Sen. 436800 : Cost 77.97 : Time 94.39s : 10981.80 words/s : L.r. 1.5689e-04
[2018-11-23 15:43:06] Ep. 7 : Up. 59000 : Sen. 471800 : Cost 76.92 : Time 93.44s : 10951.60 words/s : L.r. 1.5623e-04
[2018-11-23 15:44:39] Ep. 7 : Up. 59500 : Sen. 506800 : Cost 76.16 : Time 92.71s : 10956.38 words/s : L.r. 1.5557e-04
[2018-11-23 15:46:15] Ep. 7 : Up. 60000 : Sen. 541800 : Cost 80.35 : Time 96.85s : 10994.50 words/s : L.r. 1.5492e-04
[2018-11-23 15:46:22] [valid] Ep. 7 : Up. 60000 : cross-entropy : 49.8249 : new best
[2018-11-23 15:46:29] [valid] Ep. 7 : Up. 60000 : perplexity : 5.00047 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2018-11-23 15:50:09] [valid] Ep. 7 : Up. 60000 : translation : 27.9 : new best
[2018-11-23 15:50:09] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-23 15:50:13] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.iter60000.npz
[2018-11-23 15:50:17] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz
[2018-11-23 15:50:22] Saving Adam parameters to model/model.src0tgt0.trans.batch70.npz.optimizer.npz
[2018-11-23 15:52:05] Ep. 7 : Up. 60500 : Sen. 576800 : Cost 78.00 : Time 349.92s : 2963.41 words/s : L.r. 1.5428e-04
[2018-11-23 15:53:35] Seen 609664 samples
[2018-11-23 15:53:35] Starting epoch 8
[2018-11-23 15:53:35] [data] Shuffling files
[2018-11-23 15:53:38] [data] Done
[2018-11-23 15:53:48] Ep. 8 : Up. 61000 : Sen. 2100 : Cost 77.45 : Time 102.96s : 10015.89 words/s : L.r. 1.5364e-04
[2018-11-23 15:55:26] Ep. 8 : Up. 61500 : Sen. 37100 : Cost 78.92 : Time 97.28s : 11054.13 words/s : L.r. 1.5302e-04
[2018-11-23 15:56:57] Ep. 8 : Up. 62000 : Sen. 72100 : Cost 72.09 : Time 91.04s : 10823.90 words/s : L.r. 1.5240e-04
[2018-11-23 15:58:31] Ep. 8 : Up. 62500 : Sen. 107100 : Cost 76.26 : Time 94.42s : 10957.17 words/s : L.r. 1.5179e-04
[2018-11-23 16:00:07] Ep. 8 : Up. 63000 : Sen. 142100 : Cost 77.25 : Time 95.42s : 10961.77 words/s : L.r. 1.5119e-04
[2018-11-23 16:01:41] Ep. 8 : Up. 63500 : Sen. 177100 : Cost 76.67 : Time 94.61s : 10952.68 words/s : L.r. 1.5059e-04
[2018-11-23 16:03:15] Ep. 8 : Up. 64000 : Sen. 212100 : Cost 76.52 : Time 94.35s : 10954.69 words/s : L.r. 1.5000e-04
[2018-11-23 16:04:49] Ep. 8 : Up. 64500 : Sen. 247100 : Cost 75.45 : Time 93.62s : 10895.60 words/s : L.r. 1.4942e-04
[2018-11-23 16:06:25] Ep. 8 : Up. 65000 : Sen. 282100 : Cost 78.45 : Time 96.33s : 10964.79 words/s : L.r. 1.4884e-04
[2018-11-23 16:06:32] [valid] Ep. 8 : Up. 65000 : cross-entropy : 49.3285 : new best
[2018-11-23 16:06:40] [valid] Ep. 8 : Up. 65000 : perplexity : 4.92094 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2018-11-23 16:09:46] [valid] Ep. 8 : Up. 65000 : translation : 28.12 : new best
[2018-11-23 16:09:46] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-23 16:09:50] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.iter65000.npz
[2018-11-23 16:09:54] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz
[2018-11-23 16:09:59] Saving Adam parameters to model/model.src0tgt0.trans.batch70.npz.optimizer.npz
[2018-11-23 16:11:44] Ep. 8 : Up. 65500 : Sen. 317100 : Cost 78.67 : Time 319.07s : 3329.08 words/s : L.r. 1.4827e-04
[2018-11-23 16:13:18] Ep. 8 : Up. 66000 : Sen. 352100 : Cost 74.87 : Time 93.69s : 10788.36 words/s : L.r. 1.4771e-04
[2018-11-23 16:14:53] Ep. 8 : Up. 66500 : Sen. 387100 : Cost 75.96 : Time 95.06s : 10787.16 words/s : L.r. 1.4715e-04
[2018-11-23 16:16:27] Ep. 8 : Up. 67000 : Sen. 422100 : Cost 75.90 : Time 93.58s : 10958.05 words/s : L.r. 1.4660e-04
[2018-11-23 16:18:00] Ep. 8 : Up. 67500 : Sen. 457100 : Cost 75.91 : Time 93.65s : 10941.04 words/s : L.r. 1.4606e-04
[2018-11-23 16:19:36] Ep. 8 : Up. 68000 : Sen. 492100 : Cost 77.94 : Time 95.61s : 10985.77 words/s : L.r. 1.4552e-04
[2018-11-23 16:21:11] Ep. 8 : Up. 68500 : Sen. 527100 : Cost 77.40 : Time 94.84s : 10954.20 words/s : L.r. 1.4499e-04
[2018-11-23 16:22:45] Ep. 8 : Up. 69000 : Sen. 562100 : Cost 75.72 : Time 94.30s : 10866.71 words/s : L.r. 1.4446e-04
[2018-11-23 16:24:20] Ep. 8 : Up. 69500 : Sen. 597064 : Cost 76.93 : Time 94.82s : 10914.02 words/s : L.r. 1.4394e-04
[2018-11-23 16:24:54] Seen 609664 samples
[2018-11-23 16:24:54] Starting epoch 9
[2018-11-23 16:24:54] [data] Shuffling files
[2018-11-23 16:24:56] [data] Done
[2018-11-23 16:26:00] Ep. 9 : Up. 70000 : Sen. 22400 : Cost 74.39 : Time 100.24s : 10188.35 words/s : L.r. 1.4343e-04
[2018-11-23 16:26:07] [valid] Ep. 9 : Up. 70000 : cross-entropy : 48.9059 : new best
[2018-11-23 16:26:14] [valid] Ep. 9 : Up. 70000 : perplexity : 4.85422 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2018-11-23 16:30:48] [valid] Ep. 9 : Up. 70000 : translation : 28.24 : new best
[2018-11-23 16:30:48] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-23 16:30:52] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.iter70000.npz
[2018-11-23 16:30:56] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz
[2018-11-23 16:31:00] Saving Adam parameters to model/model.src0tgt0.trans.batch70.npz.optimizer.npz
[2018-11-23 16:32:42] Ep. 9 : Up. 70500 : Sen. 57400 : Cost 74.75 : Time 402.05s : 2566.57 words/s : L.r. 1.4292e-04
[2018-11-23 16:34:18] Ep. 9 : Up. 71000 : Sen. 92400 : Cost 75.31 : Time 95.37s : 10876.36 words/s : L.r. 1.4241e-04
[2018-11-23 16:35:52] Ep. 9 : Up. 71500 : Sen. 127400 : Cost 74.40 : Time 94.42s : 10791.89 words/s : L.r. 1.4191e-04
[2018-11-23 16:37:27] Ep. 9 : Up. 72000 : Sen. 162400 : Cost 75.83 : Time 94.80s : 10926.33 words/s : L.r. 1.4142e-04
[2018-11-23 16:39:02] Ep. 9 : Up. 72500 : Sen. 197400 : Cost 75.94 : Time 95.11s : 10952.08 words/s : L.r. 1.4093e-04
[2018-11-23 16:40:37] Ep. 9 : Up. 73000 : Sen. 232400 : Cost 76.66 : Time 95.26s : 11021.63 words/s : L.r. 1.4045e-04
[2018-11-23 16:42:11] Ep. 9 : Up. 73500 : Sen. 267400 : Cost 75.27 : Time 94.00s : 10954.07 words/s : L.r. 1.3997e-04
[2018-11-23 16:43:47] Ep. 9 : Up. 74000 : Sen. 302400 : Cost 76.34 : Time 95.74s : 10899.57 words/s : L.r. 1.3950e-04
[2018-11-23 16:45:21] Ep. 9 : Up. 74500 : Sen. 337400 : Cost 75.07 : Time 93.86s : 10949.55 words/s : L.r. 1.3903e-04
[2018-11-23 16:46:56] Ep. 9 : Up. 75000 : Sen. 372400 : Cost 76.10 : Time 94.71s : 10978.38 words/s : L.r. 1.3856e-04
[2018-11-23 16:47:03] [valid] Ep. 9 : Up. 75000 : cross-entropy : 48.6146 : new best
[2018-11-23 16:47:10] [valid] Ep. 9 : Up. 75000 : perplexity : 4.80876 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2018-11-23 16:51:30] [valid] Ep. 9 : Up. 75000 : translation : 28.35 : new best
[2018-11-23 16:51:30] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-23 16:51:34] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.iter75000.npz
[2018-11-23 16:51:38] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz
[2018-11-23 16:51:42] Saving Adam parameters to model/model.src0tgt0.trans.batch70.npz.optimizer.npz
[2018-11-23 16:53:26] Ep. 9 : Up. 75500 : Sen. 407400 : Cost 76.19 : Time 390.14s : 2674.96 words/s : L.r. 1.3810e-04
[2018-11-23 16:54:58] Ep. 9 : Up. 76000 : Sen. 442400 : Cost 73.60 : Time 92.46s : 10853.72 words/s : L.r. 1.3765e-04
[2018-11-23 16:56:33] Ep. 9 : Up. 76500 : Sen. 477400 : Cost 76.22 : Time 94.42s : 11024.76 words/s : L.r. 1.3720e-04
[2018-11-23 16:58:09] Ep. 9 : Up. 77000 : Sen. 512400 : Cost 77.62 : Time 95.98s : 11016.05 words/s : L.r. 1.3675e-04
[2018-11-23 16:59:42] Ep. 9 : Up. 77500 : Sen. 547400 : Cost 75.00 : Time 93.81s : 10910.85 words/s : L.r. 1.3631e-04
[2018-11-23 17:01:17] Ep. 9 : Up. 78000 : Sen. 582364 : Cost 75.57 : Time 94.35s : 10930.64 words/s : L.r. 1.3587e-04
[2018-11-23 17:02:31] Seen 609664 samples
[2018-11-23 17:02:31] Starting epoch 10
[2018-11-23 17:02:31] [data] Shuffling files
[2018-11-23 17:02:34] [data] Done
[2018-11-23 17:02:59] Ep. 10 : Up. 78500 : Sen. 7700 : Cost 75.51 : Time 102.28s : 10134.39 words/s : L.r. 1.3544e-04
[2018-11-23 17:04:36] Ep. 10 : Up. 79000 : Sen. 42700 : Cost 76.27 : Time 96.95s : 10998.07 words/s : L.r. 1.3501e-04
[2018-11-23 17:06:08] Ep. 10 : Up. 79500 : Sen. 77700 : Cost 71.64 : Time 92.11s : 10888.49 words/s : L.r. 1.3459e-04
[2018-11-23 17:07:42] Ep. 10 : Up. 80000 : Sen. 112700 : Cost 73.96 : Time 93.83s : 10934.60 words/s : L.r. 1.3416e-04
[2018-11-23 17:07:49] [valid] Ep. 10 : Up. 80000 : cross-entropy : 48.2654 : new best
[2018-11-23 17:07:56] [valid] Ep. 10 : Up. 80000 : perplexity : 4.75482 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2018-11-23 17:12:02] [valid] Ep. 10 : Up. 80000 : translation : 28.37 : new best
[2018-11-23 17:12:02] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-23 17:12:06] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.iter80000.npz
[2018-11-23 17:12:10] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz
[2018-11-23 17:12:15] Saving Adam parameters to model/model.src0tgt0.trans.batch70.npz.optimizer.npz
[2018-11-23 17:14:04] Ep. 10 : Up. 80500 : Sen. 147700 : Cost 75.18 : Time 382.50s : 2721.60 words/s : L.r. 1.3375e-04
[2018-11-23 17:15:39] Ep. 10 : Up. 81000 : Sen. 182700 : Cost 73.48 : Time 94.81s : 10750.60 words/s : L.r. 1.3333e-04
[2018-11-23 17:17:14] Ep. 10 : Up. 81500 : Sen. 217700 : Cost 74.80 : Time 95.03s : 10892.31 words/s : L.r. 1.3292e-04
[2018-11-23 17:18:50] Ep. 10 : Up. 82000 : Sen. 252700 : Cost 75.82 : Time 95.68s : 10953.33 words/s : L.r. 1.3252e-04
[2018-11-23 17:20:24] Ep. 10 : Up. 82500 : Sen. 287700 : Cost 74.68 : Time 94.46s : 10935.81 words/s : L.r. 1.3212e-04
[2018-11-23 17:21:59] Ep. 10 : Up. 83000 : Sen. 322700 : Cost 73.99 : Time 94.15s : 10862.51 words/s : L.r. 1.3172e-04
[2018-11-23 17:23:33] Ep. 10 : Up. 83500 : Sen. 357700 : Cost 75.81 : Time 94.84s : 11015.29 words/s : L.r. 1.3132e-04
[2018-11-23 17:25:10] Ep. 10 : Up. 84000 : Sen. 392700 : Cost 76.78 : Time 96.11s : 11002.11 words/s : L.r. 1.3093e-04
[2018-11-23 17:26:43] Ep. 10 : Up. 84500 : Sen. 427700 : Cost 73.70 : Time 93.23s : 10929.16 words/s : L.r. 1.3054e-04
[2018-11-23 17:28:16] Ep. 10 : Up. 85000 : Sen. 462700 : Cost 73.40 : Time 92.87s : 10879.53 words/s : L.r. 1.3016e-04
[2018-11-23 17:28:23] [valid] Ep. 10 : Up. 85000 : cross-entropy : 48.0213 : new best
[2018-11-23 17:28:30] [valid] Ep. 10 : Up. 85000 : perplexity : 4.71747 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2018-11-23 17:33:03] [valid] Ep. 10 : Up. 85000 : translation : 28.48 : new best
[2018-11-23 17:33:03] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-23 17:33:07] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.iter85000.npz
[2018-11-23 17:33:11] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz
[2018-11-23 17:33:15] Saving Adam parameters to model/model.src0tgt0.trans.batch70.npz.optimizer.npz
[2018-11-23 17:34:59] Ep. 10 : Up. 85500 : Sen. 497700 : Cost 76.39 : Time 402.88s : 2607.97 words/s : L.r. 1.2978e-04
[2018-11-23 17:36:33] Ep. 10 : Up. 86000 : Sen. 532700 : Cost 75.51 : Time 94.73s : 10997.18 words/s : L.r. 1.2940e-04
[2018-11-23 17:38:07] Ep. 10 : Up. 86500 : Sen. 567700 : Cost 74.40 : Time 93.88s : 10913.40 words/s : L.r. 1.2902e-04
[2018-11-23 17:39:42] Ep. 10 : Up. 87000 : Sen. 602700 : Cost 75.69 : Time 95.36s : 10944.94 words/s : L.r. 1.2865e-04
[2018-11-23 17:40:01] Seen 609664 samples
[2018-11-23 17:40:01] Starting epoch 11
[2018-11-23 17:40:01] [data] Shuffling files
[2018-11-23 17:40:03] [data] Done
[2018-11-23 17:41:23] Ep. 11 : Up. 87500 : Sen. 28000 : Cost 73.27 : Time 100.93s : 10176.22 words/s : L.r. 1.2829e-04
[2018-11-23 17:42:59] Ep. 11 : Up. 88000 : Sen. 63000 : Cost 74.10 : Time 95.33s : 10935.74 words/s : L.r. 1.2792e-04
[2018-11-23 17:44:31] Ep. 11 : Up. 88500 : Sen. 98000 : Cost 71.49 : Time 92.42s : 10907.01 words/s : L.r. 1.2756e-04
[2018-11-23 17:46:07] Ep. 11 : Up. 89000 : Sen. 133000 : Cost 75.23 : Time 96.19s : 10959.44 words/s : L.r. 1.2720e-04
[2018-11-23 17:47:41] Ep. 11 : Up. 89500 : Sen. 168000 : Cost 72.52 : Time 93.15s : 10910.85 words/s : L.r. 1.2684e-04
[2018-11-23 17:49:15] Ep. 11 : Up. 90000 : Sen. 203000 : Cost 74.33 : Time 94.17s : 10990.61 words/s : L.r. 1.2649e-04
[2018-11-23 17:49:22] [valid] Ep. 11 : Up. 90000 : cross-entropy : 47.8168 : new best
[2018-11-23 17:49:29] [valid] Ep. 11 : Up. 90000 : perplexity : 4.68642 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2018-11-23 17:53:49] [valid] Ep. 11 : Up. 90000 : translation : 28.65 : new best
[2018-11-23 17:53:49] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-23 17:53:53] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.iter90000.npz
[2018-11-23 17:53:57] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz
[2018-11-23 17:54:01] Saving Adam parameters to model/model.src0tgt0.trans.batch70.npz.optimizer.npz
[2018-11-23 17:55:46] Ep. 11 : Up. 90500 : Sen. 238000 : Cost 76.63 : Time 391.21s : 2729.87 words/s : L.r. 1.2614e-04
[2018-11-23 17:57:19] Ep. 11 : Up. 91000 : Sen. 273000 : Cost 72.65 : Time 93.00s : 10903.40 words/s : L.r. 1.2579e-04
[2018-11-23 17:58:54] Ep. 11 : Up. 91500 : Sen. 308000 : Cost 74.67 : Time 95.24s : 10951.61 words/s : L.r. 1.2545e-04
[2018-11-23 18:00:28] Ep. 11 : Up. 92000 : Sen. 343000 : Cost 73.66 : Time 93.42s : 10957.02 words/s : L.r. 1.2511e-04
[2018-11-23 18:02:03] Ep. 11 : Up. 92500 : Sen. 378000 : Cost 74.80 : Time 95.00s : 10959.82 words/s : L.r. 1.2477e-04
[2018-11-23 18:03:37] Ep. 11 : Up. 93000 : Sen. 413000 : Cost 74.65 : Time 94.67s : 10944.66 words/s : L.r. 1.2443e-04
[2018-11-23 18:05:12] Ep. 11 : Up. 93500 : Sen. 448000 : Cost 74.70 : Time 95.00s : 10953.74 words/s : L.r. 1.2410e-04
[2018-11-23 18:06:46] Ep. 11 : Up. 94000 : Sen. 483000 : Cost 73.79 : Time 93.77s : 10980.27 words/s : L.r. 1.2377e-04
[2018-11-23 18:08:20] Ep. 11 : Up. 94500 : Sen. 518000 : Cost 73.04 : Time 93.68s : 10884.91 words/s : L.r. 1.2344e-04
[2018-11-23 18:09:54] Ep. 11 : Up. 95000 : Sen. 553000 : Cost 74.84 : Time 94.26s : 11012.36 words/s : L.r. 1.2312e-04
[2018-11-23 18:10:01] [valid] Ep. 11 : Up. 95000 : cross-entropy : 47.6015 : new best
[2018-11-23 18:10:08] [valid] Ep. 11 : Up. 95000 : perplexity : 4.65392 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2018-11-23 18:14:47] [valid] Ep. 11 : Up. 95000 : translation : 28.66 : new best
[2018-11-23 18:14:47] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-23 18:14:51] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.iter95000.npz
[2018-11-23 18:14:55] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz
[2018-11-23 18:15:00] Saving Adam parameters to model/model.src0tgt0.trans.batch70.npz.optimizer.npz
[2018-11-23 18:16:45] Ep. 11 : Up. 95500 : Sen. 587964 : Cost 76.31 : Time 411.50s : 2566.26 words/s : L.r. 1.2279e-04
[2018-11-23 18:17:44] Seen 609664 samples
[2018-11-23 18:17:44] Starting epoch 12
[2018-11-23 18:17:44] [data] Shuffling files
[2018-11-23 18:17:46] [data] Done
[2018-11-23 18:18:27] Ep. 12 : Up. 96000 : Sen. 13300 : Cost 72.40 : Time 101.17s : 10074.09 words/s : L.r. 1.2247e-04
[2018-11-23 18:20:00] Ep. 12 : Up. 96500 : Sen. 48300 : Cost 72.11 : Time 93.46s : 10972.36 words/s : L.r. 1.2216e-04
[2018-11-23 18:21:37] Ep. 12 : Up. 97000 : Sen. 83300 : Cost 74.84 : Time 96.40s : 10971.19 words/s : L.r. 1.2184e-04
[2018-11-23 18:23:11] Ep. 12 : Up. 97500 : Sen. 118300 : Cost 72.90 : Time 94.02s : 10938.25 words/s : L.r. 1.2153e-04
[2018-11-23 18:24:45] Ep. 12 : Up. 98000 : Sen. 153300 : Cost 71.75 : Time 94.13s : 10816.33 words/s : L.r. 1.2122e-04
[2018-11-23 18:26:19] Ep. 12 : Up. 98500 : Sen. 188300 : Cost 73.33 : Time 94.71s : 10920.17 words/s : L.r. 1.2091e-04
[2018-11-23 18:27:56] Ep. 12 : Up. 99000 : Sen. 223300 : Cost 74.61 : Time 96.32s : 10899.14 words/s : L.r. 1.2060e-04
[2018-11-23 18:29:27] Ep. 12 : Up. 99500 : Sen. 258300 : Cost 69.81 : Time 91.35s : 10805.38 words/s : L.r. 1.2030e-04
[2018-11-23 18:31:06] Ep. 12 : Up. 100000 : Sen. 293300 : Cost 78.17 : Time 99.17s : 11026.59 words/s : L.r. 1.2000e-04
[2018-11-23 18:31:13] [valid] Ep. 12 : Up. 100000 : cross-entropy : 47.4321 : new best
[2018-11-23 18:31:20] [valid] Ep. 12 : Up. 100000 : perplexity : 4.62853 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2018-11-23 18:35:54] [valid] Ep. 12 : Up. 100000 : translation : 28.7 : new best
[2018-11-23 18:35:55] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-23 18:35:59] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.iter100000.npz
[2018-11-23 18:36:03] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz
[2018-11-23 18:36:07] Saving Adam parameters to model/model.src0tgt0.trans.batch70.npz.optimizer.npz
[2018-11-23 18:37:50] Ep. 12 : Up. 100500 : Sen. 328300 : Cost 73.64 : Time 404.02s : 2557.16 words/s : L.r. 1.1970e-04
[2018-11-23 18:39:23] Ep. 12 : Up. 101000 : Sen. 363300 : Cost 71.42 : Time 92.78s : 10830.37 words/s : L.r. 1.1940e-04
[2018-11-23 18:40:57] Ep. 12 : Up. 101500 : Sen. 398300 : Cost 72.28 : Time 93.87s : 10838.18 words/s : L.r. 1.1911e-04
[2018-11-23 18:42:35] Ep. 12 : Up. 102000 : Sen. 433300 : Cost 76.99 : Time 98.12s : 10979.66 words/s : L.r. 1.1882e-04
[2018-11-23 18:44:10] Ep. 12 : Up. 102500 : Sen. 468300 : Cost 73.75 : Time 94.77s : 10913.23 words/s : L.r. 1.1853e-04
[2018-11-23 18:45:44] Ep. 12 : Up. 103000 : Sen. 503300 : Cost 73.25 : Time 93.92s : 10913.21 words/s : L.r. 1.1824e-04
[2018-11-23 18:47:18] Ep. 12 : Up. 103500 : Sen. 538300 : Cost 73.54 : Time 94.21s : 10913.74 words/s : L.r. 1.1795e-04
[2018-11-23 18:48:53] Ep. 12 : Up. 104000 : Sen. 573300 : Cost 73.51 : Time 95.12s : 10819.46 words/s : L.r. 1.1767e-04
[2018-11-23 18:50:28] Ep. 12 : Up. 104500 : Sen. 608264 : Cost 73.88 : Time 94.99s : 10862.98 words/s : L.r. 1.1739e-04
[2018-11-23 18:50:32] Seen 609664 samples
[2018-11-23 18:50:32] Starting epoch 13
[2018-11-23 18:50:32] [data] Shuffling files
[2018-11-23 18:50:35] [data] Done
[2018-11-23 18:52:08] Ep. 13 : Up. 105000 : Sen. 33600 : Cost 70.73 : Time 99.87s : 10173.35 words/s : L.r. 1.1711e-04
[2018-11-23 18:52:15] [valid] Ep. 13 : Up. 105000 : cross-entropy : 47.2249 : new best
[2018-11-23 18:52:22] [valid] Ep. 13 : Up. 105000 : perplexity : 4.59765 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2018-11-23 18:57:02] [valid] Ep. 13 : Up. 105000 : translation : 28.72 : new best
[2018-11-23 18:57:02] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-23 18:57:09] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.iter105000.npz
[2018-11-23 18:57:13] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz
[2018-11-23 18:57:18] Saving Adam parameters to model/model.src0tgt0.trans.batch70.npz.optimizer.npz
[2018-11-23 18:59:04] Ep. 13 : Up. 105500 : Sen. 68600 : Cost 74.88 : Time 416.22s : 2570.33 words/s : L.r. 1.1683e-04
[2018-11-23 19:00:41] Ep. 13 : Up. 106000 : Sen. 103600 : Cost 74.58 : Time 96.69s : 10935.52 words/s : L.r. 1.1655e-04
[2018-11-23 19:02:14] Ep. 13 : Up. 106500 : Sen. 138600 : Cost 70.57 : Time 92.94s : 10850.13 words/s : L.r. 1.1628e-04
[2018-11-23 19:03:50] Ep. 13 : Up. 107000 : Sen. 173600 : Cost 73.62 : Time 95.98s : 10869.93 words/s : L.r. 1.1601e-04
[2018-11-23 19:05:23] Ep. 13 : Up. 107500 : Sen. 208600 : Cost 71.83 : Time 93.59s : 10939.94 words/s : L.r. 1.1574e-04
[2018-11-23 19:06:57] Ep. 13 : Up. 108000 : Sen. 243600 : Cost 72.15 : Time 93.10s : 10989.73 words/s : L.r. 1.1547e-04
[2018-11-23 19:08:32] Ep. 13 : Up. 108500 : Sen. 278600 : Cost 73.72 : Time 95.92s : 10905.64 words/s : L.r. 1.1520e-04
[2018-11-23 19:10:09] Ep. 13 : Up. 109000 : Sen. 313600 : Cost 75.02 : Time 96.57s : 10972.28 words/s : L.r. 1.1494e-04
[2018-11-23 19:11:41] Ep. 13 : Up. 109500 : Sen. 348600 : Cost 70.65 : Time 92.50s : 10836.95 words/s : L.r. 1.1468e-04
[2018-11-23 19:13:14] Ep. 13 : Up. 110000 : Sen. 383600 : Cost 70.63 : Time 92.21s : 10831.96 words/s : L.r. 1.1442e-04
[2018-11-23 19:13:21] [valid] Ep. 13 : Up. 110000 : cross-entropy : 47.1175 : new best
[2018-11-23 19:13:28] [valid] Ep. 13 : Up. 110000 : perplexity : 4.58169 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2018-11-23 19:18:03] [valid] Ep. 13 : Up. 110000 : translation : 28.77 : new best
[2018-11-23 19:18:03] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-23 19:18:08] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.iter110000.npz
[2018-11-23 19:18:12] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz
[2018-11-23 19:18:16] Saving Adam parameters to model/model.src0tgt0.trans.batch70.npz.optimizer.npz
[2018-11-23 19:20:03] Ep. 13 : Up. 110500 : Sen. 418600 : Cost 76.00 : Time 409.72s : 2618.32 words/s : L.r. 1.1416e-04
[2018-11-23 19:21:40] Ep. 13 : Up. 111000 : Sen. 453600 : Cost 73.58 : Time 96.25s : 10754.84 words/s : L.r. 1.1390e-04
[2018-11-23 19:23:15] Ep. 13 : Up. 111500 : Sen. 488600 : Cost 73.60 : Time 95.46s : 10892.41 words/s : L.r. 1.1364e-04
[2018-11-23 19:24:49] Ep. 13 : Up. 112000 : Sen. 523600 : Cost 72.42 : Time 93.55s : 10904.58 words/s : L.r. 1.1339e-04
[2018-11-23 19:26:24] Ep. 13 : Up. 112500 : Sen. 558600 : Cost 73.91 : Time 95.02s : 10927.99 words/s : L.r. 1.1314e-04
[2018-11-23 19:28:00] Ep. 13 : Up. 113000 : Sen. 593600 : Cost 74.79 : Time 96.39s : 10909.81 words/s : L.r. 1.1289e-04
[2018-11-23 19:28:43] Seen 609664 samples
[2018-11-23 19:28:43] Starting epoch 14
[2018-11-23 19:28:43] [data] Shuffling files
[2018-11-23 19:28:45] [data] Done
[2018-11-23 19:29:40] Ep. 14 : Up. 113500 : Sen. 18900 : Cost 70.51 : Time 99.77s : 10078.93 words/s : L.r. 1.1264e-04
[2018-11-23 19:31:15] Ep. 14 : Up. 114000 : Sen. 53900 : Cost 72.40 : Time 95.56s : 10931.26 words/s : L.r. 1.1239e-04
[2018-11-23 19:32:50] Ep. 14 : Up. 114500 : Sen. 88900 : Cost 71.39 : Time 94.09s : 10877.20 words/s : L.r. 1.1214e-04
[2018-11-23 19:34:25] Ep. 14 : Up. 115000 : Sen. 123900 : Cost 73.10 : Time 95.49s : 10983.83 words/s : L.r. 1.1190e-04
[2018-11-23 19:34:32] [valid] Ep. 14 : Up. 115000 : cross-entropy : 46.9536 : new best
[2018-11-23 19:34:39] [valid] Ep. 14 : Up. 115000 : perplexity : 4.55753 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2018-11-23 19:39:17] [valid] Ep. 14 : Up. 115000 : translation : 28.93 : new best
[2018-11-23 19:39:17] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-23 19:39:21] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.iter115000.npz
[2018-11-23 19:39:25] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz
[2018-11-23 19:39:29] Saving Adam parameters to model/model.src0tgt0.trans.batch70.npz.optimizer.npz
[2018-11-23 19:41:14] Ep. 14 : Up. 115500 : Sen. 158900 : Cost 73.10 : Time 409.16s : 2555.05 words/s : L.r. 1.1166e-04
[2018-11-23 19:42:49] Ep. 14 : Up. 116000 : Sen. 193900 : Cost 72.60 : Time 94.87s : 10952.51 words/s : L.r. 1.1142e-04
[2018-11-23 19:44:23] Ep. 14 : Up. 116500 : Sen. 228900 : Cost 72.01 : Time 94.05s : 10913.19 words/s : L.r. 1.1118e-04
[2018-11-23 19:45:58] Ep. 14 : Up. 117000 : Sen. 263900 : Cost 72.65 : Time 94.47s : 10968.47 words/s : L.r. 1.1094e-04
[2018-11-23 19:47:33] Ep. 14 : Up. 117500 : Sen. 298900 : Cost 74.18 : Time 95.45s : 11023.73 words/s : L.r. 1.1070e-04
[2018-11-23 19:49:06] Ep. 14 : Up. 118000 : Sen. 333900 : Cost 70.61 : Time 92.87s : 10862.85 words/s : L.r. 1.1047e-04
[2018-11-23 19:50:40] Ep. 14 : Up. 118500 : Sen. 368900 : Cost 72.46 : Time 94.20s : 10939.57 words/s : L.r. 1.1024e-04
[2018-11-23 19:52:14] Ep. 14 : Up. 119000 : Sen. 403900 : Cost 72.60 : Time 94.23s : 10972.99 words/s : L.r. 1.1000e-04
[2018-11-23 19:53:50] Ep. 14 : Up. 119500 : Sen. 438900 : Cost 73.96 : Time 96.00s : 10892.70 words/s : L.r. 1.0977e-04
[2018-11-23 19:55:24] Ep. 14 : Up. 120000 : Sen. 473900 : Cost 72.12 : Time 94.05s : 10875.02 words/s : L.r. 1.0954e-04
[2018-11-23 19:55:31] [valid] Ep. 14 : Up. 120000 : cross-entropy : 46.8402 : new best
[2018-11-23 19:55:38] [valid] Ep. 14 : Up. 120000 : perplexity : 4.54087 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2018-11-23 20:00:14] [valid] Ep. 14 : Up. 120000 : translation : 29.05 : new best
[2018-11-23 20:00:14] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-23 20:00:18] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.iter120000.npz
[2018-11-23 20:00:22] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz
[2018-11-23 20:00:27] Saving Adam parameters to model/model.src0tgt0.trans.batch70.npz.optimizer.npz
[2018-11-23 20:02:10] Ep. 14 : Up. 120500 : Sen. 508900 : Cost 72.45 : Time 405.61s : 2543.81 words/s : L.r. 1.0932e-04
[2018-11-23 20:03:44] Ep. 14 : Up. 121000 : Sen. 543900 : Cost 72.38 : Time 94.05s : 10901.04 words/s : L.r. 1.0909e-04
[2018-11-23 20:05:20] Ep. 14 : Up. 121500 : Sen. 578864 : Cost 74.22 : Time 95.98s : 10916.77 words/s : L.r. 1.0887e-04
[2018-11-23 20:06:43] Seen 609664 samples
[2018-11-23 20:06:43] Starting epoch 15
[2018-11-23 20:06:43] [data] Shuffling files
[2018-11-23 20:06:46] [data] Done
[2018-11-23 20:07:02] Ep. 15 : Up. 122000 : Sen. 4200 : Cost 72.83 : Time 102.11s : 10191.73 words/s : L.r. 1.0864e-04
[2018-11-23 20:08:38] Ep. 15 : Up. 122500 : Sen. 39200 : Cost 72.68 : Time 96.18s : 10984.18 words/s : L.r. 1.0842e-04
[2018-11-23 20:10:10] Ep. 15 : Up. 123000 : Sen. 74200 : Cost 68.66 : Time 92.08s : 10817.13 words/s : L.r. 1.0820e-04
[2018-11-23 20:11:46] Ep. 15 : Up. 123500 : Sen. 109200 : Cost 72.50 : Time 95.45s : 10957.44 words/s : L.r. 1.0798e-04
[2018-11-23 20:13:20] Ep. 15 : Up. 124000 : Sen. 144200 : Cost 71.84 : Time 93.98s : 11017.04 words/s : L.r. 1.0776e-04
[2018-11-23 20:14:55] Ep. 15 : Up. 124500 : Sen. 179200 : Cost 73.23 : Time 95.64s : 10982.66 words/s : L.r. 1.0755e-04
[2018-11-23 20:16:30] Ep. 15 : Up. 125000 : Sen. 214200 : Cost 71.22 : Time 94.23s : 10866.91 words/s : L.r. 1.0733e-04
[2018-11-23 20:16:37] [valid] Ep. 15 : Up. 125000 : cross-entropy : 46.7502 : new best
[2018-11-23 20:16:44] [valid] Ep. 15 : Up. 125000 : perplexity : 4.52768 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2018-11-23 20:21:19] [valid] Ep. 15 : Up. 125000 : translation : 29.07 : new best
[2018-11-23 20:21:19] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-23 20:21:24] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.iter125000.npz
[2018-11-23 20:21:28] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz
[2018-11-23 20:21:32] Saving Adam parameters to model/model.src0tgt0.trans.batch70.npz.optimizer.npz
[2018-11-23 20:23:14] Ep. 15 : Up. 125500 : Sen. 249200 : Cost 70.03 : Time 404.36s : 2488.58 words/s : L.r. 1.0712e-04
[2018-11-23 20:24:50] Ep. 15 : Up. 126000 : Sen. 284200 : Cost 73.10 : Time 95.84s : 10928.32 words/s : L.r. 1.0690e-04
[2018-11-23 20:26:24] Ep. 15 : Up. 126500 : Sen. 319200 : Cost 71.61 : Time 93.95s : 10897.62 words/s : L.r. 1.0669e-04
[2018-11-23 20:27:59] Ep. 15 : Up. 127000 : Sen. 354200 : Cost 72.18 : Time 94.85s : 10879.54 words/s : L.r. 1.0648e-04
[2018-11-23 20:29:34] Ep. 15 : Up. 127500 : Sen. 389200 : Cost 72.82 : Time 94.97s : 10943.65 words/s : L.r. 1.0627e-04
[2018-11-23 20:31:08] Ep. 15 : Up. 128000 : Sen. 424200 : Cost 72.38 : Time 94.69s : 10944.18 words/s : L.r. 1.0607e-04
[2018-11-23 20:32:44] Ep. 15 : Up. 128500 : Sen. 459200 : Cost 74.10 : Time 96.07s : 10995.38 words/s : L.r. 1.0586e-04
[2018-11-23 20:34:18] Ep. 15 : Up. 129000 : Sen. 494200 : Cost 71.47 : Time 93.56s : 10898.76 words/s : L.r. 1.0565e-04
[2018-11-23 20:35:54] Ep. 15 : Up. 129500 : Sen. 529200 : Cost 73.57 : Time 95.77s : 10906.93 words/s : L.r. 1.0545e-04
[2018-11-23 20:37:27] Ep. 15 : Up. 130000 : Sen. 564200 : Cost 71.72 : Time 92.95s : 11028.51 words/s : L.r. 1.0525e-04
[2018-11-23 20:37:34] [valid] Ep. 15 : Up. 130000 : cross-entropy : 46.7163 : new best
[2018-11-23 20:37:41] [valid] Ep. 15 : Up. 130000 : perplexity : 4.52274 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2018-11-23 20:42:16] [valid] Ep. 15 : Up. 130000 : translation : 29.1 : new best
[2018-11-23 20:42:16] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-23 20:42:20] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.iter130000.npz
[2018-11-23 20:42:24] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz
[2018-11-23 20:42:28] Saving Adam parameters to model/model.src0tgt0.trans.batch70.npz.optimizer.npz
[2018-11-23 20:44:13] Ep. 15 : Up. 130500 : Sen. 599164 : Cost 73.36 : Time 406.45s : 2570.78 words/s : L.r. 1.0505e-04
[2018-11-23 20:44:42] Seen 609664 samples
[2018-11-23 20:44:42] Starting epoch 16
[2018-11-23 20:44:42] [data] Shuffling files
[2018-11-23 20:44:44] [data] Done
[2018-11-23 20:45:57] Ep. 16 : Up. 131000 : Sen. 24500 : Cost 71.93 : Time 104.07s : 9989.66 words/s : L.r. 1.0484e-04
[2018-11-23 20:47:32] Ep. 16 : Up. 131500 : Sen. 59500 : Cost 69.56 : Time 94.65s : 10754.89 words/s : L.r. 1.0464e-04
[2018-11-23 20:49:07] Ep. 16 : Up. 132000 : Sen. 94500 : Cost 71.47 : Time 95.25s : 10906.68 words/s : L.r. 1.0445e-04
[2018-11-23 20:50:44] Ep. 16 : Up. 132500 : Sen. 129500 : Cost 73.50 : Time 96.70s : 10992.76 words/s : L.r. 1.0425e-04
[2018-11-23 20:52:19] Ep. 16 : Up. 133000 : Sen. 164500 : Cost 72.30 : Time 95.43s : 10960.04 words/s : L.r. 1.0405e-04
[2018-11-23 20:53:53] Ep. 16 : Up. 133500 : Sen. 199500 : Cost 70.25 : Time 93.67s : 10871.52 words/s : L.r. 1.0386e-04
[2018-11-23 20:55:26] Ep. 16 : Up. 134000 : Sen. 234500 : Cost 70.74 : Time 93.39s : 10955.98 words/s : L.r. 1.0366e-04
[2018-11-23 20:57:01] Ep. 16 : Up. 134500 : Sen. 269500 : Cost 72.18 : Time 94.50s : 10999.77 words/s : L.r. 1.0347e-04
[2018-11-23 20:58:35] Ep. 16 : Up. 135000 : Sen. 304500 : Cost 71.06 : Time 93.66s : 10954.15 words/s : L.r. 1.0328e-04
[2018-11-23 20:58:42] [valid] Ep. 16 : Up. 135000 : cross-entropy : 46.6844 : new best
[2018-11-23 20:58:49] [valid] Ep. 16 : Up. 135000 : perplexity : 4.51807 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2018-11-23 21:03:24] [valid] Ep. 16 : Up. 135000 : translation : 29.05 : stalled 1 times
[2018-11-23 21:03:24] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-23 21:03:28] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.iter135000.npz
[2018-11-23 21:03:32] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz
[2018-11-23 21:03:36] Saving Adam parameters to model/model.src0tgt0.trans.batch70.npz.optimizer.npz
[2018-11-23 21:05:19] Ep. 16 : Up. 135500 : Sen. 339500 : Cost 71.33 : Time 404.18s : 2535.10 words/s : L.r. 1.0309e-04
[2018-11-23 21:06:53] Ep. 16 : Up. 136000 : Sen. 374500 : Cost 70.44 : Time 94.03s : 10775.07 words/s : L.r. 1.0290e-04
[2018-11-23 21:08:30] Ep. 16 : Up. 136500 : Sen. 409500 : Cost 74.84 : Time 97.77s : 10969.86 words/s : L.r. 1.0271e-04
[2018-11-23 21:10:07] Ep. 16 : Up. 137000 : Sen. 444500 : Cost 74.07 : Time 96.63s : 10944.39 words/s : L.r. 1.0252e-04
[2018-11-23 21:11:40] Ep. 16 : Up. 137500 : Sen. 479500 : Cost 70.05 : Time 93.11s : 10812.89 words/s : L.r. 1.0234e-04
[2018-11-23 21:13:11] Ep. 16 : Up. 138000 : Sen. 514500 : Cost 68.98 : Time 91.20s : 10865.29 words/s : L.r. 1.0215e-04
[2018-11-23 21:14:47] Ep. 16 : Up. 138500 : Sen. 549500 : Cost 73.18 : Time 95.83s : 10924.90 words/s : L.r. 1.0197e-04
[2018-11-23 21:16:24] Ep. 16 : Up. 139000 : Sen. 584500 : Cost 73.11 : Time 96.34s : 10857.59 words/s : L.r. 1.0178e-04
[2018-11-23 21:17:32] Seen 609664 samples
[2018-11-23 21:17:32] Starting epoch 17
[2018-11-23 21:17:32] [data] Shuffling files
[2018-11-23 21:17:34] [data] Done
[2018-11-23 21:18:06] Ep. 17 : Up. 139500 : Sen. 9800 : Cost 72.30 : Time 102.30s : 10180.02 words/s : L.r. 1.0160e-04
[2018-11-23 21:19:41] Ep. 17 : Up. 140000 : Sen. 44800 : Cost 70.68 : Time 95.49s : 10857.04 words/s : L.r. 1.0142e-04
[2018-11-23 21:19:49] [valid] Ep. 17 : Up. 140000 : cross-entropy : 46.4756 : new best
[2018-11-23 21:19:56] [valid] Ep. 17 : Up. 140000 : perplexity : 4.48769 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2018-11-23 21:24:21] [valid] Ep. 17 : Up. 140000 : translation : 29.15 : new best
[2018-11-23 21:24:21] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-23 21:24:26] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.iter140000.npz
[2018-11-23 21:24:29] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz
[2018-11-23 21:24:34] Saving Adam parameters to model/model.src0tgt0.trans.batch70.npz.optimizer.npz
[2018-11-23 21:26:17] Ep. 17 : Up. 140500 : Sen. 79800 : Cost 70.95 : Time 395.19s : 2619.78 words/s : L.r. 1.0124e-04
[2018-11-23 21:27:49] Ep. 17 : Up. 141000 : Sen. 114800 : Cost 69.04 : Time 92.90s : 10863.35 words/s : L.r. 1.0106e-04
[2018-11-23 21:29:25] Ep. 17 : Up. 141500 : Sen. 149800 : Cost 71.62 : Time 95.51s : 10906.44 words/s : L.r. 1.0088e-04
[2018-11-23 21:31:01] Ep. 17 : Up. 142000 : Sen. 184800 : Cost 72.53 : Time 96.43s : 10882.40 words/s : L.r. 1.0070e-04
[2018-11-23 21:32:37] Ep. 17 : Up. 142500 : Sen. 219800 : Cost 72.27 : Time 95.24s : 10999.62 words/s : L.r. 1.0052e-04
[2018-11-23 21:34:10] Ep. 17 : Up. 143000 : Sen. 254800 : Cost 70.01 : Time 93.64s : 10846.79 words/s : L.r. 1.0035e-04
[2018-11-23 21:35:44] Ep. 17 : Up. 143500 : Sen. 289800 : Cost 70.13 : Time 93.72s : 10862.48 words/s : L.r. 1.0017e-04
[2018-11-23 21:37:18] Ep. 17 : Up. 144000 : Sen. 324800 : Cost 71.13 : Time 94.32s : 10905.47 words/s : L.r. 1.0000e-04
[2018-11-23 21:38:55] Ep. 17 : Up. 144500 : Sen. 359800 : Cost 73.39 : Time 96.54s : 10973.71 words/s : L.r. 9.9827e-05
[2018-11-23 21:40:30] Ep. 17 : Up. 145000 : Sen. 394800 : Cost 71.77 : Time 94.66s : 10939.70 words/s : L.r. 9.9655e-05
[2018-11-23 21:40:37] [valid] Ep. 17 : Up. 145000 : cross-entropy : 46.4573 : new best
[2018-11-23 21:40:44] [valid] Ep. 17 : Up. 145000 : perplexity : 4.48505 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2018-11-23 21:45:20] [valid] Ep. 17 : Up. 145000 : translation : 29.22 : new best
[2018-11-23 21:45:20] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-23 21:45:24] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.iter145000.npz
[2018-11-23 21:45:28] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz
[2018-11-23 21:45:33] Saving Adam parameters to model/model.src0tgt0.trans.batch70.npz.optimizer.npz
[2018-11-23 21:47:16] Ep. 17 : Up. 145500 : Sen. 429800 : Cost 71.43 : Time 406.62s : 2530.60 words/s : L.r. 9.9483e-05
[2018-11-23 21:48:52] Ep. 17 : Up. 146000 : Sen. 464800 : Cost 72.79 : Time 95.42s : 11009.80 words/s : L.r. 9.9313e-05
[2018-11-23 21:50:25] Ep. 17 : Up. 146500 : Sen. 499800 : Cost 71.01 : Time 93.77s : 10930.76 words/s : L.r. 9.9143e-05
[2018-11-23 21:52:00] Ep. 17 : Up. 147000 : Sen. 534800 : Cost 72.35 : Time 94.79s : 10962.72 words/s : L.r. 9.8974e-05
[2018-11-23 21:53:34] Ep. 17 : Up. 147500 : Sen. 569764 : Cost 71.10 : Time 93.52s : 10938.17 words/s : L.r. 9.8806e-05
[2018-11-23 21:55:09] Ep. 17 : Up. 148000 : Sen. 604764 : Cost 71.58 : Time 94.94s : 10852.58 words/s : L.r. 9.8639e-05
[2018-11-23 21:55:22] Seen 609664 samples
[2018-11-23 21:55:22] Starting epoch 18
[2018-11-23 21:55:22] [data] Shuffling files
[2018-11-23 21:55:24] [data] Done
[2018-11-23 21:56:52] Ep. 18 : Up. 148500 : Sen. 30100 : Cost 71.87 : Time 103.30s : 10231.54 words/s : L.r. 9.8473e-05
[2018-11-23 21:58:27] Ep. 18 : Up. 149000 : Sen. 65100 : Cost 70.45 : Time 95.57s : 10812.92 words/s : L.r. 9.8308e-05
[2018-11-23 22:00:02] Ep. 18 : Up. 149500 : Sen. 100100 : Cost 69.41 : Time 94.11s : 10859.21 words/s : L.r. 9.8143e-05
[2018-11-23 22:01:38] Ep. 18 : Up. 150000 : Sen. 135100 : Cost 71.91 : Time 96.34s : 10881.82 words/s : L.r. 9.7980e-05
[2018-11-23 22:01:45] [valid] Ep. 18 : Up. 150000 : cross-entropy : 46.4161 : new best
[2018-11-23 22:01:52] [valid] Ep. 18 : Up. 150000 : perplexity : 4.47907 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2018-11-23 22:05:54] [valid] Ep. 18 : Up. 150000 : translation : 29.25 : new best
[2018-11-23 22:05:54] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-23 22:05:58] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.iter150000.npz
[2018-11-23 22:06:02] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz
[2018-11-23 22:06:06] Saving Adam parameters to model/model.src0tgt0.trans.batch70.npz.optimizer.npz
[2018-11-23 22:07:50] Ep. 18 : Up. 150500 : Sen. 170100 : Cost 70.34 : Time 371.69s : 2768.09 words/s : L.r. 9.7817e-05
[2018-11-23 22:09:23] Ep. 18 : Up. 151000 : Sen. 205100 : Cost 69.99 : Time 93.82s : 10877.57 words/s : L.r. 9.7655e-05
[2018-11-23 22:10:58] Ep. 18 : Up. 151500 : Sen. 240100 : Cost 70.69 : Time 94.58s : 10901.99 words/s : L.r. 9.7493e-05
[2018-11-23 22:12:33] Ep. 18 : Up. 152000 : Sen. 275100 : Cost 71.13 : Time 94.88s : 10876.08 words/s : L.r. 9.7333e-05
[2018-11-23 22:14:05] Ep. 18 : Up. 152500 : Sen. 310100 : Cost 68.64 : Time 92.08s : 10867.94 words/s : L.r. 9.7173e-05
[2018-11-23 22:15:40] Ep. 18 : Up. 153000 : Sen. 345100 : Cost 72.56 : Time 95.26s : 11043.46 words/s : L.r. 9.7014e-05
[2018-11-23 22:17:17] Ep. 18 : Up. 153500 : Sen. 380100 : Cost 73.72 : Time 96.85s : 11015.09 words/s : L.r. 9.6856e-05
[2018-11-23 22:18:51] Ep. 18 : Up. 154000 : Sen. 415100 : Cost 71.15 : Time 94.33s : 10929.32 words/s : L.r. 9.6699e-05
[2018-11-23 22:20:26] Ep. 18 : Up. 154500 : Sen. 450100 : Cost 71.58 : Time 94.53s : 10937.05 words/s : L.r. 9.6542e-05
[2018-11-23 22:22:00] Ep. 18 : Up. 155000 : Sen. 485100 : Cost 71.51 : Time 94.39s : 11001.78 words/s : L.r. 9.6386e-05
[2018-11-23 22:22:07] [valid] Ep. 18 : Up. 155000 : cross-entropy : 46.4255 : stalled 1 times
[2018-11-23 22:22:14] [valid] Ep. 18 : Up. 155000 : perplexity : 4.48046 : stalled 1 times
Detokenizer Version $Revision: 4134 $
Language: en
[2018-11-23 22:26:51] [valid] Ep. 18 : Up. 155000 : translation : 29.26 : new best
[2018-11-23 22:26:51] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-23 22:26:55] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.iter155000.npz
[2018-11-23 22:26:59] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz
[2018-11-23 22:27:04] Saving Adam parameters to model/model.src0tgt0.trans.batch70.npz.optimizer.npz
[2018-11-23 22:28:49] Ep. 18 : Up. 155500 : Sen. 520100 : Cost 72.81 : Time 408.79s : 2570.69 words/s : L.r. 9.6231e-05
[2018-11-23 22:30:21] Ep. 18 : Up. 156000 : Sen. 555100 : Cost 68.78 : Time 91.93s : 10863.21 words/s : L.r. 9.6077e-05
[2018-11-23 22:31:54] Ep. 18 : Up. 156500 : Sen. 590100 : Cost 70.16 : Time 93.37s : 10860.51 words/s : L.r. 9.5923e-05
[2018-11-23 22:32:50] Seen 609664 samples
[2018-11-23 22:32:50] Starting epoch 19
[2018-11-23 22:32:50] [data] Shuffling files
[2018-11-23 22:32:52] [data] Done
[2018-11-23 22:33:38] Ep. 19 : Up. 157000 : Sen. 15400 : Cost 73.30 : Time 103.82s : 10272.75 words/s : L.r. 9.5770e-05
[2018-11-23 22:35:14] Ep. 19 : Up. 157500 : Sen. 50400 : Cost 71.11 : Time 95.98s : 10980.41 words/s : L.r. 9.5618e-05
[2018-11-23 22:36:48] Ep. 19 : Up. 158000 : Sen. 85400 : Cost 68.84 : Time 93.65s : 10811.13 words/s : L.r. 9.5467e-05
[2018-11-23 22:38:22] Ep. 19 : Up. 158500 : Sen. 120400 : Cost 69.60 : Time 93.99s : 10894.31 words/s : L.r. 9.5316e-05
[2018-11-23 22:39:58] Ep. 19 : Up. 159000 : Sen. 155400 : Cost 71.83 : Time 96.20s : 10933.29 words/s : L.r. 9.5166e-05
[2018-11-23 22:41:33] Ep. 19 : Up. 159500 : Sen. 190400 : Cost 69.91 : Time 94.45s : 10864.03 words/s : L.r. 9.5017e-05
[2018-11-23 22:43:05] Ep. 19 : Up. 160000 : Sen. 225400 : Cost 68.75 : Time 92.31s : 10905.10 words/s : L.r. 9.4868e-05
[2018-11-23 22:43:12] [valid] Ep. 19 : Up. 160000 : cross-entropy : 46.4344 : stalled 2 times
[2018-11-23 22:43:19] [valid] Ep. 19 : Up. 160000 : perplexity : 4.48173 : stalled 2 times
Detokenizer Version $Revision: 4134 $
Language: en
[2018-11-23 22:47:24] [valid] Ep. 19 : Up. 160000 : translation : 29.28 : new best
[2018-11-23 22:47:24] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-23 22:47:28] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.iter160000.npz
[2018-11-23 22:47:32] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz
[2018-11-23 22:47:36] Saving Adam parameters to model/model.src0tgt0.trans.batch70.npz.optimizer.npz
[2018-11-23 22:49:19] Ep. 19 : Up. 160500 : Sen. 260400 : Cost 69.57 : Time 374.63s : 2718.52 words/s : L.r. 9.4720e-05
[2018-11-23 22:50:55] Ep. 19 : Up. 161000 : Sen. 295400 : Cost 71.89 : Time 95.62s : 10955.58 words/s : L.r. 9.4573e-05
[2018-11-23 22:52:31] Ep. 19 : Up. 161500 : Sen. 330400 : Cost 71.93 : Time 95.66s : 10981.62 words/s : L.r. 9.4427e-05
[2018-11-23 22:54:05] Ep. 19 : Up. 162000 : Sen. 365400 : Cost 70.88 : Time 94.10s : 10960.97 words/s : L.r. 9.4281e-05
[2018-11-23 22:55:40] Ep. 19 : Up. 162500 : Sen. 400400 : Cost 71.72 : Time 95.39s : 10938.26 words/s : L.r. 9.4136e-05
[2018-11-23 22:57:14] Ep. 19 : Up. 163000 : Sen. 435400 : Cost 70.16 : Time 93.93s : 10892.46 words/s : L.r. 9.3991e-05
[2018-11-23 22:58:48] Ep. 19 : Up. 163500 : Sen. 470400 : Cost 70.98 : Time 94.28s : 10939.13 words/s : L.r. 9.3847e-05
[2018-11-23 23:00:23] Ep. 19 : Up. 164000 : Sen. 505400 : Cost 71.93 : Time 94.89s : 10984.32 words/s : L.r. 9.3704e-05
[2018-11-23 23:01:58] Ep. 19 : Up. 164500 : Sen. 540400 : Cost 71.70 : Time 94.72s : 10987.42 words/s : L.r. 9.3562e-05
[2018-11-23 23:03:33] Ep. 19 : Up. 165000 : Sen. 575400 : Cost 71.56 : Time 94.81s : 10928.70 words/s : L.r. 9.3420e-05
[2018-11-23 23:03:40] [valid] Ep. 19 : Up. 165000 : cross-entropy : 46.4009 : new best
[2018-11-23 23:03:47] [valid] Ep. 19 : Up. 165000 : perplexity : 4.47689 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2018-11-23 23:07:50] [valid] Ep. 19 : Up. 165000 : translation : 29.36 : new best
[2018-11-23 23:07:50] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-23 23:07:54] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.iter165000.npz
[2018-11-23 23:07:58] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz
[2018-11-23 23:08:02] Saving Adam parameters to model/model.src0tgt0.trans.batch70.npz.optimizer.npz
[2018-11-23 23:09:46] Seen 609664 samples
[2018-11-23 23:09:46] Starting epoch 20
[2018-11-23 23:09:46] [data] Shuffling files
[2018-11-23 23:09:48] [data] Done
[2018-11-23 23:09:54] Ep. 20 : Up. 165500 : Sen. 700 : Cost 71.69 : Time 381.28s : 2719.50 words/s : L.r. 9.3279e-05
[2018-11-23 23:11:29] Ep. 20 : Up. 166000 : Sen. 35700 : Cost 68.98 : Time 94.45s : 10863.94 words/s : L.r. 9.3138e-05
[2018-11-23 23:13:04] Ep. 20 : Up. 166500 : Sen. 70700 : Cost 70.38 : Time 94.91s : 10958.60 words/s : L.r. 9.2998e-05
[2018-11-23 23:14:36] Ep. 20 : Up. 167000 : Sen. 105700 : Cost 68.21 : Time 92.81s : 10860.70 words/s : L.r. 9.2859e-05
[2018-11-23 23:16:13] Ep. 20 : Up. 167500 : Sen. 140700 : Cost 72.19 : Time 96.27s : 11058.90 words/s : L.r. 9.2720e-05
[2018-11-23 23:17:48] Ep. 20 : Up. 168000 : Sen. 175700 : Cost 71.67 : Time 95.50s : 11054.96 words/s : L.r. 9.2582e-05
[2018-11-23 23:19:21] Ep. 20 : Up. 168500 : Sen. 210700 : Cost 68.55 : Time 92.68s : 10885.61 words/s : L.r. 9.2445e-05
[2018-11-23 23:20:57] Ep. 20 : Up. 169000 : Sen. 245700 : Cost 72.02 : Time 95.90s : 11012.51 words/s : L.r. 9.2308e-05
[2018-11-23 23:22:30] Ep. 20 : Up. 169500 : Sen. 280700 : Cost 69.20 : Time 93.13s : 10902.41 words/s : L.r. 9.2171e-05
[2018-11-23 23:24:04] Ep. 20 : Up. 170000 : Sen. 315700 : Cost 70.60 : Time 94.22s : 10950.20 words/s : L.r. 9.2036e-05
[2018-11-23 23:24:11] [valid] Ep. 20 : Up. 170000 : cross-entropy : 46.3884 : new best
[2018-11-23 23:24:18] [valid] Ep. 20 : Up. 170000 : perplexity : 4.47508 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2018-11-23 23:28:39] [valid] Ep. 20 : Up. 170000 : translation : 29.3 : stalled 1 times
[2018-11-23 23:28:39] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-23 23:28:43] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.iter170000.npz
[2018-11-23 23:28:47] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz
[2018-11-23 23:28:52] Saving Adam parameters to model/model.src0tgt0.trans.batch70.npz.optimizer.npz
[2018-11-23 23:30:37] Ep. 20 : Up. 170500 : Sen. 350700 : Cost 71.65 : Time 392.86s : 2666.93 words/s : L.r. 9.1901e-05
[2018-11-23 23:32:14] Ep. 20 : Up. 171000 : Sen. 385700 : Cost 72.29 : Time 96.72s : 10889.30 words/s : L.r. 9.1766e-05
[2018-11-23 23:33:47] Ep. 20 : Up. 171500 : Sen. 420700 : Cost 69.08 : Time 92.97s : 10871.37 words/s : L.r. 9.1632e-05
[2018-11-23 23:35:20] Ep. 20 : Up. 172000 : Sen. 455700 : Cost 69.85 : Time 93.88s : 10891.26 words/s : L.r. 9.1499e-05
[2018-11-23 23:36:56] Ep. 20 : Up. 172500 : Sen. 490700 : Cost 71.83 : Time 95.09s : 10976.38 words/s : L.r. 9.1366e-05
[2018-11-23 23:38:30] Ep. 20 : Up. 173000 : Sen. 525700 : Cost 71.24 : Time 94.26s : 10988.61 words/s : L.r. 9.1234e-05
[2018-11-23 23:40:04] Ep. 20 : Up. 173500 : Sen. 560700 : Cost 70.99 : Time 94.39s : 10951.55 words/s : L.r. 9.1103e-05
[2018-11-23 23:41:40] Ep. 20 : Up. 174000 : Sen. 595664 : Cost 71.79 : Time 95.53s : 10919.42 words/s : L.r. 9.0972e-05
[2018-11-23 23:42:17] Seen 609664 samples
[2018-11-23 23:42:17] Starting epoch 21
[2018-11-23 23:42:17] [data] Shuffling files
[2018-11-23 23:42:19] [data] Done
[2018-11-23 23:43:19] Ep. 21 : Up. 174500 : Sen. 21000 : Cost 67.89 : Time 99.24s : 10124.79 words/s : L.r. 9.0841e-05
[2018-11-23 23:44:54] Ep. 21 : Up. 175000 : Sen. 56000 : Cost 70.28 : Time 95.48s : 10955.72 words/s : L.r. 9.0711e-05
[2018-11-23 23:45:01] [valid] Ep. 21 : Up. 175000 : cross-entropy : 46.3498 : new best
[2018-11-23 23:45:08] [valid] Ep. 21 : Up. 175000 : perplexity : 4.4695 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2018-11-23 23:49:13] [valid] Ep. 21 : Up. 175000 : translation : 29.25 : stalled 2 times
[2018-11-23 23:49:13] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-23 23:49:17] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.iter175000.npz
[2018-11-23 23:49:21] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz
[2018-11-23 23:49:26] Saving Adam parameters to model/model.src0tgt0.trans.batch70.npz.optimizer.npz
[2018-11-23 23:51:09] Ep. 21 : Up. 175500 : Sen. 91000 : Cost 70.33 : Time 374.54s : 2777.31 words/s : L.r. 9.0582e-05
[2018-11-23 23:52:45] Ep. 21 : Up. 176000 : Sen. 126000 : Cost 71.43 : Time 96.34s : 10968.91 words/s : L.r. 9.0453e-05
[2018-11-23 23:54:19] Ep. 21 : Up. 176500 : Sen. 161000 : Cost 69.13 : Time 93.95s : 10884.60 words/s : L.r. 9.0325e-05
[2018-11-23 23:55:52] Ep. 21 : Up. 177000 : Sen. 196000 : Cost 69.01 : Time 93.08s : 10938.02 words/s : L.r. 9.0198e-05
[2018-11-23 23:57:28] Ep. 21 : Up. 177500 : Sen. 231000 : Cost 70.69 : Time 95.50s : 10916.25 words/s : L.r. 9.0070e-05
[2018-11-23 23:59:02] Ep. 21 : Up. 178000 : Sen. 266000 : Cost 69.80 : Time 94.04s : 10954.60 words/s : L.r. 8.9944e-05
[2018-11-24 00:00:35] Ep. 21 : Up. 178500 : Sen. 301000 : Cost 69.39 : Time 93.49s : 10906.42 words/s : L.r. 8.9818e-05
[2018-11-24 00:02:11] Ep. 21 : Up. 179000 : Sen. 336000 : Cost 71.70 : Time 95.86s : 10940.18 words/s : L.r. 8.9692e-05
[2018-11-24 00:03:46] Ep. 21 : Up. 179500 : Sen. 371000 : Cost 70.51 : Time 94.61s : 10976.45 words/s : L.r. 8.9567e-05
[2018-11-24 00:05:21] Ep. 21 : Up. 180000 : Sen. 406000 : Cost 71.53 : Time 95.42s : 10950.97 words/s : L.r. 8.9443e-05
[2018-11-24 00:05:28] [valid] Ep. 21 : Up. 180000 : cross-entropy : 46.3722 : stalled 1 times
[2018-11-24 00:05:35] [valid] Ep. 21 : Up. 180000 : perplexity : 4.47273 : stalled 1 times
Detokenizer Version $Revision: 4134 $
Language: en
[2018-11-24 00:09:43] [valid] Ep. 21 : Up. 180000 : translation : 29.32 : stalled 3 times
[2018-11-24 00:09:43] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-24 00:09:47] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.iter180000.npz
[2018-11-24 00:09:51] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz
[2018-11-24 00:09:55] Saving Adam parameters to model/model.src0tgt0.trans.batch70.npz.optimizer.npz
[2018-11-24 00:11:37] Ep. 21 : Up. 180500 : Sen. 441000 : Cost 68.02 : Time 375.38s : 2660.45 words/s : L.r. 8.9319e-05
[2018-11-24 00:13:13] Ep. 21 : Up. 181000 : Sen. 476000 : Cost 72.25 : Time 96.44s : 10937.86 words/s : L.r. 8.9195e-05
[2018-11-24 00:14:49] Ep. 21 : Up. 181500 : Sen. 511000 : Cost 72.37 : Time 96.08s : 10959.68 words/s : L.r. 8.9072e-05
[2018-11-24 00:16:25] Ep. 21 : Up. 182000 : Sen. 546000 : Cost 71.32 : Time 95.32s : 10936.95 words/s : L.r. 8.8950e-05
[2018-11-24 00:17:58] Ep. 21 : Up. 182500 : Sen. 580964 : Cost 68.40 : Time 92.99s : 10783.96 words/s : L.r. 8.8828e-05
[2018-11-24 00:19:16] Seen 609664 samples
[2018-11-24 00:19:16] Starting epoch 22
[2018-11-24 00:19:16] [data] Shuffling files
[2018-11-24 00:19:19] [data] Done
[2018-11-24 00:19:40] Ep. 22 : Up. 183000 : Sen. 6300 : Cost 71.64 : Time 102.49s : 10225.05 words/s : L.r. 8.8707e-05
[2018-11-24 00:21:14] Ep. 22 : Up. 183500 : Sen. 41300 : Cost 68.31 : Time 94.25s : 10839.07 words/s : L.r. 8.8586e-05
[2018-11-24 00:22:50] Ep. 22 : Up. 184000 : Sen. 76300 : Cost 70.65 : Time 95.87s : 10941.28 words/s : L.r. 8.8465e-05
[2018-11-24 00:24:24] Ep. 22 : Up. 184500 : Sen. 111300 : Cost 68.31 : Time 93.73s : 10844.90 words/s : L.r. 8.8345e-05
[2018-11-24 00:25:59] Ep. 22 : Up. 185000 : Sen. 146300 : Cost 70.49 : Time 94.88s : 11010.54 words/s : L.r. 8.8226e-05
[2018-11-24 00:26:06] [valid] Ep. 22 : Up. 185000 : cross-entropy : 46.4039 : stalled 2 times
[2018-11-24 00:26:13] [valid] Ep. 22 : Up. 185000 : perplexity : 4.47732 : stalled 2 times
Detokenizer Version $Revision: 4134 $
Language: en
[2018-11-24 00:30:57] [valid] Ep. 22 : Up. 185000 : translation : 29.3 : stalled 4 times
[2018-11-24 00:30:57] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-24 00:31:01] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.iter185000.npz
[2018-11-24 00:31:05] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz
[2018-11-24 00:31:09] Saving Adam parameters to model/model.src0tgt0.trans.batch70.npz.optimizer.npz
[2018-11-24 00:32:53] Ep. 22 : Up. 185500 : Sen. 181300 : Cost 70.06 : Time 413.79s : 2509.33 words/s : L.r. 8.8107e-05
[2018-11-24 00:34:27] Ep. 22 : Up. 186000 : Sen. 216300 : Cost 69.70 : Time 94.00s : 10979.61 words/s : L.r. 8.7988e-05
[2018-11-24 00:36:01] Ep. 22 : Up. 186500 : Sen. 251300 : Cost 70.07 : Time 94.31s : 10972.43 words/s : L.r. 8.7870e-05
[2018-11-24 00:37:34] Ep. 22 : Up. 187000 : Sen. 286300 : Cost 68.25 : Time 92.76s : 10879.25 words/s : L.r. 8.7753e-05
[2018-11-24 00:39:07] Ep. 22 : Up. 187500 : Sen. 321300 : Cost 69.80 : Time 93.84s : 10948.17 words/s : L.r. 8.7636e-05
[2018-11-24 00:40:44] Ep. 22 : Up. 188000 : Sen. 356300 : Cost 72.16 : Time 96.99s : 10947.69 words/s : L.r. 8.7519e-05
[2018-11-24 00:42:19] Ep. 22 : Up. 188500 : Sen. 391300 : Cost 70.45 : Time 94.89s : 10897.18 words/s : L.r. 8.7403e-05
[2018-11-24 00:43:53] Ep. 22 : Up. 189000 : Sen. 426300 : Cost 70.03 : Time 94.12s : 10928.93 words/s : L.r. 8.7287e-05
[2018-11-24 00:45:27] Ep. 22 : Up. 189500 : Sen. 461300 : Cost 69.41 : Time 93.74s : 10871.64 words/s : L.r. 8.7172e-05
[2018-11-24 00:47:02] Ep. 22 : Up. 190000 : Sen. 496300 : Cost 71.07 : Time 94.80s : 10992.00 words/s : L.r. 8.7057e-05
[2018-11-24 00:47:09] [valid] Ep. 22 : Up. 190000 : cross-entropy : 46.4531 : stalled 3 times
[2018-11-24 00:47:16] [valid] Ep. 22 : Up. 190000 : perplexity : 4.48445 : stalled 3 times
Detokenizer Version $Revision: 4134 $
Language: en
sacreBLEU: The input and reference stream(s) were of different lengths.

[2018-11-24 00:51:38] [valid] Ep. 22 : Up. 190000 : translation : 0 : stalled 5 times
[2018-11-24 00:51:38] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-24 00:51:41] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.iter190000.npz
[2018-11-24 00:51:45] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz
[2018-11-24 00:51:51] Saving Adam parameters to model/model.src0tgt0.trans.batch70.npz.optimizer.npz
[2018-11-24 00:53:36] Ep. 22 : Up. 190500 : Sen. 531300 : Cost 71.09 : Time 393.92s : 2643.81 words/s : L.r. 8.6943e-05
[2018-11-24 00:55:12] Ep. 22 : Up. 191000 : Sen. 566300 : Cost 70.72 : Time 95.65s : 10846.50 words/s : L.r. 8.6829e-05
[2018-11-24 00:56:46] Ep. 22 : Up. 191500 : Sen. 601264 : Cost 69.74 : Time 94.12s : 10858.84 words/s : L.r. 8.6716e-05
[2018-11-24 00:57:09] Seen 609664 samples
[2018-11-24 00:57:09] Starting epoch 23
[2018-11-24 00:57:09] [data] Shuffling files
[2018-11-24 00:57:12] [data] Done
[2018-11-24 00:58:27] Ep. 23 : Up. 192000 : Sen. 26600 : Cost 70.17 : Time 101.24s : 10345.23 words/s : L.r. 8.6603e-05
[2018-11-24 01:00:02] Ep. 23 : Up. 192500 : Sen. 61600 : Cost 69.70 : Time 95.40s : 10929.68 words/s : L.r. 8.6490e-05
[2018-11-24 01:01:36] Ep. 23 : Up. 193000 : Sen. 96600 : Cost 68.39 : Time 93.23s : 10970.20 words/s : L.r. 8.6378e-05
[2018-11-24 01:03:11] Ep. 23 : Up. 193500 : Sen. 131600 : Cost 69.86 : Time 95.50s : 10877.01 words/s : L.r. 8.6266e-05
[2018-11-24 01:04:48] Ep. 23 : Up. 194000 : Sen. 166600 : Cost 71.38 : Time 96.53s : 10968.90 words/s : L.r. 8.6155e-05
[2018-11-24 01:06:21] Ep. 23 : Up. 194500 : Sen. 201600 : Cost 68.68 : Time 93.61s : 10892.71 words/s : L.r. 8.6044e-05
[2018-11-24 01:07:57] Ep. 23 : Up. 195000 : Sen. 236600 : Cost 70.63 : Time 95.31s : 10970.36 words/s : L.r. 8.5934e-05
[2018-11-24 01:08:03] [valid] Ep. 23 : Up. 195000 : cross-entropy : 46.4538 : stalled 4 times
[2018-11-24 01:08:10] [valid] Ep. 23 : Up. 195000 : perplexity : 4.48456 : stalled 4 times
Detokenizer Version $Revision: 4134 $
Language: en
sacreBLEU: The input and reference stream(s) were of different lengths.

[2018-11-24 01:13:05] [valid] Ep. 23 : Up. 195000 : translation : 0 : stalled 6 times
[2018-11-24 01:13:05] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-24 01:13:10] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.iter195000.npz
[2018-11-24 01:13:13] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz
[2018-11-24 01:13:18] Saving Adam parameters to model/model.src0tgt0.trans.batch70.npz.optimizer.npz
[2018-11-24 01:15:01] Ep. 23 : Up. 195500 : Sen. 271600 : Cost 69.07 : Time 423.99s : 2417.18 words/s : L.r. 8.5824e-05
[2018-11-24 01:16:36] Ep. 23 : Up. 196000 : Sen. 306600 : Cost 70.16 : Time 95.69s : 10851.71 words/s : L.r. 8.5714e-05
[2018-11-24 01:18:10] Ep. 23 : Up. 196500 : Sen. 341600 : Cost 69.67 : Time 94.26s : 10892.36 words/s : L.r. 8.5605e-05
[2018-11-24 01:19:45] Ep. 23 : Up. 197000 : Sen. 376600 : Cost 69.50 : Time 94.20s : 10880.50 words/s : L.r. 8.5496e-05
[2018-11-24 01:21:20] Ep. 23 : Up. 197500 : Sen. 411600 : Cost 71.19 : Time 95.81s : 10980.58 words/s : L.r. 8.5388e-05
[2018-11-24 01:22:55] Ep. 23 : Up. 198000 : Sen. 446600 : Cost 69.98 : Time 94.31s : 10941.58 words/s : L.r. 8.5280e-05
[2018-11-24 01:24:30] Ep. 23 : Up. 198500 : Sen. 481600 : Cost 70.54 : Time 95.24s : 10925.50 words/s : L.r. 8.5173e-05
[2018-11-24 01:26:02] Ep. 23 : Up. 199000 : Sen. 516600 : Cost 68.35 : Time 92.11s : 10924.87 words/s : L.r. 8.5066e-05
[2018-11-24 01:27:36] Ep. 23 : Up. 199500 : Sen. 551600 : Cost 70.67 : Time 94.20s : 11022.83 words/s : L.r. 8.4959e-05
[2018-11-24 01:29:11] Ep. 23 : Up. 200000 : Sen. 586600 : Cost 71.24 : Time 95.10s : 10985.52 words/s : L.r. 8.4853e-05
[2018-11-24 01:29:19] [valid] Ep. 23 : Up. 200000 : cross-entropy : 46.4419 : stalled 5 times
[2018-11-24 01:29:26] [valid] Ep. 23 : Up. 200000 : perplexity : 4.48282 : stalled 5 times
Detokenizer Version $Revision: 4134 $
Language: en
sacreBLEU: The input and reference stream(s) were of different lengths.

[2018-11-24 01:34:01] [valid] Ep. 23 : Up. 200000 : translation : 0 : stalled 7 times
[2018-11-24 01:34:01] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-24 01:34:05] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.iter200000.npz
[2018-11-24 01:34:09] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz
[2018-11-24 01:34:13] Saving Adam parameters to model/model.src0tgt0.trans.batch70.npz.optimizer.npz
[2018-11-24 01:35:23] Seen 609664 samples
[2018-11-24 01:35:23] Starting epoch 24
[2018-11-24 01:35:23] [data] Shuffling files
[2018-11-24 01:35:25] [data] Done
[2018-11-24 01:36:03] Ep. 24 : Up. 200500 : Sen. 11900 : Cost 70.62 : Time 411.39s : 2533.51 words/s : L.r. 8.4747e-05
[2018-11-24 01:37:38] Ep. 24 : Up. 201000 : Sen. 46900 : Cost 68.58 : Time 95.04s : 10870.42 words/s : L.r. 8.4641e-05
[2018-11-24 01:39:12] Ep. 24 : Up. 201500 : Sen. 81900 : Cost 68.07 : Time 94.27s : 10829.41 words/s : L.r. 8.4536e-05
[2018-11-24 01:40:46] Ep. 24 : Up. 202000 : Sen. 116900 : Cost 68.80 : Time 93.77s : 10961.57 words/s : L.r. 8.4432e-05
[2018-11-24 01:42:19] Ep. 24 : Up. 202500 : Sen. 151900 : Cost 68.25 : Time 92.99s : 10952.25 words/s : L.r. 8.4327e-05
[2018-11-24 01:43:55] Ep. 24 : Up. 203000 : Sen. 186900 : Cost 70.95 : Time 95.66s : 11034.36 words/s : L.r. 8.4223e-05
[2018-11-24 01:45:27] Ep. 24 : Up. 203500 : Sen. 221900 : Cost 67.42 : Time 92.04s : 10923.85 words/s : L.r. 8.4120e-05
[2018-11-24 01:47:02] Ep. 24 : Up. 204000 : Sen. 256900 : Cost 71.24 : Time 95.67s : 11049.80 words/s : L.r. 8.4017e-05
[2018-11-24 01:48:38] Ep. 24 : Up. 204500 : Sen. 291900 : Cost 70.35 : Time 95.15s : 10956.69 words/s : L.r. 8.3914e-05
[2018-11-24 01:50:11] Ep. 24 : Up. 205000 : Sen. 326900 : Cost 68.74 : Time 93.19s : 10977.69 words/s : L.r. 8.3812e-05
[2018-11-24 01:50:18] [valid] Ep. 24 : Up. 205000 : cross-entropy : 46.4719 : stalled 6 times
[2018-11-24 01:50:25] [valid] Ep. 24 : Up. 205000 : perplexity : 4.48717 : stalled 6 times
[2018-11-24 01:54:21] Error: out of memory - /home/big_maggie/usr/marian_prometheus/marian_1.6.0/marian-dev/src/tensors/gpu/device.cu:30
train_trans_batch70.sh: line 26: 23870 Aborted                 (core dumped) $marian_home/marian --model model/model.src0tgt0.trans.batch70.npz --type transformer --train-sets corp/europarl.cs-en.docs.train.en.bpe corp/europarl.cs-en.docs.train.cz.bpe --max-length 80 --vocabs corp/vocab.encs.europarl.yml corp/vocab.encs.europarl.yml --mini-batch 70 --maxi-batch 1000 --early-stopping 10 --valid-freq 5000 --save-freq 5000 --disp-freq 500 --valid-metrics cross-entropy perplexity translation --valid-sets corp/europarl.cs-en.docs.dev.en.bpe corp/europarl.cs-en.docs.dev.cz.bpe --valid-script-path ./val.sh --valid-translation-output data/valid.bpe.en.output --quiet-translation --valid-mini-batch 64 --beam-size 6 --normalize 0.6 --log model/train_trans.log --valid-log model/valid_trans.log --enc-depth 6 --dec-depth 6 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --optimizer-delay 4 --devices 0 --sync-sgd --seed 1111 --exponential-smoothing
