[2018-11-24 15:48:18] [config] after-batches: 0
[2018-11-24 15:48:18] [config] after-epochs: 0
[2018-11-24 15:48:18] [config] allow-unk: false
[2018-11-24 15:48:18] [config] batch-flexible-lr: false
[2018-11-24 15:48:18] [config] batch-normal-words: 1920
[2018-11-24 15:48:18] [config] beam-size: 6
[2018-11-24 15:48:18] [config] best-deep: false
[2018-11-24 15:48:18] [config] clip-gemm: 0
[2018-11-24 15:48:18] [config] clip-norm: 5
[2018-11-24 15:48:18] [config] cost-type: ce-mean
[2018-11-24 15:48:18] [config] cpu-threads: 0
[2018-11-24 15:48:18] [config] data-weighting-type: sentence
[2018-11-24 15:48:18] [config] dec-cell: gru
[2018-11-24 15:48:18] [config] dec-cell-base-depth: 2
[2018-11-24 15:48:18] [config] dec-cell-high-depth: 1
[2018-11-24 15:48:18] [config] dec-depth: 6
[2018-11-24 15:48:18] [config] devices:
[2018-11-24 15:48:18] [config]   - 0
[2018-11-24 15:48:18] [config] dim-emb: 512
[2018-11-24 15:48:18] [config] dim-rnn: 1024
[2018-11-24 15:48:18] [config] dim-vocabs:
[2018-11-24 15:48:18] [config]   - 32000
[2018-11-24 15:48:18] [config]   - 32000
[2018-11-24 15:48:18] [config] disp-freq: 500
[2018-11-24 15:48:18] [config] disp-label-counts: false
[2018-11-24 15:48:18] [config] dropout-rnn: 0
[2018-11-24 15:48:18] [config] dropout-src: 0
[2018-11-24 15:48:18] [config] dropout-trg: 0
[2018-11-24 15:48:18] [config] dump-config: false
[2018-11-24 15:48:18] [config] early-stopping: 10
[2018-11-24 15:48:18] [config] embedding-fix-src: false
[2018-11-24 15:48:18] [config] embedding-fix-trg: false
[2018-11-24 15:48:18] [config] embedding-normalization: false
[2018-11-24 15:48:18] [config] enc-cell: gru
[2018-11-24 15:48:18] [config] enc-cell-depth: 1
[2018-11-24 15:48:18] [config] enc-depth: 6
[2018-11-24 15:48:18] [config] enc-type: bidirectional
[2018-11-24 15:48:18] [config] exponential-smoothing: 0.0001
[2018-11-24 15:48:18] [config] grad-dropping-momentum: 0
[2018-11-24 15:48:18] [config] grad-dropping-rate: 0
[2018-11-24 15:48:18] [config] grad-dropping-warmup: 100
[2018-11-24 15:48:18] [config] guided-alignment-cost: ce
[2018-11-24 15:48:18] [config] guided-alignment-weight: 1
[2018-11-24 15:48:18] [config] ignore-model-config: false
[2018-11-24 15:48:18] [config] interpolate-env-vars: false
[2018-11-24 15:48:18] [config] keep-best: false
[2018-11-24 15:48:18] [config] label-smoothing: 0.1
[2018-11-24 15:48:18] [config] layer-normalization: false
[2018-11-24 15:48:18] [config] learn-rate: 0.0003
[2018-11-24 15:48:18] [config] log: model/train_trans.log
[2018-11-24 15:48:18] [config] log-level: info
[2018-11-24 15:48:18] [config] lr-decay: 0
[2018-11-24 15:48:18] [config] lr-decay-freq: 50000
[2018-11-24 15:48:18] [config] lr-decay-inv-sqrt: 16000
[2018-11-24 15:48:18] [config] lr-decay-repeat-warmup: false
[2018-11-24 15:48:18] [config] lr-decay-reset-optimizer: false
[2018-11-24 15:48:18] [config] lr-decay-start:
[2018-11-24 15:48:18] [config]   - 10
[2018-11-24 15:48:18] [config]   - 1
[2018-11-24 15:48:18] [config] lr-decay-strategy: epoch+stalled
[2018-11-24 15:48:18] [config] lr-report: true
[2018-11-24 15:48:18] [config] lr-warmup: 16000
[2018-11-24 15:48:18] [config] lr-warmup-at-reload: false
[2018-11-24 15:48:18] [config] lr-warmup-cycle: false
[2018-11-24 15:48:18] [config] lr-warmup-start-rate: 0
[2018-11-24 15:48:18] [config] max-length: 80
[2018-11-24 15:48:18] [config] max-length-crop: false
[2018-11-24 15:48:18] [config] max-length-factor: 3
[2018-11-24 15:48:18] [config] maxi-batch: 1000
[2018-11-24 15:48:18] [config] maxi-batch-sort: trg
[2018-11-24 15:48:18] [config] mini-batch: 70
[2018-11-24 15:48:18] [config] mini-batch-fit: false
[2018-11-24 15:48:18] [config] mini-batch-fit-step: 10
[2018-11-24 15:48:18] [config] mini-batch-words: 0
[2018-11-24 15:48:18] [config] model: model/model.src0tgt0.trans.batch70.npz
[2018-11-24 15:48:18] [config] multi-node: false
[2018-11-24 15:48:18] [config] multi-node-overlap: true
[2018-11-24 15:48:18] [config] n-best: false
[2018-11-24 15:48:18] [config] no-reload: false
[2018-11-24 15:48:18] [config] no-restore-corpus: false
[2018-11-24 15:48:18] [config] no-shuffle: false
[2018-11-24 15:48:18] [config] normalize: 0.6
[2018-11-24 15:48:18] [config] optimizer: adam
[2018-11-24 15:48:18] [config] optimizer-delay: 4
[2018-11-24 15:48:18] [config] optimizer-params:
[2018-11-24 15:48:18] [config]   - 0.9
[2018-11-24 15:48:18] [config]   - 0.98
[2018-11-24 15:48:18] [config]   - 1e-09
[2018-11-24 15:48:18] [config] overwrite: false
[2018-11-24 15:48:18] [config] quiet: false
[2018-11-24 15:48:18] [config] quiet-translation: true
[2018-11-24 15:48:18] [config] relative-paths: false
[2018-11-24 15:48:18] [config] right-left: false
[2018-11-24 15:48:18] [config] save-freq: 5000
[2018-11-24 15:48:18] [config] seed: 1111
[2018-11-24 15:48:18] [config] skip: false
[2018-11-24 15:48:18] [config] sqlite: ""
[2018-11-24 15:48:18] [config] sqlite-drop: false
[2018-11-24 15:48:18] [config] sync-sgd: true
[2018-11-24 15:48:18] [config] tempdir: /tmp
[2018-11-24 15:48:18] [config] tied-embeddings: false
[2018-11-24 15:48:18] [config] tied-embeddings-all: true
[2018-11-24 15:48:18] [config] tied-embeddings-src: false
[2018-11-24 15:48:18] [config] train-sets:
[2018-11-24 15:48:18] [config]   - corp/europarl.cs-en.docs.train.en.bpe
[2018-11-24 15:48:18] [config]   - corp/europarl.cs-en.docs.train.cz.bpe
[2018-11-24 15:48:18] [config] transformer-aan-activation: swish
[2018-11-24 15:48:18] [config] transformer-aan-depth: 2
[2018-11-24 15:48:18] [config] transformer-aan-nogate: false
[2018-11-24 15:48:18] [config] transformer-decoder-autoreg: self-attention
[2018-11-24 15:48:18] [config] transformer-dim-aan: 2048
[2018-11-24 15:48:18] [config] transformer-dim-ffn: 2048
[2018-11-24 15:48:18] [config] transformer-dropout: 0.1
[2018-11-24 15:48:18] [config] transformer-dropout-attention: 0
[2018-11-24 15:48:18] [config] transformer-dropout-ffn: 0
[2018-11-24 15:48:18] [config] transformer-ffn-activation: swish
[2018-11-24 15:48:18] [config] transformer-ffn-depth: 2
[2018-11-24 15:48:18] [config] transformer-guided-alignment-layer: last
[2018-11-24 15:48:18] [config] transformer-heads: 8
[2018-11-24 15:48:18] [config] transformer-no-projection: false
[2018-11-24 15:48:18] [config] transformer-postprocess: dan
[2018-11-24 15:48:18] [config] transformer-postprocess-emb: d
[2018-11-24 15:48:18] [config] transformer-preprocess: ""
[2018-11-24 15:48:18] [config] transformer-tied-layers:
[2018-11-24 15:48:18] [config]   []
[2018-11-24 15:48:18] [config] type: transformer
[2018-11-24 15:48:18] [config] valid-freq: 5000
[2018-11-24 15:48:18] [config] valid-log: model/valid_trans.log
[2018-11-24 15:48:18] [config] valid-max-length: 1000
[2018-11-24 15:48:18] [config] valid-metrics:
[2018-11-24 15:48:18] [config]   - cross-entropy
[2018-11-24 15:48:18] [config]   - perplexity
[2018-11-24 15:48:18] [config]   - translation
[2018-11-24 15:48:18] [config] valid-mini-batch: 8
[2018-11-24 15:48:18] [config] valid-script-path: ./val.sh
[2018-11-24 15:48:18] [config] valid-sets:
[2018-11-24 15:48:18] [config]   - corp/europarl.cs-en.docs.dev.en.bpe
[2018-11-24 15:48:18] [config]   - corp/europarl.cs-en.docs.dev.cz.bpe
[2018-11-24 15:48:18] [config] valid-translation-output: data/valid.asd.bpe.en.output
[2018-11-24 15:48:18] [config] version: v1.6.0+5448f8d
[2018-11-24 15:48:18] [config] vocabs:
[2018-11-24 15:48:18] [config]   - corp/vocab.encs.europarl.yml
[2018-11-24 15:48:18] [config]   - corp/vocab.encs.europarl.yml
[2018-11-24 15:48:18] [config] word-penalty: 0
[2018-11-24 15:48:18] [config] workspace: 2048
[2018-11-24 15:48:18] [config] Model created with Marian v1.6.0+5448f8d
[2018-11-24 15:48:18] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.europarl.yml
[2018-11-24 15:48:18] [data] Setting vocabulary size for input 0 to 32000
[2018-11-24 15:48:18] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.europarl.yml
[2018-11-24 15:48:19] [data] Setting vocabulary size for input 1 to 32000
[2018-11-24 15:48:19] [memory] Extending reserved space to 2048 MB (device gpu0)
[2018-11-24 15:48:19] Loading model from model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-24 15:48:22] Loading model from model/model.src0tgt0.trans.batch70.npz
[2018-11-24 15:48:23] [memory] Reserving 230 MB, device gpu0
[2018-11-24 15:48:23] Loading Adam parameters from model/model.src0tgt0.trans.batch70.npz.optimizer.npz
[2018-11-24 15:48:28] [memory] Reserving 461 MB, device gpu0
[2018-11-24 15:48:28] [data] Restoring the corpus state to epoch 23, batch 200000
[2018-11-24 15:48:28] [data] Shuffling files
[2018-11-24 15:48:31] [data] Done
[2018-11-24 15:49:15] Training started
[2018-11-24 15:49:15] [memory] Reserving 230 MB, device gpu0
[2018-11-24 15:49:41] [memory] Reserving 230 MB, device gpu0
[2018-11-24 15:52:42] Seen 609664 samples
[2018-11-24 15:52:42] Starting epoch 24
[2018-11-24 15:52:42] [data] Shuffling files
[2018-11-24 15:52:44] [data] Done
[2018-11-24 15:53:22] Ep. 24 : Up. 200500 : Sen. 11900 : Cost 70.60 : Time 303.13s : 3438.38 words/s : L.r. 8.4747e-05
[2018-11-24 15:54:56] Ep. 24 : Up. 201000 : Sen. 46900 : Cost 68.63 : Time 93.69s : 11027.58 words/s : L.r. 8.4641e-05
[2018-11-24 15:56:28] Ep. 24 : Up. 201500 : Sen. 81900 : Cost 68.09 : Time 92.17s : 11076.44 words/s : L.r. 8.4536e-05
[2018-11-24 15:58:00] Ep. 24 : Up. 202000 : Sen. 116900 : Cost 68.80 : Time 92.14s : 11155.36 words/s : L.r. 8.4432e-05
[2018-11-24 15:59:31] Ep. 24 : Up. 202500 : Sen. 151900 : Cost 68.25 : Time 91.16s : 11173.00 words/s : L.r. 8.4327e-05
[2018-11-24 16:01:06] Ep. 24 : Up. 203000 : Sen. 186900 : Cost 70.95 : Time 94.69s : 11147.99 words/s : L.r. 8.4223e-05
[2018-11-24 16:02:37] Ep. 24 : Up. 203500 : Sen. 221900 : Cost 67.43 : Time 91.17s : 11027.76 words/s : L.r. 8.4120e-05
[2018-11-24 16:04:12] Ep. 24 : Up. 204000 : Sen. 256900 : Cost 71.23 : Time 94.59s : 11175.84 words/s : L.r. 8.4017e-05
[2018-11-24 16:05:45] Ep. 24 : Up. 204500 : Sen. 291900 : Cost 70.36 : Time 93.66s : 11131.22 words/s : L.r. 8.3914e-05
[2018-11-24 16:07:17] Ep. 24 : Up. 205000 : Sen. 326900 : Cost 68.72 : Time 92.08s : 11110.41 words/s : L.r. 8.3812e-05
[2018-11-24 16:07:29] [valid] Ep. 24 : Up. 205000 : cross-entropy : 46.4642 : stalled 6 times
[2018-11-24 16:07:42] [valid] Ep. 24 : Up. 205000 : perplexity : 4.48605 : stalled 6 times
Detokenizer Version $Revision: 4134 $
Language: en
[2018-11-24 16:12:46] [valid] Ep. 24 : Up. 205000 : translation : 29.42 : new best
[2018-11-24 16:12:46] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-24 16:12:50] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.iter205000.npz
[2018-11-24 16:12:53] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz
[2018-11-24 16:12:58] Saving Adam parameters to model/model.src0tgt0.trans.batch70.npz.optimizer.npz
[2018-11-24 16:14:39] Ep. 24 : Up. 205500 : Sen. 361900 : Cost 69.76 : Time 441.72s : 2334.92 words/s : L.r. 8.3710e-05
[2018-11-24 16:16:13] Ep. 24 : Up. 206000 : Sen. 396900 : Cost 69.33 : Time 93.81s : 10931.71 words/s : L.r. 8.3608e-05
[2018-11-24 16:17:48] Ep. 24 : Up. 206500 : Sen. 431900 : Cost 71.66 : Time 95.46s : 11071.27 words/s : L.r. 8.3507e-05
[2018-11-24 16:19:23] Ep. 24 : Up. 207000 : Sen. 466900 : Cost 71.02 : Time 94.66s : 11065.89 words/s : L.r. 8.3406e-05
[2018-11-24 16:20:56] Ep. 24 : Up. 207500 : Sen. 501900 : Cost 69.01 : Time 92.84s : 10975.47 words/s : L.r. 8.3305e-05
[2018-11-24 16:22:28] Ep. 24 : Up. 208000 : Sen. 536900 : Cost 68.54 : Time 91.75s : 11022.10 words/s : L.r. 8.3205e-05
[2018-11-24 16:24:03] Ep. 24 : Up. 208500 : Sen. 571900 : Cost 73.03 : Time 95.86s : 11212.69 words/s : L.r. 8.3105e-05
[2018-11-24 16:25:35] Ep. 24 : Up. 209000 : Sen. 606900 : Cost 68.20 : Time 92.11s : 10928.63 words/s : L.r. 8.3006e-05
[2018-11-24 16:25:44] Seen 609664 samples
[2018-11-24 16:25:44] Starting epoch 25
[2018-11-24 16:25:44] [data] Shuffling files
[2018-11-24 16:25:46] [data] Done
[2018-11-24 16:27:15] Ep. 25 : Up. 209500 : Sen. 32200 : Cost 68.52 : Time 99.72s : 10357.63 words/s : L.r. 8.2907e-05
[2018-11-24 16:28:49] Ep. 25 : Up. 210000 : Sen. 67200 : Cost 69.69 : Time 94.25s : 11090.94 words/s : L.r. 8.2808e-05
[2018-11-24 16:29:02] [valid] Ep. 25 : Up. 210000 : cross-entropy : 46.4377 : stalled 7 times
[2018-11-24 16:29:14] [valid] Ep. 25 : Up. 210000 : perplexity : 4.48221 : stalled 7 times
Detokenizer Version $Revision: 4134 $
Language: en
[2018-11-24 16:34:23] [valid] Ep. 25 : Up. 210000 : translation : 29.28 : stalled 1 times
[2018-11-24 16:34:23] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-24 16:34:27] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.iter210000.npz
[2018-11-24 16:34:31] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz
[2018-11-24 16:34:35] Saving Adam parameters to model/model.src0tgt0.trans.batch70.npz.optimizer.npz
[2018-11-24 16:36:17] Ep. 25 : Up. 210500 : Sen. 102200 : Cost 68.80 : Time 447.65s : 2311.04 words/s : L.r. 8.2709e-05
[2018-11-24 16:37:52] Ep. 25 : Up. 211000 : Sen. 137200 : Cost 69.04 : Time 95.07s : 10856.97 words/s : L.r. 8.2611e-05
[2018-11-24 16:39:26] Ep. 25 : Up. 211500 : Sen. 172200 : Cost 69.23 : Time 93.83s : 11035.59 words/s : L.r. 8.2514e-05
[2018-11-24 16:41:00] Ep. 25 : Up. 212000 : Sen. 207200 : Cost 69.26 : Time 93.62s : 11036.91 words/s : L.r. 8.2416e-05
[2018-11-24 16:42:32] Ep. 25 : Up. 212500 : Sen. 242200 : Cost 68.58 : Time 92.78s : 11039.28 words/s : L.r. 8.2319e-05
[2018-11-24 16:44:08] Ep. 25 : Up. 213000 : Sen. 277200 : Cost 71.04 : Time 95.47s : 11063.24 words/s : L.r. 8.2223e-05
[2018-11-24 16:45:41] Ep. 25 : Up. 213500 : Sen. 312200 : Cost 69.87 : Time 93.52s : 11094.18 words/s : L.r. 8.2126e-05
[2018-11-24 16:47:13] Ep. 25 : Up. 214000 : Sen. 347200 : Cost 67.98 : Time 92.03s : 11000.45 words/s : L.r. 8.2030e-05
[2018-11-24 16:48:47] Ep. 25 : Up. 214500 : Sen. 382200 : Cost 70.29 : Time 93.96s : 11088.79 words/s : L.r. 8.1935e-05
[2018-11-24 16:50:21] Ep. 25 : Up. 215000 : Sen. 417200 : Cost 69.88 : Time 93.13s : 11105.45 words/s : L.r. 8.1839e-05
[2018-11-24 16:50:33] [valid] Ep. 25 : Up. 215000 : cross-entropy : 46.4612 : stalled 8 times
[2018-11-24 16:50:45] [valid] Ep. 25 : Up. 215000 : perplexity : 4.48562 : stalled 8 times
Detokenizer Version $Revision: 4134 $
Language: en
[2018-11-24 16:55:46] [valid] Ep. 25 : Up. 215000 : translation : 29.36 : stalled 2 times
[2018-11-24 16:55:46] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-24 16:55:50] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.iter215000.npz
[2018-11-24 16:55:55] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz
[2018-11-24 16:55:59] Saving Adam parameters to model/model.src0tgt0.trans.batch70.npz.optimizer.npz
[2018-11-24 16:57:42] Ep. 25 : Up. 215500 : Sen. 452200 : Cost 71.87 : Time 441.72s : 2405.86 words/s : L.r. 8.1744e-05
[2018-11-24 16:59:15] Ep. 25 : Up. 216000 : Sen. 487200 : Cost 68.42 : Time 92.29s : 10990.26 words/s : L.r. 8.1650e-05
[2018-11-24 17:00:49] Ep. 25 : Up. 216500 : Sen. 522200 : Cost 70.67 : Time 94.65s : 11040.35 words/s : L.r. 8.1555e-05
[2018-11-24 17:02:21] Ep. 25 : Up. 217000 : Sen. 557200 : Cost 68.69 : Time 92.22s : 11048.83 words/s : L.r. 8.1461e-05
[2018-11-24 17:03:53] Ep. 25 : Up. 217500 : Sen. 592164 : Cost 68.25 : Time 91.89s : 10977.97 words/s : L.r. 8.1368e-05
[2018-11-24 17:04:42] Seen 609664 samples
[2018-11-24 17:04:42] Starting epoch 26
[2018-11-24 17:04:42] [data] Shuffling files
[2018-11-24 17:04:44] [data] Done
[2018-11-24 17:05:34] Ep. 26 : Up. 218000 : Sen. 17500 : Cost 69.72 : Time 100.45s : 10356.05 words/s : L.r. 8.1274e-05
[2018-11-24 17:07:07] Ep. 26 : Up. 218500 : Sen. 52500 : Cost 68.33 : Time 93.57s : 11048.18 words/s : L.r. 8.1181e-05
[2018-11-24 17:08:42] Ep. 26 : Up. 219000 : Sen. 87500 : Cost 69.81 : Time 94.50s : 11108.42 words/s : L.r. 8.1088e-05
[2018-11-24 17:10:13] Ep. 26 : Up. 219500 : Sen. 122500 : Cost 66.75 : Time 91.57s : 10967.99 words/s : L.r. 8.0996e-05
[2018-11-24 17:11:48] Ep. 26 : Up. 220000 : Sen. 157500 : Cost 70.88 : Time 94.64s : 11226.09 words/s : L.r. 8.0904e-05
[2018-11-24 17:12:00] [valid] Ep. 26 : Up. 220000 : cross-entropy : 46.476 : stalled 9 times
[2018-11-24 17:12:12] [valid] Ep. 26 : Up. 220000 : perplexity : 4.48776 : stalled 9 times
Detokenizer Version $Revision: 4134 $
Language: en
[2018-11-24 17:17:20] [valid] Ep. 26 : Up. 220000 : translation : 29.39 : stalled 3 times
[2018-11-24 17:17:20] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-24 17:17:24] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.iter220000.npz
[2018-11-24 17:17:28] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz
[2018-11-24 17:17:32] Saving Adam parameters to model/model.src0tgt0.trans.batch70.npz.optimizer.npz
[2018-11-24 17:19:13] Ep. 26 : Up. 220500 : Sen. 192500 : Cost 68.22 : Time 445.13s : 2298.35 words/s : L.r. 8.0812e-05
[2018-11-24 17:20:50] Ep. 26 : Up. 221000 : Sen. 227500 : Cost 69.63 : Time 96.83s : 10760.69 words/s : L.r. 8.0721e-05
[2018-11-24 17:22:25] Ep. 26 : Up. 221500 : Sen. 262500 : Cost 69.49 : Time 94.55s : 10955.43 words/s : L.r. 8.0630e-05
[2018-11-24 17:24:00] Ep. 26 : Up. 222000 : Sen. 297500 : Cost 70.69 : Time 95.69s : 10963.54 words/s : L.r. 8.0539e-05
[2018-11-24 17:25:34] Ep. 26 : Up. 222500 : Sen. 332500 : Cost 69.69 : Time 94.05s : 11055.20 words/s : L.r. 8.0448e-05
[2018-11-24 17:27:07] Ep. 26 : Up. 223000 : Sen. 367500 : Cost 68.87 : Time 92.76s : 11062.84 words/s : L.r. 8.0358e-05
[2018-11-24 17:28:39] Ep. 26 : Up. 223500 : Sen. 402500 : Cost 67.47 : Time 91.82s : 10971.21 words/s : L.r. 8.0268e-05
[2018-11-24 17:30:13] Ep. 26 : Up. 224000 : Sen. 437500 : Cost 70.69 : Time 94.59s : 11104.29 words/s : L.r. 8.0178e-05
[2018-11-24 17:31:46] Ep. 26 : Up. 224500 : Sen. 472500 : Cost 69.30 : Time 92.70s : 11096.72 words/s : L.r. 8.0089e-05
[2018-11-24 17:33:21] Ep. 26 : Up. 225000 : Sen. 507500 : Cost 71.27 : Time 95.14s : 11134.49 words/s : L.r. 8.0000e-05
[2018-11-24 17:33:34] [valid] Ep. 26 : Up. 225000 : cross-entropy : 46.495 : stalled 10 times
[2018-11-24 17:33:46] [valid] Ep. 26 : Up. 225000 : perplexity : 4.49052 : stalled 10 times
Detokenizer Version $Revision: 4134 $
Language: en
[2018-11-24 17:38:50] [valid] Ep. 26 : Up. 225000 : translation : 29.36 : stalled 4 times
[2018-11-24 17:38:50] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-24 17:38:53] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.iter225000.npz
[2018-11-24 17:38:57] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz
[2018-11-24 17:39:01] Saving Adam parameters to model/model.src0tgt0.trans.batch70.npz.optimizer.npz
[2018-11-24 17:39:08] Training finished
[2018-11-24 17:39:08] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz.orig.npz
[2018-11-24 17:39:12] Saving model weights and runtime parameters to model/model.src0tgt0.trans.batch70.npz
[2018-11-24 17:39:16] Saving Adam parameters to model/model.src0tgt0.trans.batch70.npz.optimizer.npz
