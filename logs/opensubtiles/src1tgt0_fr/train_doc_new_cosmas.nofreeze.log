[2019-04-30 01:14:10] [marian] Marian v1.7.8 27b6420 2019-04-22 13:27:24 +0200
[2019-04-30 01:14:10] [marian] Running on cosmas.lingea.cz as process 87323 with command line:
[2019-04-30 01:14:10] [marian] /home/large/data/models/marian/marian-doc/marian-doc-laynorm-cosmas/doc-marian/build/marian --model model/model.src1tgt0.doc.new.cosmas.nofreeze.npz --pretrained-model ../src0tgt0_fr/model/model.src0tgt0.newvocab.iter630000.npz --type transformer-context --train-sets corp/opensub.en-fr.docs.train.en.bpe.src_prev corp/opensub.en-fr.docs.train.en.bpe.src corp/opensub.en-fr.docs.train.fr.bpe --max-length 55 --dim-vocabs 30000 30000 --vocabs corp/vocab.encz.opensub.new.yml corp/vocab.encz.opensub.new.yml corp/vocab.encz.opensub.new.yml --mini-batch-fit -w 8200 --mini-batch 1000 --maxi-batch 1000 --early-stopping 10 --valid-freq 5000 --save-freq 5000 --disp-freq 500 --valid-metrics cross-entropy perplexity translation --valid-sets corp/opensub.en-fr.docs.dev.en.bpe.src_prev corp/opensub.en-fr.docs.dev.en.bpe.src corp/opensub.en-fr.docs.dev.fr.bpe --valid-script-path ./val.sh --valid-translation-output data/valid.bpe.en.output --quiet-translation --valid-mini-batch 64 --beam-size 6 --normalize 0.6 --log model/train_trans.gate.log --valid-log model/valid_trans.gate.log --enc-depth 6 --dec-depth 6 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0002 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --optimizer-delay 4 --devices 0 1 --sync-sgd --seed 1111 --exponential-smoothing --no-restore-corpus
[2019-04-30 01:14:11] [config] after-batches: 0
[2019-04-30 01:14:11] [config] after-epochs: 0
[2019-04-30 01:14:11] [config] allow-unk: false
[2019-04-30 01:14:11] [config] beam-size: 6
[2019-04-30 01:14:11] [config] bert-class-symbol: "[CLS]"
[2019-04-30 01:14:11] [config] bert-mask-symbol: "[MASK]"
[2019-04-30 01:14:11] [config] bert-masking-fraction: 0.15
[2019-04-30 01:14:11] [config] bert-sep-symbol: "[SEP]"
[2019-04-30 01:14:11] [config] bert-train-type-embeddings: true
[2019-04-30 01:14:11] [config] bert-type-vocab-size: 2
[2019-04-30 01:14:11] [config] best-deep: false
[2019-04-30 01:14:11] [config] clip-gemm: 0
[2019-04-30 01:14:11] [config] clip-norm: 5
[2019-04-30 01:14:11] [config] context-enc-depth: 1
[2019-04-30 01:14:11] [config] cost-type: ce-mean
[2019-04-30 01:14:11] [config] cpu-threads: 0
[2019-04-30 01:14:11] [config] data-weighting: ""
[2019-04-30 01:14:11] [config] data-weighting-type: sentence
[2019-04-30 01:14:11] [config] dec-cell: gru
[2019-04-30 01:14:11] [config] dec-cell-base-depth: 2
[2019-04-30 01:14:11] [config] dec-cell-high-depth: 1
[2019-04-30 01:14:11] [config] dec-depth: 6
[2019-04-30 01:14:11] [config] devices:
[2019-04-30 01:14:11] [config]   - 0
[2019-04-30 01:14:11] [config]   - 1
[2019-04-30 01:14:11] [config] dim-emb: 512
[2019-04-30 01:14:11] [config] dim-rnn: 1024
[2019-04-30 01:14:11] [config] dim-vocabs:
[2019-04-30 01:14:11] [config]   - 30000
[2019-04-30 01:14:11] [config]   - 30000
[2019-04-30 01:14:11] [config]   - 30000
[2019-04-30 01:14:11] [config] disp-first: 0
[2019-04-30 01:14:11] [config] disp-freq: 500
[2019-04-30 01:14:11] [config] disp-label-counts: false
[2019-04-30 01:14:11] [config] dropout-rnn: 0
[2019-04-30 01:14:11] [config] dropout-src: 0
[2019-04-30 01:14:11] [config] dropout-trg: 0
[2019-04-30 01:14:11] [config] dump-config: ""
[2019-04-30 01:14:11] [config] early-stopping: 10
[2019-04-30 01:14:11] [config] embedding-fix-src: false
[2019-04-30 01:14:11] [config] embedding-fix-trg: false
[2019-04-30 01:14:11] [config] embedding-normalization: false
[2019-04-30 01:14:11] [config] embedding-vectors:
[2019-04-30 01:14:11] [config]   []
[2019-04-30 01:14:11] [config] enc-cell: gru
[2019-04-30 01:14:11] [config] enc-cell-depth: 1
[2019-04-30 01:14:11] [config] enc-depth: 6
[2019-04-30 01:14:11] [config] enc-type: bidirectional
[2019-04-30 01:14:11] [config] exponential-smoothing: 0.0001
[2019-04-30 01:14:11] [config] freeze: false
[2019-04-30 01:14:11] [config] grad-dropping-momentum: 0
[2019-04-30 01:14:11] [config] grad-dropping-rate: 0
[2019-04-30 01:14:11] [config] grad-dropping-warmup: 100
[2019-04-30 01:14:11] [config] guided-alignment: none
[2019-04-30 01:14:11] [config] guided-alignment-cost: mse
[2019-04-30 01:14:11] [config] guided-alignment-weight: 0.1
[2019-04-30 01:14:11] [config] hier-att: false
[2019-04-30 01:14:11] [config] ignore-model-config: false
[2019-04-30 01:14:11] [config] input-types:
[2019-04-30 01:14:11] [config]   []
[2019-04-30 01:14:11] [config] interpolate-env-vars: false
[2019-04-30 01:14:11] [config] keep-best: false
[2019-04-30 01:14:11] [config] label-smoothing: 0.1
[2019-04-30 01:14:11] [config] layer-normalization: false
[2019-04-30 01:14:11] [config] learn-rate: 0.0002
[2019-04-30 01:14:11] [config] log: model/train_trans.gate.log
[2019-04-30 01:14:11] [config] log-level: info
[2019-04-30 01:14:11] [config] log-time-zone: ""
[2019-04-30 01:14:11] [config] lr-decay: 0
[2019-04-30 01:14:11] [config] lr-decay-freq: 50000
[2019-04-30 01:14:11] [config] lr-decay-inv-sqrt:
[2019-04-30 01:14:11] [config]   - 16000
[2019-04-30 01:14:11] [config] lr-decay-repeat-warmup: false
[2019-04-30 01:14:11] [config] lr-decay-reset-optimizer: false
[2019-04-30 01:14:11] [config] lr-decay-start:
[2019-04-30 01:14:11] [config]   - 10
[2019-04-30 01:14:11] [config]   - 1
[2019-04-30 01:14:11] [config] lr-decay-strategy: epoch+stalled
[2019-04-30 01:14:11] [config] lr-report: true
[2019-04-30 01:14:11] [config] lr-warmup: 16000
[2019-04-30 01:14:11] [config] lr-warmup-at-reload: false
[2019-04-30 01:14:11] [config] lr-warmup-cycle: false
[2019-04-30 01:14:11] [config] lr-warmup-start-rate: 0
[2019-04-30 01:14:11] [config] max-length: 55
[2019-04-30 01:14:11] [config] max-length-crop: false
[2019-04-30 01:14:11] [config] max-length-factor: 3
[2019-04-30 01:14:11] [config] maxi-batch: 1000
[2019-04-30 01:14:11] [config] maxi-batch-sort: trg
[2019-04-30 01:14:11] [config] mini-batch: 1000
[2019-04-30 01:14:11] [config] mini-batch-fit: true
[2019-04-30 01:14:11] [config] mini-batch-fit-step: 10
[2019-04-30 01:14:11] [config] mini-batch-overstuff: 1
[2019-04-30 01:14:11] [config] mini-batch-track-lr: false
[2019-04-30 01:14:11] [config] mini-batch-understuff: 1
[2019-04-30 01:14:11] [config] mini-batch-warmup: 0
[2019-04-30 01:14:11] [config] mini-batch-words: 0
[2019-04-30 01:14:11] [config] mini-batch-words-ref: 0
[2019-04-30 01:14:11] [config] model: model/model.src1tgt0.doc.new.cosmas.nofreeze.npz
[2019-04-30 01:14:11] [config] multi-loss-type: sum
[2019-04-30 01:14:11] [config] multi-node: false
[2019-04-30 01:14:11] [config] multi-node-overlap: true
[2019-04-30 01:14:11] [config] n-best: false
[2019-04-30 01:14:11] [config] no-nccl: true
[2019-04-30 01:14:11] [config] no-reload: false
[2019-04-30 01:14:11] [config] no-restore-corpus: true
[2019-04-30 01:14:11] [config] no-shuffle: false
[2019-04-30 01:14:11] [config] normalize: 0.6
[2019-04-30 01:14:11] [config] num-devices: 0
[2019-04-30 01:14:11] [config] optimizer: adam
[2019-04-30 01:14:11] [config] optimizer-delay: 4
[2019-04-30 01:14:11] [config] optimizer-params:
[2019-04-30 01:14:11] [config]   - 0.9
[2019-04-30 01:14:11] [config]   - 0.98
[2019-04-30 01:14:11] [config]   - 1e-09
[2019-04-30 01:14:11] [config] overwrite: false
[2019-04-30 01:14:11] [config] pretrained-model: ../src0tgt0_fr/model/model.src0tgt0.newvocab.iter630000.npz
[2019-04-30 01:14:11] [config] quiet: false
[2019-04-30 01:14:11] [config] quiet-translation: true
[2019-04-30 01:14:11] [config] relative-paths: false
[2019-04-30 01:14:11] [config] right-left: false
[2019-04-30 01:14:11] [config] save-freq: 5000
[2019-04-30 01:14:11] [config] seed: 1111
[2019-04-30 01:14:11] [config] shuffle-in-ram: false
[2019-04-30 01:14:11] [config] skip: false
[2019-04-30 01:14:11] [config] sqlite: ""
[2019-04-30 01:14:11] [config] sqlite-drop: false
[2019-04-30 01:14:11] [config] sync-sgd: true
[2019-04-30 01:14:11] [config] tempdir: /tmp
[2019-04-30 01:14:11] [config] tied-embeddings: false
[2019-04-30 01:14:11] [config] tied-embeddings-all: true
[2019-04-30 01:14:11] [config] tied-embeddings-src: false
[2019-04-30 01:14:11] [config] train-sets:
[2019-04-30 01:14:11] [config]   - corp/opensub.en-fr.docs.train.en.bpe.src_prev
[2019-04-30 01:14:11] [config]   - corp/opensub.en-fr.docs.train.en.bpe.src
[2019-04-30 01:14:11] [config]   - corp/opensub.en-fr.docs.train.fr.bpe
[2019-04-30 01:14:11] [config] transformer-aan-activation: swish
[2019-04-30 01:14:11] [config] transformer-aan-depth: 2
[2019-04-30 01:14:11] [config] transformer-aan-nogate: false
[2019-04-30 01:14:11] [config] transformer-decoder-autoreg: self-attention
[2019-04-30 01:14:11] [config] transformer-dim-aan: 2048
[2019-04-30 01:14:11] [config] transformer-dim-ffn: 2048
[2019-04-30 01:14:11] [config] transformer-dropout: 0.1
[2019-04-30 01:14:11] [config] transformer-dropout-attention: 0
[2019-04-30 01:14:11] [config] transformer-dropout-ffn: 0
[2019-04-30 01:14:11] [config] transformer-ffn-activation: swish
[2019-04-30 01:14:11] [config] transformer-ffn-depth: 2
[2019-04-30 01:14:11] [config] transformer-guided-alignment-layer: last
[2019-04-30 01:14:11] [config] transformer-heads: 8
[2019-04-30 01:14:11] [config] transformer-no-projection: false
[2019-04-30 01:14:11] [config] transformer-postprocess: dan
[2019-04-30 01:14:11] [config] transformer-postprocess-emb: d
[2019-04-30 01:14:11] [config] transformer-preprocess: ""
[2019-04-30 01:14:11] [config] transformer-tied-layers:
[2019-04-30 01:14:11] [config]   []
[2019-04-30 01:14:11] [config] transformer-train-position-embeddings: false
[2019-04-30 01:14:11] [config] type: transformer-context
[2019-04-30 01:14:11] [config] ulr: false
[2019-04-30 01:14:11] [config] ulr-dim-emb: 0
[2019-04-30 01:14:11] [config] ulr-dropout: 0
[2019-04-30 01:14:11] [config] ulr-keys-vectors: ""
[2019-04-30 01:14:11] [config] ulr-query-vectors: ""
[2019-04-30 01:14:11] [config] ulr-softmax-temperature: 1
[2019-04-30 01:14:11] [config] ulr-trainable-transformation: false
[2019-04-30 01:14:11] [config] valid-freq: 5000
[2019-04-30 01:14:11] [config] valid-log: model/valid_trans.gate.log
[2019-04-30 01:14:11] [config] valid-max-length: 1000
[2019-04-30 01:14:11] [config] valid-metrics:
[2019-04-30 01:14:11] [config]   - cross-entropy
[2019-04-30 01:14:11] [config]   - perplexity
[2019-04-30 01:14:11] [config]   - translation
[2019-04-30 01:14:11] [config] valid-mini-batch: 64
[2019-04-30 01:14:11] [config] valid-script-path: ./val.sh
[2019-04-30 01:14:11] [config] valid-sets:
[2019-04-30 01:14:11] [config]   - corp/opensub.en-fr.docs.dev.en.bpe.src_prev
[2019-04-30 01:14:11] [config]   - corp/opensub.en-fr.docs.dev.en.bpe.src
[2019-04-30 01:14:11] [config]   - corp/opensub.en-fr.docs.dev.fr.bpe
[2019-04-30 01:14:11] [config] valid-translation-output: data/valid.bpe.en.output
[2019-04-30 01:14:11] [config] version: v1.7.8 27b6420 2019-04-22 13:27:24 +0200
[2019-04-30 01:14:11] [config] vocabs:
[2019-04-30 01:14:11] [config]   - corp/vocab.encz.opensub.new.yml
[2019-04-30 01:14:11] [config]   - corp/vocab.encz.opensub.new.yml
[2019-04-30 01:14:11] [config]   - corp/vocab.encz.opensub.new.yml
[2019-04-30 01:14:11] [config] word-penalty: 0
[2019-04-30 01:14:11] [config] workspace: 8200
[2019-04-30 01:14:11] [config] Loaded model has been created with Marian v1.7.8 27b6420 2019-04-22 13:27:24 +0200
[2019-04-30 01:14:11] Using synchronous training
[2019-04-30 01:14:11] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encz.opensub.new.yml
[2019-04-30 01:14:11] [data] Setting vocabulary size for input 0 to 30000
[2019-04-30 01:14:11] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encz.opensub.new.yml
[2019-04-30 01:14:11] [data] Setting vocabulary size for input 1 to 30000
[2019-04-30 01:14:11] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encz.opensub.new.yml
[2019-04-30 01:14:12] [data] Setting vocabulary size for input 2 to 30000
[2019-04-30 01:14:12] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-04-30 01:14:12] [batching] Collecting statistics for batch fitting with step size 10
[2019-04-30 01:14:14] [memory] Extending reserved space to 8320 MB (device gpu0)
[2019-04-30 01:14:15] [memory] Extending reserved space to 8320 MB (device gpu1)
[2019-04-30 01:14:15] [comm] NCCL communicator overridden
[2019-04-30 01:14:15] [training] Using 2 GPUs
[2019-04-30 01:14:15] [memory] Reserving 311 MB, device gpu0
[2019-04-30 01:14:15] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-04-30 01:14:15] [memory] Reserving 311 MB, device gpu0
[2019-04-30 01:14:24] [batching] Done. Typical MB size is 33746 target words
[2019-04-30 01:14:24] [memory] Extending reserved space to 8320 MB (device gpu0)
[2019-04-30 01:14:24] [memory] Extending reserved space to 8320 MB (device gpu1)
[2019-04-30 01:14:24] [comm] NCCL communicator overridden
[2019-04-30 01:14:24] [training] Using 2 GPUs
[2019-04-30 01:14:24] Loading model from model/model.src1tgt0.doc.new.cosmas.nofreeze.npz.orig.npz
[2019-04-30 01:14:26] Loading model from model/model.src1tgt0.doc.new.cosmas.nofreeze.npz.orig.npz
[2019-04-30 01:14:26] Loading Adam parameters from model/model.src1tgt0.doc.new.cosmas.nofreeze.npz.optimizer.npz
[2019-04-30 01:14:28] [memory] Reserving 311 MB, device gpu0
[2019-04-30 01:14:28] [memory] Reserving 311 MB, device gpu1
[2019-04-30 01:14:29] [training] Model reloaded from model/model.src1tgt0.doc.new.cosmas.nofreeze.npz
[2019-04-30 01:14:29] Training started
[2019-04-30 01:14:29] [data] Shuffling data
tcmalloc: large alloc 1073741824 bytes == 0x14c668000 @ 
tcmalloc: large alloc 2147483648 bytes == 0x7fe78fd00000 @ 
tcmalloc: large alloc 2147483648 bytes == 0x7fe70f500000 @ 
tcmalloc: large alloc 2147483648 bytes == 0x14c668000 @ 
[2019-04-30 01:14:48] [data] Done reading 41736982 sentences
[2019-04-30 01:17:07] [data] Done shuffling 41736982 sentences to temp files
[2019-04-30 01:17:25] [training] Batches are processed as 1 process(es) x 2 devices/process
[2019-04-30 01:17:25] [memory] Reserving 311 MB, device gpu1
[2019-04-30 01:17:25] [memory] Reserving 311 MB, device gpu0
[2019-04-30 01:17:25] [memory] Reserving 311 MB, device gpu1
[2019-04-30 01:17:25] [memory] Reserving 311 MB, device gpu0
[2019-04-30 01:17:26] Loading model from model/model.src1tgt0.doc.new.cosmas.nofreeze.npz
[2019-04-30 01:17:27] [memory] Reserving 311 MB, device cpu0
[2019-04-30 01:17:27] [memory] Reserving 155 MB, device gpu0
[2019-04-30 01:17:27] [memory] Reserving 155 MB, device gpu1
[2019-04-30 01:17:28] [memory] Reserving 155 MB, device gpu0
[2019-04-30 01:17:28] [memory] Reserving 155 MB, device gpu1
[2019-04-30 01:25:51] Ep. 1 : Up. 5500 : Sen. 659,100 : Cost 84.92448425 : Time 698.94s : 8937.81 words/s : L.r. 6.8750e-05
[2019-04-30 01:34:26] Ep. 1 : Up. 6000 : Sen. 1,334,789 : Cost 93.20806122 : Time 515.49s : 12375.83 words/s : L.r. 7.5000e-05
[2019-04-30 01:42:57] Ep. 1 : Up. 6500 : Sen. 1,994,063 : Cost 92.72857666 : Time 511.02s : 12151.17 words/s : L.r. 8.1250e-05
[2019-04-30 01:51:29] Ep. 1 : Up. 7000 : Sen. 2,657,424 : Cost 86.91905212 : Time 511.68s : 12200.77 words/s : L.r. 8.7500e-05
[2019-04-30 01:59:58] Ep. 1 : Up. 7500 : Sen. 3,315,632 : Cost 82.13947296 : Time 509.58s : 12179.47 words/s : L.r. 9.3750e-05
[2019-04-30 02:08:34] Ep. 1 : Up. 8000 : Sen. 3,970,848 : Cost 86.77685547 : Time 515.72s : 12230.99 words/s : L.r. 1.0000e-04
[2019-04-30 02:17:13] Ep. 1 : Up. 8500 : Sen. 4,643,191 : Cost 92.20622253 : Time 518.67s : 12177.51 words/s : L.r. 1.0625e-04
[2019-04-30 02:25:44] Ep. 1 : Up. 9000 : Sen. 5,300,695 : Cost 99.59196472 : Time 510.92s : 12199.40 words/s : L.r. 1.1250e-04
[2019-04-30 02:34:16] Ep. 1 : Up. 9500 : Sen. 5,962,113 : Cost 109.79638672 : Time 512.05s : 12167.58 words/s : L.r. 1.1875e-04
[2019-04-30 02:42:49] Ep. 1 : Up. 10000 : Sen. 6,629,719 : Cost 110.71404266 : Time 513.50s : 12153.41 words/s : L.r. 1.2500e-04
[2019-04-30 02:42:49] Saving model weights and runtime parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.npz.orig.npz
[2019-04-30 02:42:52] Saving model weights and runtime parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.iter10000.npz
[2019-04-30 02:42:53] Saving model weights and runtime parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.npz
[2019-04-30 02:42:54] Saving Adam parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.npz.optimizer.npz
[2019-04-30 02:43:03] [valid] Ep. 1 : Up. 10000 : cross-entropy : 164.399 : new best
[2019-04-30 02:43:06] [valid] Ep. 1 : Up. 10000 : perplexity : 346384 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-30 02:43:14] [valid] Ep. 1 : Up. 10000 : translation : 0 : new best
[2019-04-30 02:51:59] Ep. 1 : Up. 10500 : Sen. 7,307,402 : Cost 116.21968079 : Time 549.62s : 11741.98 words/s : L.r. 1.3125e-04
[2019-04-30 03:00:27] Ep. 1 : Up. 11000 : Sen. 7,958,452 : Cost 125.34806061 : Time 508.50s : 12108.69 words/s : L.r. 1.3750e-04
[2019-04-30 03:09:09] Ep. 1 : Up. 11500 : Sen. 8,630,389 : Cost 128.35421753 : Time 521.61s : 12212.13 words/s : L.r. 1.4375e-04
[2019-04-30 03:17:37] Ep. 1 : Up. 12000 : Sen. 9,283,296 : Cost 145.65733337 : Time 508.12s : 12184.15 words/s : L.r. 1.5000e-04
[2019-04-30 03:26:12] Ep. 1 : Up. 12500 : Sen. 9,943,016 : Cost 133.41525269 : Time 515.16s : 12055.83 words/s : L.r. 1.5625e-04
[2019-04-30 03:34:55] Ep. 1 : Up. 13000 : Sen. 10,614,477 : Cost 147.09991455 : Time 522.92s : 12261.70 words/s : L.r. 1.6250e-04
[2019-04-30 03:43:24] Ep. 1 : Up. 13500 : Sen. 11,265,314 : Cost 125.22078705 : Time 509.17s : 12109.06 words/s : L.r. 1.6875e-04
[2019-04-30 03:51:55] Ep. 1 : Up. 14000 : Sen. 11,927,684 : Cost 117.70966339 : Time 510.90s : 12117.15 words/s : L.r. 1.7500e-04
[2019-04-30 04:00:32] Ep. 1 : Up. 14500 : Sen. 12,595,423 : Cost 116.85020447 : Time 516.82s : 12195.38 words/s : L.r. 1.8125e-04
[2019-04-30 04:09:09] Ep. 1 : Up. 15000 : Sen. 13,253,530 : Cost 104.76097107 : Time 516.79s : 12184.69 words/s : L.r. 1.8750e-04
[2019-04-30 04:09:09] Saving model weights and runtime parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.npz.orig.npz
[2019-04-30 04:09:10] Saving model weights and runtime parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.iter15000.npz
[2019-04-30 04:09:12] Saving model weights and runtime parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.npz
[2019-04-30 04:09:13] Saving Adam parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.npz.optimizer.npz
[2019-04-30 04:09:20] [valid] Ep. 1 : Up. 15000 : cross-entropy : 249.048 : stalled 1 times (last best: 164.399)
[2019-04-30 04:09:23] [valid] Ep. 1 : Up. 15000 : perplexity : 2.46532e+08 : stalled 1 times (last best: 346384)
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-30 04:09:29] [valid] Ep. 1 : Up. 15000 : translation : 0 : stalled 1 times (last best: 0)
[2019-04-30 04:18:02] Ep. 1 : Up. 15500 : Sen. 13,908,696 : Cost 97.52117157 : Time 533.14s : 11707.71 words/s : L.r. 1.9375e-04
[2019-04-30 04:26:38] Ep. 1 : Up. 16000 : Sen. 14,578,672 : Cost 93.96455383 : Time 515.77s : 12182.07 words/s : L.r. 2.0000e-04
[2019-04-30 04:35:11] Ep. 1 : Up. 16500 : Sen. 15,233,173 : Cost 92.37724304 : Time 513.15s : 12060.16 words/s : L.r. 1.9695e-04
[2019-04-30 04:43:51] Ep. 1 : Up. 17000 : Sen. 15,908,194 : Cost 87.71192932 : Time 520.47s : 12187.05 words/s : L.r. 1.9403e-04
[2019-04-30 04:52:28] Ep. 1 : Up. 17500 : Sen. 16,570,105 : Cost 87.14765930 : Time 516.78s : 12276.30 words/s : L.r. 1.9124e-04
[2019-04-30 05:00:57] Ep. 1 : Up. 18000 : Sen. 17,255,536 : Cost 79.69960785 : Time 509.08s : 12102.67 words/s : L.r. 1.8856e-04
[2019-04-30 05:09:33] Ep. 1 : Up. 18500 : Sen. 17,897,281 : Cost 85.22303772 : Time 516.01s : 12121.59 words/s : L.r. 1.8600e-04
[2019-04-30 05:18:13] Ep. 1 : Up. 19000 : Sen. 18,574,126 : Cost 79.36992645 : Time 519.39s : 12125.74 words/s : L.r. 1.8353e-04
[2019-04-30 05:26:43] Ep. 1 : Up. 19500 : Sen. 19,220,469 : Cost 81.68404388 : Time 510.71s : 12224.46 words/s : L.r. 1.8116e-04
[2019-04-30 05:35:16] Ep. 1 : Up. 20000 : Sen. 19,866,781 : Cost 81.14589691 : Time 513.01s : 12206.84 words/s : L.r. 1.7889e-04
[2019-04-30 05:35:16] Saving model weights and runtime parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.npz.orig.npz
[2019-04-30 05:35:18] Saving model weights and runtime parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.iter20000.npz
[2019-04-30 05:35:19] Saving model weights and runtime parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.npz
[2019-04-30 05:35:21] Saving Adam parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.npz.optimizer.npz
[2019-04-30 05:35:28] [valid] Ep. 1 : Up. 20000 : cross-entropy : 244.738 : stalled 2 times (last best: 164.399)
[2019-04-30 05:35:31] [valid] Ep. 1 : Up. 20000 : perplexity : 1.76456e+08 : stalled 2 times (last best: 346384)
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-30 05:41:03] [valid] Ep. 1 : Up. 20000 : translation : 0 : stalled 2 times (last best: 0)
[2019-04-30 05:49:40] Ep. 1 : Up. 20500 : Sen. 20,544,604 : Cost 78.21923065 : Time 863.80s : 7331.19 words/s : L.r. 1.7669e-04
[2019-04-30 05:58:10] Ep. 1 : Up. 21000 : Sen. 21,220,469 : Cost 77.68238831 : Time 510.29s : 12087.57 words/s : L.r. 1.7457e-04
[2019-04-30 06:06:46] Ep. 1 : Up. 21500 : Sen. 21,868,131 : Cost 86.70590210 : Time 515.48s : 12157.99 words/s : L.r. 1.7253e-04
[2019-04-30 06:15:27] Ep. 1 : Up. 22000 : Sen. 22,544,155 : Cost 105.06287384 : Time 521.19s : 12263.30 words/s : L.r. 1.7056e-04
[2019-04-30 06:24:05] Ep. 1 : Up. 22500 : Sen. 23,205,810 : Cost 122.12297821 : Time 518.02s : 12093.09 words/s : L.r. 1.6865e-04
[2019-04-30 06:32:32] Ep. 1 : Up. 23000 : Sen. 23,850,411 : Cost 118.06586456 : Time 506.87s : 12115.76 words/s : L.r. 1.6681e-04
[2019-04-30 06:41:12] Ep. 1 : Up. 23500 : Sen. 24,532,755 : Cost 118.30094147 : Time 519.54s : 12194.74 words/s : L.r. 1.6503e-04
[2019-04-30 06:49:41] Ep. 1 : Up. 24000 : Sen. 25,176,792 : Cost 146.46191406 : Time 509.65s : 12180.43 words/s : L.r. 1.6330e-04
[2019-04-30 06:58:17] Ep. 1 : Up. 24500 : Sen. 25,835,963 : Cost 139.05873108 : Time 516.21s : 12102.00 words/s : L.r. 1.6162e-04
[2019-04-30 07:06:56] Ep. 1 : Up. 25000 : Sen. 26,508,842 : Cost 130.68574524 : Time 518.39s : 12202.49 words/s : L.r. 1.6000e-04
[2019-04-30 07:06:56] Saving model weights and runtime parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.npz.orig.npz
[2019-04-30 07:06:57] Saving model weights and runtime parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.iter25000.npz
[2019-04-30 07:06:59] Saving model weights and runtime parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.npz
[2019-04-30 07:07:00] Saving Adam parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.npz.optimizer.npz
[2019-04-30 07:07:07] [valid] Ep. 1 : Up. 25000 : cross-entropy : 169.907 : stalled 3 times (last best: 164.399)
[2019-04-30 07:07:11] [valid] Ep. 1 : Up. 25000 : perplexity : 531081 : stalled 3 times (last best: 346384)
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-30 07:11:05] [valid] Ep. 1 : Up. 25000 : translation : 0 : stalled 3 times (last best: 0)
[2019-04-30 07:19:45] Ep. 1 : Up. 25500 : Sen. 27,185,459 : Cost 122.70278931 : Time 769.34s : 8245.04 words/s : L.r. 1.5842e-04
[2019-04-30 07:28:17] Ep. 1 : Up. 26000 : Sen. 27,844,420 : Cost 118.20476532 : Time 511.88s : 12149.47 words/s : L.r. 1.5689e-04
[2019-04-30 07:36:55] Ep. 1 : Up. 26500 : Sen. 28,509,941 : Cost 115.72367859 : Time 518.22s : 12250.76 words/s : L.r. 1.5541e-04
[2019-04-30 07:45:29] Ep. 1 : Up. 27000 : Sen. 29,172,705 : Cost 144.37301636 : Time 513.37s : 12114.65 words/s : L.r. 1.5396e-04
[2019-04-30 07:54:01] Ep. 1 : Up. 27500 : Sen. 29,824,020 : Cost 158.58575439 : Time 512.61s : 12086.24 words/s : L.r. 1.5255e-04
[2019-04-30 08:02:39] Ep. 1 : Up. 28000 : Sen. 30,491,361 : Cost 135.52398682 : Time 517.69s : 12207.48 words/s : L.r. 1.5119e-04
[2019-04-30 08:11:16] Ep. 1 : Up. 28500 : Sen. 31,158,511 : Cost 124.72097778 : Time 517.21s : 12174.79 words/s : L.r. 1.4985e-04
[2019-04-30 08:20:00] Ep. 1 : Up. 29000 : Sen. 31,824,001 : Cost 123.03917694 : Time 523.49s : 12326.76 words/s : L.r. 1.4856e-04
[2019-04-30 08:28:36] Ep. 1 : Up. 29500 : Sen. 32,506,828 : Cost 112.57437897 : Time 516.87s : 12004.23 words/s : L.r. 1.4729e-04
[2019-04-30 08:37:08] Ep. 1 : Up. 30000 : Sen. 33,162,474 : Cost 112.30560303 : Time 511.35s : 12159.39 words/s : L.r. 1.4606e-04
[2019-04-30 08:37:08] Saving model weights and runtime parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.npz.orig.npz
[2019-04-30 08:37:10] Saving model weights and runtime parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.iter30000.npz
[2019-04-30 08:37:11] Saving model weights and runtime parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.npz
[2019-04-30 08:37:12] Saving Adam parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.npz.optimizer.npz
[2019-04-30 08:37:19] [valid] Ep. 1 : Up. 30000 : cross-entropy : 355.678 : stalled 4 times (last best: 164.399)
[2019-04-30 08:37:22] [valid] Ep. 1 : Up. 30000 : perplexity : 9.65724e+11 : stalled 4 times (last best: 346384)
Detokenizer Version $Revision: 4134 $
Language: en
sacreBLEU: The input and reference stream(s) were of different lengths.

[2019-04-30 08:42:52] [valid] Ep. 1 : Up. 30000 : translation : 0 : stalled 4 times (last best: 0)
[2019-04-30 08:51:31] Ep. 1 : Up. 30500 : Sen. 33,821,819 : Cost 108.64732361 : Time 863.04s : 7433.70 words/s : L.r. 1.4486e-04
[2019-04-30 08:59:53] Ep. 1 : Up. 31000 : Sen. 34,498,822 : Cost 95.05534363 : Time 502.31s : 12052.21 words/s : L.r. 1.4368e-04
[2019-04-30 09:08:35] Ep. 1 : Up. 31500 : Sen. 35,142,506 : Cost 106.11321259 : Time 522.26s : 12249.64 words/s : L.r. 1.4254e-04
[2019-04-30 09:17:10] Ep. 1 : Up. 32000 : Sen. 35,819,028 : Cost 100.06233978 : Time 514.24s : 12279.47 words/s : L.r. 1.4142e-04
[2019-04-30 09:25:52] Ep. 1 : Up. 32500 : Sen. 36,487,219 : Cost 106.07032776 : Time 522.67s : 12210.28 words/s : L.r. 1.4033e-04
[2019-04-30 09:34:20] Ep. 1 : Up. 33000 : Sen. 37,128,280 : Cost 109.04865265 : Time 508.03s : 12053.42 words/s : L.r. 1.3926e-04
[2019-04-30 09:43:00] Ep. 1 : Up. 33500 : Sen. 37,811,377 : Cost 104.20601654 : Time 520.02s : 12203.80 words/s : L.r. 1.3822e-04
[2019-04-30 09:51:26] Ep. 1 : Up. 34000 : Sen. 38,447,456 : Cost 110.23548889 : Time 505.94s : 12071.10 words/s : L.r. 1.3720e-04
[2019-04-30 10:00:04] Ep. 1 : Up. 34500 : Sen. 39,131,382 : Cost 113.47827911 : Time 517.91s : 12233.85 words/s : L.r. 1.3620e-04
[2019-04-30 10:08:34] Ep. 1 : Up. 35000 : Sen. 39,784,305 : Cost 107.12783051 : Time 509.34s : 12012.95 words/s : L.r. 1.3522e-04
[2019-04-30 10:08:34] Saving model weights and runtime parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.npz.orig.npz
[2019-04-30 10:08:35] Saving model weights and runtime parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.iter35000.npz
[2019-04-30 10:08:36] Saving model weights and runtime parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.npz
[2019-04-30 10:08:38] Saving Adam parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.npz.optimizer.npz
[2019-04-30 10:08:45] [valid] Ep. 1 : Up. 35000 : cross-entropy : 444.293 : stalled 5 times (last best: 164.399)
[2019-04-30 10:08:48] [valid] Ep. 1 : Up. 35000 : perplexity : 9.35048e+14 : stalled 5 times (last best: 346384)
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-30 10:14:21] [valid] Ep. 1 : Up. 35000 : translation : 0 : stalled 5 times (last best: 0)
[2019-04-30 10:23:00] Ep. 1 : Up. 35500 : Sen. 40,437,152 : Cost 107.62367249 : Time 866.28s : 7284.36 words/s : L.r. 1.3427e-04
[2019-04-30 10:31:27] Ep. 1 : Up. 36000 : Sen. 41,106,910 : Cost 105.39736176 : Time 506.66s : 12121.23 words/s : L.r. 1.3333e-04
[2019-04-30 10:39:35] Ep. 1 : Up. 36500 : Sen. 41,706,929 : Cost 116.19007874 : Time 488.30s : 11913.06 words/s : L.r. 1.3242e-04
[2019-04-30 10:39:37] Seen 41709169 samples
[2019-04-30 10:39:37] Starting epoch 2
[2019-04-30 10:39:37] [data] Shuffling data
tcmalloc: large alloc 2147483648 bytes == 0x14c1a8000 @ 
tcmalloc: large alloc 2147483648 bytes == 0x7fe1c8000000 @ 
[2019-04-30 10:39:51] [data] Done reading 41736982 sentences
[2019-04-30 10:42:14] [data] Done shuffling 41736982 sentences to temp files
[2019-04-30 10:51:02] Ep. 2 : Up. 37000 : Sen. 662,618 : Cost 108.89767456 : Time 686.79s : 9090.33 words/s : L.r. 1.3152e-04
[2019-04-30 10:59:35] Ep. 2 : Up. 37500 : Sen. 1,308,130 : Cost 120.71474457 : Time 512.90s : 12142.86 words/s : L.r. 1.3064e-04
[2019-04-30 11:08:14] Ep. 2 : Up. 38000 : Sen. 1,982,917 : Cost 114.64050293 : Time 519.72s : 12215.38 words/s : L.r. 1.2978e-04
[2019-04-30 11:16:50] Ep. 2 : Up. 38500 : Sen. 2,664,322 : Cost 110.59790039 : Time 515.85s : 12125.73 words/s : L.r. 1.2893e-04
[2019-04-30 11:25:31] Ep. 2 : Up. 39000 : Sen. 3,334,097 : Cost 260.36746216 : Time 521.24s : 12200.47 words/s : L.r. 1.2810e-04
[2019-04-30 11:34:03] Ep. 2 : Up. 39500 : Sen. 3,977,244 : Cost 882.16033936 : Time 511.63s : 12119.04 words/s : L.r. 1.2729e-04
[2019-04-30 11:42:31] Ep. 2 : Up. 40000 : Sen. 4,629,742 : Cost 566.32470703 : Time 508.52s : 12035.08 words/s : L.r. 1.2649e-04
[2019-04-30 11:42:31] Saving model weights and runtime parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.npz.orig.npz
[2019-04-30 11:42:34] Saving model weights and runtime parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.iter40000.npz
[2019-04-30 11:42:35] Saving model weights and runtime parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.npz
[2019-04-30 11:42:37] Saving Adam parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.npz.optimizer.npz
[2019-04-30 11:42:44] [valid] Ep. 2 : Up. 40000 : cross-entropy : 309.7 : stalled 6 times (last best: 164.399)
[2019-04-30 11:42:47] [valid] Ep. 2 : Up. 40000 : perplexity : 2.72642e+10 : stalled 6 times (last best: 346384)
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-30 11:48:23] [valid] Ep. 2 : Up. 40000 : translation : 0 : stalled 6 times (last best: 0)
[2019-04-30 11:57:10] Ep. 2 : Up. 40500 : Sen. 5,314,832 : Cost 409.70855713 : Time 878.47s : 7473.81 words/s : L.r. 1.2571e-04
[2019-04-30 12:05:37] Ep. 2 : Up. 41000 : Sen. 5,957,820 : Cost 322.47250366 : Time 507.34s : 11993.22 words/s : L.r. 1.2494e-04
[2019-04-30 12:14:11] Ep. 2 : Up. 41500 : Sen. 6,619,420 : Cost 280.04598999 : Time 513.81s : 12094.61 words/s : L.r. 1.2418e-04
[2019-04-30 12:22:49] Ep. 2 : Up. 42000 : Sen. 7,301,967 : Cost 283.26699829 : Time 518.31s : 12121.70 words/s : L.r. 1.2344e-04
[2019-04-30 12:31:23] Ep. 2 : Up. 42500 : Sen. 7,950,010 : Cost 270.69140625 : Time 513.39s : 12111.74 words/s : L.r. 1.2271e-04
[2019-04-30 12:40:02] Ep. 2 : Up. 43000 : Sen. 8,611,981 : Cost 243.37117004 : Time 519.53s : 12188.00 words/s : L.r. 1.2200e-04
[2019-04-30 12:48:28] Ep. 2 : Up. 43500 : Sen. 9,256,969 : Cost 213.97959900 : Time 505.44s : 12080.20 words/s : L.r. 1.2130e-04
[2019-04-30 12:57:08] Ep. 2 : Up. 44000 : Sen. 9,926,683 : Cost 193.22947693 : Time 519.77s : 12210.00 words/s : L.r. 1.2060e-04
[2019-04-30 13:05:34] Ep. 2 : Up. 44500 : Sen. 10,573,665 : Cost 185.47901917 : Time 506.20s : 12083.36 words/s : L.r. 1.1993e-04
[2019-04-30 13:14:15] Ep. 2 : Up. 45000 : Sen. 11,253,040 : Cost 177.39125061 : Time 520.95s : 12160.80 words/s : L.r. 1.1926e-04
[2019-04-30 13:14:15] Saving model weights and runtime parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.npz.orig.npz
[2019-04-30 13:14:16] Saving model weights and runtime parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.iter45000.npz
[2019-04-30 13:14:18] Saving model weights and runtime parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.npz
[2019-04-30 13:14:19] Saving Adam parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.npz.optimizer.npz
[2019-04-30 13:14:26] [valid] Ep. 2 : Up. 45000 : cross-entropy : 727.877 : stalled 7 times (last best: 164.399)
[2019-04-30 13:14:30] [valid] Ep. 2 : Up. 45000 : perplexity : 3.36051e+24 : stalled 7 times (last best: 346384)
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-30 13:20:04] [valid] Ep. 2 : Up. 45000 : translation : 0 : stalled 7 times (last best: 0)
[2019-04-30 13:28:49] Ep. 2 : Up. 45500 : Sen. 11,934,986 : Cost 169.04605103 : Time 874.11s : 7389.16 words/s : L.r. 1.1860e-04
[2019-04-30 13:37:21] Ep. 2 : Up. 46000 : Sen. 12,574,281 : Cost 164.58374023 : Time 512.33s : 12102.81 words/s : L.r. 1.1795e-04
[2019-04-30 13:46:03] Ep. 2 : Up. 46500 : Sen. 13,250,425 : Cost 153.09114075 : Time 522.22s : 12228.10 words/s : L.r. 1.1732e-04
[2019-04-30 13:54:32] Ep. 2 : Up. 47000 : Sen. 13,909,426 : Cost 141.66833496 : Time 508.98s : 12009.94 words/s : L.r. 1.1669e-04
[2019-04-30 14:03:20] Ep. 2 : Up. 47500 : Sen. 14,591,783 : Cost 139.88496399 : Time 527.47s : 12232.02 words/s : L.r. 1.1608e-04
[2019-04-30 14:11:46] Ep. 2 : Up. 48000 : Sen. 15,251,766 : Cost 133.34112549 : Time 506.66s : 12099.67 words/s : L.r. 1.1547e-04
[2019-04-30 14:20:13] Ep. 2 : Up. 48500 : Sen. 15,880,999 : Cost 138.50230408 : Time 506.08s : 12136.43 words/s : L.r. 1.1487e-04
[2019-04-30 14:28:48] Ep. 2 : Up. 49000 : Sen. 16,534,005 : Cost 132.87480164 : Time 515.59s : 12064.27 words/s : L.r. 1.1429e-04
[2019-04-30 14:37:33] Ep. 2 : Up. 49500 : Sen. 17,227,997 : Cost 124.84117126 : Time 524.78s : 12280.02 words/s : L.r. 1.1371e-04
[2019-04-30 14:46:07] Ep. 2 : Up. 50000 : Sen. 17,885,968 : Cost 125.45563507 : Time 513.91s : 12068.81 words/s : L.r. 1.1314e-04
[2019-04-30 14:46:07] Saving model weights and runtime parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.npz.orig.npz
[2019-04-30 14:46:09] Saving model weights and runtime parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.iter50000.npz
[2019-04-30 14:46:10] Saving model weights and runtime parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.npz
[2019-04-30 14:46:12] Saving Adam parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.npz.optimizer.npz
[2019-04-30 14:46:19] [valid] Ep. 2 : Up. 50000 : cross-entropy : 427.173 : stalled 8 times (last best: 164.399)
[2019-04-30 14:46:22] [valid] Ep. 2 : Up. 50000 : perplexity : 2.47719e+14 : stalled 8 times (last best: 346384)
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-30 14:51:56] [valid] Ep. 2 : Up. 50000 : translation : 0 : stalled 8 times (last best: 0)
[2019-04-30 15:00:28] Ep. 2 : Up. 50500 : Sen. 18,551,709 : Cost 123.00553131 : Time 861.15s : 7235.24 words/s : L.r. 1.1258e-04
[2019-04-30 15:09:11] Ep. 2 : Up. 51000 : Sen. 19,238,332 : Cost 118.92680359 : Time 523.55s : 12234.13 words/s : L.r. 1.1202e-04
[2019-04-30 15:17:39] Ep. 2 : Up. 51500 : Sen. 19,866,020 : Cost 123.89363098 : Time 507.42s : 12065.19 words/s : L.r. 1.1148e-04
[2019-04-30 15:26:24] Ep. 2 : Up. 52000 : Sen. 20,548,879 : Cost 120.39672089 : Time 524.62s : 12252.34 words/s : L.r. 1.1094e-04
[2019-04-30 15:34:51] Ep. 2 : Up. 52500 : Sen. 21,190,716 : Cost 117.49343109 : Time 507.89s : 11985.32 words/s : L.r. 1.1041e-04
[2019-04-30 15:43:27] Ep. 2 : Up. 53000 : Sen. 21,857,923 : Cost 113.52788544 : Time 515.92s : 12141.19 words/s : L.r. 1.0989e-04
[2019-04-30 15:52:04] Ep. 2 : Up. 53500 : Sen. 22,522,373 : Cost 120.88964081 : Time 516.52s : 12240.39 words/s : L.r. 1.0937e-04
[2019-04-30 16:00:45] Ep. 2 : Up. 54000 : Sen. 23,196,691 : Cost 115.70031738 : Time 520.72s : 12155.96 words/s : L.r. 1.0887e-04
[2019-04-30 16:09:26] Ep. 2 : Up. 54500 : Sen. 23,867,635 : Cost 112.16794586 : Time 521.05s : 12128.10 words/s : L.r. 1.0837e-04
[2019-04-30 16:18:10] Ep. 2 : Up. 55000 : Sen. 24,540,333 : Cost 116.40140533 : Time 524.28s : 12292.13 words/s : L.r. 1.0787e-04
[2019-04-30 16:18:10] Saving model weights and runtime parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.npz.orig.npz
[2019-04-30 16:18:12] Saving model weights and runtime parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.iter55000.npz
[2019-04-30 16:18:13] Saving model weights and runtime parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.npz
[2019-04-30 16:18:15] Saving Adam parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.npz.optimizer.npz
[2019-04-30 16:18:22] [valid] Ep. 2 : Up. 55000 : cross-entropy : 545.294 : stalled 9 times (last best: 164.399)
[2019-04-30 16:18:25] [valid] Ep. 2 : Up. 55000 : perplexity : 2.3667e+18 : stalled 9 times (last best: 346384)
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-30 16:24:01] [valid] Ep. 2 : Up. 55000 : translation : 0 : stalled 9 times (last best: 0)
[2019-04-30 16:32:29] Ep. 2 : Up. 55500 : Sen. 25,198,460 : Cost 114.88291168 : Time 858.95s : 7116.23 words/s : L.r. 1.0738e-04
[2019-04-30 16:41:04] Ep. 2 : Up. 56000 : Sen. 25,853,625 : Cost 113.32435608 : Time 515.25s : 12145.29 words/s : L.r. 1.0690e-04
[2019-04-30 16:49:42] Ep. 2 : Up. 56500 : Sen. 26,526,256 : Cost 110.69464111 : Time 517.90s : 12131.55 words/s : L.r. 1.0643e-04
[2019-04-30 16:58:22] Ep. 2 : Up. 57000 : Sen. 27,195,340 : Cost 111.27349091 : Time 520.13s : 12147.74 words/s : L.r. 1.0596e-04
[2019-04-30 17:06:58] Ep. 2 : Up. 57500 : Sen. 27,853,107 : Cost 112.33112335 : Time 515.88s : 12167.84 words/s : L.r. 1.0550e-04
[2019-04-30 17:15:28] Ep. 2 : Up. 58000 : Sen. 28,502,411 : Cost 110.80336761 : Time 510.26s : 12170.90 words/s : L.r. 1.0505e-04
[2019-04-30 17:24:10] Ep. 2 : Up. 58500 : Sen. 29,169,071 : Cost 109.93592834 : Time 521.70s : 12105.89 words/s : L.r. 1.0460e-04
[2019-04-30 17:32:44] Ep. 2 : Up. 59000 : Sen. 29,843,991 : Cost 114.84931946 : Time 514.14s : 12090.69 words/s : L.r. 1.0415e-04
[2019-04-30 17:41:29] Ep. 2 : Up. 59500 : Sen. 30,492,653 : Cost 119.16871643 : Time 525.20s : 12215.86 words/s : L.r. 1.0371e-04
[2019-04-30 17:49:49] Ep. 2 : Up. 60000 : Sen. 31,139,056 : Cost 111.14079285 : Time 499.46s : 11966.55 words/s : L.r. 1.0328e-04
[2019-04-30 17:49:49] Saving model weights and runtime parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.npz.orig.npz
[2019-04-30 17:49:51] Saving model weights and runtime parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.iter60000.npz
[2019-04-30 17:49:52] Saving model weights and runtime parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.npz
[2019-04-30 17:49:54] Saving Adam parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.npz.optimizer.npz
[2019-04-30 17:50:02] [valid] Ep. 2 : Up. 60000 : cross-entropy : 546.252 : stalled 10 times (last best: 164.399)
[2019-04-30 17:50:05] [valid] Ep. 2 : Up. 60000 : perplexity : 2.54932e+18 : stalled 10 times (last best: 346384)
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-30 17:55:41] [valid] Ep. 2 : Up. 60000 : translation : 0 : stalled 10 times (last best: 0)
[2019-04-30 17:55:41] Training finished
[2019-04-30 17:55:41] Saving model weights and runtime parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.npz.orig.npz
[2019-04-30 17:55:43] Saving model weights and runtime parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.npz
[2019-04-30 17:55:45] Saving Adam parameters to model/model.src1tgt0.doc.new.cosmas.nofreeze.npz.optimizer.npz
