[2019-05-19 19:58:24] [marian] Marian v1.7.8 211bce5 2019-05-18 17:09:38 +0200
[2019-05-19 19:58:24] [marian] Running on metis.lingea.cz as process 59935 with command line:
[2019-05-19 19:58:24] [marian] /home/large/data/models/marian/marian-doc/doc-marian3_metis_prev_gate_voita/build/marian --model model/model.src1tgt0.voita.fix.npz --pretrained-model ../src0tgt0_fr/model/model.src0tgt0.newvocab.iter630000.npz --type transformer-voita --train-sets corp/opensub.en-fr.docs.train.en.bpe.src_prev corp/opensub.en-fr.docs.train.en.bpe.src corp/opensub.en-fr.docs.train.fr.bpe --max-length 55 --dim-vocabs 30000 30000 --vocabs corp/vocab.encz.opensub.new.yml corp/vocab.encz.opensub.new.yml corp/vocab.encz.opensub.new.yml --mini-batch-fit -w 8200 --mini-batch 1000 --maxi-batch 1000 --early-stopping 10 --valid-freq 5000 --save-freq 5000 --disp-freq 500 --valid-metrics cross-entropy perplexity translation --valid-sets corp/opensub.en-fr.docs.dev.en.bpe.src_prev corp/opensub.en-fr.docs.dev.en.bpe.src corp/opensub.en-fr.docs.dev.fr.bpe --valid-script-path ./val.sh --valid-translation-output data/valid.bpe.en.output --quiet-translation --valid-mini-batch 64 --beam-size 6 --normalize 0.6 --log model/train_trans.gate.log --valid-log model/valid_trans.gate.log --enc-depth 6 --dec-depth 6 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0002 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --optimizer-delay 8 --devices 2 --sync-sgd --seed 1111 --exponential-smoothing --no-restore-corpus
[2019-05-19 19:58:24] [config] after-batches: 0
[2019-05-19 19:58:24] [config] after-epochs: 0
[2019-05-19 19:58:24] [config] allow-unk: false
[2019-05-19 19:58:24] [config] beam-size: 6
[2019-05-19 19:58:24] [config] bert-class-symbol: "[CLS]"
[2019-05-19 19:58:24] [config] bert-mask-symbol: "[MASK]"
[2019-05-19 19:58:24] [config] bert-masking-fraction: 0.15
[2019-05-19 19:58:24] [config] bert-sep-symbol: "[SEP]"
[2019-05-19 19:58:24] [config] bert-train-type-embeddings: true
[2019-05-19 19:58:24] [config] bert-type-vocab-size: 2
[2019-05-19 19:58:24] [config] best-deep: false
[2019-05-19 19:58:24] [config] clip-gemm: 0
[2019-05-19 19:58:24] [config] clip-norm: 5
[2019-05-19 19:58:24] [config] context-enc-depth: 1
[2019-05-19 19:58:24] [config] context-gate: false
[2019-05-19 19:58:24] [config] cost-type: ce-mean
[2019-05-19 19:58:24] [config] cpu-threads: 0
[2019-05-19 19:58:24] [config] data-weighting: ""
[2019-05-19 19:58:24] [config] data-weighting-type: sentence
[2019-05-19 19:58:24] [config] dec-cell: gru
[2019-05-19 19:58:24] [config] dec-cell-base-depth: 2
[2019-05-19 19:58:24] [config] dec-cell-high-depth: 1
[2019-05-19 19:58:24] [config] dec-depth: 6
[2019-05-19 19:58:24] [config] devices:
[2019-05-19 19:58:24] [config]   - 2
[2019-05-19 19:58:24] [config] dim-emb: 512
[2019-05-19 19:58:24] [config] dim-rnn: 1024
[2019-05-19 19:58:24] [config] dim-vocabs:
[2019-05-19 19:58:24] [config]   - 30000
[2019-05-19 19:58:24] [config]   - 30000
[2019-05-19 19:58:24] [config]   - 30000
[2019-05-19 19:58:24] [config] disp-first: 0
[2019-05-19 19:58:24] [config] disp-freq: 500
[2019-05-19 19:58:24] [config] disp-label-counts: false
[2019-05-19 19:58:24] [config] dropout-rnn: 0
[2019-05-19 19:58:24] [config] dropout-src: 0
[2019-05-19 19:58:24] [config] dropout-trg: 0
[2019-05-19 19:58:24] [config] dump-config: ""
[2019-05-19 19:58:24] [config] early-stopping: 10
[2019-05-19 19:58:24] [config] embedding-fix-src: false
[2019-05-19 19:58:24] [config] embedding-fix-trg: false
[2019-05-19 19:58:24] [config] embedding-normalization: false
[2019-05-19 19:58:24] [config] embedding-vectors:
[2019-05-19 19:58:24] [config]   []
[2019-05-19 19:58:24] [config] enc-cell: gru
[2019-05-19 19:58:24] [config] enc-cell-depth: 1
[2019-05-19 19:58:24] [config] enc-depth: 6
[2019-05-19 19:58:24] [config] enc-type: bidirectional
[2019-05-19 19:58:24] [config] exponential-smoothing: 0.0001
[2019-05-19 19:58:24] [config] freeze: false
[2019-05-19 19:58:24] [config] grad-dropping-momentum: 0
[2019-05-19 19:58:24] [config] grad-dropping-rate: 0
[2019-05-19 19:58:24] [config] grad-dropping-warmup: 100
[2019-05-19 19:58:24] [config] guided-alignment: none
[2019-05-19 19:58:24] [config] guided-alignment-cost: mse
[2019-05-19 19:58:24] [config] guided-alignment-weight: 0.1
[2019-05-19 19:58:24] [config] ignore-model-config: false
[2019-05-19 19:58:24] [config] input-types:
[2019-05-19 19:58:24] [config]   []
[2019-05-19 19:58:24] [config] interpolate-env-vars: false
[2019-05-19 19:58:24] [config] keep-best: false
[2019-05-19 19:58:24] [config] label-smoothing: 0.1
[2019-05-19 19:58:24] [config] layer-normalization: false
[2019-05-19 19:58:24] [config] learn-rate: 0.0002
[2019-05-19 19:58:24] [config] log: model/train_trans.gate.log
[2019-05-19 19:58:24] [config] log-level: info
[2019-05-19 19:58:24] [config] log-time-zone: ""
[2019-05-19 19:58:24] [config] lr-decay: 0
[2019-05-19 19:58:24] [config] lr-decay-freq: 50000
[2019-05-19 19:58:24] [config] lr-decay-inv-sqrt:
[2019-05-19 19:58:24] [config]   - 16000
[2019-05-19 19:58:24] [config] lr-decay-repeat-warmup: false
[2019-05-19 19:58:24] [config] lr-decay-reset-optimizer: false
[2019-05-19 19:58:24] [config] lr-decay-start:
[2019-05-19 19:58:24] [config]   - 10
[2019-05-19 19:58:24] [config]   - 1
[2019-05-19 19:58:24] [config] lr-decay-strategy: epoch+stalled
[2019-05-19 19:58:24] [config] lr-report: true
[2019-05-19 19:58:24] [config] lr-warmup: 16000
[2019-05-19 19:58:24] [config] lr-warmup-at-reload: false
[2019-05-19 19:58:24] [config] lr-warmup-cycle: false
[2019-05-19 19:58:24] [config] lr-warmup-start-rate: 0
[2019-05-19 19:58:24] [config] max-length: 55
[2019-05-19 19:58:24] [config] max-length-crop: false
[2019-05-19 19:58:24] [config] max-length-factor: 3
[2019-05-19 19:58:24] [config] maxi-batch: 1000
[2019-05-19 19:58:24] [config] maxi-batch-sort: trg
[2019-05-19 19:58:24] [config] mini-batch: 1000
[2019-05-19 19:58:24] [config] mini-batch-fit: true
[2019-05-19 19:58:24] [config] mini-batch-fit-step: 10
[2019-05-19 19:58:24] [config] mini-batch-overstuff: 1
[2019-05-19 19:58:24] [config] mini-batch-track-lr: false
[2019-05-19 19:58:24] [config] mini-batch-understuff: 1
[2019-05-19 19:58:24] [config] mini-batch-warmup: 0
[2019-05-19 19:58:24] [config] mini-batch-words: 0
[2019-05-19 19:58:24] [config] mini-batch-words-ref: 0
[2019-05-19 19:58:24] [config] model: model/model.src1tgt0.voita.fix.npz
[2019-05-19 19:58:24] [config] multi-loss-type: sum
[2019-05-19 19:58:24] [config] multi-node: false
[2019-05-19 19:58:24] [config] multi-node-overlap: true
[2019-05-19 19:58:24] [config] n-best: false
[2019-05-19 19:58:24] [config] no-nccl: false
[2019-05-19 19:58:24] [config] no-reload: false
[2019-05-19 19:58:24] [config] no-restore-corpus: true
[2019-05-19 19:58:24] [config] no-shuffle: false
[2019-05-19 19:58:24] [config] normalize: 0.6
[2019-05-19 19:58:24] [config] num-devices: 0
[2019-05-19 19:58:24] [config] optimizer: adam
[2019-05-19 19:58:24] [config] optimizer-delay: 8
[2019-05-19 19:58:24] [config] optimizer-params:
[2019-05-19 19:58:24] [config]   - 0.9
[2019-05-19 19:58:24] [config]   - 0.98
[2019-05-19 19:58:24] [config]   - 1e-09
[2019-05-19 19:58:24] [config] overwrite: false
[2019-05-19 19:58:24] [config] pretrained-model: ../src0tgt0_fr/model/model.src0tgt0.newvocab.iter630000.npz
[2019-05-19 19:58:24] [config] quiet: false
[2019-05-19 19:58:24] [config] quiet-translation: true
[2019-05-19 19:58:24] [config] relative-paths: false
[2019-05-19 19:58:24] [config] right-left: false
[2019-05-19 19:58:24] [config] save-freq: 5000
[2019-05-19 19:58:24] [config] seed: 1111
[2019-05-19 19:58:24] [config] shuffle-in-ram: false
[2019-05-19 19:58:24] [config] skip: false
[2019-05-19 19:58:24] [config] sqlite: ""
[2019-05-19 19:58:24] [config] sqlite-drop: false
[2019-05-19 19:58:24] [config] sync-sgd: true
[2019-05-19 19:58:24] [config] tempdir: /tmp
[2019-05-19 19:58:24] [config] tied-embeddings: false
[2019-05-19 19:58:24] [config] tied-embeddings-all: true
[2019-05-19 19:58:24] [config] tied-embeddings-src: false
[2019-05-19 19:58:24] [config] train-sets:
[2019-05-19 19:58:24] [config]   - corp/opensub.en-fr.docs.train.en.bpe.src_prev
[2019-05-19 19:58:24] [config]   - corp/opensub.en-fr.docs.train.en.bpe.src
[2019-05-19 19:58:24] [config]   - corp/opensub.en-fr.docs.train.fr.bpe
[2019-05-19 19:58:24] [config] transformer-aan-activation: swish
[2019-05-19 19:58:24] [config] transformer-aan-depth: 2
[2019-05-19 19:58:24] [config] transformer-aan-nogate: false
[2019-05-19 19:58:24] [config] transformer-decoder-autoreg: self-attention
[2019-05-19 19:58:24] [config] transformer-dim-aan: 2048
[2019-05-19 19:58:24] [config] transformer-dim-ffn: 2048
[2019-05-19 19:58:24] [config] transformer-dropout: 0.1
[2019-05-19 19:58:24] [config] transformer-dropout-attention: 0
[2019-05-19 19:58:24] [config] transformer-dropout-ffn: 0
[2019-05-19 19:58:24] [config] transformer-ffn-activation: swish
[2019-05-19 19:58:24] [config] transformer-ffn-depth: 2
[2019-05-19 19:58:24] [config] transformer-guided-alignment-layer: last
[2019-05-19 19:58:24] [config] transformer-heads: 8
[2019-05-19 19:58:24] [config] transformer-no-projection: false
[2019-05-19 19:58:24] [config] transformer-postprocess: dan
[2019-05-19 19:58:24] [config] transformer-postprocess-emb: d
[2019-05-19 19:58:24] [config] transformer-preprocess: ""
[2019-05-19 19:58:24] [config] transformer-tied-layers:
[2019-05-19 19:58:24] [config]   []
[2019-05-19 19:58:24] [config] transformer-train-position-embeddings: false
[2019-05-19 19:58:24] [config] type: transformer-voita
[2019-05-19 19:58:24] [config] ulr: false
[2019-05-19 19:58:24] [config] ulr-dim-emb: 0
[2019-05-19 19:58:24] [config] ulr-dropout: 0
[2019-05-19 19:58:24] [config] ulr-keys-vectors: ""
[2019-05-19 19:58:24] [config] ulr-query-vectors: ""
[2019-05-19 19:58:24] [config] ulr-softmax-temperature: 1
[2019-05-19 19:58:24] [config] ulr-trainable-transformation: false
[2019-05-19 19:58:24] [config] valid-freq: 5000
[2019-05-19 19:58:24] [config] valid-log: model/valid_trans.gate.log
[2019-05-19 19:58:24] [config] valid-max-length: 1000
[2019-05-19 19:58:24] [config] valid-metrics:
[2019-05-19 19:58:24] [config]   - cross-entropy
[2019-05-19 19:58:24] [config]   - perplexity
[2019-05-19 19:58:24] [config]   - translation
[2019-05-19 19:58:24] [config] valid-mini-batch: 64
[2019-05-19 19:58:24] [config] valid-script-path: ./val.sh
[2019-05-19 19:58:24] [config] valid-sets:
[2019-05-19 19:58:24] [config]   - corp/opensub.en-fr.docs.dev.en.bpe.src_prev
[2019-05-19 19:58:24] [config]   - corp/opensub.en-fr.docs.dev.en.bpe.src
[2019-05-19 19:58:24] [config]   - corp/opensub.en-fr.docs.dev.fr.bpe
[2019-05-19 19:58:24] [config] valid-translation-output: data/valid.bpe.en.output
[2019-05-19 19:58:24] [config] version: v1.7.8 211bce5 2019-05-18 17:09:38 +0200
[2019-05-19 19:58:24] [config] vocabs:
[2019-05-19 19:58:24] [config]   - corp/vocab.encz.opensub.new.yml
[2019-05-19 19:58:24] [config]   - corp/vocab.encz.opensub.new.yml
[2019-05-19 19:58:24] [config]   - corp/vocab.encz.opensub.new.yml
[2019-05-19 19:58:24] [config] word-penalty: 0
[2019-05-19 19:58:24] [config] workspace: 8200
[2019-05-19 19:58:24] [config] Loaded model has been created with Marian v1.7.8 211bce5 2019-05-18 17:09:38 +0200
[2019-05-19 19:58:24] Using synchronous training
[2019-05-19 19:58:24] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encz.opensub.new.yml
[2019-05-19 19:58:24] [data] Setting vocabulary size for input 0 to 30000
[2019-05-19 19:58:24] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encz.opensub.new.yml
[2019-05-19 19:58:24] [data] Setting vocabulary size for input 1 to 30000
[2019-05-19 19:58:24] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encz.opensub.new.yml
[2019-05-19 19:58:25] [data] Setting vocabulary size for input 2 to 30000
[2019-05-19 19:58:25] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-05-19 19:58:25] [batching] Collecting statistics for batch fitting with step size 10
[2019-05-19 19:58:25] [memory] Extending reserved space to 8320 MB (device gpu2)
[2019-05-19 19:58:25] [comm] Using NCCL 2.4.2 for GPU communication
[2019-05-19 19:58:25] [comm] NCCLCommunicator constructed successfully.
[2019-05-19 19:58:25] [training] Using 1 GPUs
[2019-05-19 19:58:25] [memory] Reserving 245 MB, device gpu2
[2019-05-19 19:58:25] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-05-19 19:58:26] [memory] Reserving 245 MB, device gpu2
[2019-05-19 19:58:35] [batching] Done. Typical MB size is 38080 target words
[2019-05-19 19:58:35] [memory] Extending reserved space to 8320 MB (device gpu2)
[2019-05-19 19:58:35] [comm] Using NCCL 2.4.2 for GPU communication
[2019-05-19 19:58:35] [comm] NCCLCommunicator constructed successfully.
[2019-05-19 19:58:35] [training] Using 1 GPUs
[2019-05-19 19:58:35] Loading model from model/model.src1tgt0.voita.fix.npz.orig.npz
[2019-05-19 19:58:38] Loading Adam parameters from model/model.src1tgt0.voita.fix.npz.optimizer.npz
[2019-05-19 19:58:43] [memory] Reserving 514 MB, device gpu2
[2019-05-19 19:58:44] [training] Model reloaded from model/model.src1tgt0.voita.fix.npz
[2019-05-19 19:58:44] Training started
[2019-05-19 19:58:44] [data] Shuffling data
tcmalloc: large alloc 1073741824 bytes == 0x1158c4000 @ 
tcmalloc: large alloc 2147483648 bytes == 0x7f7930000000 @ 
tcmalloc: large alloc 2147483648 bytes == 0x7f78b0000000 @ 
tcmalloc: large alloc 2147483648 bytes == 0x1158c4000 @ 
[2019-05-19 19:58:57] [data] Done reading 41736982 sentences
[2019-05-19 20:08:40] [data] Done shuffling 41736982 sentences to temp files
[2019-05-19 20:09:07] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-05-19 20:09:07] [memory] Reserving 257 MB, device gpu2
[2019-05-19 20:09:07] [memory] Reserving 257 MB, device gpu2
[2019-05-19 20:09:07] Loading model from model/model.src1tgt0.voita.fix.npz
[2019-05-19 20:09:09] [memory] Reserving 257 MB, device cpu0
[2019-05-19 20:09:09] [memory] Reserving 257 MB, device gpu2
[2019-05-19 20:24:35] Ep. 1 : Up. 15500 : Sen. 719,827 : Cost 23.82662964 : Time 1570.66s : 4279.21 words/s : L.r. 1.9375e-04
[2019-05-19 20:40:47] Ep. 1 : Up. 16000 : Sen. 1,457,485 : Cost 24.15456390 : Time 971.34s : 7220.50 words/s : L.r. 2.0000e-04
[2019-05-19 20:57:01] Ep. 1 : Up. 16500 : Sen. 2,184,699 : Cost 24.40090561 : Time 974.57s : 7135.82 words/s : L.r. 1.9695e-04
[2019-05-19 21:12:44] Ep. 1 : Up. 17000 : Sen. 2,903,614 : Cost 23.92679214 : Time 943.01s : 7151.17 words/s : L.r. 1.9403e-04
[2019-05-19 21:28:38] Ep. 1 : Up. 17500 : Sen. 3,612,394 : Cost 24.56686783 : Time 954.00s : 7164.06 words/s : L.r. 1.9124e-04
[2019-05-19 21:44:34] Ep. 1 : Up. 18000 : Sen. 4,351,369 : Cost 23.39904022 : Time 956.23s : 7137.77 words/s : L.r. 1.8856e-04
[2019-05-19 22:00:28] Ep. 1 : Up. 18500 : Sen. 5,064,993 : Cost 24.51877975 : Time 953.64s : 7168.81 words/s : L.r. 1.8600e-04
[2019-05-19 22:16:21] Ep. 1 : Up. 19000 : Sen. 5,774,255 : Cost 24.54252434 : Time 953.43s : 7158.33 words/s : L.r. 1.8353e-04
[2019-05-19 22:32:42] Ep. 1 : Up. 19500 : Sen. 6,533,152 : Cost 23.09062767 : Time 980.24s : 7112.97 words/s : L.r. 1.8116e-04
[2019-05-19 22:48:32] Ep. 1 : Up. 20000 : Sen. 7,238,983 : Cost 24.57111359 : Time 950.11s : 7133.67 words/s : L.r. 1.7889e-04
[2019-05-19 22:48:32] Saving model weights and runtime parameters to model/model.src1tgt0.voita.fix.npz.orig.npz
[2019-05-19 22:48:37] Saving model weights and runtime parameters to model/model.src1tgt0.voita.fix.iter20000.npz
[2019-05-19 22:48:40] Saving model weights and runtime parameters to model/model.src1tgt0.voita.fix.npz
[2019-05-19 22:48:46] Saving Adam parameters to model/model.src1tgt0.voita.fix.npz.optimizer.npz
[2019-05-19 22:49:00] [valid] Ep. 1 : Up. 20000 : cross-entropy : 19.1659 : stalled 1 times (last best: 19.0347)
[2019-05-19 22:49:06] [valid] Ep. 1 : Up. 20000 : perplexity : 4.42397 : stalled 1 times (last best: 4.37914)
Detokenizer Version $Revision: 4134 $
Language: en
[2019-05-19 22:50:26] [valid] Ep. 1 : Up. 20000 : translation : 34.3 : stalled 2 times (last best: 34.3)
[2019-05-19 23:06:15] Ep. 1 : Up. 20500 : Sen. 7,963,280 : Cost 23.72854805 : Time 1063.59s : 6383.48 words/s : L.r. 1.7669e-04
[2019-05-19 23:22:13] Ep. 1 : Up. 21000 : Sen. 8,691,933 : Cost 23.69765282 : Time 957.33s : 7154.41 words/s : L.r. 1.7457e-04
[2019-05-19 23:38:22] Ep. 1 : Up. 21500 : Sen. 9,417,693 : Cost 24.13505936 : Time 969.22s : 7108.76 words/s : L.r. 1.7253e-04
[2019-05-19 23:54:20] Ep. 1 : Up. 22000 : Sen. 10,140,497 : Cost 23.97520828 : Time 958.51s : 7113.53 words/s : L.r. 1.7056e-04
[2019-05-20 00:10:04] Ep. 1 : Up. 22500 : Sen. 10,852,010 : Cost 23.82725334 : Time 943.93s : 7105.42 words/s : L.r. 1.6865e-04
[2019-05-20 00:25:58] Ep. 1 : Up. 23000 : Sen. 11,549,775 : Cost 24.79181480 : Time 953.46s : 7166.76 words/s : L.r. 1.6681e-04
[2019-05-20 00:41:59] Ep. 1 : Up. 23500 : Sen. 12,277,297 : Cost 23.44652748 : Time 960.79s : 7016.54 words/s : L.r. 1.6503e-04
[2019-05-20 00:58:06] Ep. 1 : Up. 24000 : Sen. 13,010,739 : Cost 23.60216713 : Time 967.52s : 7101.08 words/s : L.r. 1.6330e-04
[2019-05-20 01:14:24] Ep. 1 : Up. 24500 : Sen. 13,757,036 : Cost 23.52203178 : Time 977.38s : 7134.14 words/s : L.r. 1.6162e-04
[2019-05-20 01:30:12] Ep. 1 : Up. 25000 : Sen. 14,460,467 : Cost 24.19966125 : Time 948.70s : 7092.95 words/s : L.r. 1.6000e-04
[2019-05-20 01:30:12] Saving model weights and runtime parameters to model/model.src1tgt0.voita.fix.npz.orig.npz
[2019-05-20 01:30:17] Saving model weights and runtime parameters to model/model.src1tgt0.voita.fix.iter25000.npz
[2019-05-20 01:30:21] Saving model weights and runtime parameters to model/model.src1tgt0.voita.fix.npz
[2019-05-20 01:30:27] Saving Adam parameters to model/model.src1tgt0.voita.fix.npz.optimizer.npz
[2019-05-20 01:30:43] [valid] Ep. 1 : Up. 25000 : cross-entropy : 19.1557 : stalled 2 times (last best: 19.0347)
[2019-05-20 01:30:49] [valid] Ep. 1 : Up. 25000 : perplexity : 4.42044 : stalled 2 times (last best: 4.37914)
Detokenizer Version $Revision: 4134 $
Language: en
[2019-05-20 01:32:09] [valid] Ep. 1 : Up. 25000 : translation : 34.3 : stalled 3 times (last best: 34.3)
[2019-05-20 01:48:14] Ep. 1 : Up. 25500 : Sen. 15,203,420 : Cost 23.41599274 : Time 1081.88s : 6377.07 words/s : L.r. 1.5842e-04
[2019-05-20 02:03:59] Ep. 1 : Up. 26000 : Sen. 15,902,812 : Cost 24.16737747 : Time 944.51s : 7082.33 words/s : L.r. 1.5689e-04
[2019-05-20 02:20:23] Ep. 1 : Up. 26500 : Sen. 16,644,631 : Cost 23.61714363 : Time 984.63s : 7107.57 words/s : L.r. 1.5541e-04
[2019-05-20 02:36:15] Ep. 1 : Up. 27000 : Sen. 17,334,243 : Cost 24.75544167 : Time 952.13s : 7052.27 words/s : L.r. 1.5396e-04
[2019-05-20 02:52:27] Ep. 1 : Up. 27500 : Sen. 18,075,069 : Cost 23.51301575 : Time 972.04s : 7130.51 words/s : L.r. 1.5255e-04
train_doc_new_spider.newest.voita.fix.sh: line 30: 59935 Terminated              $marian_home/marian --model model/model.src1tgt0.voita.fix.npz --pretrained-model ../src0tgt0_fr/model/model.src0tgt0.newvocab.iter630000.npz --type transformer-voita --train-sets corp/opensub.en-fr.docs.train.en.bpe.src_prev corp/opensub.en-fr.docs.train.en.bpe.src corp/opensub.en-fr.docs.train.fr.bpe --max-length 55 --dim-vocabs 30000 30000 --vocabs corp/vocab.encz.opensub.new.yml corp/vocab.encz.opensub.new.yml corp/vocab.encz.opensub.new.yml --mini-batch-fit -w 8200 --mini-batch 1000 --maxi-batch 1000 --early-stopping 10 --valid-freq 5000 --save-freq 5000 --disp-freq 500 --valid-metrics cross-entropy perplexity translation --valid-sets corp/opensub.en-fr.docs.dev.en.bpe.src_prev corp/opensub.en-fr.docs.dev.en.bpe.src corp/opensub.en-fr.docs.dev.fr.bpe --valid-script-path ./val.sh --valid-translation-output data/valid.bpe.en.output --quiet-translation --valid-mini-batch 64 --beam-size 6 --normalize 0.6 --log model/train_trans.gate.log --valid-log model/valid_trans.gate.log --enc-depth 6 --dec-depth 6 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0002 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --optimizer-delay 8 --devices 2 --sync-sgd --seed 1111 --exponential-smoothing --no-restore-corpus
