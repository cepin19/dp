[2019-03-27 14:56:16] [marian] Marian v1.7.8 02f2cbe 2019-03-27 14:50:43 +0100
[2019-03-27 14:56:16] [marian] Running on poseidon.lingea.cz as process 12530 with command line:
[2019-03-27 14:56:16] [marian] /home/large/data/models/marian/marian-doc/marian_voita/doc-marian/build/marian --model model/model.src1tgt0.doc.pretrained.npz --pretrained-model ../src0tgt0_fr/model/model.src0tgt0.newvocab.iter195000.npz --type transformer-context --train-sets corp/opensub.en-fr.docs.train.en.bpe.src_prev corp/opensub.en-fr.docs.train.en.bpe.src corp/opensub.en-fr.docs.train.fr.bpe --max-length 55 --dim-vocabs 30000 30000 --vocabs corp/vocab.encz.opensub.new.yml corp/vocab.encz.opensub.new.yml corp/vocab.encz.opensub.new.yml --mini-batch-fit -w 9000 --mini-batch 1000 --maxi-batch 1000 --early-stopping 10 --valid-freq 5000 --save-freq 5000 --disp-freq 500 --valid-metrics cross-entropy perplexity translation --valid-sets corp/opensub.en-fr.docs.dev.en.bpe.src_prev corp/opensub.en-fr.docs.dev.en.bpe.src corp/opensub.en-fr.docs.dev.fr.bpe --valid-script-path ./val.sh --valid-translation-output data/valid.bpe.en.output --quiet-translation --valid-mini-batch 64 --beam-size 6 --normalize 0.6 --log model/train_trans.gate.log --valid-log model/valid_trans.gate.log --enc-depth 6 --dec-depth 6 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --optimizer-delay 4 --devices 0 1 --no-nccl --sync-sgd --seed 1111 --exponential-smoothing --no-restore-corpus
[2019-03-27 14:56:16] [config] after-batches: 0
[2019-03-27 14:56:16] [config] after-epochs: 0
[2019-03-27 14:56:16] [config] allow-unk: false
[2019-03-27 14:56:16] [config] beam-size: 6
[2019-03-27 14:56:16] [config] bert-class-symbol: "[CLS]"
[2019-03-27 14:56:16] [config] bert-mask-symbol: "[MASK]"
[2019-03-27 14:56:16] [config] bert-masking-fraction: 0.15
[2019-03-27 14:56:16] [config] bert-sep-symbol: "[SEP]"
[2019-03-27 14:56:16] [config] bert-train-type-embeddings: true
[2019-03-27 14:56:16] [config] bert-type-vocab-size: 2
[2019-03-27 14:56:16] [config] best-deep: false
[2019-03-27 14:56:16] [config] clip-gemm: 0
[2019-03-27 14:56:16] [config] clip-norm: 5
[2019-03-27 14:56:16] [config] context-enc-depth: 1
[2019-03-27 14:56:16] [config] cost-type: ce-mean
[2019-03-27 14:56:16] [config] cpu-threads: 0
[2019-03-27 14:56:16] [config] data-weighting: ""
[2019-03-27 14:56:16] [config] data-weighting-type: sentence
[2019-03-27 14:56:16] [config] dec-cell: gru
[2019-03-27 14:56:16] [config] dec-cell-base-depth: 2
[2019-03-27 14:56:16] [config] dec-cell-high-depth: 1
[2019-03-27 14:56:16] [config] dec-depth: 6
[2019-03-27 14:56:16] [config] devices:
[2019-03-27 14:56:16] [config]   - 0
[2019-03-27 14:56:16] [config]   - 1
[2019-03-27 14:56:16] [config] dim-emb: 512
[2019-03-27 14:56:16] [config] dim-rnn: 1024
[2019-03-27 14:56:16] [config] dim-vocabs:
[2019-03-27 14:56:16] [config]   - 30000
[2019-03-27 14:56:16] [config]   - 30000
[2019-03-27 14:56:16] [config] disp-first: 0
[2019-03-27 14:56:16] [config] disp-freq: 500
[2019-03-27 14:56:16] [config] disp-label-counts: false
[2019-03-27 14:56:16] [config] dropout-rnn: 0
[2019-03-27 14:56:16] [config] dropout-src: 0
[2019-03-27 14:56:16] [config] dropout-trg: 0
[2019-03-27 14:56:16] [config] dump-config: ""
[2019-03-27 14:56:16] [config] early-stopping: 10
[2019-03-27 14:56:16] [config] embedding-fix-src: false
[2019-03-27 14:56:16] [config] embedding-fix-trg: false
[2019-03-27 14:56:16] [config] embedding-normalization: false
[2019-03-27 14:56:16] [config] embedding-vectors:
[2019-03-27 14:56:16] [config]   []
[2019-03-27 14:56:16] [config] enc-cell: gru
[2019-03-27 14:56:16] [config] enc-cell-depth: 1
[2019-03-27 14:56:16] [config] enc-depth: 6
[2019-03-27 14:56:16] [config] enc-type: bidirectional
[2019-03-27 14:56:16] [config] exponential-smoothing: 0.0001
[2019-03-27 14:56:16] [config] grad-dropping-momentum: 0
[2019-03-27 14:56:16] [config] grad-dropping-rate: 0
[2019-03-27 14:56:16] [config] grad-dropping-warmup: 100
[2019-03-27 14:56:16] [config] guided-alignment: none
[2019-03-27 14:56:16] [config] guided-alignment-cost: mse
[2019-03-27 14:56:16] [config] guided-alignment-weight: 0.1
[2019-03-27 14:56:16] [config] hier-att: false
[2019-03-27 14:56:16] [config] ignore-model-config: false
[2019-03-27 14:56:16] [config] input-types:
[2019-03-27 14:56:16] [config]   []
[2019-03-27 14:56:16] [config] interpolate-env-vars: false
[2019-03-27 14:56:16] [config] keep-best: false
[2019-03-27 14:56:16] [config] label-smoothing: 0.1
[2019-03-27 14:56:16] [config] layer-normalization: false
[2019-03-27 14:56:16] [config] learn-rate: 0.0003
[2019-03-27 14:56:16] [config] log: model/train_trans.gate.log
[2019-03-27 14:56:16] [config] log-level: info
[2019-03-27 14:56:16] [config] log-time-zone: ""
[2019-03-27 14:56:16] [config] lr-decay: 0
[2019-03-27 14:56:16] [config] lr-decay-freq: 50000
[2019-03-27 14:56:16] [config] lr-decay-inv-sqrt:
[2019-03-27 14:56:16] [config]   - 16000
[2019-03-27 14:56:16] [config] lr-decay-repeat-warmup: false
[2019-03-27 14:56:16] [config] lr-decay-reset-optimizer: false
[2019-03-27 14:56:16] [config] lr-decay-start:
[2019-03-27 14:56:16] [config]   - 10
[2019-03-27 14:56:16] [config]   - 1
[2019-03-27 14:56:16] [config] lr-decay-strategy: epoch+stalled
[2019-03-27 14:56:16] [config] lr-report: true
[2019-03-27 14:56:16] [config] lr-warmup: 16000
[2019-03-27 14:56:16] [config] lr-warmup-at-reload: false
[2019-03-27 14:56:16] [config] lr-warmup-cycle: false
[2019-03-27 14:56:16] [config] lr-warmup-start-rate: 0
[2019-03-27 14:56:16] [config] max-length: 55
[2019-03-27 14:56:16] [config] max-length-crop: false
[2019-03-27 14:56:16] [config] max-length-factor: 3
[2019-03-27 14:56:16] [config] maxi-batch: 1000
[2019-03-27 14:56:16] [config] maxi-batch-sort: trg
[2019-03-27 14:56:16] [config] mini-batch: 1000
[2019-03-27 14:56:16] [config] mini-batch-fit: true
[2019-03-27 14:56:16] [config] mini-batch-fit-step: 10
[2019-03-27 14:56:16] [config] mini-batch-overstuff: 1
[2019-03-27 14:56:16] [config] mini-batch-track-lr: false
[2019-03-27 14:56:16] [config] mini-batch-understuff: 1
[2019-03-27 14:56:16] [config] mini-batch-warmup: 0
[2019-03-27 14:56:16] [config] mini-batch-words: 0
[2019-03-27 14:56:16] [config] mini-batch-words-ref: 0
[2019-03-27 14:56:16] [config] model: model/model.src1tgt0.doc.pretrained.npz
[2019-03-27 14:56:16] [config] multi-loss-type: sum
[2019-03-27 14:56:16] [config] multi-node: false
[2019-03-27 14:56:16] [config] multi-node-overlap: true
[2019-03-27 14:56:16] [config] n-best: false
[2019-03-27 14:56:16] [config] no-nccl: true
[2019-03-27 14:56:16] [config] no-reload: false
[2019-03-27 14:56:16] [config] no-restore-corpus: true
[2019-03-27 14:56:16] [config] no-shuffle: false
[2019-03-27 14:56:16] [config] normalize: 0.6
[2019-03-27 14:56:16] [config] num-devices: 0
[2019-03-27 14:56:16] [config] optimizer: adam
[2019-03-27 14:56:16] [config] optimizer-delay: 4
[2019-03-27 14:56:16] [config] optimizer-params:
[2019-03-27 14:56:16] [config]   - 0.9
[2019-03-27 14:56:16] [config]   - 0.98
[2019-03-27 14:56:16] [config]   - 1e-09
[2019-03-27 14:56:16] [config] overwrite: false
[2019-03-27 14:56:16] [config] pretrained-model: ../src0tgt0_fr/model/model.src0tgt0.newvocab.iter195000.npz
[2019-03-27 14:56:16] [config] quiet: false
[2019-03-27 14:56:16] [config] quiet-translation: true
[2019-03-27 14:56:16] [config] relative-paths: false
[2019-03-27 14:56:16] [config] right-left: false
[2019-03-27 14:56:16] [config] save-freq: 5000
[2019-03-27 14:56:16] [config] seed: 1111
[2019-03-27 14:56:16] [config] shuffle-in-ram: false
[2019-03-27 14:56:16] [config] skip: false
[2019-03-27 14:56:16] [config] sqlite: ""
[2019-03-27 14:56:16] [config] sqlite-drop: false
[2019-03-27 14:56:16] [config] sync-sgd: true
[2019-03-27 14:56:16] [config] tempdir: /tmp
[2019-03-27 14:56:16] [config] tied-embeddings: false
[2019-03-27 14:56:16] [config] tied-embeddings-all: true
[2019-03-27 14:56:16] [config] tied-embeddings-src: false
[2019-03-27 14:56:16] [config] train-sets:
[2019-03-27 14:56:16] [config]   - corp/opensub.en-fr.docs.train.en.bpe.src_prev
[2019-03-27 14:56:16] [config]   - corp/opensub.en-fr.docs.train.en.bpe.src
[2019-03-27 14:56:16] [config]   - corp/opensub.en-fr.docs.train.fr.bpe
[2019-03-27 14:56:16] [config] transformer-aan-activation: swish
[2019-03-27 14:56:16] [config] transformer-aan-depth: 2
[2019-03-27 14:56:16] [config] transformer-aan-nogate: false
[2019-03-27 14:56:16] [config] transformer-decoder-autoreg: self-attention
[2019-03-27 14:56:16] [config] transformer-dim-aan: 2048
[2019-03-27 14:56:16] [config] transformer-dim-ffn: 2048
[2019-03-27 14:56:16] [config] transformer-dropout: 0.1
[2019-03-27 14:56:16] [config] transformer-dropout-attention: 0
[2019-03-27 14:56:16] [config] transformer-dropout-ffn: 0
[2019-03-27 14:56:16] [config] transformer-ffn-activation: swish
[2019-03-27 14:56:16] [config] transformer-ffn-depth: 2
[2019-03-27 14:56:16] [config] transformer-guided-alignment-layer: last
[2019-03-27 14:56:16] [config] transformer-heads: 8
[2019-03-27 14:56:16] [config] transformer-no-projection: false
[2019-03-27 14:56:16] [config] transformer-postprocess: dan
[2019-03-27 14:56:16] [config] transformer-postprocess-emb: d
[2019-03-27 14:56:16] [config] transformer-preprocess: ""
[2019-03-27 14:56:16] [config] transformer-tied-layers:
[2019-03-27 14:56:16] [config]   []
[2019-03-27 14:56:16] [config] transformer-train-position-embeddings: false
[2019-03-27 14:56:16] [config] type: transformer-context
[2019-03-27 14:56:16] [config] ulr: false
[2019-03-27 14:56:16] [config] ulr-dim-emb: 0
[2019-03-27 14:56:16] [config] ulr-dropout: 0
[2019-03-27 14:56:16] [config] ulr-keys-vectors: ""
[2019-03-27 14:56:16] [config] ulr-query-vectors: ""
[2019-03-27 14:56:16] [config] ulr-softmax-temperature: 1
[2019-03-27 14:56:16] [config] ulr-trainable-transformation: false
[2019-03-27 14:56:16] [config] valid-freq: 5000
[2019-03-27 14:56:16] [config] valid-log: model/valid_trans.gate.log
[2019-03-27 14:56:16] [config] valid-max-length: 1000
[2019-03-27 14:56:16] [config] valid-metrics:
[2019-03-27 14:56:16] [config]   - cross-entropy
[2019-03-27 14:56:16] [config]   - perplexity
[2019-03-27 14:56:16] [config]   - translation
[2019-03-27 14:56:16] [config] valid-mini-batch: 64
[2019-03-27 14:56:16] [config] valid-script-path: ./val.sh
[2019-03-27 14:56:16] [config] valid-sets:
[2019-03-27 14:56:16] [config]   - corp/opensub.en-fr.docs.dev.en.bpe.src_prev
[2019-03-27 14:56:16] [config]   - corp/opensub.en-fr.docs.dev.en.bpe.src
[2019-03-27 14:56:16] [config]   - corp/opensub.en-fr.docs.dev.fr.bpe
[2019-03-27 14:56:16] [config] valid-translation-output: data/valid.bpe.en.output
[2019-03-27 14:56:16] [config] vocabs:
[2019-03-27 14:56:16] [config]   - corp/vocab.encz.opensub.new.yml
[2019-03-27 14:56:16] [config]   - corp/vocab.encz.opensub.new.yml
[2019-03-27 14:56:16] [config]   - corp/vocab.encz.opensub.new.yml
[2019-03-27 14:56:16] [config] word-penalty: 0
[2019-03-27 14:56:16] [config] workspace: 9000
[2019-03-27 14:56:16] [config] Model is being created with Marian v1.7.8 02f2cbe 2019-03-27 14:50:43 +0100
[2019-03-27 14:56:16] Using synchronous training
[2019-03-27 14:56:16] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encz.opensub.new.yml
[2019-03-27 14:56:16] [data] Setting vocabulary size for input 0 to 30000
[2019-03-27 14:56:16] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encz.opensub.new.yml
[2019-03-27 14:56:16] [data] Setting vocabulary size for input 1 to 30000
[2019-03-27 14:56:16] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encz.opensub.new.yml
[2019-03-27 14:56:17] [data] Setting vocabulary size for input 2 to 30000
[2019-03-27 14:56:17] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-03-27 14:56:17] [batching] Collecting statistics for batch fitting with step size 10
[2019-03-27 14:56:18] [memory] Extending reserved space to 9088 MB (device gpu0)
[2019-03-27 14:56:19] [memory] Extending reserved space to 9088 MB (device gpu1)
[2019-03-27 14:56:19] [comm] NCCL communicator overridden
[2019-03-27 14:56:19] [training] Using 2 GPUs
[2019-03-27 14:56:19] [memory] Reserving 311 MB, device gpu0
[2019-03-27 14:56:19] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-03-27 14:56:20] [memory] Reserving 311 MB, device gpu0
[2019-03-27 14:56:31] [batching] Done. Typical MB size is 37200 target words
[2019-03-27 14:56:31] [memory] Extending reserved space to 9088 MB (device gpu0)
[2019-03-27 14:56:32] [memory] Extending reserved space to 9088 MB (device gpu1)
[2019-03-27 14:56:32] [comm] NCCL communicator overridden
[2019-03-27 14:56:32] [training] Using 2 GPUs
[2019-03-27 14:56:32] [training] Initializing model weights with the pre-trained model ../src0tgt0_fr/model/model.src0tgt0.newvocab.iter195000.npz
[2019-03-27 14:56:32] Loading model from ../src0tgt0_fr/model/model.src0tgt0.newvocab.iter195000.npz
[2019-03-27 14:56:34] Loading model from ../src0tgt0_fr/model/model.src0tgt0.newvocab.iter195000.npz
[2019-03-27 14:56:35] Training started
[2019-03-27 14:56:35] [data] Shuffling data
[2019-03-27 14:57:03] [data] Done reading 41736982 sentences
[2019-03-27 15:00:47] [data] Done shuffling 41736982 sentences to temp files
[2019-03-27 15:01:33] [training] Batches are processed as 1 process(es) x 2 devices/process
[2019-03-27 15:01:33] [memory] Reserving 383 MB, device gpu0
[2019-03-27 15:01:33] [memory] Reserving 383 MB, device gpu1
[2019-03-27 15:01:33] [memory] Reserving 383 MB, device gpu0
[2019-03-27 15:01:33] [memory] Reserving 383 MB, device gpu1
[2019-03-27 15:01:33] [memory] Reserving 191 MB, device gpu0
[2019-03-27 15:01:33] [memory] Reserving 191 MB, device gpu1
[2019-03-27 15:01:34] [memory] Reserving 191 MB, device gpu0
[2019-03-27 15:01:34] [memory] Reserving 191 MB, device gpu1
[2019-03-27 15:01:34] [memory] Reserving 383 MB, device gpu1
[2019-03-27 15:01:34] [memory] Reserving 383 MB, device gpu0
[2019-03-27 15:10:09] Ep. 1 : Up. 500 : Sen. 721,361 : Cost 72.59041595 : Time 832.53s : 8083.28 words/s : L.r. 9.3750e-06
[2019-03-27 15:18:58] Ep. 1 : Up. 1000 : Sen. 1,458,316 : Cost 68.41859436 : Time 528.60s : 13213.85 words/s : L.r. 1.8750e-05
[2019-03-27 15:27:34] Ep. 1 : Up. 1500 : Sen. 2,155,644 : Cost 69.42807007 : Time 515.75s : 12960.93 words/s : L.r. 2.8125e-05
[2019-03-27 15:36:10] Ep. 1 : Up. 2000 : Sen. 2,854,284 : Cost 68.94741058 : Time 516.37s : 12983.23 words/s : L.r. 3.7500e-05
[2019-03-27 15:44:55] Ep. 1 : Up. 2500 : Sen. 3,589,014 : Cost 67.12503052 : Time 525.53s : 13122.71 words/s : L.r. 4.6875e-05
[2019-03-27 15:53:39] Ep. 1 : Up. 3000 : Sen. 4,320,021 : Cost 67.76999664 : Time 523.80s : 12981.14 words/s : L.r. 5.6250e-05
[2019-03-27 16:02:17] Ep. 1 : Up. 3500 : Sen. 5,021,774 : Cost 72.63215637 : Time 517.33s : 13001.18 words/s : L.r. 6.5625e-05
[2019-03-27 16:10:51] Ep. 1 : Up. 4000 : Sen. 5,729,505 : Cost 73.27962494 : Time 514.52s : 12898.80 words/s : L.r. 7.5000e-05
[2019-03-27 16:19:34] Ep. 1 : Up. 4500 : Sen. 6,457,822 : Cost 78.04930115 : Time 523.04s : 13134.33 words/s : L.r. 8.4375e-05
[2019-03-27 16:28:13] Ep. 1 : Up. 5000 : Sen. 7,166,030 : Cost 85.29252625 : Time 518.85s : 12926.88 words/s : L.r. 9.3750e-05
[2019-03-27 16:28:13] Saving model weights and runtime parameters to model/model.src1tgt0.doc.pretrained.npz.orig.npz
[2019-03-27 16:28:19] Saving model weights and runtime parameters to model/model.src1tgt0.doc.pretrained.iter5000.npz
[2019-03-27 16:28:25] Saving model weights and runtime parameters to model/model.src1tgt0.doc.pretrained.npz
[2019-03-27 16:28:31] Saving Adam parameters to model/model.src1tgt0.doc.pretrained.npz.optimizer.npz
[2019-03-27 16:28:49] [valid] Ep. 1 : Up. 5000 : cross-entropy : 97.2606 : new best
[2019-03-27 16:28:52] [valid] Ep. 1 : Up. 5000 : perplexity : 1893.54 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-03-27 16:29:28] [valid] Ep. 1 : Up. 5000 : translation : 0 : new best
[2019-03-27 16:38:02] Ep. 1 : Up. 5500 : Sen. 7,872,418 : Cost 95.75559235 : Time 588.93s : 11350.90 words/s : L.r. 1.0313e-04
[2019-03-27 16:46:44] Ep. 1 : Up. 6000 : Sen. 8,609,528 : Cost 102.89044189 : Time 522.10s : 13170.95 words/s : L.r. 1.1250e-04
[2019-03-27 16:55:22] Ep. 1 : Up. 6500 : Sen. 9,318,155 : Cost 100.01918793 : Time 517.76s : 12997.80 words/s : L.r. 1.2188e-04
[2019-03-27 17:03:59] Ep. 1 : Up. 7000 : Sen. 10,026,045 : Cost 95.36280823 : Time 516.83s : 13064.35 words/s : L.r. 1.3125e-04
[2019-03-27 17:12:42] Ep. 1 : Up. 7500 : Sen. 10,762,224 : Cost 93.07128906 : Time 523.30s : 13207.66 words/s : L.r. 1.4063e-04
[2019-03-27 17:21:09] Ep. 1 : Up. 8000 : Sen. 11,432,533 : Cost 102.39897156 : Time 507.42s : 12974.42 words/s : L.r. 1.5000e-04
[2019-03-27 17:29:51] Ep. 1 : Up. 8500 : Sen. 12,166,152 : Cost 108.96063232 : Time 522.10s : 13074.68 words/s : L.r. 1.5938e-04
[2019-03-27 17:38:25] Ep. 1 : Up. 9000 : Sen. 12,877,415 : Cost 100.56618500 : Time 514.09s : 13095.97 words/s : L.r. 1.6875e-04
[2019-03-27 17:47:14] Ep. 1 : Up. 9500 : Sen. 13,614,495 : Cost 92.05629730 : Time 528.52s : 13279.44 words/s : L.r. 1.7813e-04
[2019-03-27 17:55:36] Ep. 1 : Up. 10000 : Sen. 14,298,489 : Cost 84.27695465 : Time 502.32s : 12844.82 words/s : L.r. 1.8750e-04
[2019-03-27 17:55:36] Saving model weights and runtime parameters to model/model.src1tgt0.doc.pretrained.npz.orig.npz
[2019-03-27 17:55:43] Saving model weights and runtime parameters to model/model.src1tgt0.doc.pretrained.iter10000.npz
[2019-03-27 17:55:48] Saving model weights and runtime parameters to model/model.src1tgt0.doc.pretrained.npz
[2019-03-27 17:55:55] Saving Adam parameters to model/model.src1tgt0.doc.pretrained.npz.optimizer.npz
[2019-03-27 17:56:10] [valid] Ep. 1 : Up. 10000 : cross-entropy : 124.688 : stalled 1 times (last best: 97.2606)
[2019-03-27 17:56:13] [valid] Ep. 1 : Up. 10000 : perplexity : 15902.8 : stalled 1 times (last best: 1893.54)
Detokenizer Version $Revision: 4134 $
Language: en
[2019-03-27 18:05:20] [valid] Ep. 1 : Up. 10000 : translation : 0 : stalled 1 times (last best: 0)
[2019-03-27 18:13:59] Ep. 1 : Up. 10500 : Sen. 15,028,967 : Cost 79.28084564 : Time 1102.82s : 6171.16 words/s : L.r. 1.9688e-04
[2019-03-27 18:22:38] Ep. 1 : Up. 11000 : Sen. 15,756,087 : Cost 75.67202759 : Time 519.11s : 13009.87 words/s : L.r. 2.0625e-04
[2019-03-27 18:31:23] Ep. 1 : Up. 11500 : Sen. 16,482,334 : Cost 75.46974182 : Time 524.40s : 13242.41 words/s : L.r. 2.1563e-04
[2019-03-27 18:39:56] Ep. 1 : Up. 12000 : Sen. 17,193,178 : Cost 72.44300842 : Time 512.97s : 13014.48 words/s : L.r. 2.2500e-04
[2019-03-27 18:48:29] Ep. 1 : Up. 12500 : Sen. 17,891,150 : Cost 72.78139496 : Time 513.21s : 13046.19 words/s : L.r. 2.3438e-04
[2019-03-27 18:57:15] Ep. 1 : Up. 13000 : Sen. 18,627,764 : Cost 71.42144012 : Time 525.95s : 13218.49 words/s : L.r. 2.4375e-04
[2019-03-27 19:05:53] Ep. 1 : Up. 13500 : Sen. 19,359,330 : Cost 72.33602905 : Time 518.69s : 13084.28 words/s : L.r. 2.5313e-04
[2019-03-27 19:14:27] Ep. 1 : Up. 14000 : Sen. 20,051,791 : Cost 81.01057434 : Time 513.33s : 13046.92 words/s : L.r. 2.6250e-04
[2019-03-27 19:23:05] Ep. 1 : Up. 14500 : Sen. 20,777,160 : Cost 86.62326050 : Time 517.81s : 13109.83 words/s : L.r. 2.7188e-04
[2019-03-27 19:31:48] Ep. 1 : Up. 15000 : Sen. 21,504,558 : Cost 95.73682404 : Time 523.02s : 13176.94 words/s : L.r. 2.8125e-04
[2019-03-27 19:31:48] Saving model weights and runtime parameters to model/model.src1tgt0.doc.pretrained.npz.orig.npz
[2019-03-27 19:31:54] Saving model weights and runtime parameters to model/model.src1tgt0.doc.pretrained.iter15000.npz
[2019-03-27 19:32:01] Saving model weights and runtime parameters to model/model.src1tgt0.doc.pretrained.npz
[2019-03-27 19:32:08] Saving Adam parameters to model/model.src1tgt0.doc.pretrained.npz.optimizer.npz
[2019-03-27 19:32:25] [valid] Ep. 1 : Up. 15000 : cross-entropy : 150.276 : stalled 2 times (last best: 97.2606)
[2019-03-27 19:32:28] [valid] Ep. 1 : Up. 15000 : perplexity : 115788 : stalled 2 times (last best: 1893.54)
Detokenizer Version $Revision: 4134 $
Language: en
[2019-03-27 19:45:25] [valid] Ep. 1 : Up. 15000 : translation : 0 : stalled 2 times (last best: 0)
[2019-03-27 19:53:53] Ep. 1 : Up. 15500 : Sen. 22,191,900 : Cost 100.55810547 : Time 1324.89s : 4955.94 words/s : L.r. 2.9063e-04
[2019-03-27 20:02:38] Ep. 1 : Up. 16000 : Sen. 22,931,974 : Cost 100.94248962 : Time 525.81s : 13195.51 words/s : L.r. 3.0000e-04
[2019-03-27 20:11:13] Ep. 1 : Up. 16500 : Sen. 23,649,983 : Cost 107.77915955 : Time 514.92s : 13084.06 words/s : L.r. 2.9542e-04
[2019-03-27 20:19:46] Ep. 1 : Up. 17000 : Sen. 24,352,117 : Cost 108.24482727 : Time 512.39s : 13030.78 words/s : L.r. 2.9104e-04
[2019-03-27 20:28:25] Ep. 1 : Up. 17500 : Sen. 25,066,160 : Cost 114.77661896 : Time 519.18s : 13118.56 words/s : L.r. 2.8685e-04
train_doc.sh: line 29: 12530 Terminated              $marian_home/marian --model model/model.src1tgt0.doc.pretrained.npz --pretrained-model ../src0tgt0_fr/model/model.src0tgt0.newvocab.iter195000.npz --type transformer-context --train-sets corp/opensub.en-fr.docs.train.en.bpe.src_prev corp/opensub.en-fr.docs.train.en.bpe.src corp/opensub.en-fr.docs.train.fr.bpe --max-length 55 --dim-vocabs 30000 30000 --vocabs corp/vocab.encz.opensub.new.yml corp/vocab.encz.opensub.new.yml corp/vocab.encz.opensub.new.yml --mini-batch-fit -w 9000 --mini-batch 1000 --maxi-batch 1000 --early-stopping 10 --valid-freq 5000 --save-freq 5000 --disp-freq 500 --valid-metrics cross-entropy perplexity translation --valid-sets corp/opensub.en-fr.docs.dev.en.bpe.src_prev corp/opensub.en-fr.docs.dev.en.bpe.src corp/opensub.en-fr.docs.dev.fr.bpe --valid-script-path ./val.sh --valid-translation-output data/valid.bpe.en.output --quiet-translation --valid-mini-batch 64 --beam-size 6 --normalize 0.6 --log model/train_trans.gate.log --valid-log model/valid_trans.gate.log --enc-depth 6 --dec-depth 6 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --optimizer-delay 4 --devices 0 1 --no-nccl --sync-sgd --seed 1111 --exponential-smoothing --no-restore-corpus
