[2019-02-21 13:10:06] [marian] Marian v1.7.3 3efcfdf 2018-12-05 21:03:05 -0800
[2019-02-21 13:10:06] [marian] Running on metis.lingea.cz as process 69892 with command line:
[2019-02-21 13:10:06] [marian] /home/big_maggie/usr/marian_metis/marian_1.7.3/marian-dev/build/marian --model model/model.src1tgt0.dual.npz --type transformer --train-sets corp/opensub.en-fr.docs.train.en.bpe.src_prev corp/opensub.en-fr.docs.train.en.bpe.src corp/opensub.en-fr.docs.train.fr.bpe --max-length 55 --dim-vocabs 30000 30000 --vocabs corp/vocab.encz.opensub.new.yml corp/vocab.encz.opensub.new.yml corp/vocab.encz.opensub.new.yml --mini-batch-fit -w 9000 --mini-batch 1000 --maxi-batch 1000 --early-stopping 10 --valid-freq 5000 --save-freq 5000 --disp-freq 500 --valid-metrics cross-entropy perplexity translation --valid-sets corp/opensub.en-fr.docs.dev.en.bpe.src_prev corp/opensub.en-fr.docs.dev.en.bpe.src corp/opensub.en-fr.docs.dev.fr.bpe --valid-script-path ./val.sh --valid-translation-output data/valid.bpe.en.output --quiet-translation --valid-mini-batch 64 --beam-size 6 --normalize 0.6 --log model/train_trans.newvocab.log --valid-log model/valid_trans.newvocab.log --enc-depth 6 --dec-depth 6 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --optimizer-delay 8 --devices 0 2 --sync-sgd --seed 1111 --exponential-smoothing --no-restore-corpus
[2019-02-21 13:10:06] [config] after-batches: 0
[2019-02-21 13:10:06] [config] after-epochs: 0
[2019-02-21 13:10:06] [config] allow-unk: false
[2019-02-21 13:10:06] [config] beam-size: 6
[2019-02-21 13:10:06] [config] best-deep: false
[2019-02-21 13:10:06] [config] clip-gemm: 0
[2019-02-21 13:10:06] [config] clip-norm: 5
[2019-02-21 13:10:06] [config] cost-type: ce-mean
[2019-02-21 13:10:06] [config] cpu-threads: 0
[2019-02-21 13:10:06] [config] data-weighting-type: sentence
[2019-02-21 13:10:06] [config] dec-cell: gru
[2019-02-21 13:10:06] [config] dec-cell-base-depth: 2
[2019-02-21 13:10:06] [config] dec-cell-high-depth: 1
[2019-02-21 13:10:06] [config] dec-depth: 6
[2019-02-21 13:10:06] [config] devices:
[2019-02-21 13:10:06] [config]   - 0
[2019-02-21 13:10:06] [config]   - 2
[2019-02-21 13:10:06] [config] dim-emb: 512
[2019-02-21 13:10:06] [config] dim-rnn: 1024
[2019-02-21 13:10:06] [config] dim-vocabs:
[2019-02-21 13:10:06] [config]   - 30000
[2019-02-21 13:10:06] [config]   - 30000
[2019-02-21 13:10:06] [config] disp-first: 0
[2019-02-21 13:10:06] [config] disp-freq: 500
[2019-02-21 13:10:06] [config] disp-label-counts: false
[2019-02-21 13:10:06] [config] dropout-rnn: 0
[2019-02-21 13:10:06] [config] dropout-src: 0
[2019-02-21 13:10:06] [config] dropout-trg: 0
[2019-02-21 13:10:06] [config] early-stopping: 10
[2019-02-21 13:10:06] [config] embedding-fix-src: false
[2019-02-21 13:10:06] [config] embedding-fix-trg: false
[2019-02-21 13:10:06] [config] embedding-normalization: false
[2019-02-21 13:10:06] [config] enc-cell: gru
[2019-02-21 13:10:06] [config] enc-cell-depth: 1
[2019-02-21 13:10:06] [config] enc-depth: 6
[2019-02-21 13:10:06] [config] enc-type: bidirectional
[2019-02-21 13:10:06] [config] exponential-smoothing: 0.0001
[2019-02-21 13:10:06] [config] grad-dropping-momentum: 0
[2019-02-21 13:10:06] [config] grad-dropping-rate: 0
[2019-02-21 13:10:06] [config] grad-dropping-warmup: 100
[2019-02-21 13:10:06] [config] guided-alignment: none
[2019-02-21 13:10:06] [config] guided-alignment-cost: mse
[2019-02-21 13:10:06] [config] guided-alignment-weight: 0.1
[2019-02-21 13:10:06] [config] ignore-model-config: false
[2019-02-21 13:10:06] [config] interpolate-env-vars: false
[2019-02-21 13:10:06] [config] keep-best: false
[2019-02-21 13:10:06] [config] label-smoothing: 0.1
[2019-02-21 13:10:06] [config] layer-normalization: false
[2019-02-21 13:10:06] [config] learn-rate: 0.0003
[2019-02-21 13:10:06] [config] log: model/train_trans.newvocab.log
[2019-02-21 13:10:06] [config] log-level: info
[2019-02-21 13:10:06] [config] lr-decay: 0
[2019-02-21 13:10:06] [config] lr-decay-freq: 50000
[2019-02-21 13:10:06] [config] lr-decay-inv-sqrt: 16000
[2019-02-21 13:10:06] [config] lr-decay-repeat-warmup: false
[2019-02-21 13:10:06] [config] lr-decay-reset-optimizer: false
[2019-02-21 13:10:06] [config] lr-decay-start:
[2019-02-21 13:10:06] [config]   - 10
[2019-02-21 13:10:06] [config]   - 1
[2019-02-21 13:10:06] [config] lr-decay-strategy: epoch+stalled
[2019-02-21 13:10:06] [config] lr-report: true
[2019-02-21 13:10:06] [config] lr-warmup: 16000
[2019-02-21 13:10:06] [config] lr-warmup-at-reload: false
[2019-02-21 13:10:06] [config] lr-warmup-cycle: false
[2019-02-21 13:10:06] [config] lr-warmup-start-rate: 0
[2019-02-21 13:10:06] [config] max-length: 55
[2019-02-21 13:10:06] [config] max-length-crop: false
[2019-02-21 13:10:06] [config] max-length-factor: 3
[2019-02-21 13:10:06] [config] maxi-batch: 1000
[2019-02-21 13:10:06] [config] maxi-batch-sort: trg
[2019-02-21 13:10:06] [config] mini-batch: 1000
[2019-02-21 13:10:06] [config] mini-batch-fit: true
[2019-02-21 13:10:06] [config] mini-batch-fit-step: 10
[2019-02-21 13:10:06] [config] mini-batch-words: 0
[2019-02-21 13:10:06] [config] model: model/model.src1tgt0.dual.npz
[2019-02-21 13:10:06] [config] multi-node: false
[2019-02-21 13:10:06] [config] multi-node-overlap: true
[2019-02-21 13:10:06] [config] n-best: false
[2019-02-21 13:10:06] [config] no-reload: false
[2019-02-21 13:10:06] [config] no-restore-corpus: true
[2019-02-21 13:10:06] [config] no-shuffle: false
[2019-02-21 13:10:06] [config] normalize: 0.6
[2019-02-21 13:10:06] [config] optimizer: adam
[2019-02-21 13:10:06] [config] optimizer-delay: 8
[2019-02-21 13:10:06] [config] optimizer-params:
[2019-02-21 13:10:06] [config]   - 0.9
[2019-02-21 13:10:06] [config]   - 0.98
[2019-02-21 13:10:06] [config]   - 1e-09
[2019-02-21 13:10:06] [config] overwrite: false
[2019-02-21 13:10:06] [config] quiet: false
[2019-02-21 13:10:06] [config] quiet-translation: true
[2019-02-21 13:10:06] [config] relative-paths: false
[2019-02-21 13:10:06] [config] right-left: false
[2019-02-21 13:10:06] [config] save-freq: 5000
[2019-02-21 13:10:06] [config] seed: 1111
[2019-02-21 13:10:06] [config] shuffle-in-ram: false
[2019-02-21 13:10:06] [config] skip: false
[2019-02-21 13:10:06] [config] sqlite: ""
[2019-02-21 13:10:06] [config] sqlite-drop: false
[2019-02-21 13:10:06] [config] sync-sgd: true
[2019-02-21 13:10:06] [config] tempdir: /tmp
[2019-02-21 13:10:06] [config] tied-embeddings: false
[2019-02-21 13:10:06] [config] tied-embeddings-all: true
[2019-02-21 13:10:06] [config] tied-embeddings-src: false
[2019-02-21 13:10:06] [config] train-sets:
[2019-02-21 13:10:06] [config]   - corp/opensub.en-fr.docs.train.en.bpe.src_prev
[2019-02-21 13:10:06] [config]   - corp/opensub.en-fr.docs.train.en.bpe.src
[2019-02-21 13:10:06] [config]   - corp/opensub.en-fr.docs.train.fr.bpe
[2019-02-21 13:10:06] [config] transformer-aan-activation: swish
[2019-02-21 13:10:06] [config] transformer-aan-depth: 2
[2019-02-21 13:10:06] [config] transformer-aan-nogate: false
[2019-02-21 13:10:06] [config] transformer-decoder-autoreg: self-attention
[2019-02-21 13:10:06] [config] transformer-dim-aan: 2048
[2019-02-21 13:10:06] [config] transformer-dim-ffn: 2048
[2019-02-21 13:10:06] [config] transformer-dropout: 0.1
[2019-02-21 13:10:06] [config] transformer-dropout-attention: 0
[2019-02-21 13:10:06] [config] transformer-dropout-ffn: 0
[2019-02-21 13:10:06] [config] transformer-ffn-activation: swish
[2019-02-21 13:10:06] [config] transformer-ffn-depth: 2
[2019-02-21 13:10:06] [config] transformer-guided-alignment-layer: last
[2019-02-21 13:10:06] [config] transformer-heads: 8
[2019-02-21 13:10:06] [config] transformer-no-projection: false
[2019-02-21 13:10:06] [config] transformer-postprocess: dan
[2019-02-21 13:10:06] [config] transformer-postprocess-emb: d
[2019-02-21 13:10:06] [config] transformer-preprocess: ""
[2019-02-21 13:10:06] [config] transformer-tied-layers:
[2019-02-21 13:10:06] [config]   []
[2019-02-21 13:10:06] [config] type: transformer
[2019-02-21 13:10:06] [config] ulr: false
[2019-02-21 13:10:06] [config] ulr-dim-emb: 0
[2019-02-21 13:10:06] [config] ulr-dropout: 0
[2019-02-21 13:10:06] [config] ulr-keys-vectors: ""
[2019-02-21 13:10:06] [config] ulr-query-vectors: ""
[2019-02-21 13:10:06] [config] ulr-softmax-temperature: 1
[2019-02-21 13:10:06] [config] ulr-trainable-transformation: false
[2019-02-21 13:10:06] [config] valid-freq: 5000
[2019-02-21 13:10:06] [config] valid-log: model/valid_trans.newvocab.log
[2019-02-21 13:10:06] [config] valid-max-length: 1000
[2019-02-21 13:10:06] [config] valid-metrics:
[2019-02-21 13:10:06] [config]   - cross-entropy
[2019-02-21 13:10:06] [config]   - perplexity
[2019-02-21 13:10:06] [config]   - translation
[2019-02-21 13:10:06] [config] valid-mini-batch: 64
[2019-02-21 13:10:06] [config] valid-script-path: ./val.sh
[2019-02-21 13:10:06] [config] valid-sets:
[2019-02-21 13:10:06] [config]   - corp/opensub.en-fr.docs.dev.en.bpe.src_prev
[2019-02-21 13:10:06] [config]   - corp/opensub.en-fr.docs.dev.en.bpe.src
[2019-02-21 13:10:06] [config]   - corp/opensub.en-fr.docs.dev.fr.bpe
[2019-02-21 13:10:06] [config] valid-translation-output: data/valid.bpe.en.output
[2019-02-21 13:10:06] [config] vocabs:
[2019-02-21 13:10:06] [config]   - corp/vocab.encz.opensub.new.yml
[2019-02-21 13:10:06] [config]   - corp/vocab.encz.opensub.new.yml
[2019-02-21 13:10:06] [config]   - corp/vocab.encz.opensub.new.yml
[2019-02-21 13:10:06] [config] word-penalty: 0
[2019-02-21 13:10:06] [config] workspace: 9000
[2019-02-21 13:10:06] [config] Model is being created with Marian v1.7.3 3efcfdf 2018-12-05 21:03:05 -0800
[2019-02-21 13:10:06] Using synchronous training
[2019-02-21 13:10:06] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encz.opensub.new.yml
[2019-02-21 13:10:06] [data] Setting vocabulary size for input 0 to 30000
[2019-02-21 13:10:06] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encz.opensub.new.yml
[2019-02-21 13:10:06] [data] Setting vocabulary size for input 1 to 30000
[2019-02-21 13:10:06] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encz.opensub.new.yml
[2019-02-21 13:10:07] [data] Setting vocabulary size for input 2 to 30000
[2019-02-21 13:10:07] [batching] Collecting statistics for batch fitting with step size 10
[2019-02-21 13:10:07] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-02-21 13:10:07] [memory] Extending reserved space to 9088 MB (device gpu0)
[2019-02-21 13:10:08] [memory] Extending reserved space to 9088 MB (device gpu2)
[2019-02-21 13:10:08] [memory] Reserving 227 MB, device gpu0
[2019-02-21 13:10:08] [memory] Reserving 227 MB, device gpu0
[2019-02-21 13:10:18] [batching] Done
[2019-02-21 13:10:18] [memory] Extending reserved space to 9088 MB (device gpu0)
[2019-02-21 13:10:19] [memory] Extending reserved space to 9088 MB (device gpu2)
[2019-02-21 13:10:19] Training started
[2019-02-21 13:10:19] [data] Shuffling files
tcmalloc: large alloc 1073741824 bytes == 0xfa822000 @ 
tcmalloc: large alloc 2147483648 bytes == 0x7faf81ffc000 @ 
tcmalloc: large alloc 2147483648 bytes == 0x7faf01ffc000 @ 
tcmalloc: large alloc 2147483648 bytes == 0xfa822000 @ 
[2019-02-21 13:10:44] [data] Done reading 41736982 sentences
[2019-02-21 13:24:31] [data] Done shuffling 41736982 sentences to temp files
[2019-02-21 13:25:07] [memory] Reserving 227 MB, device gpu0
[2019-02-21 13:25:07] [memory] Reserving 227 MB, device gpu2
[2019-02-21 13:25:08] [memory] Reserving 113 MB, device gpu0
[2019-02-21 13:25:08] [memory] Reserving 113 MB, device gpu2
[2019-02-21 13:25:08] [memory] Reserving 227 MB, device gpu0
[2019-02-21 13:25:08] [memory] Reserving 227 MB, device gpu2
[2019-02-21 13:25:09] [memory] Reserving 113 MB, device gpu0
[2019-02-21 13:25:09] [memory] Reserving 113 MB, device gpu2
[2019-02-21 13:25:09] [memory] Reserving 227 MB, device gpu2
[2019-02-21 13:25:09] [memory] Reserving 227 MB, device gpu0
[2019-02-21 13:39:05] Ep. 1 : Up. 500 : Sen. 1,571,144 : Cost 92.43887329 : Time 1726.31s : 8556.52 words/s : L.r. 9.3750e-06
[2019-02-21 13:53:07] Ep. 1 : Up. 1000 : Sen. 3,092,248 : Cost 73.51071167 : Time 841.96s : 17270.84 words/s : L.r. 1.8750e-05
[2019-02-21 14:07:34] Ep. 1 : Up. 1500 : Sen. 4,667,029 : Cost 61.44990540 : Time 866.81s : 16850.14 words/s : L.r. 2.8125e-05
[2019-02-21 14:22:20] Ep. 1 : Up. 2000 : Sen. 6,213,029 : Cost 59.13465500 : Time 886.78s : 16595.76 words/s : L.r. 3.7500e-05
[2019-02-21 14:36:38] Ep. 1 : Up. 2500 : Sen. 7,772,027 : Cost 55.75465393 : Time 857.34s : 17289.64 words/s : L.r. 4.6875e-05
[2019-02-21 14:50:49] Ep. 1 : Up. 3000 : Sen. 9,267,576 : Cost 54.73373032 : Time 851.81s : 16803.10 words/s : L.r. 5.6250e-05
[2019-02-21 15:05:42] Ep. 1 : Up. 3500 : Sen. 10,838,666 : Cost 51.50181198 : Time 892.05s : 16391.67 words/s : L.r. 6.5625e-05
[2019-02-21 15:20:17] Ep. 1 : Up. 4000 : Sen. 12,338,064 : Cost 52.81728745 : Time 875.59s : 16504.46 words/s : L.r. 7.5000e-05
[2019-02-21 15:34:51] Ep. 1 : Up. 4500 : Sen. 13,919,956 : Cost 49.46228790 : Time 874.13s : 16902.07 words/s : L.r. 8.4375e-05
[2019-02-21 15:49:36] Ep. 1 : Up. 5000 : Sen. 15,480,439 : Cost 49.65651321 : Time 884.93s : 16542.51 words/s : L.r. 9.3750e-05
[2019-02-21 15:49:36] Saving model weights and runtime parameters to model/model.src1tgt0.dual.npz.orig.npz
[2019-02-21 15:49:40] Saving model weights and runtime parameters to model/model.src1tgt0.dual.iter5000.npz
[2019-02-21 15:49:45] Saving model weights and runtime parameters to model/model.src1tgt0.dual.npz
[2019-02-21 15:49:49] Saving Adam parameters to model/model.src1tgt0.dual.npz.optimizer.npz
[2019-02-21 15:50:01] [valid] Ep. 1 : Up. 5000 : cross-entropy : 61.017 : new best
[2019-02-21 15:50:03] [valid] Ep. 1 : Up. 5000 : perplexity : 113.767 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-02-21 15:51:39] [valid] Ep. 1 : Up. 5000 : translation : 0.01 : new best
[2019-02-21 16:06:14] Ep. 1 : Up. 5500 : Sen. 16,996,240 : Cost 50.04115295 : Time 997.97s : 14465.26 words/s : L.r. 1.0313e-04
[2019-02-21 16:20:32] Ep. 1 : Up. 6000 : Sen. 18,514,830 : Cost 49.53416061 : Time 858.02s : 16841.44 words/s : L.r. 1.1250e-04
[2019-02-21 16:35:15] Ep. 1 : Up. 6500 : Sen. 20,124,987 : Cost 48.17615509 : Time 883.33s : 17169.87 words/s : L.r. 1.2188e-04
[2019-02-21 16:50:23] Ep. 1 : Up. 7000 : Sen. 21,642,922 : Cost 48.27975845 : Time 907.58s : 15910.73 words/s : L.r. 1.3125e-04
[2019-02-21 17:05:02] Ep. 1 : Up. 7500 : Sen. 23,214,856 : Cost 47.46441650 : Time 878.76s : 16798.83 words/s : L.r. 1.4063e-04
[2019-02-21 17:19:19] Ep. 1 : Up. 8000 : Sen. 24,773,876 : Cost 47.04641724 : Time 857.17s : 16978.16 words/s : L.r. 1.5000e-04
[2019-02-21 17:33:35] Ep. 1 : Up. 8500 : Sen. 26,333,183 : Cost 47.68297195 : Time 855.62s : 17587.60 words/s : L.r. 1.5938e-04
[2019-02-21 17:47:42] Ep. 1 : Up. 9000 : Sen. 27,897,830 : Cost 46.31325912 : Time 847.32s : 17245.94 words/s : L.r. 1.6875e-04
[2019-02-21 18:01:59] Ep. 1 : Up. 9500 : Sen. 29,416,186 : Cost 46.84041595 : Time 856.93s : 16729.64 words/s : L.r. 1.7813e-04
[2019-02-21 18:16:28] Ep. 1 : Up. 10000 : Sen. 30,989,088 : Cost 46.66326904 : Time 869.35s : 17196.82 words/s : L.r. 1.8750e-04
[2019-02-21 18:16:28] Saving model weights and runtime parameters to model/model.src1tgt0.dual.npz.orig.npz
[2019-02-21 18:16:33] Saving model weights and runtime parameters to model/model.src1tgt0.dual.iter10000.npz
[2019-02-21 18:16:37] Saving model weights and runtime parameters to model/model.src1tgt0.dual.npz
[2019-02-21 18:16:42] Saving Adam parameters to model/model.src1tgt0.dual.npz.optimizer.npz
[2019-02-21 18:16:53] [valid] Ep. 1 : Up. 10000 : cross-entropy : 54.5907 : new best
[2019-02-21 18:16:56] [valid] Ep. 1 : Up. 10000 : perplexity : 69.1001 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-02-21 18:18:32] [valid] Ep. 1 : Up. 10000 : translation : 0.01 : stalled 1 times
[2019-02-21 18:32:35] Ep. 1 : Up. 10500 : Sen. 32,520,297 : Cost 46.06640625 : Time 966.65s : 14837.25 words/s : L.r. 1.9688e-04
[2019-02-21 18:46:54] Ep. 1 : Up. 11000 : Sen. 34,076,075 : Cost 45.94720459 : Time 859.56s : 17182.41 words/s : L.r. 2.0625e-04
[2019-02-21 19:01:31] Ep. 1 : Up. 11500 : Sen. 35,644,904 : Cost 45.84596634 : Time 876.30s : 16870.16 words/s : L.r. 2.1563e-04
[2019-02-21 19:15:58] Ep. 1 : Up. 12000 : Sen. 37,186,379 : Cost 45.81073761 : Time 867.33s : 16790.12 words/s : L.r. 2.2500e-04
[2019-02-21 19:30:46] Ep. 1 : Up. 12500 : Sen. 38,737,992 : Cost 46.00195694 : Time 888.39s : 16714.98 words/s : L.r. 2.3438e-04
[2019-02-21 19:45:27] Ep. 1 : Up. 13000 : Sen. 40,324,394 : Cost 44.98448181 : Time 880.16s : 16755.59 words/s : L.r. 2.4375e-04
[2019-02-21 19:58:37] Seen 41709169 samples
[2019-02-21 19:58:37] Starting epoch 2
[2019-02-21 19:58:37] [data] Shuffling files
tcmalloc: large alloc 2147483648 bytes == 0x7faf81ffc000 @ 
tcmalloc: large alloc 2147483648 bytes == 0x7fadd4000000 @ 
[2019-02-21 19:58:59] [data] Done reading 41736982 sentences
[2019-02-21 20:13:11] [data] Done shuffling 41736982 sentences to temp files
[2019-02-21 20:14:12] Ep. 2 : Up. 13500 : Sen. 51,825 : Cost 46.11419678 : Time 1725.86s : 8003.16 words/s : L.r. 2.5313e-04
[2019-02-21 20:28:14] Ep. 2 : Up. 14000 : Sen. 1,624,292 : Cost 44.52716446 : Time 841.43s : 17424.40 words/s : L.r. 2.6250e-04
[2019-02-21 20:43:03] Ep. 2 : Up. 14500 : Sen. 3,149,467 : Cost 46.13551712 : Time 888.76s : 16493.94 words/s : L.r. 2.7188e-04
[2019-02-21 20:57:20] Ep. 2 : Up. 15000 : Sen. 4,648,591 : Cost 45.44349289 : Time 856.97s : 16719.47 words/s : L.r. 2.8125e-04
[2019-02-21 20:57:20] Saving model weights and runtime parameters to model/model.src1tgt0.dual.npz.orig.npz
[2019-02-21 20:57:24] Saving model weights and runtime parameters to model/model.src1tgt0.dual.iter15000.npz
[2019-02-21 20:57:29] Saving model weights and runtime parameters to model/model.src1tgt0.dual.npz
[2019-02-21 20:57:33] Saving Adam parameters to model/model.src1tgt0.dual.npz.optimizer.npz
[2019-02-21 20:57:45] [valid] Ep. 2 : Up. 15000 : cross-entropy : 52.0402 : new best
[2019-02-21 20:57:47] [valid] Ep. 2 : Up. 15000 : perplexity : 56.6939 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-02-21 20:59:27] [valid] Ep. 2 : Up. 15000 : translation : 0.03 : new best
[2019-02-21 21:13:41] Ep. 2 : Up. 15500 : Sen. 6,257,889 : Cost 44.05604553 : Time 980.93s : 15172.21 words/s : L.r. 2.9063e-04
[2019-02-21 21:28:11] Ep. 2 : Up. 16000 : Sen. 7,769,330 : Cost 45.52916718 : Time 870.90s : 16596.54 words/s : L.r. 3.0000e-04
[2019-02-21 21:42:54] Ep. 2 : Up. 16500 : Sen. 9,343,109 : Cost 44.43368149 : Time 882.28s : 16756.61 words/s : L.r. 2.9542e-04
[2019-02-21 21:57:36] Ep. 2 : Up. 17000 : Sen. 10,890,676 : Cost 45.40876770 : Time 882.45s : 16654.42 words/s : L.r. 2.9104e-04
[2019-02-21 22:12:03] Ep. 2 : Up. 17500 : Sen. 12,430,127 : Cost 44.75397491 : Time 867.22s : 16799.03 words/s : L.r. 2.8685e-04
[2019-02-21 22:27:14] Ep. 2 : Up. 18000 : Sen. 13,997,936 : Cost 44.34641647 : Time 910.94s : 16230.76 words/s : L.r. 2.8284e-04
[2019-02-21 22:42:51] Ep. 2 : Up. 18500 : Sen. 15,528,126 : Cost 44.93692398 : Time 936.17s : 15586.86 words/s : L.r. 2.7899e-04
[2019-02-21 22:58:11] Ep. 2 : Up. 19000 : Sen. 17,096,634 : Cost 43.81260681 : Time 920.78s : 15892.08 words/s : L.r. 2.7530e-04
[2019-02-21 23:13:01] Ep. 2 : Up. 19500 : Sen. 18,658,682 : Cost 43.78779984 : Time 889.63s : 16384.23 words/s : L.r. 2.7175e-04
[2019-02-21 23:27:08] Ep. 2 : Up. 20000 : Sen. 20,163,257 : Cost 45.03439331 : Time 847.30s : 17027.44 words/s : L.r. 2.6833e-04
[2019-02-21 23:27:08] Saving model weights and runtime parameters to model/model.src1tgt0.dual.npz.orig.npz
[2019-02-21 23:27:12] Saving model weights and runtime parameters to model/model.src1tgt0.dual.iter20000.npz
[2019-02-21 23:27:17] Saving model weights and runtime parameters to model/model.src1tgt0.dual.npz
[2019-02-21 23:27:21] Saving Adam parameters to model/model.src1tgt0.dual.npz.optimizer.npz
[2019-02-21 23:27:33] [valid] Ep. 2 : Up. 20000 : cross-entropy : 50.7029 : new best
[2019-02-21 23:27:35] [valid] Ep. 2 : Up. 20000 : perplexity : 51.1066 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-02-21 23:29:15] [valid] Ep. 2 : Up. 20000 : translation : 0.03 : stalled 1 times
[2019-02-21 23:43:26] Ep. 2 : Up. 20500 : Sen. 21,702,427 : Cost 44.68958664 : Time 977.98s : 14963.08 words/s : L.r. 2.6504e-04
[2019-02-21 23:57:40] Ep. 2 : Up. 21000 : Sen. 23,269,293 : Cost 43.66757584 : Time 853.71s : 17153.86 words/s : L.r. 2.6186e-04
[2019-02-22 00:11:55] Ep. 2 : Up. 21500 : Sen. 24,827,169 : Cost 44.27919006 : Time 855.51s : 17318.52 words/s : L.r. 2.5880e-04
[2019-02-22 00:26:00] Ep. 2 : Up. 22000 : Sen. 26,358,141 : Cost 43.83670044 : Time 844.26s : 17061.48 words/s : L.r. 2.5584e-04
[2019-02-22 00:40:21] Ep. 2 : Up. 22500 : Sen. 27,932,029 : Cost 44.19284058 : Time 861.37s : 17297.77 words/s : L.r. 2.5298e-04
[2019-02-22 00:54:21] Ep. 2 : Up. 23000 : Sen. 29,414,667 : Cost 45.42181015 : Time 840.29s : 17098.40 words/s : L.r. 2.5022e-04
[2019-02-22 01:08:29] Ep. 2 : Up. 23500 : Sen. 30,997,936 : Cost 42.95925140 : Time 847.94s : 17380.41 words/s : L.r. 2.4754e-04
[2019-02-22 01:22:33] Ep. 2 : Up. 24000 : Sen. 32,541,819 : Cost 44.37719727 : Time 843.44s : 17474.07 words/s : L.r. 2.4495e-04
[2019-02-22 01:36:38] Ep. 2 : Up. 24500 : Sen. 34,084,522 : Cost 43.59914398 : Time 844.88s : 17127.39 words/s : L.r. 2.4244e-04
[2019-02-22 01:50:48] Ep. 2 : Up. 25000 : Sen. 35,635,514 : Cost 44.28374100 : Time 849.95s : 17413.79 words/s : L.r. 2.4000e-04
[2019-02-22 01:50:48] Saving model weights and runtime parameters to model/model.src1tgt0.dual.npz.orig.npz
[2019-02-22 01:50:52] Saving model weights and runtime parameters to model/model.src1tgt0.dual.iter25000.npz
[2019-02-22 01:50:56] Saving model weights and runtime parameters to model/model.src1tgt0.dual.npz
[2019-02-22 01:51:00] Saving Adam parameters to model/model.src1tgt0.dual.npz.optimizer.npz
[2019-02-22 01:51:12] [valid] Ep. 2 : Up. 25000 : cross-entropy : 49.7601 : new best
[2019-02-22 01:51:14] [valid] Ep. 2 : Up. 25000 : perplexity : 47.5013 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-02-22 01:52:52] [valid] Ep. 2 : Up. 25000 : translation : 0.03 : stalled 2 times
[2019-02-22 02:06:53] Ep. 2 : Up. 25500 : Sen. 37,194,201 : Cost 43.28166962 : Time 965.64s : 15069.91 words/s : L.r. 2.3764e-04
[2019-02-22 02:20:53] Ep. 2 : Up. 26000 : Sen. 38,728,856 : Cost 43.44750595 : Time 839.69s : 17278.55 words/s : L.r. 2.3534e-04
[2019-02-22 02:35:06] Ep. 2 : Up. 26500 : Sen. 40,276,081 : Cost 44.73744583 : Time 853.39s : 17336.81 words/s : L.r. 2.3311e-04
[2019-02-22 02:48:09] Seen 41709169 samples
[2019-02-22 02:48:09] Starting epoch 3
[2019-02-22 02:48:09] [data] Shuffling files
[2019-02-22 02:48:33] [data] Done reading 41736982 sentences
[2019-02-22 03:02:52] [data] Done shuffling 41736982 sentences to temp files
[2019-02-22 03:03:50] Ep. 3 : Up. 27000 : Sen. 45,545 : Cost 42.85201263 : Time 1723.85s : 8029.34 words/s : L.r. 2.3094e-04
[2019-02-22 03:17:34] Ep. 3 : Up. 27500 : Sen. 1,580,822 : Cost 43.95984268 : Time 823.80s : 17718.75 words/s : L.r. 2.2883e-04
[2019-02-22 03:31:30] Ep. 3 : Up. 28000 : Sen. 3,121,670 : Cost 43.17755127 : Time 836.42s : 17248.13 words/s : L.r. 2.2678e-04
[2019-02-22 03:45:26] Ep. 3 : Up. 28500 : Sen. 4,689,089 : Cost 43.15990067 : Time 835.80s : 17684.97 words/s : L.r. 2.2478e-04
[2019-02-22 03:59:23] Ep. 3 : Up. 29000 : Sen. 6,199,291 : Cost 44.72739792 : Time 837.12s : 17364.58 words/s : L.r. 2.2283e-04
[2019-02-22 04:13:38] Ep. 3 : Up. 29500 : Sen. 7,795,691 : Cost 42.19855118 : Time 855.21s : 17270.66 words/s : L.r. 2.2094e-04
[2019-02-22 04:27:32] Ep. 3 : Up. 30000 : Sen. 9,308,283 : Cost 44.14043045 : Time 833.56s : 17330.71 words/s : L.r. 2.1909e-04
[2019-02-22 04:27:32] Saving model weights and runtime parameters to model/model.src1tgt0.dual.npz.orig.npz
[2019-02-22 04:27:36] Saving model weights and runtime parameters to model/model.src1tgt0.dual.iter30000.npz
[2019-02-22 04:27:40] Saving model weights and runtime parameters to model/model.src1tgt0.dual.npz
[2019-02-22 04:27:45] Saving Adam parameters to model/model.src1tgt0.dual.npz.optimizer.npz
[2019-02-22 04:27:57] [valid] Ep. 3 : Up. 30000 : cross-entropy : 49.1861 : new best
[2019-02-22 04:27:59] [valid] Ep. 3 : Up. 30000 : perplexity : 45.4323 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-02-22 04:29:41] [valid] Ep. 3 : Up. 30000 : translation : 0.03 : stalled 3 times
[2019-02-22 04:43:38] Ep. 3 : Up. 30500 : Sen. 10,833,614 : Cost 44.08695984 : Time 966.36s : 15081.86 words/s : L.r. 2.1729e-04
[2019-02-22 04:57:42] Ep. 3 : Up. 31000 : Sen. 12,404,398 : Cost 43.01543045 : Time 843.12s : 17495.54 words/s : L.r. 2.1553e-04
[2019-02-22 05:11:37] Ep. 3 : Up. 31500 : Sen. 13,960,517 : Cost 43.22834015 : Time 835.74s : 17595.50 words/s : L.r. 2.1381e-04
[2019-02-22 05:25:39] Ep. 3 : Up. 32000 : Sen. 15,514,960 : Cost 43.02706146 : Time 842.15s : 17326.67 words/s : L.r. 2.1213e-04
[2019-02-22 05:39:33] Ep. 3 : Up. 32500 : Sen. 17,054,157 : Cost 43.72746658 : Time 833.89s : 17564.04 words/s : L.r. 2.1049e-04
[2019-02-22 05:53:23] Ep. 3 : Up. 33000 : Sen. 18,613,527 : Cost 42.63156128 : Time 830.05s : 17465.33 words/s : L.r. 2.0889e-04
[2019-02-22 06:07:26] Ep. 3 : Up. 33500 : Sen. 20,153,641 : Cost 43.88086700 : Time 842.35s : 17519.87 words/s : L.r. 2.0733e-04
[2019-02-22 06:21:23] Ep. 3 : Up. 34000 : Sen. 21,740,584 : Cost 42.45062256 : Time 837.22s : 17690.51 words/s : L.r. 2.0580e-04
[2019-02-22 06:35:13] Ep. 3 : Up. 34500 : Sen. 23,225,905 : Cost 44.73100281 : Time 829.83s : 17342.74 words/s : L.r. 2.0430e-04
[2019-02-22 06:49:31] Ep. 3 : Up. 35000 : Sen. 24,800,138 : Cost 42.83998489 : Time 858.23s : 17200.91 words/s : L.r. 2.0284e-04
[2019-02-22 06:49:31] Saving model weights and runtime parameters to model/model.src1tgt0.dual.npz.orig.npz
[2019-02-22 06:49:35] Saving model weights and runtime parameters to model/model.src1tgt0.dual.iter35000.npz
[2019-02-22 06:49:40] Saving model weights and runtime parameters to model/model.src1tgt0.dual.npz
[2019-02-22 06:49:44] Saving Adam parameters to model/model.src1tgt0.dual.npz.optimizer.npz
[2019-02-22 06:49:56] [valid] Ep. 3 : Up. 35000 : cross-entropy : 48.6403 : new best
[2019-02-22 06:49:58] [valid] Ep. 3 : Up. 35000 : perplexity : 43.5487 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-02-22 06:51:42] [valid] Ep. 3 : Up. 35000 : translation : 0.03 : stalled 4 times
[2019-02-22 07:05:54] Ep. 3 : Up. 35500 : Sen. 26,369,970 : Cost 43.18312454 : Time 982.93s : 15141.39 words/s : L.r. 2.0140e-04
[2019-02-22 07:19:38] Ep. 3 : Up. 36000 : Sen. 27,900,108 : Cost 43.19992065 : Time 824.34s : 17528.97 words/s : L.r. 2.0000e-04
[2019-02-22 07:33:28] Ep. 3 : Up. 36500 : Sen. 29,430,754 : Cost 43.38626862 : Time 830.14s : 17489.36 words/s : L.r. 1.9863e-04
[2019-02-22 07:47:37] Ep. 3 : Up. 37000 : Sen. 31,002,223 : Cost 43.03379822 : Time 848.92s : 17468.33 words/s : L.r. 1.9728e-04
[2019-02-22 08:01:27] Ep. 3 : Up. 37500 : Sen. 32,535,629 : Cost 43.53541946 : Time 830.03s : 17645.54 words/s : L.r. 1.9596e-04
[2019-02-22 08:15:20] Ep. 3 : Up. 38000 : Sen. 34,103,633 : Cost 42.25173950 : Time 832.90s : 17474.46 words/s : L.r. 1.9467e-04
[2019-02-22 08:29:13] Ep. 3 : Up. 38500 : Sen. 35,622,067 : Cost 44.07680893 : Time 832.36s : 17646.10 words/s : L.r. 1.9340e-04
[2019-02-22 08:43:18] Ep. 3 : Up. 39000 : Sen. 37,193,276 : Cost 42.97538376 : Time 845.60s : 17545.39 words/s : L.r. 1.9215e-04
[2019-02-22 08:57:14] Ep. 3 : Up. 39500 : Sen. 38,734,065 : Cost 42.42746735 : Time 836.16s : 17111.17 words/s : L.r. 1.9093e-04
[2019-02-22 09:11:21] Ep. 3 : Up. 40000 : Sen. 40,325,180 : Cost 42.61648941 : Time 846.85s : 17541.77 words/s : L.r. 1.8974e-04
[2019-02-22 09:11:21] Saving model weights and runtime parameters to model/model.src1tgt0.dual.npz.orig.npz
[2019-02-22 09:11:26] Saving model weights and runtime parameters to model/model.src1tgt0.dual.iter40000.npz
[2019-02-22 09:11:30] Saving model weights and runtime parameters to model/model.src1tgt0.dual.npz
[2019-02-22 09:11:35] Saving Adam parameters to model/model.src1tgt0.dual.npz.optimizer.npz
[2019-02-22 09:11:46] [valid] Ep. 3 : Up. 40000 : cross-entropy : 48.3294 : new best
[2019-02-22 09:11:48] [valid] Ep. 3 : Up. 40000 : perplexity : 42.5107 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-02-22 09:13:40] [valid] Ep. 3 : Up. 40000 : translation : 0.03 : stalled 5 times
[2019-02-22 09:26:50] Seen 41709169 samples
[2019-02-22 09:26:50] Starting epoch 4
[2019-02-22 09:26:50] [data] Shuffling files
[2019-02-22 09:27:14] [data] Done reading 41736982 sentences
[2019-02-22 09:40:55] [data] Done shuffling 41736982 sentences to temp files
[2019-02-22 09:41:56] Ep. 4 : Up. 40500 : Sen. 50,765 : Cost 43.81567001 : Time 1834.61s : 7538.52 words/s : L.r. 1.8856e-04
[2019-02-22 09:55:58] Ep. 4 : Up. 41000 : Sen. 1,625,464 : Cost 43.03092194 : Time 842.40s : 17711.40 words/s : L.r. 1.8741e-04
[2019-02-22 10:09:53] Ep. 4 : Up. 41500 : Sen. 3,170,588 : Cost 42.67837143 : Time 835.25s : 17351.80 words/s : L.r. 1.8628e-04
[2019-02-22 10:24:04] Ep. 4 : Up. 42000 : Sen. 4,683,465 : Cost 43.33500290 : Time 850.42s : 16967.90 words/s : L.r. 1.8516e-04
[2019-02-22 10:38:11] Ep. 4 : Up. 42500 : Sen. 6,237,613 : Cost 42.97804260 : Time 847.58s : 17457.64 words/s : L.r. 1.8407e-04
[2019-02-22 10:52:17] Ep. 4 : Up. 43000 : Sen. 7,772,056 : Cost 42.69111252 : Time 845.34s : 17032.69 words/s : L.r. 1.8300e-04
[2019-02-22 11:06:46] Ep. 4 : Up. 43500 : Sen. 9,335,685 : Cost 43.02960968 : Time 869.39s : 17061.71 words/s : L.r. 1.8194e-04
[2019-02-22 11:21:00] Ep. 4 : Up. 44000 : Sen. 10,898,178 : Cost 42.53290939 : Time 853.89s : 17143.03 words/s : L.r. 1.8091e-04
[2019-02-22 11:35:05] Ep. 4 : Up. 44500 : Sen. 12,448,084 : Cost 42.81712341 : Time 844.64s : 17339.66 words/s : L.r. 1.7989e-04
[2019-02-22 11:49:22] Ep. 4 : Up. 45000 : Sen. 13,994,480 : Cost 42.99358368 : Time 856.85s : 17144.03 words/s : L.r. 1.7889e-04
[2019-02-22 11:49:22] Saving model weights and runtime parameters to model/model.src1tgt0.dual.npz.orig.npz
[2019-02-22 11:49:26] Saving model weights and runtime parameters to model/model.src1tgt0.dual.iter45000.npz
[2019-02-22 11:49:30] Saving model weights and runtime parameters to model/model.src1tgt0.dual.npz
[2019-02-22 11:49:36] Saving Adam parameters to model/model.src1tgt0.dual.npz.optimizer.npz
[2019-02-22 11:49:47] [valid] Ep. 4 : Up. 45000 : cross-entropy : 48.0939 : new best
[2019-02-22 11:49:50] [valid] Ep. 4 : Up. 45000 : perplexity : 41.7411 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-02-22 11:51:42] [valid] Ep. 4 : Up. 45000 : translation : 0.03 : stalled 6 times
[2019-02-22 12:05:49] Ep. 4 : Up. 45500 : Sen. 15,559,596 : Cost 42.34814453 : Time 987.58s : 14893.25 words/s : L.r. 1.7790e-04
[2019-02-22 12:20:11] Ep. 4 : Up. 46000 : Sen. 17,117,508 : Cost 42.95057297 : Time 861.69s : 17100.07 words/s : L.r. 1.7693e-04
[2019-02-22 12:34:21] Ep. 4 : Up. 46500 : Sen. 18,609,137 : Cost 43.37623596 : Time 849.79s : 16839.22 words/s : L.r. 1.7598e-04
[2019-02-22 12:48:40] Ep. 4 : Up. 47000 : Sen. 20,202,122 : Cost 42.20318985 : Time 859.02s : 17197.24 words/s : L.r. 1.7504e-04
[2019-02-22 13:02:41] Ep. 4 : Up. 47500 : Sen. 21,757,258 : Cost 42.43560028 : Time 840.93s : 17325.57 words/s : L.r. 1.7411e-04
[2019-02-22 13:16:43] Ep. 4 : Up. 48000 : Sen. 23,309,922 : Cost 43.04725647 : Time 841.96s : 17526.49 words/s : L.r. 1.7321e-04
[2019-02-22 13:30:34] Ep. 4 : Up. 48500 : Sen. 24,855,951 : Cost 43.02154160 : Time 831.60s : 17814.10 words/s : L.r. 1.7231e-04
[2019-02-22 13:44:39] Ep. 4 : Up. 49000 : Sen. 26,446,582 : Cost 42.58493805 : Time 845.06s : 17740.93 words/s : L.r. 1.7143e-04
[2019-02-22 13:58:21] Ep. 4 : Up. 49500 : Sen. 27,960,951 : Cost 42.98488617 : Time 821.39s : 17451.88 words/s : L.r. 1.7056e-04
train_trans_dual.sh: line 27: 69892 Terminated              $marian_home/marian --model model/model.src1tgt0.dual.npz --type transformer --train-sets corp/opensub.en-fr.docs.train.en.bpe.src_prev corp/opensub.en-fr.docs.train.en.bpe.src corp/opensub.en-fr.docs.train.fr.bpe --max-length 55 --dim-vocabs 30000 30000 --vocabs corp/vocab.encz.opensub.new.yml corp/vocab.encz.opensub.new.yml corp/vocab.encz.opensub.new.yml --mini-batch-fit -w 9000 --mini-batch 1000 --maxi-batch 1000 --early-stopping 10 --valid-freq 5000 --save-freq 5000 --disp-freq 500 --valid-metrics cross-entropy perplexity translation --valid-sets corp/opensub.en-fr.docs.dev.en.bpe.src_prev corp/opensub.en-fr.docs.dev.en.bpe.src corp/opensub.en-fr.docs.dev.fr.bpe --valid-script-path ./val.sh --valid-translation-output data/valid.bpe.en.output --quiet-translation --valid-mini-batch 64 --beam-size 6 --normalize 0.6 --log model/train_trans.newvocab.log --valid-log model/valid_trans.newvocab.log --enc-depth 6 --dec-depth 6 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --optimizer-delay 8 --devices 0 2 --sync-sgd --seed 1111 --exponential-smoothing --no-restore-corpus
