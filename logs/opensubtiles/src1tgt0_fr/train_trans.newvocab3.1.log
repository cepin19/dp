[2019-02-19 15:47:37] [marian] Marian v1.7.6 9cc5b17 2018-12-14 15:11:34 -0800
[2019-02-19 15:47:37] [marian] Running on spider3.lingea.cz as process 20397 with command line:
[2019-02-19 15:47:37] [marian] /home/big_maggie/usr/marian_spider/marian_1.7.6/marian-dev/build/marian --model model/model.src1tgt0.newvocab.3.npz --type transformer --train-sets corp/opensub.en-fr.docs.train.en.bpe corp/opensub.en-fr.docs.train.fr.bpe --max-length 110 --dim-vocabs 30000 30000 --vocabs corp/vocab.encz.opensub.new.yml corp/vocab.encz.opensub.new.yml --mini-batch-fit -w 10000 --mini-batch 1000 --maxi-batch 1000 --early-stopping 10 --valid-freq 5000 --save-freq 5000 --disp-freq 500 --valid-metrics cross-entropy perplexity translation --valid-sets corp/opensub.en-fr.docs.dev.en.bpe corp/opensub.en-fr.docs.dev.fr.bpe --valid-script-path ./val.sh --valid-translation-output data/valid.bpe.en.output --quiet-translation --valid-mini-batch 64 --beam-size 6 --normalize 0.6 --log model/train_trans.newvocab.log --valid-log model/valid_trans.newvocab.log --enc-depth 6 --dec-depth 6 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --optimizer-delay 8 --devices 0 1 --sync-sgd --seed 1111 --exponential-smoothing --no-nccl --no-restore-corpus
[2019-02-19 15:47:39] [config] after-batches: 0
[2019-02-19 15:47:39] [config] after-epochs: 0
[2019-02-19 15:47:39] [config] allow-unk: false
[2019-02-19 15:47:39] [config] beam-size: 6
[2019-02-19 15:47:39] [config] best-deep: false
[2019-02-19 15:47:39] [config] clip-gemm: 0
[2019-02-19 15:47:39] [config] clip-norm: 5
[2019-02-19 15:47:39] [config] cost-type: ce-mean
[2019-02-19 15:47:39] [config] cpu-threads: 0
[2019-02-19 15:47:39] [config] data-weighting-type: sentence
[2019-02-19 15:47:39] [config] dec-cell: gru
[2019-02-19 15:47:39] [config] dec-cell-base-depth: 2
[2019-02-19 15:47:39] [config] dec-cell-high-depth: 1
[2019-02-19 15:47:39] [config] dec-depth: 6
[2019-02-19 15:47:39] [config] devices:
[2019-02-19 15:47:39] [config]   - 0
[2019-02-19 15:47:39] [config]   - 1
[2019-02-19 15:47:39] [config] dim-emb: 512
[2019-02-19 15:47:39] [config] dim-rnn: 1024
[2019-02-19 15:47:39] [config] dim-vocabs:
[2019-02-19 15:47:39] [config]   - 30000
[2019-02-19 15:47:39] [config]   - 30000
[2019-02-19 15:47:39] [config] disp-first: 0
[2019-02-19 15:47:39] [config] disp-freq: 500
[2019-02-19 15:47:39] [config] disp-label-counts: false
[2019-02-19 15:47:39] [config] dropout-rnn: 0
[2019-02-19 15:47:39] [config] dropout-src: 0
[2019-02-19 15:47:39] [config] dropout-trg: 0
[2019-02-19 15:47:39] [config] early-stopping: 10
[2019-02-19 15:47:39] [config] embedding-fix-src: false
[2019-02-19 15:47:39] [config] embedding-fix-trg: false
[2019-02-19 15:47:39] [config] embedding-normalization: false
[2019-02-19 15:47:39] [config] enc-cell: gru
[2019-02-19 15:47:39] [config] enc-cell-depth: 1
[2019-02-19 15:47:39] [config] enc-depth: 6
[2019-02-19 15:47:39] [config] enc-type: bidirectional
[2019-02-19 15:47:39] [config] exponential-smoothing: 0.0001
[2019-02-19 15:47:39] [config] grad-dropping-momentum: 0
[2019-02-19 15:47:39] [config] grad-dropping-rate: 0
[2019-02-19 15:47:39] [config] grad-dropping-warmup: 100
[2019-02-19 15:47:39] [config] guided-alignment: none
[2019-02-19 15:47:39] [config] guided-alignment-cost: mse
[2019-02-19 15:47:39] [config] guided-alignment-weight: 0.1
[2019-02-19 15:47:39] [config] ignore-model-config: false
[2019-02-19 15:47:39] [config] interpolate-env-vars: false
[2019-02-19 15:47:39] [config] keep-best: false
[2019-02-19 15:47:39] [config] label-smoothing: 0.1
[2019-02-19 15:47:39] [config] layer-normalization: false
[2019-02-19 15:47:39] [config] learn-rate: 0.0003
[2019-02-19 15:47:39] [config] log: model/train_trans.newvocab.log
[2019-02-19 15:47:39] [config] log-level: info
[2019-02-19 15:47:39] [config] lr-decay: 0
[2019-02-19 15:47:39] [config] lr-decay-freq: 50000
[2019-02-19 15:47:39] [config] lr-decay-inv-sqrt: 16000
[2019-02-19 15:47:39] [config] lr-decay-repeat-warmup: false
[2019-02-19 15:47:39] [config] lr-decay-reset-optimizer: false
[2019-02-19 15:47:39] [config] lr-decay-start:
[2019-02-19 15:47:39] [config]   - 10
[2019-02-19 15:47:39] [config]   - 1
[2019-02-19 15:47:39] [config] lr-decay-strategy: epoch+stalled
[2019-02-19 15:47:39] [config] lr-report: true
[2019-02-19 15:47:39] [config] lr-warmup: 16000
[2019-02-19 15:47:39] [config] lr-warmup-at-reload: false
[2019-02-19 15:47:39] [config] lr-warmup-cycle: false
[2019-02-19 15:47:39] [config] lr-warmup-start-rate: 0
[2019-02-19 15:47:39] [config] max-length: 110
[2019-02-19 15:47:39] [config] max-length-crop: false
[2019-02-19 15:47:39] [config] max-length-factor: 3
[2019-02-19 15:47:39] [config] maxi-batch: 1000
[2019-02-19 15:47:39] [config] maxi-batch-sort: trg
[2019-02-19 15:47:39] [config] mini-batch: 1000
[2019-02-19 15:47:39] [config] mini-batch-fit: true
[2019-02-19 15:47:39] [config] mini-batch-fit-step: 10
[2019-02-19 15:47:39] [config] mini-batch-words: 0
[2019-02-19 15:47:39] [config] model: model/model.src1tgt0.newvocab.3.npz
[2019-02-19 15:47:39] [config] multi-node: false
[2019-02-19 15:47:39] [config] multi-node-overlap: true
[2019-02-19 15:47:39] [config] n-best: false
[2019-02-19 15:47:39] [config] no-nccl: true
[2019-02-19 15:47:39] [config] no-reload: false
[2019-02-19 15:47:39] [config] no-restore-corpus: true
[2019-02-19 15:47:39] [config] no-shuffle: false
[2019-02-19 15:47:39] [config] normalize: 0.6
[2019-02-19 15:47:39] [config] optimizer: adam
[2019-02-19 15:47:39] [config] optimizer-delay: 8
[2019-02-19 15:47:39] [config] optimizer-params:
[2019-02-19 15:47:39] [config]   - 0.9
[2019-02-19 15:47:39] [config]   - 0.98
[2019-02-19 15:47:39] [config]   - 1e-09
[2019-02-19 15:47:39] [config] overwrite: false
[2019-02-19 15:47:39] [config] quiet: false
[2019-02-19 15:47:39] [config] quiet-translation: true
[2019-02-19 15:47:39] [config] relative-paths: false
[2019-02-19 15:47:39] [config] right-left: false
[2019-02-19 15:47:39] [config] save-freq: 5000
[2019-02-19 15:47:39] [config] seed: 1111
[2019-02-19 15:47:39] [config] sentencepiece-alphas:
[2019-02-19 15:47:39] [config]   []
[2019-02-19 15:47:39] [config] sentencepiece-max-lines: 10000000
[2019-02-19 15:47:39] [config] sentencepiece-options: ""
[2019-02-19 15:47:39] [config] shuffle-in-ram: false
[2019-02-19 15:47:39] [config] skip: false
[2019-02-19 15:47:39] [config] sqlite: ""
[2019-02-19 15:47:39] [config] sqlite-drop: false
[2019-02-19 15:47:39] [config] sync-sgd: true
[2019-02-19 15:47:39] [config] tempdir: /tmp
[2019-02-19 15:47:39] [config] tied-embeddings: false
[2019-02-19 15:47:39] [config] tied-embeddings-all: true
[2019-02-19 15:47:39] [config] tied-embeddings-src: false
[2019-02-19 15:47:39] [config] train-sets:
[2019-02-19 15:47:39] [config]   - corp/opensub.en-fr.docs.train.en.bpe
[2019-02-19 15:47:39] [config]   - corp/opensub.en-fr.docs.train.fr.bpe
[2019-02-19 15:47:39] [config] transformer-aan-activation: swish
[2019-02-19 15:47:39] [config] transformer-aan-depth: 2
[2019-02-19 15:47:39] [config] transformer-aan-nogate: false
[2019-02-19 15:47:39] [config] transformer-decoder-autoreg: self-attention
[2019-02-19 15:47:39] [config] transformer-dim-aan: 2048
[2019-02-19 15:47:39] [config] transformer-dim-ffn: 2048
[2019-02-19 15:47:39] [config] transformer-dropout: 0.1
[2019-02-19 15:47:39] [config] transformer-dropout-attention: 0
[2019-02-19 15:47:39] [config] transformer-dropout-ffn: 0
[2019-02-19 15:47:39] [config] transformer-ffn-activation: swish
[2019-02-19 15:47:39] [config] transformer-ffn-depth: 2
[2019-02-19 15:47:39] [config] transformer-guided-alignment-layer: last
[2019-02-19 15:47:39] [config] transformer-heads: 8
[2019-02-19 15:47:39] [config] transformer-no-projection: false
[2019-02-19 15:47:39] [config] transformer-postprocess: dan
[2019-02-19 15:47:39] [config] transformer-postprocess-emb: d
[2019-02-19 15:47:39] [config] transformer-preprocess: ""
[2019-02-19 15:47:39] [config] transformer-tied-layers:
[2019-02-19 15:47:39] [config]   []
[2019-02-19 15:47:39] [config] type: transformer
[2019-02-19 15:47:39] [config] ulr: false
[2019-02-19 15:47:39] [config] ulr-dim-emb: 0
[2019-02-19 15:47:39] [config] ulr-dropout: 0
[2019-02-19 15:47:39] [config] ulr-keys-vectors: ""
[2019-02-19 15:47:39] [config] ulr-query-vectors: ""
[2019-02-19 15:47:39] [config] ulr-softmax-temperature: 1
[2019-02-19 15:47:39] [config] ulr-trainable-transformation: false
[2019-02-19 15:47:39] [config] valid-freq: 5000
[2019-02-19 15:47:39] [config] valid-log: model/valid_trans.newvocab.log
[2019-02-19 15:47:39] [config] valid-max-length: 1000
[2019-02-19 15:47:39] [config] valid-metrics:
[2019-02-19 15:47:39] [config]   - cross-entropy
[2019-02-19 15:47:39] [config]   - perplexity
[2019-02-19 15:47:39] [config]   - translation
[2019-02-19 15:47:39] [config] valid-mini-batch: 64
[2019-02-19 15:47:39] [config] valid-script-path: ./val.sh
[2019-02-19 15:47:39] [config] valid-sets:
[2019-02-19 15:47:39] [config]   - corp/opensub.en-fr.docs.dev.en.bpe
[2019-02-19 15:47:39] [config]   - corp/opensub.en-fr.docs.dev.fr.bpe
[2019-02-19 15:47:39] [config] valid-translation-output: data/valid.bpe.en.output
[2019-02-19 15:47:39] [config] version: v1.7.5 4478901 2018-12-10 07:49:46 -0800
[2019-02-19 15:47:39] [config] vocabs:
[2019-02-19 15:47:39] [config]   - corp/vocab.encz.opensub.new.yml
[2019-02-19 15:47:39] [config]   - corp/vocab.encz.opensub.new.yml
[2019-02-19 15:47:39] [config] word-penalty: 0
[2019-02-19 15:47:39] [config] workspace: 10000
[2019-02-19 15:47:39] [config] Loaded model has been created with Marian v1.7.5 4478901 2018-12-10 07:49:46 -0800, will be overwritten with current version v1.7.6 9cc5b17 2018-12-14 15:11:34 -0800 at saving
[2019-02-19 15:47:39] Using synchronous training
[2019-02-19 15:47:39] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encz.opensub.new.yml
[2019-02-19 15:47:39] [data] Setting vocabulary size for input 0 to 30000
[2019-02-19 15:47:39] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encz.opensub.new.yml
[2019-02-19 15:47:40] [data] Setting vocabulary size for input 1 to 30000
[2019-02-19 15:47:40] [batching] Collecting statistics for batch fitting with step size 10
[2019-02-19 15:47:40] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-02-19 15:47:43] [memory] Extending reserved space to 10112 MB (device gpu0)
[2019-02-19 15:47:44] [memory] Extending reserved space to 10112 MB (device gpu1)
[2019-02-19 15:47:44] [comm] NCCL communicator overridden
[2019-02-19 15:47:44] [memory] Reserving 227 MB, device gpu0
[2019-02-19 15:47:45] [memory] Reserving 227 MB, device gpu0
[2019-02-19 15:48:03] [batching] Done
[2019-02-19 15:48:03] [memory] Extending reserved space to 10112 MB (device gpu0)
[2019-02-19 15:48:03] [memory] Extending reserved space to 10112 MB (device gpu1)
[2019-02-19 15:48:03] [comm] NCCL communicator overridden
[2019-02-19 15:48:04] Loading model from model/model.src1tgt0.newvocab.3.npz.orig.npz
[2019-02-19 15:48:06] Loading model from model/model.src1tgt0.newvocab.3.npz.orig.npz
[2019-02-19 15:48:07] Loading Adam parameters from model/model.src1tgt0.newvocab.3.npz.optimizer.npz
[2019-02-19 15:48:11] [memory] Reserving 227 MB, device gpu0
[2019-02-19 15:48:11] [memory] Reserving 227 MB, device gpu1
[2019-02-19 15:48:12] Training started
[2019-02-19 15:48:12] [data] Shuffling files
[2019-02-19 15:48:57] [data] Done reading 41736982 sentences
[2019-02-19 15:52:41] [data] Done shuffling 41736982 sentences to temp files
[2019-02-19 15:53:15] [memory] Reserving 227 MB, device gpu0
[2019-02-19 15:53:15] [memory] Reserving 227 MB, device gpu1
[2019-02-19 15:53:16] Loading model from model/model.src1tgt0.newvocab.3.npz
[2019-02-19 15:53:17] [memory] Reserving 227 MB, device cpu0
[2019-02-19 15:53:17] [memory] Reserving 113 MB, device gpu0
[2019-02-19 15:53:17] [memory] Reserving 113 MB, device gpu1
[2019-02-19 15:53:17] [memory] Reserving 227 MB, device gpu0
[2019-02-19 15:53:17] [memory] Reserving 227 MB, device gpu1
[2019-02-19 15:53:19] [memory] Reserving 113 MB, device gpu0
[2019-02-19 15:53:19] [memory] Reserving 113 MB, device gpu1
[2019-02-19 16:12:44] Ep. 34 : Up. 335500 : Sen. 2,127,573 : Cost 22.86811256 : Time 1481.27s : 13597.17 words/s : L.r. 6.5514e-05
[2019-02-19 16:32:14] Ep. 34 : Up. 336000 : Sen. 4,217,290 : Cost 22.98651505 : Time 1169.96s : 16973.51 words/s : L.r. 6.5465e-05
[2019-02-19 16:52:09] Ep. 34 : Up. 336500 : Sen. 6,364,894 : Cost 23.10610008 : Time 1194.30s : 17181.84 words/s : L.r. 6.5417e-05
[2019-02-19 17:11:33] Ep. 34 : Up. 337000 : Sen. 8,468,768 : Cost 22.63137436 : Time 1163.99s : 16913.58 words/s : L.r. 6.5368e-05
[2019-02-19 17:31:12] Ep. 34 : Up. 337500 : Sen. 10,601,399 : Cost 22.99408150 : Time 1179.13s : 17193.30 words/s : L.r. 6.5320e-05
[2019-02-19 17:50:38] Ep. 34 : Up. 338000 : Sen. 12,732,457 : Cost 22.66565895 : Time 1165.76s : 17156.07 words/s : L.r. 6.5271e-05
[2019-02-19 18:10:08] Ep. 34 : Up. 338500 : Sen. 14,838,672 : Cost 23.36593437 : Time 1170.60s : 17350.35 words/s : L.r. 6.5223e-05
[2019-02-19 18:29:28] Ep. 34 : Up. 339000 : Sen. 16,954,656 : Cost 22.75097466 : Time 1160.30s : 17158.35 words/s : L.r. 6.5175e-05
[2019-02-19 18:49:06] Ep. 34 : Up. 339500 : Sen. 19,093,043 : Cost 22.74766922 : Time 1177.97s : 17073.93 words/s : L.r. 6.5127e-05
[2019-02-19 19:08:54] Ep. 34 : Up. 340000 : Sen. 21,238,966 : Cost 23.09742165 : Time 1187.14s : 17237.26 words/s : L.r. 6.5079e-05
[2019-02-19 19:08:54] Saving model weights and runtime parameters to model/model.src1tgt0.newvocab.3.npz.orig.npz
[2019-02-19 19:08:58] Saving model weights and runtime parameters to model/model.src1tgt0.newvocab.3.iter340000.npz
[2019-02-19 19:09:01] Saving model weights and runtime parameters to model/model.src1tgt0.newvocab.3.npz
[2019-02-19 19:09:05] Saving Adam parameters to model/model.src1tgt0.newvocab.3.npz.optimizer.npz
[2019-02-19 19:09:17] [valid] Ep. 34 : Up. 340000 : cross-entropy : 18.2663 : new best
[2019-02-19 19:09:19] [valid] Ep. 34 : Up. 340000 : perplexity : 4.12572 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-02-19 19:10:37] [valid] Ep. 34 : Up. 340000 : translation : 35.19 : stalled 6 times
[2019-02-19 19:30:08] Ep. 34 : Up. 340500 : Sen. 23,312,296 : Cost 23.20541382 : Time 1274.74s : 15566.41 words/s : L.r. 6.5031e-05
[2019-02-19 19:49:54] Ep. 34 : Up. 341000 : Sen. 25,442,715 : Cost 22.99476051 : Time 1185.92s : 17070.46 words/s : L.r. 6.4984e-05
[2019-02-19 20:09:34] Ep. 34 : Up. 341500 : Sen. 27,571,973 : Cost 22.69009018 : Time 1179.94s : 16918.32 words/s : L.r. 6.4936e-05
[2019-02-19 20:29:10] Ep. 34 : Up. 342000 : Sen. 29,697,907 : Cost 22.77204132 : Time 1175.87s : 17031.34 words/s : L.r. 6.4889e-05
[2019-02-19 20:48:39] Ep. 34 : Up. 342500 : Sen. 31,789,441 : Cost 23.19462776 : Time 1169.16s : 17114.15 words/s : L.r. 6.4841e-05
[2019-02-19 21:08:15] Ep. 34 : Up. 343000 : Sen. 33,925,540 : Cost 22.78472328 : Time 1175.67s : 17103.97 words/s : L.r. 6.4794e-05
[2019-02-19 21:27:51] Ep. 34 : Up. 343500 : Sen. 36,069,176 : Cost 22.83229828 : Time 1176.18s : 17180.77 words/s : L.r. 6.4747e-05
[2019-02-19 21:47:15] Ep. 34 : Up. 344000 : Sen. 38,193,856 : Cost 22.76350021 : Time 1163.48s : 17169.48 words/s : L.r. 6.4700e-05
[2019-02-19 22:06:41] Ep. 34 : Up. 344500 : Sen. 40,306,781 : Cost 23.08086205 : Time 1166.81s : 17226.79 words/s : L.r. 6.4653e-05
[2019-02-19 22:20:00] Seen 41736017 samples
[2019-02-19 22:20:00] Starting epoch 35
[2019-02-19 22:20:00] [data] Shuffling files
[2019-02-19 22:20:15] [data] Done reading 41736982 sentences
[2019-02-19 22:23:51] [data] Done shuffling 41736982 sentences to temp files
[2019-02-19 22:30:32] Ep. 35 : Up. 345000 : Sen. 668,912 : Cost 23.23773575 : Time 1430.95s : 14088.05 words/s : L.r. 6.4606e-05
[2019-02-19 22:30:32] Saving model weights and runtime parameters to model/model.src1tgt0.newvocab.3.npz.orig.npz
[2019-02-19 22:30:36] Saving model weights and runtime parameters to model/model.src1tgt0.newvocab.3.iter345000.npz
[2019-02-19 22:30:40] Saving model weights and runtime parameters to model/model.src1tgt0.newvocab.3.npz
[2019-02-19 22:30:45] Saving Adam parameters to model/model.src1tgt0.newvocab.3.npz.optimizer.npz
[2019-02-19 22:30:55] [valid] Ep. 35 : Up. 345000 : cross-entropy : 18.2633 : new best
[2019-02-19 22:30:58] [valid] Ep. 35 : Up. 345000 : perplexity : 4.12475 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-02-19 22:32:15] [valid] Ep. 35 : Up. 345000 : translation : 35.13 : stalled 7 times
[2019-02-19 22:51:48] Ep. 35 : Up. 345500 : Sen. 2,788,564 : Cost 22.64185715 : Time 1275.69s : 15590.25 words/s : L.r. 6.4559e-05
[2019-02-19 23:11:34] Ep. 35 : Up. 346000 : Sen. 4,920,806 : Cost 23.01278687 : Time 1186.13s : 17110.45 words/s : L.r. 6.4512e-05
[2019-02-19 23:31:15] Ep. 35 : Up. 346500 : Sen. 7,029,202 : Cost 22.99645615 : Time 1181.18s : 16977.36 words/s : L.r. 6.4466e-05
[2019-02-19 23:50:58] Ep. 35 : Up. 347000 : Sen. 9,147,774 : Cost 22.82635117 : Time 1182.30s : 16937.64 words/s : L.r. 6.4419e-05
[2019-02-20 00:10:56] Ep. 35 : Up. 347500 : Sen. 11,279,348 : Cost 23.18595505 : Time 1198.13s : 17046.60 words/s : L.r. 6.4373e-05
[2019-02-20 00:30:29] Ep. 35 : Up. 348000 : Sen. 13,426,654 : Cost 22.16176987 : Time 1173.04s : 16813.47 words/s : L.r. 6.4327e-05
[2019-02-20 00:50:19] Ep. 35 : Up. 348500 : Sen. 15,563,210 : Cost 23.16908455 : Time 1190.53s : 17199.71 words/s : L.r. 6.4281e-05
[2019-02-20 01:09:47] Ep. 35 : Up. 349000 : Sen. 17,667,650 : Cost 22.98877525 : Time 1168.12s : 17098.61 words/s : L.r. 6.4235e-05
[2019-02-20 01:29:08] Ep. 35 : Up. 349500 : Sen. 19,754,565 : Cost 23.14533234 : Time 1160.70s : 17169.34 words/s : L.r. 6.4189e-05
[2019-02-20 01:48:33] Ep. 35 : Up. 350000 : Sen. 21,883,570 : Cost 22.86316872 : Time 1165.31s : 17291.79 words/s : L.r. 6.4143e-05
[2019-02-20 01:48:33] Saving model weights and runtime parameters to model/model.src1tgt0.newvocab.3.npz.orig.npz
[2019-02-20 01:48:38] Saving model weights and runtime parameters to model/model.src1tgt0.newvocab.3.iter350000.npz
[2019-02-20 01:48:41] Saving model weights and runtime parameters to model/model.src1tgt0.newvocab.3.npz
[2019-02-20 01:48:45] Saving Adam parameters to model/model.src1tgt0.newvocab.3.npz.optimizer.npz
[2019-02-20 01:48:56] [valid] Ep. 35 : Up. 350000 : cross-entropy : 18.2671 : stalled 1 times
[2019-02-20 01:48:58] [valid] Ep. 35 : Up. 350000 : perplexity : 4.12597 : stalled 1 times
Detokenizer Version $Revision: 4134 $
Language: en
[2019-02-20 01:50:19] [valid] Ep. 35 : Up. 350000 : translation : 35.1 : stalled 8 times
[2019-02-20 02:09:37] Ep. 35 : Up. 350500 : Sen. 23,991,792 : Cost 22.77868271 : Time 1263.58s : 15713.22 words/s : L.r. 6.4097e-05
[2019-02-20 02:29:10] Ep. 35 : Up. 351000 : Sen. 26,100,398 : Cost 23.02347374 : Time 1172.51s : 17114.79 words/s : L.r. 6.4051e-05
[2019-02-20 02:48:48] Ep. 35 : Up. 351500 : Sen. 28,230,044 : Cost 22.84866142 : Time 1178.76s : 17056.08 words/s : L.r. 6.4006e-05
[2019-02-20 03:08:29] Ep. 35 : Up. 352000 : Sen. 30,359,496 : Cost 22.85719681 : Time 1180.75s : 17049.66 words/s : L.r. 6.3960e-05
[2019-02-20 03:28:01] Ep. 35 : Up. 352500 : Sen. 32,458,953 : Cost 22.90456009 : Time 1171.81s : 16927.72 words/s : L.r. 6.3915e-05
[2019-02-20 03:47:47] Ep. 35 : Up. 353000 : Sen. 34,576,147 : Cost 23.13622093 : Time 1185.93s : 17053.31 words/s : L.r. 6.3870e-05
[2019-02-20 04:07:30] Ep. 35 : Up. 353500 : Sen. 36,691,012 : Cost 22.94325066 : Time 1183.15s : 16953.76 words/s : L.r. 6.3824e-05
[2019-02-20 04:27:19] Ep. 35 : Up. 354000 : Sen. 38,820,539 : Cost 23.15681267 : Time 1189.38s : 17089.42 words/s : L.r. 6.3779e-05
[2019-02-20 04:46:50] Ep. 35 : Up. 354500 : Sen. 40,938,363 : Cost 22.79417229 : Time 1171.06s : 17042.33 words/s : L.r. 6.3734e-05
[2019-02-20 04:54:15] Seen 41736017 samples
[2019-02-20 04:54:15] Starting epoch 36
[2019-02-20 04:54:15] [data] Shuffling files
[2019-02-20 04:54:30] [data] Done reading 41736982 sentences
[2019-02-20 04:58:09] [data] Done shuffling 41736982 sentences to temp files
[2019-02-20 05:10:30] Ep. 36 : Up. 355000 : Sen. 1,280,593 : Cost 22.87908936 : Time 1419.21s : 13853.76 words/s : L.r. 6.3689e-05
[2019-02-20 05:10:30] Saving model weights and runtime parameters to model/model.src1tgt0.newvocab.3.npz.orig.npz
[2019-02-20 05:10:33] Saving model weights and runtime parameters to model/model.src1tgt0.newvocab.3.iter355000.npz
[2019-02-20 05:10:37] Saving model weights and runtime parameters to model/model.src1tgt0.newvocab.3.npz
[2019-02-20 05:10:42] Saving Adam parameters to model/model.src1tgt0.newvocab.3.npz.optimizer.npz
[2019-02-20 05:10:52] [valid] Ep. 36 : Up. 355000 : cross-entropy : 18.2594 : new best
[2019-02-20 05:10:55] [valid] Ep. 36 : Up. 355000 : perplexity : 4.12351 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-02-20 05:12:18] [valid] Ep. 36 : Up. 355000 : translation : 35.1 : stalled 9 times
[2019-02-20 05:31:45] Ep. 36 : Up. 355500 : Sen. 3,399,177 : Cost 22.81093025 : Time 1275.86s : 15709.63 words/s : L.r. 6.3645e-05
[2019-02-20 05:51:15] Ep. 36 : Up. 356000 : Sen. 5,529,904 : Cost 22.91070366 : Time 1169.31s : 17294.62 words/s : L.r. 6.3600e-05
[2019-02-20 06:10:44] Ep. 36 : Up. 356500 : Sen. 7,694,283 : Cost 22.36140442 : Time 1169.55s : 17160.67 words/s : L.r. 6.3555e-05
[2019-02-20 06:30:03] Ep. 36 : Up. 357000 : Sen. 9,786,512 : Cost 23.19748688 : Time 1158.80s : 17314.87 words/s : L.r. 6.3511e-05
[2019-02-20 06:49:29] Ep. 36 : Up. 357500 : Sen. 11,878,084 : Cost 23.09209442 : Time 1165.51s : 17139.55 words/s : L.r. 6.3466e-05
[2019-02-20 07:09:01] Ep. 36 : Up. 358000 : Sen. 13,987,328 : Cost 23.06188393 : Time 1172.02s : 17153.90 words/s : L.r. 6.3422e-05
[2019-02-20 07:28:38] Ep. 36 : Up. 358500 : Sen. 16,126,486 : Cost 22.82870293 : Time 1177.67s : 17164.16 words/s : L.r. 6.3378e-05
[2019-02-20 07:48:25] Ep. 36 : Up. 359000 : Sen. 18,243,381 : Cost 23.17245483 : Time 1186.38s : 17072.47 words/s : L.r. 6.3334e-05
[2019-02-20 08:07:57] Ep. 36 : Up. 359500 : Sen. 20,389,101 : Cost 22.31824303 : Time 1172.33s : 16933.90 words/s : L.r. 6.3290e-05
[2019-02-20 08:27:35] Ep. 36 : Up. 360000 : Sen. 22,473,555 : Cost 23.50817490 : Time 1178.17s : 17159.33 words/s : L.r. 6.3246e-05
[2019-02-20 08:27:35] Saving model weights and runtime parameters to model/model.src1tgt0.newvocab.3.npz.orig.npz
[2019-02-20 08:27:39] Saving model weights and runtime parameters to model/model.src1tgt0.newvocab.3.iter360000.npz
[2019-02-20 08:27:43] Saving model weights and runtime parameters to model/model.src1tgt0.newvocab.3.npz
[2019-02-20 08:27:47] Saving Adam parameters to model/model.src1tgt0.newvocab.3.npz.optimizer.npz
[2019-02-20 08:27:57] [valid] Ep. 36 : Up. 360000 : cross-entropy : 18.2577 : new best
[2019-02-20 08:28:00] [valid] Ep. 36 : Up. 360000 : perplexity : 4.12297 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-02-20 08:29:21] [valid] Ep. 36 : Up. 360000 : translation : 35.21 : stalled 10 times
[2019-02-20 08:48:57] Ep. 36 : Up. 360500 : Sen. 24,616,730 : Cost 22.43177223 : Time 1281.44s : 15521.01 words/s : L.r. 6.3202e-05
[2019-02-20 09:08:39] Ep. 36 : Up. 361000 : Sen. 26,723,527 : Cost 23.26626015 : Time 1182.80s : 17108.12 words/s : L.r. 6.3158e-05
[2019-02-20 09:28:14] Ep. 36 : Up. 361500 : Sen. 28,839,747 : Cost 22.80463219 : Time 1174.36s : 16997.78 words/s : L.r. 6.3114e-05
[2019-02-20 09:48:03] Ep. 36 : Up. 362000 : Sen. 30,986,928 : Cost 22.94086647 : Time 1189.21s : 17118.06 words/s : L.r. 6.3071e-05
[2019-02-20 10:07:48] Ep. 36 : Up. 362500 : Sen. 33,111,600 : Cost 22.99742126 : Time 1184.85s : 17043.52 words/s : L.r. 6.3027e-05
[2019-02-20 10:27:19] Ep. 36 : Up. 363000 : Sen. 35,202,969 : Cost 22.98826027 : Time 1171.63s : 16937.90 words/s : L.r. 6.2984e-05
[2019-02-20 10:47:02] Ep. 36 : Up. 363500 : Sen. 37,315,873 : Cost 23.01716995 : Time 1182.14s : 16993.54 words/s : L.r. 6.2940e-05
[2019-02-20 11:06:49] Ep. 36 : Up. 364000 : Sen. 39,484,093 : Cost 22.48196793 : Time 1187.01s : 17016.30 words/s : L.r. 6.2897e-05
[2019-02-20 11:25:57] Ep. 36 : Up. 364500 : Sen. 41,527,073 : Cost 23.25907326 : Time 1148.88s : 17044.60 words/s : L.r. 6.2854e-05
[2019-02-20 11:27:53] Seen 41736017 samples
[2019-02-20 11:27:53] Starting epoch 37
[2019-02-20 11:27:53] [data] Shuffling files
[2019-02-20 11:28:07] [data] Done reading 41736982 sentences
[2019-02-20 11:31:49] [data] Done shuffling 41736982 sentences to temp files
[2019-02-20 11:49:57] Ep. 37 : Up. 365000 : Sen. 1,904,519 : Cost 22.91367912 : Time 1439.47s : 13932.46 words/s : L.r. 6.2811e-05
[2019-02-20 11:49:57] Saving model weights and runtime parameters to model/model.src1tgt0.newvocab.3.npz.orig.npz
[2019-02-20 11:50:01] Saving model weights and runtime parameters to model/model.src1tgt0.newvocab.3.iter365000.npz
[2019-02-20 11:50:04] Saving model weights and runtime parameters to model/model.src1tgt0.newvocab.3.npz
[2019-02-20 11:50:08] Saving Adam parameters to model/model.src1tgt0.newvocab.3.npz.optimizer.npz
[2019-02-20 11:50:18] [valid] Ep. 37 : Up. 365000 : cross-entropy : 18.2519 : new best
[2019-02-20 11:50:21] [valid] Ep. 37 : Up. 365000 : perplexity : 4.12108 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-02-20 11:51:40] [valid] Ep. 37 : Up. 365000 : translation : 35.2 : stalled 11 times
[2019-02-20 12:11:11] Ep. 37 : Up. 365500 : Sen. 4,025,808 : Cost 22.80823898 : Time 1273.78s : 15743.27 words/s : L.r. 6.2768e-05
[2019-02-20 12:30:48] Ep. 37 : Up. 366000 : Sen. 6,145,503 : Cost 22.96820831 : Time 1177.31s : 17120.99 words/s : L.r. 6.2725e-05
[2019-02-20 12:50:23] Ep. 37 : Up. 366500 : Sen. 8,285,209 : Cost 22.56208611 : Time 1175.15s : 17038.46 words/s : L.r. 6.2682e-05
[2019-02-20 13:09:47] Ep. 37 : Up. 367000 : Sen. 10,389,512 : Cost 22.87960243 : Time 1163.61s : 17121.90 words/s : L.r. 6.2639e-05
[2019-02-20 13:29:25] Ep. 37 : Up. 367500 : Sen. 12,531,844 : Cost 22.96115494 : Time 1177.88s : 17300.04 words/s : L.r. 6.2597e-05
[2019-02-20 13:49:00] Ep. 37 : Up. 368000 : Sen. 14,674,659 : Cost 22.88432693 : Time 1175.26s : 17263.60 words/s : L.r. 6.2554e-05
[2019-02-20 14:08:14] Ep. 37 : Up. 368500 : Sen. 16,757,231 : Cost 23.15167427 : Time 1154.49s : 17245.03 words/s : L.r. 6.2512e-05
[2019-02-20 14:27:43] Ep. 37 : Up. 369000 : Sen. 18,881,604 : Cost 22.87207794 : Time 1168.47s : 17209.47 words/s : L.r. 6.2470e-05
[2019-02-20 14:47:02] Ep. 37 : Up. 369500 : Sen. 21,000,000 : Cost 22.86189461 : Time 1159.17s : 17278.24 words/s : L.r. 6.2427e-05
[2019-02-20 15:06:25] Ep. 37 : Up. 370000 : Sen. 23,134,604 : Cost 22.68370247 : Time 1163.21s : 17222.45 words/s : L.r. 6.2385e-05
[2019-02-20 15:06:25] Saving model weights and runtime parameters to model/model.src1tgt0.newvocab.3.npz.orig.npz
[2019-02-20 15:06:29] Saving model weights and runtime parameters to model/model.src1tgt0.newvocab.3.iter370000.npz
[2019-02-20 15:06:33] Saving model weights and runtime parameters to model/model.src1tgt0.newvocab.3.npz
[2019-02-20 15:06:37] Saving Adam parameters to model/model.src1tgt0.newvocab.3.npz.optimizer.npz
[2019-02-20 15:06:48] [valid] Ep. 37 : Up. 370000 : cross-entropy : 18.2532 : stalled 1 times
[2019-02-20 15:06:51] [valid] Ep. 37 : Up. 370000 : perplexity : 4.1215 : stalled 1 times
Detokenizer Version $Revision: 4134 $
Language: en
[2019-02-20 15:08:09] [valid] Ep. 37 : Up. 370000 : translation : 35.15 : stalled 12 times
[2019-02-20 15:27:29] Ep. 37 : Up. 370500 : Sen. 25,235,093 : Cost 22.93934250 : Time 1263.46s : 15785.42 words/s : L.r. 6.2343e-05
[2019-02-20 15:47:10] Ep. 37 : Up. 371000 : Sen. 27,359,808 : Cost 23.20722198 : Time 1181.66s : 17234.06 words/s : L.r. 6.2301e-05
[2019-02-20 16:06:31] Ep. 37 : Up. 371500 : Sen. 29,429,114 : Cost 23.10649490 : Time 1160.26s : 17033.12 words/s : L.r. 6.2259e-05
[2019-02-20 16:26:19] Ep. 37 : Up. 372000 : Sen. 31,576,861 : Cost 22.81539536 : Time 1188.78s : 17036.42 words/s : L.r. 6.2217e-05
[2019-02-20 16:46:05] Ep. 37 : Up. 372500 : Sen. 33,725,775 : Cost 22.79877090 : Time 1185.73s : 17078.06 words/s : L.r. 6.2175e-05
[2019-02-20 17:05:41] Ep. 37 : Up. 373000 : Sen. 35,843,604 : Cost 22.83979225 : Time 1175.55s : 17031.45 words/s : L.r. 6.2134e-05
[2019-02-20 17:25:19] Ep. 37 : Up. 373500 : Sen. 37,941,291 : Cost 23.06172371 : Time 1178.10s : 16948.90 words/s : L.r. 6.2092e-05
[2019-02-20 17:45:02] Ep. 37 : Up. 374000 : Sen. 40,063,130 : Cost 22.90921402 : Time 1183.40s : 16984.93 words/s : L.r. 6.2051e-05
[2019-02-20 18:00:37] Seen 41736017 samples
[2019-02-20 18:00:37] Starting epoch 38
[2019-02-20 18:00:37] [data] Shuffling files
[2019-02-20 18:00:51] [data] Done reading 41736982 sentences
[2019-02-20 18:04:33] [data] Done shuffling 41736982 sentences to temp files
[2019-02-20 18:08:57] Ep. 38 : Up. 374500 : Sen. 437,744 : Cost 22.66791344 : Time 1435.03s : 13813.79 words/s : L.r. 6.2009e-05
[2019-02-20 18:28:46] Ep. 38 : Up. 375000 : Sen. 2,559,236 : Cost 23.03497887 : Time 1188.73s : 17031.11 words/s : L.r. 6.1968e-05
[2019-02-20 18:28:46] Saving model weights and runtime parameters to model/model.src1tgt0.newvocab.3.npz.orig.npz
[2019-02-20 18:28:50] Saving model weights and runtime parameters to model/model.src1tgt0.newvocab.3.iter375000.npz
[2019-02-20 18:28:54] Saving model weights and runtime parameters to model/model.src1tgt0.newvocab.3.npz
[2019-02-20 18:28:58] Saving Adam parameters to model/model.src1tgt0.newvocab.3.npz.optimizer.npz
[2019-02-20 18:29:10] [valid] Ep. 38 : Up. 375000 : cross-entropy : 18.2537 : stalled 2 times
[2019-02-20 18:29:13] [valid] Ep. 38 : Up. 375000 : perplexity : 4.12166 : stalled 2 times
Detokenizer Version $Revision: 4134 $
Language: en
[2019-02-20 18:30:32] [valid] Ep. 38 : Up. 375000 : translation : 35.2 : stalled 13 times
[2019-02-20 18:50:06] Ep. 38 : Up. 375500 : Sen. 4,636,570 : Cost 22.97754860 : Time 1279.51s : 15433.71 words/s : L.r. 6.1926e-05
[2019-02-20 19:09:54] Ep. 38 : Up. 376000 : Sen. 6,771,779 : Cost 23.06135941 : Time 1188.14s : 17169.30 words/s : L.r. 6.1885e-05
[2019-02-20 19:29:32] Ep. 38 : Up. 376500 : Sen. 8,908,128 : Cost 22.51374817 : Time 1177.96s : 16928.53 words/s : L.r. 6.1844e-05
[2019-02-20 19:49:09] Ep. 38 : Up. 377000 : Sen. 11,029,614 : Cost 22.90351105 : Time 1177.35s : 17086.41 words/s : L.r. 6.1803e-05
[2019-02-20 20:08:46] Ep. 38 : Up. 377500 : Sen. 13,155,243 : Cost 22.69311142 : Time 1177.44s : 16962.47 words/s : L.r. 6.1762e-05
[2019-02-20 20:28:10] Ep. 38 : Up. 378000 : Sen. 15,252,298 : Cost 23.05503845 : Time 1163.96s : 17200.79 words/s : L.r. 6.1721e-05
[2019-02-20 20:47:46] Ep. 38 : Up. 378500 : Sen. 17,414,408 : Cost 22.49112892 : Time 1175.32s : 17165.41 words/s : L.r. 6.1681e-05
[2019-02-20 21:07:07] Ep. 38 : Up. 379000 : Sen. 19,461,119 : Cost 23.70093346 : Time 1161.04s : 17216.48 words/s : L.r. 6.1640e-05
[2019-02-20 21:26:49] Ep. 38 : Up. 379500 : Sen. 21,631,838 : Cost 22.78380203 : Time 1182.15s : 17349.09 words/s : L.r. 6.1599e-05
[2019-02-20 21:46:03] Ep. 38 : Up. 380000 : Sen. 23,750,222 : Cost 22.47937012 : Time 1154.30s : 17069.89 words/s : L.r. 6.1559e-05
[2019-02-20 21:46:03] Saving model weights and runtime parameters to model/model.src1tgt0.newvocab.3.npz.orig.npz
[2019-02-20 21:46:07] Saving model weights and runtime parameters to model/model.src1tgt0.newvocab.3.iter380000.npz
[2019-02-20 21:46:11] Saving model weights and runtime parameters to model/model.src1tgt0.newvocab.3.npz
[2019-02-20 21:46:15] Saving Adam parameters to model/model.src1tgt0.newvocab.3.npz.optimizer.npz
[2019-02-20 21:46:25] [valid] Ep. 38 : Up. 380000 : cross-entropy : 18.2613 : stalled 3 times
[2019-02-20 21:46:28] [valid] Ep. 38 : Up. 380000 : perplexity : 4.1241 : stalled 3 times
Detokenizer Version $Revision: 4134 $
Language: en
[2019-02-20 21:47:48] [valid] Ep. 38 : Up. 380000 : translation : 35.14 : stalled 14 times
[2019-02-20 22:07:16] Ep. 38 : Up. 380500 : Sen. 25,854,038 : Cost 23.33864212 : Time 1272.69s : 15930.89 words/s : L.r. 6.1518e-05
[2019-02-20 22:26:37] Ep. 38 : Up. 381000 : Sen. 27,981,424 : Cost 22.67440605 : Time 1160.73s : 17202.37 words/s : L.r. 6.1478e-05
[2019-02-20 22:46:00] Ep. 38 : Up. 381500 : Sen. 30,123,157 : Cost 22.58964348 : Time 1163.24s : 17225.39 words/s : L.r. 6.1438e-05
[2019-02-20 23:05:28] Ep. 38 : Up. 382000 : Sen. 32,212,692 : Cost 23.38365364 : Time 1168.51s : 17261.60 words/s : L.r. 6.1397e-05
[2019-02-20 23:25:12] Ep. 38 : Up. 382500 : Sen. 34,374,996 : Cost 22.67147064 : Time 1183.90s : 17144.20 words/s : L.r. 6.1357e-05
[2019-02-20 23:44:26] Ep. 38 : Up. 383000 : Sen. 36,422,136 : Cost 23.29450226 : Time 1153.86s : 17053.54 words/s : L.r. 6.1317e-05
[2019-02-21 00:04:10] Ep. 38 : Up. 383500 : Sen. 38,581,139 : Cost 22.56021881 : Time 1184.08s : 17040.08 words/s : L.r. 6.1277e-05
[2019-02-21 00:23:52] Ep. 38 : Up. 384000 : Sen. 40,701,117 : Cost 23.04279900 : Time 1182.20s : 17087.67 words/s : L.r. 6.1237e-05
[2019-02-21 00:33:30] Seen 41736017 samples
[2019-02-21 00:33:30] Starting epoch 39
[2019-02-21 00:33:30] [data] Shuffling files
[2019-02-21 00:33:45] [data] Done reading 41736982 sentences
[2019-02-21 00:37:26] [data] Done shuffling 41736982 sentences to temp files
[2019-02-21 00:47:32] Ep. 39 : Up. 384500 : Sen. 1,039,033 : Cost 22.95043373 : Time 1419.76s : 13864.50 words/s : L.r. 6.1197e-05
[2019-02-21 01:07:16] Ep. 39 : Up. 385000 : Sen. 3,168,244 : Cost 22.82278824 : Time 1183.34s : 17026.24 words/s : L.r. 6.1158e-05
[2019-02-21 01:07:16] Saving model weights and runtime parameters to model/model.src1tgt0.newvocab.3.npz.orig.npz
[2019-02-21 01:07:20] Saving model weights and runtime parameters to model/model.src1tgt0.newvocab.3.iter385000.npz
[2019-02-21 01:07:23] Saving model weights and runtime parameters to model/model.src1tgt0.newvocab.3.npz
[2019-02-21 01:07:28] Saving Adam parameters to model/model.src1tgt0.newvocab.3.npz.optimizer.npz
[2019-02-21 01:07:39] [valid] Ep. 39 : Up. 385000 : cross-entropy : 18.2583 : stalled 4 times
[2019-02-21 01:07:42] [valid] Ep. 39 : Up. 385000 : perplexity : 4.12314 : stalled 4 times
Detokenizer Version $Revision: 4134 $
Language: en
[2019-02-21 01:09:02] [valid] Ep. 39 : Up. 385000 : translation : 35.13 : stalled 15 times
[2019-02-21 01:28:36] Ep. 39 : Up. 385500 : Sen. 5,280,981 : Cost 22.59660149 : Time 1280.26s : 15460.20 words/s : L.r. 6.1118e-05
[2019-02-21 01:48:21] Ep. 39 : Up. 386000 : Sen. 7,421,067 : Cost 22.74178314 : Time 1185.07s : 17031.28 words/s : L.r. 6.1078e-05
[2019-02-21 02:08:09] Ep. 39 : Up. 386500 : Sen. 9,537,528 : Cost 23.24263000 : Time 1187.89s : 17134.71 words/s : L.r. 6.1039e-05
[2019-02-21 02:27:48] Ep. 39 : Up. 387000 : Sen. 11,630,513 : Cost 23.15752220 : Time 1178.88s : 17006.72 words/s : L.r. 6.0999e-05
[2019-02-21 02:47:27] Ep. 39 : Up. 387500 : Sen. 13,779,925 : Cost 22.45140457 : Time 1179.51s : 16984.27 words/s : L.r. 6.0960e-05
[2019-02-21 03:07:07] Ep. 39 : Up. 388000 : Sen. 15,907,866 : Cost 22.86541939 : Time 1179.84s : 17072.77 words/s : L.r. 6.0921e-05
[2019-02-21 03:26:37] Ep. 39 : Up. 388500 : Sen. 17,997,040 : Cost 23.07516479 : Time 1170.49s : 17033.53 words/s : L.r. 6.0882e-05
[2019-02-21 03:46:17] Ep. 39 : Up. 389000 : Sen. 20,108,464 : Cost 23.15042686 : Time 1179.95s : 17120.05 words/s : L.r. 6.0842e-05
[2019-02-21 04:05:56] Ep. 39 : Up. 389500 : Sen. 22,251,072 : Cost 22.83369637 : Time 1178.19s : 17181.62 words/s : L.r. 6.0803e-05
[2019-02-21 04:25:28] Ep. 39 : Up. 390000 : Sen. 24,359,825 : Cost 22.88075829 : Time 1172.11s : 17044.36 words/s : L.r. 6.0764e-05
[2019-02-21 04:25:28] Saving model weights and runtime parameters to model/model.src1tgt0.newvocab.3.npz.orig.npz
[2019-02-21 04:25:32] Saving model weights and runtime parameters to model/model.src1tgt0.newvocab.3.iter390000.npz
[2019-02-21 04:25:36] Saving model weights and runtime parameters to model/model.src1tgt0.newvocab.3.npz
[2019-02-21 04:25:40] Saving Adam parameters to model/model.src1tgt0.newvocab.3.npz.optimizer.npz
[2019-02-21 04:25:51] [valid] Ep. 39 : Up. 390000 : cross-entropy : 18.2572 : stalled 5 times
[2019-02-21 04:25:54] [valid] Ep. 39 : Up. 390000 : perplexity : 4.12279 : stalled 5 times
Detokenizer Version $Revision: 4134 $
Language: en
[2019-02-21 04:27:11] [valid] Ep. 39 : Up. 390000 : translation : 35.13 : stalled 16 times
[2019-02-21 04:46:34] Ep. 39 : Up. 390500 : Sen. 26,488,906 : Cost 22.58297539 : Time 1266.39s : 15704.24 words/s : L.r. 6.0725e-05
[2019-02-21 05:06:10] Ep. 39 : Up. 391000 : Sen. 28,605,847 : Cost 23.14369011 : Time 1175.85s : 17253.89 words/s : L.r. 6.0687e-05
[2019-02-21 05:25:36] Ep. 39 : Up. 391500 : Sen. 30,729,680 : Cost 22.87737274 : Time 1166.19s : 17236.27 words/s : L.r. 6.0648e-05
[2019-02-21 05:44:55] Ep. 39 : Up. 392000 : Sen. 32,833,217 : Cost 22.84867668 : Time 1158.65s : 17155.58 words/s : L.r. 6.0609e-05
[2019-02-21 06:04:21] Ep. 39 : Up. 392500 : Sen. 34,958,165 : Cost 22.95529175 : Time 1166.17s : 17305.35 words/s : L.r. 6.0571e-05
[2019-02-21 06:23:47] Ep. 39 : Up. 393000 : Sen. 37,100,940 : Cost 22.72557640 : Time 1166.14s : 17285.68 words/s : L.r. 6.0532e-05
[2019-02-21 06:43:12] Ep. 39 : Up. 393500 : Sen. 39,210,285 : Cost 23.15981483 : Time 1165.33s : 17307.17 words/s : L.r. 6.0494e-05
[2019-02-21 07:02:26] Ep. 39 : Up. 394000 : Sen. 41,318,789 : Cost 22.63181496 : Time 1153.74s : 17112.59 words/s : L.r. 6.0455e-05
[2019-02-21 07:06:25] Seen 41736017 samples
[2019-02-21 07:06:25] Starting epoch 40
[2019-02-21 07:06:25] [data] Shuffling files
[2019-02-21 07:06:39] [data] Done reading 41736982 sentences
[2019-02-21 07:10:17] [data] Done shuffling 41736982 sentences to temp files
[2019-02-21 07:26:15] Ep. 40 : Up. 394500 : Sen. 1,688,646 : Cost 22.81134415 : Time 1428.68s : 13956.60 words/s : L.r. 6.0417e-05
[2019-02-21 07:45:35] Ep. 40 : Up. 395000 : Sen. 3,807,666 : Cost 22.64582062 : Time 1159.87s : 17157.39 words/s : L.r. 6.0379e-05
[2019-02-21 07:45:35] Saving model weights and runtime parameters to model/model.src1tgt0.newvocab.3.npz.orig.npz
[2019-02-21 07:45:39] Saving model weights and runtime parameters to model/model.src1tgt0.newvocab.3.iter395000.npz
[2019-02-21 07:45:43] Saving model weights and runtime parameters to model/model.src1tgt0.newvocab.3.npz
[2019-02-21 07:45:47] Saving Adam parameters to model/model.src1tgt0.newvocab.3.npz.optimizer.npz
[2019-02-21 07:45:57] [valid] Ep. 40 : Up. 395000 : cross-entropy : 18.2494 : new best
[2019-02-21 07:46:00] [valid] Ep. 40 : Up. 395000 : perplexity : 4.12031 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-02-21 07:47:19] [valid] Ep. 40 : Up. 395000 : translation : 35.15 : stalled 17 times
[2019-02-21 08:06:52] Ep. 40 : Up. 395500 : Sen. 5,904,412 : Cost 23.12721443 : Time 1277.53s : 15722.31 words/s : L.r. 6.0340e-05
[2019-02-21 08:26:28] Ep. 40 : Up. 396000 : Sen. 8,018,688 : Cost 23.04432869 : Time 1176.09s : 17165.60 words/s : L.r. 6.0302e-05
[2019-02-21 08:46:11] Ep. 40 : Up. 396500 : Sen. 10,169,262 : Cost 22.67276955 : Time 1182.45s : 17116.52 words/s : L.r. 6.0264e-05
[2019-02-21 09:05:32] Ep. 40 : Up. 397000 : Sen. 12,244,103 : Cost 23.12465858 : Time 1161.01s : 17080.08 words/s : L.r. 6.0226e-05
[2019-02-21 09:25:14] Ep. 40 : Up. 397500 : Sen. 14,392,401 : Cost 22.62507439 : Time 1181.95s : 17072.75 words/s : L.r. 6.0188e-05
[2019-02-21 09:44:29] Ep. 40 : Up. 398000 : Sen. 16,461,546 : Cost 22.95445061 : Time 1154.79s : 16997.47 words/s : L.r. 6.0151e-05
[2019-02-21 10:04:14] Ep. 40 : Up. 398500 : Sen. 18,589,964 : Cost 22.96584892 : Time 1185.79s : 17072.03 words/s : L.r. 6.0113e-05
[2019-02-21 10:23:57] Ep. 40 : Up. 399000 : Sen. 20,712,596 : Cost 23.02297020 : Time 1182.31s : 17105.38 words/s : L.r. 6.0075e-05
[2019-02-21 10:43:42] Ep. 40 : Up. 399500 : Sen. 22,854,843 : Cost 22.77263069 : Time 1185.53s : 17030.83 words/s : L.r. 6.0038e-05
[2019-02-21 11:03:22] Ep. 40 : Up. 400000 : Sen. 24,963,408 : Cost 22.98519325 : Time 1179.93s : 17005.65 words/s : L.r. 6.0000e-05
[2019-02-21 11:03:22] Saving model weights and runtime parameters to model/model.src1tgt0.newvocab.3.npz.orig.npz
[2019-02-21 11:03:26] Saving model weights and runtime parameters to model/model.src1tgt0.newvocab.3.iter400000.npz
[2019-02-21 11:03:30] Saving model weights and runtime parameters to model/model.src1tgt0.newvocab.3.npz
[2019-02-21 11:03:34] Saving Adam parameters to model/model.src1tgt0.newvocab.3.npz.optimizer.npz
[2019-02-21 11:03:45] [valid] Ep. 40 : Up. 400000 : cross-entropy : 18.2429 : new best
[2019-02-21 11:03:48] [valid] Ep. 40 : Up. 400000 : perplexity : 4.11823 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-02-21 11:05:09] [valid] Ep. 40 : Up. 400000 : translation : 35.17 : stalled 18 times
[2019-02-21 11:24:53] Ep. 40 : Up. 400500 : Sen. 27,093,865 : Cost 22.73580742 : Time 1290.66s : 15543.17 words/s : L.r. 5.9963e-05
[2019-02-21 11:44:38] Ep. 40 : Up. 401000 : Sen. 29,213,061 : Cost 23.15645027 : Time 1184.96s : 17127.81 words/s : L.r. 5.9925e-05
[2019-02-21 12:04:16] Ep. 40 : Up. 401500 : Sen. 31,339,156 : Cost 22.74256325 : Time 1178.55s : 17008.85 words/s : L.r. 5.9888e-05
[2019-02-21 12:23:44] Ep. 40 : Up. 402000 : Sen. 33,438,752 : Cost 22.82376289 : Time 1167.36s : 16943.07 words/s : L.r. 5.9851e-05
[2019-02-21 12:43:35] Ep. 40 : Up. 402500 : Sen. 35,592,445 : Cost 22.94655991 : Time 1190.98s : 17187.03 words/s : L.r. 5.9813e-05
[2019-02-21 13:03:05] Ep. 40 : Up. 403000 : Sen. 37,686,527 : Cost 23.07061768 : Time 1170.22s : 17042.49 words/s : L.r. 5.9776e-05
[2019-02-21 13:22:47] Ep. 40 : Up. 403500 : Sen. 39,845,564 : Cost 22.53103828 : Time 1181.73s : 17068.53 words/s : L.r. 5.9739e-05
[2019-02-21 13:40:28] Seen 41736017 samples
[2019-02-21 13:40:28] Starting epoch 41
[2019-02-21 13:40:28] [data] Shuffling files
[2019-02-21 13:40:42] [data] Done reading 41736982 sentences
[2019-02-21 13:44:27] [data] Done shuffling 41736982 sentences to temp files
[2019-02-21 13:46:34] Ep. 41 : Up. 404000 : Sen. 180,496 : Cost 23.01604652 : Time 1427.31s : 13798.72 words/s : L.r. 5.9702e-05
[2019-02-21 14:06:07] Ep. 41 : Up. 404500 : Sen. 2,316,951 : Cost 22.80807686 : Time 1173.35s : 17256.98 words/s : L.r. 5.9665e-05
[2019-02-21 14:25:30] Ep. 41 : Up. 405000 : Sen. 4,410,842 : Cost 22.88539696 : Time 1162.79s : 17079.66 words/s : L.r. 5.9628e-05
[2019-02-21 14:25:30] Saving model weights and runtime parameters to model/model.src1tgt0.newvocab.3.npz.orig.npz
[2019-02-21 14:25:35] Saving model weights and runtime parameters to model/model.src1tgt0.newvocab.3.iter405000.npz
[2019-02-21 14:25:41] Saving model weights and runtime parameters to model/model.src1tgt0.newvocab.3.npz
[2019-02-21 14:25:47] Saving Adam parameters to model/model.src1tgt0.newvocab.3.npz.optimizer.npz
[2019-02-21 14:26:01] [valid] Ep. 41 : Up. 405000 : cross-entropy : 18.2427 : new best
[2019-02-21 14:26:04] [valid] Ep. 41 : Up. 405000 : perplexity : 4.11816 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-02-21 14:27:25] [valid] Ep. 41 : Up. 405000 : translation : 35.12 : stalled 19 times
[2019-02-21 14:47:02] Ep. 41 : Up. 405500 : Sen. 6,548,976 : Cost 22.60457611 : Time 1292.29s : 15533.97 words/s : L.r. 5.9592e-05
[2019-02-21 15:06:49] Ep. 41 : Up. 406000 : Sen. 8,668,794 : Cost 23.14455795 : Time 1186.85s : 17149.29 words/s : L.r. 5.9555e-05
[2019-02-21 15:26:10] Ep. 41 : Up. 406500 : Sen. 10,775,572 : Cost 22.86746407 : Time 1161.06s : 17191.38 words/s : L.r. 5.9518e-05
[2019-02-21 15:45:45] Ep. 41 : Up. 407000 : Sen. 12,919,738 : Cost 22.94633675 : Time 1174.44s : 17352.64 words/s : L.r. 5.9482e-05
[2019-02-21 16:05:06] Ep. 41 : Up. 407500 : Sen. 15,035,408 : Cost 22.77239799 : Time 1161.64s : 17191.57 words/s : L.r. 5.9445e-05
[2019-02-21 16:24:33] Ep. 41 : Up. 408000 : Sen. 17,152,480 : Cost 22.65732574 : Time 1167.07s : 17045.30 words/s : L.r. 5.9409e-05
[2019-02-21 16:47:30] Ep. 41 : Up. 408500 : Sen. 19,258,114 : Cost 23.00447845 : Time 1376.67s : 14574.81 words/s : L.r. 5.9372e-05
train_trans.sh: line 27: 20397 Terminated              $marian_home/marian --model model/model.src1tgt0.newvocab.3.npz --type transformer --train-sets corp/opensub.en-fr.docs.train.en.bpe corp/opensub.en-fr.docs.train.fr.bpe --max-length 110 --dim-vocabs 30000 30000 --vocabs corp/vocab.encz.opensub.new.yml corp/vocab.encz.opensub.new.yml --mini-batch-fit -w 10000 --mini-batch 1000 --maxi-batch 1000 --early-stopping 10 --valid-freq 5000 --save-freq 5000 --disp-freq 500 --valid-metrics cross-entropy perplexity translation --valid-sets corp/opensub.en-fr.docs.dev.en.bpe corp/opensub.en-fr.docs.dev.fr.bpe --valid-script-path ./val.sh --valid-translation-output data/valid.bpe.en.output --quiet-translation --valid-mini-batch 64 --beam-size 6 --normalize 0.6 --log model/train_trans.newvocab.log --valid-log model/valid_trans.newvocab.log --enc-depth 6 --dec-depth 6 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --optimizer-delay 8 --devices 0 1 --sync-sgd --seed 1111 --exponential-smoothing --no-nccl --no-restore-corpus
