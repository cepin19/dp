[2019-05-08 23:17:28] [marian] Marian v1.7.8 12fc6fc 2019-05-08 22:41:02 +0200
[2019-05-08 23:17:28] [marian] Running on bakchus.lingea.cz as process 32629 with command line:
[2019-05-08 23:17:28] [marian] /home/large/data/models/marian/marian-doc/doc-marian3/build/marian --model model/model.voita.gat32.npz --pretrained-model ../src0tgt0_fr/model/model.src0tgt0.newvocab.iter630000.npz --type transformer-voita --train-sets corp/opensub.en-fr.docs.train.en.bpe.src_prev corp/opensub.en-fr.docs.train.en.bpe.src corp/opensub.en-fr.docs.train.fr.bpe --max-length 55 --dim-vocabs 30000 30000 --vocabs corp/vocab.encz.opensub.new.yml corp/vocab.encz.opensub.new.yml corp/vocab.encz.opensub.new.yml --mini-batch-fit -w 9300 --mini-batch 1000 --maxi-batch 1000 --early-stopping 10 --valid-freq 5000 --save-freq 5000 --disp-freq 500 --valid-metrics cross-entropy perplexity translation --valid-sets corp/opensub.en-fr.docs.dev.en.bpe.src_prev corp/opensub.en-fr.docs.dev.en.bpe.src corp/opensub.en-fr.docs.dev.fr.bpe --valid-script-path ./val.sh --valid-translation-output data/valid.bpe.en.output --quiet-translation --valid-mini-batch 64 --beam-size 6 --normalize 0.6 --log model/train_trans.gate.log --valid-log model/valid_trans.gate.log --enc-depth 6 --dec-depth 6 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0002 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --optimizer-delay 4 --devices 0 --sync-sgd --seed 1111 --exponential-smoothing --no-restore-corpus
[2019-05-08 23:17:28] [config] after-batches: 0
[2019-05-08 23:17:28] [config] after-epochs: 0
[2019-05-08 23:17:28] [config] allow-unk: false
[2019-05-08 23:17:28] [config] beam-size: 6
[2019-05-08 23:17:28] [config] bert-class-symbol: "[CLS]"
[2019-05-08 23:17:28] [config] bert-mask-symbol: "[MASK]"
[2019-05-08 23:17:28] [config] bert-masking-fraction: 0.15
[2019-05-08 23:17:28] [config] bert-sep-symbol: "[SEP]"
[2019-05-08 23:17:28] [config] bert-train-type-embeddings: true
[2019-05-08 23:17:28] [config] bert-type-vocab-size: 2
[2019-05-08 23:17:28] [config] best-deep: false
[2019-05-08 23:17:28] [config] clip-gemm: 0
[2019-05-08 23:17:28] [config] clip-norm: 5
[2019-05-08 23:17:28] [config] context-enc-depth: 1
[2019-05-08 23:17:28] [config] cost-type: ce-mean
[2019-05-08 23:17:28] [config] cpu-threads: 0
[2019-05-08 23:17:28] [config] data-weighting: ""
[2019-05-08 23:17:28] [config] data-weighting-type: sentence
[2019-05-08 23:17:28] [config] dec-cell: gru
[2019-05-08 23:17:28] [config] dec-cell-base-depth: 2
[2019-05-08 23:17:28] [config] dec-cell-high-depth: 1
[2019-05-08 23:17:28] [config] dec-depth: 6
[2019-05-08 23:17:28] [config] devices:
[2019-05-08 23:17:28] [config]   - 0
[2019-05-08 23:17:28] [config] dim-emb: 512
[2019-05-08 23:17:28] [config] dim-rnn: 1024
[2019-05-08 23:17:28] [config] dim-vocabs:
[2019-05-08 23:17:28] [config]   - 30000
[2019-05-08 23:17:28] [config]   - 30000
[2019-05-08 23:17:28] [config] disp-first: 0
[2019-05-08 23:17:28] [config] disp-freq: 500
[2019-05-08 23:17:28] [config] disp-label-counts: false
[2019-05-08 23:17:28] [config] dropout-rnn: 0
[2019-05-08 23:17:28] [config] dropout-src: 0
[2019-05-08 23:17:28] [config] dropout-trg: 0
[2019-05-08 23:17:28] [config] dump-config: ""
[2019-05-08 23:17:28] [config] early-stopping: 10
[2019-05-08 23:17:28] [config] embedding-fix-src: false
[2019-05-08 23:17:28] [config] embedding-fix-trg: false
[2019-05-08 23:17:28] [config] embedding-normalization: false
[2019-05-08 23:17:28] [config] embedding-vectors:
[2019-05-08 23:17:28] [config]   []
[2019-05-08 23:17:28] [config] enc-cell: gru
[2019-05-08 23:17:28] [config] enc-cell-depth: 1
[2019-05-08 23:17:28] [config] enc-depth: 6
[2019-05-08 23:17:28] [config] enc-type: bidirectional
[2019-05-08 23:17:28] [config] exponential-smoothing: 0.0001
[2019-05-08 23:17:28] [config] freeze: false
[2019-05-08 23:17:28] [config] grad-dropping-momentum: 0
[2019-05-08 23:17:28] [config] grad-dropping-rate: 0
[2019-05-08 23:17:28] [config] grad-dropping-warmup: 100
[2019-05-08 23:17:28] [config] guided-alignment: none
[2019-05-08 23:17:28] [config] guided-alignment-cost: mse
[2019-05-08 23:17:28] [config] guided-alignment-weight: 0.1
[2019-05-08 23:17:28] [config] ignore-model-config: false
[2019-05-08 23:17:28] [config] input-types:
[2019-05-08 23:17:28] [config]   []
[2019-05-08 23:17:28] [config] interpolate-env-vars: false
[2019-05-08 23:17:28] [config] keep-best: false
[2019-05-08 23:17:28] [config] label-smoothing: 0.1
[2019-05-08 23:17:28] [config] layer-normalization: false
[2019-05-08 23:17:28] [config] learn-rate: 0.0002
[2019-05-08 23:17:28] [config] log: model/train_trans.gate.log
[2019-05-08 23:17:28] [config] log-level: info
[2019-05-08 23:17:28] [config] log-time-zone: ""
[2019-05-08 23:17:28] [config] lr-decay: 0
[2019-05-08 23:17:28] [config] lr-decay-freq: 50000
[2019-05-08 23:17:28] [config] lr-decay-inv-sqrt:
[2019-05-08 23:17:28] [config]   - 16000
[2019-05-08 23:17:28] [config] lr-decay-repeat-warmup: false
[2019-05-08 23:17:28] [config] lr-decay-reset-optimizer: false
[2019-05-08 23:17:28] [config] lr-decay-start:
[2019-05-08 23:17:28] [config]   - 10
[2019-05-08 23:17:28] [config]   - 1
[2019-05-08 23:17:28] [config] lr-decay-strategy: epoch+stalled
[2019-05-08 23:17:28] [config] lr-report: true
[2019-05-08 23:17:28] [config] lr-warmup: 16000
[2019-05-08 23:17:28] [config] lr-warmup-at-reload: false
[2019-05-08 23:17:28] [config] lr-warmup-cycle: false
[2019-05-08 23:17:28] [config] lr-warmup-start-rate: 0
[2019-05-08 23:17:28] [config] max-length: 55
[2019-05-08 23:17:28] [config] max-length-crop: false
[2019-05-08 23:17:28] [config] max-length-factor: 3
[2019-05-08 23:17:28] [config] maxi-batch: 1000
[2019-05-08 23:17:28] [config] maxi-batch-sort: trg
[2019-05-08 23:17:28] [config] mini-batch: 1000
[2019-05-08 23:17:28] [config] mini-batch-fit: true
[2019-05-08 23:17:28] [config] mini-batch-fit-step: 10
[2019-05-08 23:17:28] [config] mini-batch-overstuff: 1
[2019-05-08 23:17:28] [config] mini-batch-track-lr: false
[2019-05-08 23:17:28] [config] mini-batch-understuff: 1
[2019-05-08 23:17:28] [config] mini-batch-warmup: 0
[2019-05-08 23:17:28] [config] mini-batch-words: 0
[2019-05-08 23:17:28] [config] mini-batch-words-ref: 0
[2019-05-08 23:17:28] [config] model: model/model.voita.gat32.npz
[2019-05-08 23:17:28] [config] multi-loss-type: sum
[2019-05-08 23:17:28] [config] multi-node: false
[2019-05-08 23:17:28] [config] multi-node-overlap: true
[2019-05-08 23:17:28] [config] n-best: false
[2019-05-08 23:17:28] [config] no-nccl: false
[2019-05-08 23:17:28] [config] no-reload: false
[2019-05-08 23:17:28] [config] no-restore-corpus: true
[2019-05-08 23:17:28] [config] no-shuffle: false
[2019-05-08 23:17:28] [config] normalize: 0.6
[2019-05-08 23:17:28] [config] num-devices: 0
[2019-05-08 23:17:28] [config] optimizer: adam
[2019-05-08 23:17:28] [config] optimizer-delay: 4
[2019-05-08 23:17:28] [config] optimizer-params:
[2019-05-08 23:17:28] [config]   - 0.9
[2019-05-08 23:17:28] [config]   - 0.98
[2019-05-08 23:17:28] [config]   - 1e-09
[2019-05-08 23:17:28] [config] overwrite: false
[2019-05-08 23:17:28] [config] pretrained-model: ../src0tgt0_fr/model/model.src0tgt0.newvocab.iter630000.npz
[2019-05-08 23:17:28] [config] quiet: false
[2019-05-08 23:17:28] [config] quiet-translation: true
[2019-05-08 23:17:28] [config] relative-paths: false
[2019-05-08 23:17:28] [config] right-left: false
[2019-05-08 23:17:28] [config] save-freq: 5000
[2019-05-08 23:17:28] [config] seed: 1111
[2019-05-08 23:17:28] [config] shuffle-in-ram: false
[2019-05-08 23:17:28] [config] skip: false
[2019-05-08 23:17:28] [config] sqlite: ""
[2019-05-08 23:17:28] [config] sqlite-drop: false
[2019-05-08 23:17:28] [config] sync-sgd: true
[2019-05-08 23:17:28] [config] tempdir: /tmp
[2019-05-08 23:17:28] [config] tied-embeddings: false
[2019-05-08 23:17:28] [config] tied-embeddings-all: true
[2019-05-08 23:17:28] [config] tied-embeddings-src: false
[2019-05-08 23:17:28] [config] train-sets:
[2019-05-08 23:17:28] [config]   - corp/opensub.en-fr.docs.train.en.bpe.src_prev
[2019-05-08 23:17:28] [config]   - corp/opensub.en-fr.docs.train.en.bpe.src
[2019-05-08 23:17:28] [config]   - corp/opensub.en-fr.docs.train.fr.bpe
[2019-05-08 23:17:28] [config] transformer-aan-activation: swish
[2019-05-08 23:17:28] [config] transformer-aan-depth: 2
[2019-05-08 23:17:28] [config] transformer-aan-nogate: false
[2019-05-08 23:17:28] [config] transformer-decoder-autoreg: self-attention
[2019-05-08 23:17:28] [config] transformer-dim-aan: 2048
[2019-05-08 23:17:28] [config] transformer-dim-ffn: 2048
[2019-05-08 23:17:28] [config] transformer-dropout: 0.1
[2019-05-08 23:17:28] [config] transformer-dropout-attention: 0
[2019-05-08 23:17:28] [config] transformer-dropout-ffn: 0
[2019-05-08 23:17:28] [config] transformer-ffn-activation: swish
[2019-05-08 23:17:28] [config] transformer-ffn-depth: 2
[2019-05-08 23:17:28] [config] transformer-guided-alignment-layer: last
[2019-05-08 23:17:28] [config] transformer-heads: 8
[2019-05-08 23:17:28] [config] transformer-no-projection: false
[2019-05-08 23:17:28] [config] transformer-postprocess: dan
[2019-05-08 23:17:28] [config] transformer-postprocess-emb: d
[2019-05-08 23:17:28] [config] transformer-preprocess: ""
[2019-05-08 23:17:28] [config] transformer-tied-layers:
[2019-05-08 23:17:28] [config]   []
[2019-05-08 23:17:28] [config] transformer-train-position-embeddings: false
[2019-05-08 23:17:28] [config] type: transformer-voita
[2019-05-08 23:17:28] [config] ulr: false
[2019-05-08 23:17:28] [config] ulr-dim-emb: 0
[2019-05-08 23:17:28] [config] ulr-dropout: 0
[2019-05-08 23:17:28] [config] ulr-keys-vectors: ""
[2019-05-08 23:17:28] [config] ulr-query-vectors: ""
[2019-05-08 23:17:28] [config] ulr-softmax-temperature: 1
[2019-05-08 23:17:28] [config] ulr-trainable-transformation: false
[2019-05-08 23:17:28] [config] valid-freq: 5000
[2019-05-08 23:17:28] [config] valid-log: model/valid_trans.gate.log
[2019-05-08 23:17:28] [config] valid-max-length: 1000
[2019-05-08 23:17:28] [config] valid-metrics:
[2019-05-08 23:17:28] [config]   - cross-entropy
[2019-05-08 23:17:28] [config]   - perplexity
[2019-05-08 23:17:28] [config]   - translation
[2019-05-08 23:17:28] [config] valid-mini-batch: 64
[2019-05-08 23:17:28] [config] valid-script-path: ./val.sh
[2019-05-08 23:17:28] [config] valid-sets:
[2019-05-08 23:17:28] [config]   - corp/opensub.en-fr.docs.dev.en.bpe.src_prev
[2019-05-08 23:17:28] [config]   - corp/opensub.en-fr.docs.dev.en.bpe.src
[2019-05-08 23:17:28] [config]   - corp/opensub.en-fr.docs.dev.fr.bpe
[2019-05-08 23:17:28] [config] valid-translation-output: data/valid.bpe.en.output
[2019-05-08 23:17:28] [config] vocabs:
[2019-05-08 23:17:28] [config]   - corp/vocab.encz.opensub.new.yml
[2019-05-08 23:17:28] [config]   - corp/vocab.encz.opensub.new.yml
[2019-05-08 23:17:28] [config]   - corp/vocab.encz.opensub.new.yml
[2019-05-08 23:17:28] [config] word-penalty: 0
[2019-05-08 23:17:28] [config] workspace: 9300
[2019-05-08 23:17:28] [config] Model is being created with Marian v1.7.8 12fc6fc 2019-05-08 22:41:02 +0200
[2019-05-08 23:17:28] Using synchronous training
[2019-05-08 23:17:28] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encz.opensub.new.yml
[2019-05-08 23:17:29] [data] Setting vocabulary size for input 0 to 30000
[2019-05-08 23:17:29] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encz.opensub.new.yml
[2019-05-08 23:17:29] [data] Setting vocabulary size for input 1 to 30000
[2019-05-08 23:17:29] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encz.opensub.new.yml
[2019-05-08 23:17:29] [data] Setting vocabulary size for input 2 to 30000
[2019-05-08 23:17:29] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-05-08 23:17:29] [batching] Collecting statistics for batch fitting with step size 10
[2019-05-08 23:17:30] [memory] Extending reserved space to 9344 MB (device gpu0)
[2019-05-08 23:17:30] [comm] Using NCCL 2.4.2 for GPU communication
[2019-05-08 23:17:31] [comm] NCCLCommunicator constructed successfully.
[2019-05-08 23:17:31] [training] Using 1 GPUs
[2019-05-08 23:17:31] [memory] Reserving 237 MB, device gpu0
[2019-05-08 23:17:31] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-05-08 23:17:32] [memory] Reserving 237 MB, device gpu0
[2019-05-08 23:17:44] [batching] Done. Typical MB size is 21840 target words
[2019-05-08 23:17:44] [memory] Extending reserved space to 9344 MB (device gpu0)
[2019-05-08 23:17:44] [comm] Using NCCL 2.4.2 for GPU communication
[2019-05-08 23:17:44] [comm] NCCLCommunicator constructed successfully.
[2019-05-08 23:17:44] [training] Using 1 GPUs
[2019-05-08 23:17:44] [training] Initializing model weights with the pre-trained model ../src0tgt0_fr/model/model.src0tgt0.newvocab.iter630000.npz
[2019-05-08 23:17:44] Loading model from ../src0tgt0_fr/model/model.src0tgt0.newvocab.iter630000.npz
[2019-05-08 23:17:46] Training started
[2019-05-08 23:17:46] [data] Shuffling data
[2019-05-08 23:18:29] [data] Done reading 41736982 sentences
[2019-05-08 23:21:54] [data] Done shuffling 41736982 sentences to temp files
[2019-05-08 23:22:31] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-05-08 23:22:31] [memory] Reserving 249 MB, device gpu0
[2019-05-08 23:22:32] [memory] Reserving 249 MB, device gpu0
[2019-05-08 23:22:32] [memory] Reserving 249 MB, device gpu0
[2019-05-08 23:22:33] [memory] Reserving 498 MB, device gpu0
[2019-05-08 23:31:02] Ep. 1 : Up. 500 : Sen. 481,176 : Cost 60.40637970 : Time 813.24s : 5463.77 words/s : L.r. 6.2500e-06
[2019-05-08 23:39:40] Ep. 1 : Up. 1000 : Sen. 948,383 : Cost 25.83437729 : Time 517.52s : 8680.58 words/s : L.r. 1.2500e-05
[2019-05-08 23:48:22] Ep. 1 : Up. 1500 : Sen. 1,430,450 : Cost 23.65386009 : Time 521.89s : 8632.72 words/s : L.r. 1.8750e-05
[2019-05-08 23:57:01] Ep. 1 : Up. 2000 : Sen. 1,901,686 : Cost 24.06532860 : Time 519.22s : 8664.52 words/s : L.r. 2.5000e-05
[2019-05-09 00:05:46] Ep. 1 : Up. 2500 : Sen. 2,378,288 : Cost 24.08266258 : Time 525.19s : 8651.69 words/s : L.r. 3.1250e-05
[2019-05-09 00:14:15] Ep. 1 : Up. 3000 : Sen. 2,843,733 : Cost 23.44917488 : Time 508.88s : 8630.79 words/s : L.r. 3.7500e-05
[2019-05-09 00:22:50] Ep. 1 : Up. 3500 : Sen. 3,299,767 : Cost 24.50586319 : Time 515.25s : 8635.94 words/s : L.r. 4.3750e-05
[2019-05-09 00:31:31] Ep. 1 : Up. 4000 : Sen. 3,782,479 : Cost 22.87637711 : Time 520.68s : 8513.15 words/s : L.r. 5.0000e-05
[2019-05-09 00:40:11] Ep. 1 : Up. 4500 : Sen. 4,260,777 : Cost 23.29438591 : Time 519.92s : 8615.04 words/s : L.r. 5.6250e-05
[2019-05-09 00:48:52] Ep. 1 : Up. 5000 : Sen. 4,725,790 : Cost 24.22668839 : Time 521.24s : 8607.33 words/s : L.r. 6.2500e-05
[2019-05-09 00:48:52] Saving model weights and runtime parameters to model/model.voita.gat32.npz.orig.npz
[2019-05-09 00:48:57] Saving model weights and runtime parameters to model/model.voita.gat32.iter5000.npz
[2019-05-09 00:49:01] Saving model weights and runtime parameters to model/model.voita.gat32.npz
[2019-05-09 00:49:05] Saving Adam parameters to model/model.voita.gat32.npz.optimizer.npz
[2019-05-09 00:49:19] [valid] Ep. 1 : Up. 5000 : cross-entropy : 19.2566 : new best
[2019-05-09 00:49:25] [valid] Ep. 1 : Up. 5000 : perplexity : 4.45521 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-05-09 00:50:30] [valid] Ep. 1 : Up. 5000 : translation : 34.15 : new best
[2019-05-09 00:59:03] Ep. 1 : Up. 5500 : Sen. 5,204,499 : Cost 22.85630989 : Time 610.38s : 7182.60 words/s : L.r. 6.8750e-05
[2019-05-09 01:07:49] Ep. 1 : Up. 6000 : Sen. 5,671,244 : Cost 24.35979080 : Time 525.94s : 8618.67 words/s : L.r. 7.5000e-05
[2019-05-09 01:16:27] Ep. 1 : Up. 6500 : Sen. 6,136,632 : Cost 23.98965454 : Time 518.06s : 8697.35 words/s : L.r. 8.1250e-05
[2019-05-09 01:25:13] Ep. 1 : Up. 7000 : Sen. 6,613,609 : Cost 23.52381516 : Time 526.24s : 8554.69 words/s : L.r. 8.7500e-05
[2019-05-09 01:33:52] Ep. 1 : Up. 7500 : Sen. 7,091,964 : Cost 23.40324593 : Time 518.98s : 8579.09 words/s : L.r. 9.3750e-05
[2019-05-09 01:42:30] Ep. 1 : Up. 8000 : Sen. 7,556,491 : Cost 23.92927551 : Time 518.29s : 8512.81 words/s : L.r. 1.0000e-04
[2019-05-09 01:51:15] Ep. 1 : Up. 8500 : Sen. 8,037,273 : Cost 23.68016815 : Time 524.83s : 8648.99 words/s : L.r. 1.0625e-04
[2019-05-09 01:59:54] Ep. 1 : Up. 9000 : Sen. 8,517,143 : Cost 23.39468956 : Time 519.00s : 8626.71 words/s : L.r. 1.1250e-04
[2019-05-09 02:08:35] Ep. 1 : Up. 9500 : Sen. 8,989,896 : Cost 23.80783081 : Time 520.86s : 8573.50 words/s : L.r. 1.1875e-04
[2019-05-09 02:17:00] Ep. 1 : Up. 10000 : Sen. 9,447,976 : Cost 23.57843208 : Time 505.23s : 8455.49 words/s : L.r. 1.2500e-04
[2019-05-09 02:17:00] Saving model weights and runtime parameters to model/model.voita.gat32.npz.orig.npz
[2019-05-09 02:17:04] Saving model weights and runtime parameters to model/model.voita.gat32.iter10000.npz
[2019-05-09 02:17:08] Saving model weights and runtime parameters to model/model.voita.gat32.npz
[2019-05-09 02:17:12] Saving Adam parameters to model/model.voita.gat32.npz.optimizer.npz
[2019-05-09 02:17:27] [valid] Ep. 1 : Up. 10000 : cross-entropy : 19.1797 : new best
[2019-05-09 02:17:33] [valid] Ep. 1 : Up. 10000 : perplexity : 4.42869 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-05-09 02:18:39] [valid] Ep. 1 : Up. 10000 : translation : 34.41 : new best
[2019-05-09 02:27:23] Ep. 1 : Up. 10500 : Sen. 9,922,221 : Cost 24.16843224 : Time 623.36s : 7310.17 words/s : L.r. 1.3125e-04
[2019-05-09 02:35:57] Ep. 1 : Up. 11000 : Sen. 10,390,666 : Cost 23.82370567 : Time 513.77s : 8599.48 words/s : L.r. 1.3750e-04
[2019-05-09 02:44:32] Ep. 1 : Up. 11500 : Sen. 10,865,770 : Cost 23.58786583 : Time 514.95s : 8589.69 words/s : L.r. 1.4375e-04
[2019-05-09 02:53:09] Ep. 1 : Up. 12000 : Sen. 11,332,027 : Cost 24.31594849 : Time 517.15s : 8626.47 words/s : L.r. 1.5000e-04
[2019-05-09 03:01:50] Ep. 1 : Up. 12500 : Sen. 11,800,518 : Cost 24.38149261 : Time 520.41s : 8611.50 words/s : L.r. 1.5625e-04
[2019-05-09 03:10:23] Ep. 1 : Up. 13000 : Sen. 12,266,446 : Cost 23.76618958 : Time 513.47s : 8528.43 words/s : L.r. 1.6250e-04
[2019-05-09 03:19:09] Ep. 1 : Up. 13500 : Sen. 12,745,591 : Cost 24.23431969 : Time 525.81s : 8663.04 words/s : L.r. 1.6875e-04
[2019-05-09 03:27:47] Ep. 1 : Up. 14000 : Sen. 13,214,452 : Cost 24.07963181 : Time 517.85s : 8591.06 words/s : L.r. 1.7500e-04
[2019-05-09 03:36:22] Ep. 1 : Up. 14500 : Sen. 13,687,367 : Cost 23.84622192 : Time 515.52s : 8568.97 words/s : L.r. 1.8125e-04
[2019-05-09 03:45:02] Ep. 1 : Up. 15000 : Sen. 14,146,402 : Cost 25.44136810 : Time 519.83s : 8652.95 words/s : L.r. 1.8750e-04
[2019-05-09 03:45:02] Saving model weights and runtime parameters to model/model.voita.gat32.npz.orig.npz
[2019-05-09 03:45:07] Saving model weights and runtime parameters to model/model.voita.gat32.iter15000.npz
[2019-05-09 03:45:10] Saving model weights and runtime parameters to model/model.voita.gat32.npz
[2019-05-09 03:45:15] Saving Adam parameters to model/model.voita.gat32.npz.optimizer.npz
[2019-05-09 03:45:30] [valid] Ep. 1 : Up. 15000 : cross-entropy : 19.2909 : stalled 1 times (last best: 19.1797)
[2019-05-09 03:45:35] [valid] Ep. 1 : Up. 15000 : perplexity : 4.46708 : stalled 1 times (last best: 4.42869)
Detokenizer Version $Revision: 4134 $
Language: en
[2019-05-09 03:46:41] [valid] Ep. 1 : Up. 15000 : translation : 34.17 : stalled 1 times (last best: 34.41)
[2019-05-09 03:55:25] Ep. 1 : Up. 15500 : Sen. 14,629,058 : Cost 23.72946930 : Time 622.40s : 7192.49 words/s : L.r. 1.9375e-04
[2019-05-09 04:04:00] Ep. 1 : Up. 16000 : Sen. 15,105,707 : Cost 23.64043427 : Time 515.89s : 8582.76 words/s : L.r. 2.0000e-04
[2019-05-09 04:12:39] Ep. 1 : Up. 16500 : Sen. 15,567,792 : Cost 24.93846512 : Time 518.28s : 8585.66 words/s : L.r. 1.9695e-04
[2019-05-09 04:21:19] Ep. 1 : Up. 17000 : Sen. 16,049,913 : Cost 23.62482262 : Time 520.11s : 8592.83 words/s : L.r. 1.9403e-04
[2019-05-09 04:29:54] Ep. 1 : Up. 17500 : Sen. 16,521,282 : Cost 24.07547188 : Time 515.05s : 8589.21 words/s : L.r. 1.9124e-04
[2019-05-09 04:38:42] Ep. 1 : Up. 18000 : Sen. 16,996,580 : Cost 24.86492920 : Time 527.81s : 8695.48 words/s : L.r. 1.8856e-04
[2019-05-09 04:47:24] Ep. 1 : Up. 18500 : Sen. 17,476,346 : Cost 24.07585144 : Time 522.76s : 8649.35 words/s : L.r. 1.8600e-04
[2019-05-09 04:55:57] Ep. 1 : Up. 19000 : Sen. 17,938,059 : Cost 24.38775253 : Time 512.31s : 8543.35 words/s : L.r. 1.8353e-04
[2019-05-09 05:04:38] Ep. 1 : Up. 19500 : Sen. 18,416,942 : Cost 23.98739243 : Time 521.49s : 8610.03 words/s : L.r. 1.8116e-04
[2019-05-09 05:13:23] Ep. 1 : Up. 20000 : Sen. 18,896,933 : Cost 24.10888863 : Time 524.57s : 8584.13 words/s : L.r. 1.7889e-04
[2019-05-09 05:13:23] Saving model weights and runtime parameters to model/model.voita.gat32.npz.orig.npz
[2019-05-09 05:13:27] Saving model weights and runtime parameters to model/model.voita.gat32.iter20000.npz
[2019-05-09 05:13:31] Saving model weights and runtime parameters to model/model.voita.gat32.npz
[2019-05-09 05:13:36] Saving Adam parameters to model/model.voita.gat32.npz.optimizer.npz
[2019-05-09 05:13:50] [valid] Ep. 1 : Up. 20000 : cross-entropy : 19.4424 : stalled 2 times (last best: 19.1797)
[2019-05-09 05:13:56] [valid] Ep. 1 : Up. 20000 : perplexity : 4.5199 : stalled 2 times (last best: 4.42869)
Detokenizer Version $Revision: 4134 $
Language: en
[2019-05-09 05:15:01] [valid] Ep. 1 : Up. 20000 : translation : 34.07 : stalled 2 times (last best: 34.41)
[2019-05-09 05:23:34] Ep. 1 : Up. 20500 : Sen. 19,358,960 : Cost 24.39231682 : Time 610.97s : 7145.49 words/s : L.r. 1.7669e-04
[2019-05-09 05:32:25] Ep. 1 : Up. 21000 : Sen. 19,847,892 : Cost 24.04392815 : Time 531.51s : 8692.15 words/s : L.r. 1.7457e-04
[2019-05-09 05:41:00] Ep. 1 : Up. 21500 : Sen. 20,322,526 : Cost 23.75210571 : Time 514.66s : 8547.04 words/s : L.r. 1.7253e-04
[2019-05-09 05:49:40] Ep. 1 : Up. 22000 : Sen. 20,788,362 : Cost 24.61178207 : Time 520.32s : 8597.49 words/s : L.r. 1.7056e-04
[2019-05-09 05:58:26] Ep. 1 : Up. 22500 : Sen. 21,267,860 : Cost 24.12359238 : Time 526.05s : 8647.81 words/s : L.r. 1.6865e-04
[2019-05-09 06:07:09] Ep. 1 : Up. 23000 : Sen. 21,744,610 : Cost 24.25555038 : Time 522.63s : 8680.46 words/s : L.r. 1.6681e-04
[2019-05-09 06:15:40] Ep. 1 : Up. 23500 : Sen. 22,203,855 : Cost 24.49468231 : Time 510.74s : 8501.80 words/s : L.r. 1.6503e-04
[2019-05-09 06:24:25] Ep. 1 : Up. 24000 : Sen. 22,677,112 : Cost 24.40351105 : Time 525.57s : 8676.54 words/s : L.r. 1.6330e-04
[2019-05-09 06:33:00] Ep. 1 : Up. 24500 : Sen. 23,144,408 : Cost 23.96148300 : Time 514.27s : 8445.07 words/s : L.r. 1.6162e-04
[2019-05-09 06:41:38] Ep. 1 : Up. 25000 : Sen. 23,627,306 : Cost 23.27756119 : Time 518.02s : 8550.76 words/s : L.r. 1.6000e-04
[2019-05-09 06:41:38] Saving model weights and runtime parameters to model/model.voita.gat32.npz.orig.npz
[2019-05-09 06:41:42] Saving model weights and runtime parameters to model/model.voita.gat32.iter25000.npz
[2019-05-09 06:41:46] Saving model weights and runtime parameters to model/model.voita.gat32.npz
[2019-05-09 06:41:51] Saving Adam parameters to model/model.voita.gat32.npz.optimizer.npz
[2019-05-09 06:42:05] [valid] Ep. 1 : Up. 25000 : cross-entropy : 19.459 : stalled 3 times (last best: 19.1797)
[2019-05-09 06:42:11] [valid] Ep. 1 : Up. 25000 : perplexity : 4.5257 : stalled 3 times (last best: 4.42869)
Detokenizer Version $Revision: 4134 $
Language: en
[2019-05-09 06:43:17] [valid] Ep. 1 : Up. 25000 : translation : 33.94 : stalled 3 times (last best: 34.41)
[2019-05-09 06:52:02] Ep. 1 : Up. 25500 : Sen. 24,085,909 : Cost 25.44165993 : Time 624.10s : 7275.20 words/s : L.r. 1.5842e-04
[2019-05-09 07:00:42] Ep. 1 : Up. 26000 : Sen. 24,560,271 : Cost 24.16455650 : Time 520.77s : 8623.12 words/s : L.r. 1.5689e-04
[2019-05-09 07:09:16] Ep. 1 : Up. 26500 : Sen. 25,029,620 : Cost 23.84723091 : Time 513.97s : 8553.66 words/s : L.r. 1.5541e-04
[2019-05-09 07:17:52] Ep. 1 : Up. 27000 : Sen. 25,509,345 : Cost 23.44184494 : Time 515.09s : 8548.27 words/s : L.r. 1.5396e-04
[2019-05-09 07:26:39] Ep. 1 : Up. 27500 : Sen. 25,980,875 : Cost 24.69228935 : Time 527.06s : 8673.12 words/s : L.r. 1.5255e-04
[2019-05-09 07:35:19] Ep. 1 : Up. 28000 : Sen. 26,449,004 : Cost 24.34705544 : Time 520.32s : 8546.08 words/s : L.r. 1.5119e-04
[2019-05-09 07:44:00] Ep. 1 : Up. 28500 : Sen. 26,924,091 : Cost 23.87774277 : Time 520.80s : 8617.60 words/s : L.r. 1.4985e-04
[2019-05-09 07:52:46] Ep. 1 : Up. 29000 : Sen. 27,397,779 : Cost 24.71675873 : Time 526.53s : 8684.94 words/s : L.r. 1.4856e-04
[2019-05-09 08:01:33] Ep. 1 : Up. 29500 : Sen. 27,883,100 : Cost 23.57194710 : Time 526.66s : 8535.63 words/s : L.r. 1.4729e-04
[2019-05-09 08:10:02] Ep. 1 : Up. 30000 : Sen. 28,343,547 : Cost 24.06373405 : Time 509.54s : 8499.35 words/s : L.r. 1.4606e-04
[2019-05-09 08:10:02] Saving model weights and runtime parameters to model/model.voita.gat32.npz.orig.npz
[2019-05-09 08:10:07] Saving model weights and runtime parameters to model/model.voita.gat32.iter30000.npz
[2019-05-09 08:10:10] Saving model weights and runtime parameters to model/model.voita.gat32.npz
[2019-05-09 08:10:15] Saving Adam parameters to model/model.voita.gat32.npz.optimizer.npz
[2019-05-09 08:10:28] [valid] Ep. 1 : Up. 30000 : cross-entropy : 19.4323 : stalled 4 times (last best: 19.1797)
[2019-05-09 08:10:34] [valid] Ep. 1 : Up. 30000 : perplexity : 4.51633 : stalled 4 times (last best: 4.42869)
Detokenizer Version $Revision: 4134 $
Language: en
[2019-05-09 08:11:41] [valid] Ep. 1 : Up. 30000 : translation : 34.19 : stalled 4 times (last best: 34.41)
[2019-05-09 08:20:24] Ep. 1 : Up. 30500 : Sen. 28,822,887 : Cost 23.96549034 : Time 621.91s : 7262.91 words/s : L.r. 1.4486e-04
[2019-05-09 08:29:08] Ep. 1 : Up. 31000 : Sen. 29,295,014 : Cost 24.34212112 : Time 523.90s : 8630.84 words/s : L.r. 1.4368e-04
[2019-05-09 08:37:37] Ep. 1 : Up. 31500 : Sen. 29,757,642 : Cost 23.77670670 : Time 508.33s : 8542.36 words/s : L.r. 1.4254e-04
[2019-05-09 08:46:31] Ep. 1 : Up. 32000 : Sen. 30,237,925 : Cost 24.47416687 : Time 534.22s : 8620.85 words/s : L.r. 1.4142e-04
[2019-05-09 08:55:07] Ep. 1 : Up. 32500 : Sen. 30,703,768 : Cost 24.05625153 : Time 515.85s : 8550.13 words/s : L.r. 1.4033e-04
[2019-05-09 09:03:48] Ep. 1 : Up. 33000 : Sen. 31,202,413 : Cost 22.79760170 : Time 521.06s : 8610.19 words/s : L.r. 1.3926e-04
[2019-05-09 09:12:28] Ep. 1 : Up. 33500 : Sen. 31,667,817 : Cost 24.27531433 : Time 519.89s : 8537.44 words/s : L.r. 1.3822e-04
[2019-05-09 09:21:08] Ep. 1 : Up. 34000 : Sen. 32,139,044 : Cost 24.28679657 : Time 519.92s : 8672.58 words/s : L.r. 1.3720e-04
[2019-05-09 09:29:47] Ep. 1 : Up. 34500 : Sen. 32,610,247 : Cost 24.31307983 : Time 519.90s : 8656.50 words/s : L.r. 1.3620e-04
[2019-05-09 09:38:28] Ep. 1 : Up. 35000 : Sen. 33,075,532 : Cost 24.34843445 : Time 520.70s : 8547.59 words/s : L.r. 1.3522e-04
[2019-05-09 09:38:28] Saving model weights and runtime parameters to model/model.voita.gat32.npz.orig.npz
[2019-05-09 09:38:32] Saving model weights and runtime parameters to model/model.voita.gat32.iter35000.npz
[2019-05-09 09:38:36] Saving model weights and runtime parameters to model/model.voita.gat32.npz
[2019-05-09 09:38:40] Saving Adam parameters to model/model.voita.gat32.npz.optimizer.npz
[2019-05-09 09:38:54] [valid] Ep. 1 : Up. 35000 : cross-entropy : 19.3998 : stalled 5 times (last best: 19.1797)
[2019-05-09 09:39:00] [valid] Ep. 1 : Up. 35000 : perplexity : 4.50498 : stalled 5 times (last best: 4.42869)
Detokenizer Version $Revision: 4134 $
Language: en
[2019-05-09 09:40:06] [valid] Ep. 1 : Up. 35000 : translation : 34.11 : stalled 5 times (last best: 34.41)
[2019-05-09 09:48:42] Ep. 1 : Up. 35500 : Sen. 33,546,292 : Cost 24.02648735 : Time 613.68s : 7251.64 words/s : L.r. 1.3427e-04
[2019-05-09 09:57:28] Ep. 1 : Up. 36000 : Sen. 34,026,327 : Cost 23.72845650 : Time 525.98s : 8548.14 words/s : L.r. 1.3333e-04
[2019-05-09 10:06:15] Ep. 1 : Up. 36500 : Sen. 34,500,608 : Cost 24.45585823 : Time 527.01s : 8669.29 words/s : L.r. 1.3242e-04
[2019-05-09 10:14:53] Ep. 1 : Up. 37000 : Sen. 34,982,373 : Cost 23.31611443 : Time 518.25s : 8567.47 words/s : L.r. 1.3152e-04
[2019-05-09 10:23:26] Ep. 1 : Up. 37500 : Sen. 35,464,458 : Cost 22.98449326 : Time 512.73s : 8581.04 words/s : L.r. 1.3064e-04
[2019-05-09 10:32:09] Ep. 1 : Up. 38000 : Sen. 35,924,843 : Cost 25.04325867 : Time 523.21s : 8647.13 words/s : L.r. 1.2978e-04
[2019-05-09 10:40:47] Ep. 1 : Up. 38500 : Sen. 36,381,322 : Cost 25.06327820 : Time 517.94s : 8618.21 words/s : L.r. 1.2893e-04
[2019-05-09 10:49:25] Ep. 1 : Up. 39000 : Sen. 36,861,314 : Cost 23.10605240 : Time 517.76s : 8486.68 words/s : L.r. 1.2810e-04
[2019-05-09 10:58:16] Ep. 1 : Up. 39500 : Sen. 37,348,850 : Cost 24.06753731 : Time 531.29s : 8705.99 words/s : L.r. 1.2729e-04
[2019-05-09 11:06:56] Ep. 1 : Up. 40000 : Sen. 37,818,555 : Cost 24.07733345 : Time 520.39s : 8570.33 words/s : L.r. 1.2649e-04
[2019-05-09 11:06:56] Saving model weights and runtime parameters to model/model.voita.gat32.npz.orig.npz
[2019-05-09 11:07:01] Saving model weights and runtime parameters to model/model.voita.gat32.iter40000.npz
[2019-05-09 11:07:04] Saving model weights and runtime parameters to model/model.voita.gat32.npz
[2019-05-09 11:07:09] Saving Adam parameters to model/model.voita.gat32.npz.optimizer.npz
[2019-05-09 11:07:23] [valid] Ep. 1 : Up. 40000 : cross-entropy : 19.3638 : stalled 6 times (last best: 19.1797)
[2019-05-09 11:07:29] [valid] Ep. 1 : Up. 40000 : perplexity : 4.4924 : stalled 6 times (last best: 4.42869)
Detokenizer Version $Revision: 4134 $
Language: en
[2019-05-09 11:08:35] [valid] Ep. 1 : Up. 40000 : translation : 34.23 : stalled 6 times (last best: 34.41)
[2019-05-09 11:17:03] Ep. 1 : Up. 40500 : Sen. 38,274,172 : Cost 24.18753624 : Time 606.84s : 7120.40 words/s : L.r. 1.2571e-04
[2019-05-09 11:25:42] Ep. 1 : Up. 41000 : Sen. 38,741,924 : Cost 24.11561966 : Time 519.21s : 8638.60 words/s : L.r. 1.2494e-04
[2019-05-09 11:34:32] Ep. 1 : Up. 41500 : Sen. 39,242,214 : Cost 22.95358849 : Time 529.59s : 8612.89 words/s : L.r. 1.2418e-04
[2019-05-09 11:43:14] Ep. 1 : Up. 42000 : Sen. 39,710,424 : Cost 24.39696693 : Time 521.71s : 8579.16 words/s : L.r. 1.2344e-04
[2019-05-09 11:51:40] Ep. 1 : Up. 42500 : Sen. 40,165,220 : Cost 23.82444191 : Time 506.65s : 8453.72 words/s : L.r. 1.2271e-04
[2019-05-09 12:00:14] Ep. 1 : Up. 43000 : Sen. 40,627,736 : Cost 24.39549255 : Time 514.04s : 8611.66 words/s : L.r. 1.2200e-04
[2019-05-09 12:08:55] Ep. 1 : Up. 43500 : Sen. 41,108,145 : Cost 23.62339973 : Time 520.98s : 8644.30 words/s : L.r. 1.2130e-04
[2019-05-09 12:17:19] Ep. 1 : Up. 44000 : Sen. 41,561,708 : Cost 23.62334633 : Time 503.92s : 8437.26 words/s : L.r. 1.2060e-04
[2019-05-09 12:20:13] Seen 41709169 samples
[2019-05-09 12:20:13] Starting epoch 2
[2019-05-09 12:20:13] [data] Shuffling data
[2019-05-09 12:20:56] [data] Done reading 41736982 sentences
[2019-05-09 12:24:25] [data] Done shuffling 41736982 sentences to temp files
[2019-05-09 12:30:45] Ep. 2 : Up. 44500 : Sen. 323,175 : Cost 23.84676743 : Time 805.46s : 5509.73 words/s : L.r. 1.1993e-04
[2019-05-09 12:39:17] Ep. 2 : Up. 45000 : Sen. 785,474 : Cost 23.49867439 : Time 512.51s : 8430.65 words/s : L.r. 1.1926e-04
[2019-05-09 12:39:17] Saving model weights and runtime parameters to model/model.voita.gat32.npz.orig.npz
[2019-05-09 12:39:22] Saving model weights and runtime parameters to model/model.voita.gat32.iter45000.npz
[2019-05-09 12:39:26] Saving model weights and runtime parameters to model/model.voita.gat32.npz
[2019-05-09 12:39:30] Saving Adam parameters to model/model.voita.gat32.npz.optimizer.npz
[2019-05-09 12:39:44] [valid] Ep. 2 : Up. 45000 : cross-entropy : 19.3383 : stalled 7 times (last best: 19.1797)
[2019-05-09 12:39:50] [valid] Ep. 2 : Up. 45000 : perplexity : 4.48351 : stalled 7 times (last best: 4.42869)
Detokenizer Version $Revision: 4134 $
Language: en
[2019-05-09 12:40:57] [valid] Ep. 2 : Up. 45000 : translation : 34.31 : stalled 7 times (last best: 34.41)
[2019-05-09 12:49:48] Ep. 2 : Up. 45500 : Sen. 1,260,918 : Cost 24.29607773 : Time 630.68s : 7305.10 words/s : L.r. 1.1860e-04
[2019-05-09 12:58:21] Ep. 2 : Up. 46000 : Sen. 1,728,081 : Cost 23.41076088 : Time 512.97s : 8462.76 words/s : L.r. 1.1795e-04
[2019-05-09 13:07:03] Ep. 2 : Up. 46500 : Sen. 2,188,531 : Cost 24.78091049 : Time 522.41s : 8632.36 words/s : L.r. 1.1732e-04
[2019-05-09 13:15:41] Ep. 2 : Up. 47000 : Sen. 2,656,032 : Cost 23.82941628 : Time 517.74s : 8533.90 words/s : L.r. 1.1669e-04
[2019-05-09 13:24:30] Ep. 2 : Up. 47500 : Sen. 3,149,916 : Cost 23.39384079 : Time 529.34s : 8718.66 words/s : L.r. 1.1608e-04
train_voita_gated_new.sh: line 30: 32629 Terminated              $marian_home/marian --model model/model.voita.gat32.npz --pretrained-model ../src0tgt0_fr/model/model.src0tgt0.newvocab.iter630000.npz --type transformer-voita --train-sets corp/opensub.en-fr.docs.train.en.bpe.src_prev corp/opensub.en-fr.docs.train.en.bpe.src corp/opensub.en-fr.docs.train.fr.bpe --max-length 55 --dim-vocabs 30000 30000 --vocabs corp/vocab.encz.opensub.new.yml corp/vocab.encz.opensub.new.yml corp/vocab.encz.opensub.new.yml --mini-batch-fit -w 9300 --mini-batch 1000 --maxi-batch 1000 --early-stopping 10 --valid-freq 5000 --save-freq 5000 --disp-freq 500 --valid-metrics cross-entropy perplexity translation --valid-sets corp/opensub.en-fr.docs.dev.en.bpe.src_prev corp/opensub.en-fr.docs.dev.en.bpe.src corp/opensub.en-fr.docs.dev.fr.bpe --valid-script-path ./val.sh --valid-translation-output data/valid.bpe.en.output --quiet-translation --valid-mini-batch 64 --beam-size 6 --normalize 0.6 --log model/train_trans.gate.log --valid-log model/valid_trans.gate.log --enc-depth 6 --dec-depth 6 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0002 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --optimizer-delay 4 --devices 0 --sync-sgd --seed 1111 --exponential-smoothing --no-restore-corpus
