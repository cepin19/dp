[2019-05-22 00:03:04] [marian] Marian v1.7.8 63e1cfe 2019-02-11 21:04:00 -0800
[2019-05-22 00:03:04] [marian] Running on bakchus.lingea.cz as process 20599 with command line:
[2019-05-22 00:03:04] [marian] /home/big_maggie/usr/marian_bakchus/marian-dev/build/marian --model model/model.src1tgt1.npz --type transformer --train-sets corp/opensub.cs-en.docs.train.en.bpe corp/opensub.cs-en.docs.train.cs.bpe --max-length 165 --vocabs corp/vocab.encz.opensub.yml corp/vocab.encz.opensub.yml --mini-batch-fit -w 9300 --maxi-batch 1000 --early-stopping 10 --valid-freq 5000 --save-freq 5000 --disp-freq 500 --valid-metrics cross-entropy perplexity translation --valid-sets corp/opensub.cs-en.docs.dev.en.bpe corp/opensub.cs-en.docs.dev.cs.bpe --valid-script-path ./val.sh --valid-translation-output data/valid.bpe.en.output --quiet-translation --valid-mini-batch 32 --beam-size 6 --normalize 0.6 --log model/train_trans2.log --valid-log model/valid_trans2.log --enc-depth 6 --dec-depth 6 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --optimizer-delay 4 --devices 0 --sync-sgd --seed 1111 --no-nccl --exponential-smoothing --no-restore-corpus
[2019-05-22 00:03:04] [config] after-batches: 0
[2019-05-22 00:03:04] [config] after-epochs: 0
[2019-05-22 00:03:04] [config] allow-unk: false
[2019-05-22 00:03:04] [config] beam-size: 6
[2019-05-22 00:03:04] [config] bert-class-symbol: "[CLS]"
[2019-05-22 00:03:04] [config] bert-mask-symbol: "[MASK]"
[2019-05-22 00:03:04] [config] bert-masking-fraction: 0.15
[2019-05-22 00:03:04] [config] bert-sep-symbol: "[SEP]"
[2019-05-22 00:03:04] [config] bert-train-type-embeddings: true
[2019-05-22 00:03:04] [config] bert-type-vocab-size: 2
[2019-05-22 00:03:04] [config] best-deep: false
[2019-05-22 00:03:04] [config] clip-gemm: 0
[2019-05-22 00:03:04] [config] clip-norm: 5
[2019-05-22 00:03:04] [config] cost-type: ce-mean
[2019-05-22 00:03:04] [config] cpu-threads: 0
[2019-05-22 00:03:04] [config] data-weighting: ""
[2019-05-22 00:03:04] [config] data-weighting-type: sentence
[2019-05-22 00:03:04] [config] dec-cell: gru
[2019-05-22 00:03:04] [config] dec-cell-base-depth: 2
[2019-05-22 00:03:04] [config] dec-cell-high-depth: 1
[2019-05-22 00:03:04] [config] dec-depth: 6
[2019-05-22 00:03:04] [config] devices:
[2019-05-22 00:03:04] [config]   - 0
[2019-05-22 00:03:04] [config] dim-emb: 512
[2019-05-22 00:03:04] [config] dim-rnn: 1024
[2019-05-22 00:03:04] [config] dim-vocabs:
[2019-05-22 00:03:04] [config]   - 33485
[2019-05-22 00:03:04] [config]   - 33485
[2019-05-22 00:03:04] [config] disp-first: 0
[2019-05-22 00:03:04] [config] disp-freq: 500
[2019-05-22 00:03:04] [config] disp-label-counts: false
[2019-05-22 00:03:04] [config] dropout-rnn: 0
[2019-05-22 00:03:04] [config] dropout-src: 0
[2019-05-22 00:03:04] [config] dropout-trg: 0
[2019-05-22 00:03:04] [config] dump-config: ""
[2019-05-22 00:03:04] [config] early-stopping: 10
[2019-05-22 00:03:04] [config] embedding-fix-src: false
[2019-05-22 00:03:04] [config] embedding-fix-trg: false
[2019-05-22 00:03:04] [config] embedding-normalization: false
[2019-05-22 00:03:04] [config] embedding-vectors:
[2019-05-22 00:03:04] [config]   []
[2019-05-22 00:03:04] [config] enc-cell: gru
[2019-05-22 00:03:04] [config] enc-cell-depth: 1
[2019-05-22 00:03:04] [config] enc-depth: 6
[2019-05-22 00:03:04] [config] enc-type: bidirectional
[2019-05-22 00:03:04] [config] exponential-smoothing: 0.0001
[2019-05-22 00:03:04] [config] grad-dropping-momentum: 0
[2019-05-22 00:03:04] [config] grad-dropping-rate: 0
[2019-05-22 00:03:04] [config] grad-dropping-warmup: 100
[2019-05-22 00:03:04] [config] guided-alignment: none
[2019-05-22 00:03:04] [config] guided-alignment-cost: mse
[2019-05-22 00:03:04] [config] guided-alignment-weight: 0.1
[2019-05-22 00:03:04] [config] ignore-model-config: false
[2019-05-22 00:03:04] [config] input-types:
[2019-05-22 00:03:04] [config]   []
[2019-05-22 00:03:04] [config] interpolate-env-vars: false
[2019-05-22 00:03:04] [config] keep-best: false
[2019-05-22 00:03:04] [config] label-smoothing: 0.1
[2019-05-22 00:03:04] [config] layer-normalization: false
[2019-05-22 00:03:04] [config] learn-rate: 0.0003
[2019-05-22 00:03:04] [config] log: model/train_trans2.log
[2019-05-22 00:03:04] [config] log-level: info
[2019-05-22 00:03:04] [config] log-time-zone: ""
[2019-05-22 00:03:04] [config] lr-decay: 0
[2019-05-22 00:03:04] [config] lr-decay-freq: 50000
[2019-05-22 00:03:04] [config] lr-decay-inv-sqrt:
[2019-05-22 00:03:04] [config]   - 16000
[2019-05-22 00:03:04] [config] lr-decay-repeat-warmup: false
[2019-05-22 00:03:04] [config] lr-decay-reset-optimizer: false
[2019-05-22 00:03:04] [config] lr-decay-start:
[2019-05-22 00:03:04] [config]   - 10
[2019-05-22 00:03:04] [config]   - 1
[2019-05-22 00:03:04] [config] lr-decay-strategy: epoch+stalled
[2019-05-22 00:03:04] [config] lr-report: true
[2019-05-22 00:03:04] [config] lr-warmup: 16000
[2019-05-22 00:03:04] [config] lr-warmup-at-reload: false
[2019-05-22 00:03:04] [config] lr-warmup-cycle: false
[2019-05-22 00:03:04] [config] lr-warmup-start-rate: 0
[2019-05-22 00:03:04] [config] max-length: 165
[2019-05-22 00:03:04] [config] max-length-crop: false
[2019-05-22 00:03:04] [config] max-length-factor: 3
[2019-05-22 00:03:04] [config] maxi-batch: 1000
[2019-05-22 00:03:04] [config] maxi-batch-sort: trg
[2019-05-22 00:03:04] [config] mini-batch: 64
[2019-05-22 00:03:04] [config] mini-batch-fit: true
[2019-05-22 00:03:04] [config] mini-batch-fit-step: 10
[2019-05-22 00:03:04] [config] mini-batch-overstuff: 1
[2019-05-22 00:03:04] [config] mini-batch-track-lr: false
[2019-05-22 00:03:04] [config] mini-batch-understuff: 1
[2019-05-22 00:03:04] [config] mini-batch-warmup: 0
[2019-05-22 00:03:04] [config] mini-batch-words: 0
[2019-05-22 00:03:04] [config] mini-batch-words-ref: 0
[2019-05-22 00:03:04] [config] model: model/model.src1tgt1.npz
[2019-05-22 00:03:04] [config] multi-loss-type: sum
[2019-05-22 00:03:04] [config] multi-node: false
[2019-05-22 00:03:04] [config] multi-node-overlap: true
[2019-05-22 00:03:04] [config] n-best: false
[2019-05-22 00:03:04] [config] no-nccl: true
[2019-05-22 00:03:04] [config] no-reload: false
[2019-05-22 00:03:04] [config] no-restore-corpus: true
[2019-05-22 00:03:04] [config] no-shuffle: false
[2019-05-22 00:03:04] [config] normalize: 0.6
[2019-05-22 00:03:04] [config] num-devices: 0
[2019-05-22 00:03:04] [config] optimizer: adam
[2019-05-22 00:03:04] [config] optimizer-delay: 4
[2019-05-22 00:03:04] [config] optimizer-params:
[2019-05-22 00:03:04] [config]   - 0.9
[2019-05-22 00:03:04] [config]   - 0.98
[2019-05-22 00:03:04] [config]   - 1e-09
[2019-05-22 00:03:04] [config] overwrite: false
[2019-05-22 00:03:04] [config] pretrained-model: ""
[2019-05-22 00:03:04] [config] quiet: false
[2019-05-22 00:03:04] [config] quiet-translation: true
[2019-05-22 00:03:04] [config] relative-paths: false
[2019-05-22 00:03:04] [config] right-left: false
[2019-05-22 00:03:04] [config] save-freq: 5000
[2019-05-22 00:03:04] [config] seed: 1111
[2019-05-22 00:03:04] [config] shuffle-in-ram: false
[2019-05-22 00:03:04] [config] skip: false
[2019-05-22 00:03:04] [config] sqlite: ""
[2019-05-22 00:03:04] [config] sqlite-drop: false
[2019-05-22 00:03:04] [config] sync-sgd: true
[2019-05-22 00:03:04] [config] tempdir: /tmp
[2019-05-22 00:03:04] [config] tied-embeddings: false
[2019-05-22 00:03:04] [config] tied-embeddings-all: true
[2019-05-22 00:03:04] [config] tied-embeddings-src: false
[2019-05-22 00:03:04] [config] train-sets:
[2019-05-22 00:03:04] [config]   - corp/opensub.cs-en.docs.train.en.bpe
[2019-05-22 00:03:04] [config]   - corp/opensub.cs-en.docs.train.cs.bpe
[2019-05-22 00:03:04] [config] transformer-aan-activation: swish
[2019-05-22 00:03:04] [config] transformer-aan-depth: 2
[2019-05-22 00:03:04] [config] transformer-aan-nogate: false
[2019-05-22 00:03:04] [config] transformer-decoder-autoreg: self-attention
[2019-05-22 00:03:04] [config] transformer-dim-aan: 2048
[2019-05-22 00:03:04] [config] transformer-dim-ffn: 2048
[2019-05-22 00:03:04] [config] transformer-dropout: 0.1
[2019-05-22 00:03:04] [config] transformer-dropout-attention: 0
[2019-05-22 00:03:04] [config] transformer-dropout-ffn: 0
[2019-05-22 00:03:04] [config] transformer-ffn-activation: swish
[2019-05-22 00:03:04] [config] transformer-ffn-depth: 2
[2019-05-22 00:03:04] [config] transformer-guided-alignment-layer: last
[2019-05-22 00:03:04] [config] transformer-heads: 8
[2019-05-22 00:03:04] [config] transformer-no-projection: false
[2019-05-22 00:03:04] [config] transformer-postprocess: dan
[2019-05-22 00:03:04] [config] transformer-postprocess-emb: d
[2019-05-22 00:03:04] [config] transformer-preprocess: ""
[2019-05-22 00:03:04] [config] transformer-tied-layers:
[2019-05-22 00:03:04] [config]   []
[2019-05-22 00:03:04] [config] transformer-train-position-embeddings: false
[2019-05-22 00:03:04] [config] type: transformer
[2019-05-22 00:03:04] [config] ulr: false
[2019-05-22 00:03:04] [config] ulr-dim-emb: 0
[2019-05-22 00:03:04] [config] ulr-dropout: 0
[2019-05-22 00:03:04] [config] ulr-keys-vectors: ""
[2019-05-22 00:03:04] [config] ulr-query-vectors: ""
[2019-05-22 00:03:04] [config] ulr-softmax-temperature: 1
[2019-05-22 00:03:04] [config] ulr-trainable-transformation: false
[2019-05-22 00:03:04] [config] valid-freq: 5000
[2019-05-22 00:03:04] [config] valid-log: model/valid_trans2.log
[2019-05-22 00:03:04] [config] valid-max-length: 1000
[2019-05-22 00:03:04] [config] valid-metrics:
[2019-05-22 00:03:04] [config]   - cross-entropy
[2019-05-22 00:03:04] [config]   - perplexity
[2019-05-22 00:03:04] [config]   - translation
[2019-05-22 00:03:04] [config] valid-mini-batch: 32
[2019-05-22 00:03:04] [config] valid-script-path: ./val.sh
[2019-05-22 00:03:04] [config] valid-sets:
[2019-05-22 00:03:04] [config]   - corp/opensub.cs-en.docs.dev.en.bpe
[2019-05-22 00:03:04] [config]   - corp/opensub.cs-en.docs.dev.cs.bpe
[2019-05-22 00:03:04] [config] valid-translation-output: data/valid.bpe.en.output
[2019-05-22 00:03:04] [config] version: v1.7.8 63e1cfe 2019-02-11 21:04:00 -0800
[2019-05-22 00:03:04] [config] vocabs:
[2019-05-22 00:03:04] [config]   - corp/vocab.encz.opensub.yml
[2019-05-22 00:03:04] [config]   - corp/vocab.encz.opensub.yml
[2019-05-22 00:03:04] [config] word-penalty: 0
[2019-05-22 00:03:04] [config] workspace: 9300
[2019-05-22 00:03:04] [config] Loaded model has been created with Marian v1.7.8 63e1cfe 2019-02-11 21:04:00 -0800
[2019-05-22 00:03:04] Using synchronous training
[2019-05-22 00:03:04] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encz.opensub.yml
[2019-05-22 00:03:05] [data] Setting vocabulary size for input 0 to 33485
[2019-05-22 00:03:05] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encz.opensub.yml
[2019-05-22 00:03:05] [data] Setting vocabulary size for input 1 to 33485
[2019-05-22 00:03:05] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-05-22 00:03:05] [batching] Collecting statistics for batch fitting with step size 10
[2019-05-22 00:03:08] [memory] Extending reserved space to 9344 MB (device gpu0)
[2019-05-22 00:03:09] [comm] NCCL communicator overridden
[2019-05-22 00:03:09] [training] Using 1 GPUs
[2019-05-22 00:03:09] [memory] Reserving 233 MB, device gpu0
[2019-05-22 00:03:09] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-05-22 00:03:09] [memory] Reserving 233 MB, device gpu0
[2019-05-22 00:03:29] [batching] Done. Typical MB size is 20861 target words
[2019-05-22 00:03:29] [memory] Extending reserved space to 9344 MB (device gpu0)
[2019-05-22 00:03:29] [comm] NCCL communicator overridden
[2019-05-22 00:03:29] [training] Using 1 GPUs
[2019-05-22 00:03:29] Loading model from model/model.src1tgt1.npz.orig.npz
[2019-05-22 00:03:32] Loading Adam parameters from model/model.src1tgt1.npz.optimizer.npz
[2019-05-22 00:03:36] [memory] Reserving 467 MB, device gpu0
[2019-05-22 00:03:36] [training] Model reloaded from model/model.src1tgt1.npz
[2019-05-22 00:03:36] Training started
[2019-05-22 00:03:36] [data] Shuffling data
[2019-05-22 00:04:43] [data] Done reading 42314920 sentences
[2019-05-22 00:07:19] [data] Done shuffling 42314920 sentences to temp files
[2019-05-22 00:07:29] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-05-22 00:07:29] [memory] Reserving 233 MB, device gpu0
[2019-05-22 00:07:30] [memory] Reserving 233 MB, device gpu0
[2019-05-22 00:07:31] Loading model from model/model.src1tgt1.npz
[2019-05-22 00:07:34] [memory] Reserving 233 MB, device cpu0
[2019-05-22 00:07:34] [memory] Reserving 233 MB, device gpu0
[2019-05-22 00:07:34] [memory] Reserving 233 MB, device gpu0
[2019-05-22 00:13:32] Ep. 3 : Up. 270500 : Sen. 262,452 : Cost 25.45395851 : Time 627.54s : 3740.90 words/s : L.r. 7.2962e-05
[2019-05-22 00:19:40] Ep. 3 : Up. 271000 : Sen. 531,071 : Cost 25.12590981 : Time 367.52s : 6485.09 words/s : L.r. 7.2895e-05
[2019-05-22 00:25:46] Ep. 3 : Up. 271500 : Sen. 795,782 : Cost 25.56055260 : Time 366.38s : 6499.89 words/s : L.r. 7.2828e-05
[2019-05-22 00:31:50] Ep. 3 : Up. 272000 : Sen. 1,059,038 : Cost 25.22930908 : Time 364.07s : 6439.35 words/s : L.r. 7.2761e-05
[2019-05-22 00:37:58] Ep. 3 : Up. 272500 : Sen. 1,325,267 : Cost 25.31830406 : Time 367.12s : 6468.06 words/s : L.r. 7.2694e-05
[2019-05-22 00:44:04] Ep. 3 : Up. 273000 : Sen. 1,591,967 : Cost 25.18023872 : Time 366.23s : 6467.33 words/s : L.r. 7.2627e-05
[2019-05-22 00:50:14] Ep. 3 : Up. 273500 : Sen. 1,859,284 : Cost 25.11188507 : Time 369.75s : 6418.40 words/s : L.r. 7.2561e-05
[2019-05-22 00:56:24] Ep. 3 : Up. 274000 : Sen. 2,126,677 : Cost 25.31436539 : Time 369.98s : 6456.51 words/s : L.r. 7.2495e-05
[2019-05-22 01:02:33] Ep. 3 : Up. 274500 : Sen. 2,396,452 : Cost 24.92479515 : Time 369.62s : 6440.16 words/s : L.r. 7.2429e-05
[2019-05-22 01:08:41] Ep. 3 : Up. 275000 : Sen. 2,659,733 : Cost 25.60301971 : Time 367.71s : 6458.81 words/s : L.r. 7.2363e-05
[2019-05-22 01:08:41] Saving model weights and runtime parameters to model/model.src1tgt1.npz.orig.npz
[2019-05-22 01:08:45] Saving model weights and runtime parameters to model/model.src1tgt1.iter275000.npz
[2019-05-22 01:08:48] Saving model weights and runtime parameters to model/model.src1tgt1.npz
[2019-05-22 01:08:52] Saving Adam parameters to model/model.src1tgt1.npz.optimizer.npz
[2019-05-22 01:09:11] [valid] Ep. 3 : Up. 275000 : cross-entropy : 16.9138 : new best
[2019-05-22 01:09:24] [valid] Ep. 3 : Up. 275000 : perplexity : 5.83769 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-05-22 01:11:47] [valid] Ep. 3 : Up. 275000 : translation : 27.8 : stalled 2 times (last best: 27.8)
[2019-05-22 01:17:59] Ep. 3 : Up. 275500 : Sen. 2,930,391 : Cost 25.20459557 : Time 557.67s : 4321.15 words/s : L.r. 7.2297e-05
[2019-05-22 01:24:04] Ep. 3 : Up. 276000 : Sen. 3,192,233 : Cost 25.37539101 : Time 365.04s : 6422.51 words/s : L.r. 7.2232e-05
[2019-05-22 01:30:11] Ep. 3 : Up. 276500 : Sen. 3,458,164 : Cost 25.29266739 : Time 367.68s : 6464.48 words/s : L.r. 7.2166e-05
[2019-05-22 01:36:16] Ep. 3 : Up. 277000 : Sen. 3,720,559 : Cost 25.37461090 : Time 364.35s : 6454.93 words/s : L.r. 7.2101e-05
[2019-05-22 01:42:21] Ep. 3 : Up. 277500 : Sen. 3,986,820 : Cost 24.75735664 : Time 365.00s : 6397.64 words/s : L.r. 7.2036e-05
[2019-05-22 01:48:23] Ep. 3 : Up. 278000 : Sen. 4,245,894 : Cost 25.66136742 : Time 362.18s : 6469.46 words/s : L.r. 7.1971e-05
[2019-05-22 01:54:36] Ep. 3 : Up. 278500 : Sen. 4,516,735 : Cost 25.37867928 : Time 373.51s : 6503.36 words/s : L.r. 7.1907e-05
[2019-05-22 02:00:42] Ep. 3 : Up. 279000 : Sen. 4,782,693 : Cost 24.78737259 : Time 365.27s : 6404.94 words/s : L.r. 7.1842e-05
[2019-05-22 02:06:47] Ep. 3 : Up. 279500 : Sen. 5,046,252 : Cost 25.45469093 : Time 365.28s : 6469.53 words/s : L.r. 7.1778e-05
[2019-05-22 02:12:50] Ep. 3 : Up. 280000 : Sen. 5,310,836 : Cost 25.17668343 : Time 363.47s : 6487.92 words/s : L.r. 7.1714e-05
[2019-05-22 02:12:50] Saving model weights and runtime parameters to model/model.src1tgt1.npz.orig.npz
[2019-05-22 02:12:54] Saving model weights and runtime parameters to model/model.src1tgt1.iter280000.npz
[2019-05-22 02:12:57] Saving model weights and runtime parameters to model/model.src1tgt1.npz
[2019-05-22 02:13:01] Saving Adam parameters to model/model.src1tgt1.npz.optimizer.npz
[2019-05-22 02:13:21] [valid] Ep. 3 : Up. 280000 : cross-entropy : 16.8649 : new best
[2019-05-22 02:13:34] [valid] Ep. 3 : Up. 280000 : perplexity : 5.80802 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-05-22 02:16:01] [valid] Ep. 3 : Up. 280000 : translation : 27.9 : new best
[2019-05-22 02:22:08] Ep. 3 : Up. 280500 : Sen. 5,575,933 : Cost 25.28888321 : Time 557.79s : 4252.78 words/s : L.r. 7.1650e-05
[2019-05-22 02:28:18] Ep. 3 : Up. 281000 : Sen. 5,845,458 : Cost 24.95966911 : Time 369.43s : 6451.57 words/s : L.r. 7.1586e-05
[2019-05-22 02:34:24] Ep. 3 : Up. 281500 : Sen. 6,109,723 : Cost 25.21396255 : Time 366.63s : 6429.38 words/s : L.r. 7.1522e-05
[2019-05-22 02:40:36] Ep. 3 : Up. 282000 : Sen. 6,375,955 : Cost 25.58272934 : Time 371.79s : 6468.63 words/s : L.r. 7.1459e-05
[2019-05-22 02:46:47] Ep. 3 : Up. 282500 : Sen. 6,645,150 : Cost 24.95417595 : Time 371.22s : 6413.60 words/s : L.r. 7.1396e-05
[2019-05-22 02:52:55] Ep. 3 : Up. 283000 : Sen. 6,910,548 : Cost 25.32336044 : Time 367.61s : 6468.77 words/s : L.r. 7.1333e-05
[2019-05-22 02:58:59] Ep. 3 : Up. 283500 : Sen. 7,173,324 : Cost 25.03872108 : Time 364.06s : 6405.16 words/s : L.r. 7.1270e-05
[2019-05-22 03:05:04] Ep. 3 : Up. 284000 : Sen. 7,434,841 : Cost 25.44034004 : Time 365.08s : 6435.50 words/s : L.r. 7.1207e-05
[2019-05-22 03:11:13] Ep. 3 : Up. 284500 : Sen. 7,700,482 : Cost 25.27647781 : Time 368.62s : 6451.02 words/s : L.r. 7.1144e-05
[2019-05-22 03:17:21] Ep. 3 : Up. 285000 : Sen. 7,965,745 : Cost 24.98214912 : Time 368.48s : 6390.08 words/s : L.r. 7.1082e-05
[2019-05-22 03:17:21] Saving model weights and runtime parameters to model/model.src1tgt1.npz.orig.npz
[2019-05-22 03:17:25] Saving model weights and runtime parameters to model/model.src1tgt1.iter285000.npz
[2019-05-22 03:17:28] Saving model weights and runtime parameters to model/model.src1tgt1.npz
[2019-05-22 03:17:32] Saving Adam parameters to model/model.src1tgt1.npz.optimizer.npz
[2019-05-22 03:17:52] [valid] Ep. 3 : Up. 285000 : cross-entropy : 16.8106 : new best
[2019-05-22 03:18:04] [valid] Ep. 3 : Up. 285000 : perplexity : 5.7752 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-05-22 03:20:33] [valid] Ep. 3 : Up. 285000 : translation : 28 : new best
[2019-05-22 03:26:40] Ep. 3 : Up. 285500 : Sen. 8,229,108 : Cost 25.30315018 : Time 558.55s : 4226.35 words/s : L.r. 7.1020e-05
[2019-05-22 03:32:48] Ep. 3 : Up. 286000 : Sen. 8,495,671 : Cost 25.24412727 : Time 368.39s : 6465.62 words/s : L.r. 7.0957e-05
[2019-05-22 03:39:02] Ep. 3 : Up. 286500 : Sen. 8,765,660 : Cost 25.19250679 : Time 374.20s : 6440.53 words/s : L.r. 7.0896e-05
[2019-05-22 03:45:10] Ep. 3 : Up. 287000 : Sen. 9,030,970 : Cost 25.26055145 : Time 367.95s : 6447.39 words/s : L.r. 7.0834e-05
[2019-05-22 03:51:20] Ep. 3 : Up. 287500 : Sen. 9,297,508 : Cost 24.95976639 : Time 369.78s : 6382.78 words/s : L.r. 7.0772e-05
[2019-05-22 03:57:29] Ep. 3 : Up. 288000 : Sen. 9,567,669 : Cost 25.01885223 : Time 369.21s : 6494.03 words/s : L.r. 7.0711e-05
[2019-05-22 04:03:35] Ep. 3 : Up. 288500 : Sen. 9,830,866 : Cost 25.37392235 : Time 365.90s : 6463.72 words/s : L.r. 7.0649e-05
[2019-05-22 04:09:44] Ep. 3 : Up. 289000 : Sen. 10,099,478 : Cost 24.92683601 : Time 369.12s : 6436.39 words/s : L.r. 7.0588e-05
[2019-05-22 04:15:51] Ep. 3 : Up. 289500 : Sen. 10,365,644 : Cost 25.15968513 : Time 366.94s : 6472.56 words/s : L.r. 7.0527e-05
[2019-05-22 04:22:05] Ep. 3 : Up. 290000 : Sen. 10,635,562 : Cost 25.44304085 : Time 374.02s : 6497.54 words/s : L.r. 7.0466e-05
[2019-05-22 04:22:05] Saving model weights and runtime parameters to model/model.src1tgt1.npz.orig.npz
[2019-05-22 04:22:09] Saving model weights and runtime parameters to model/model.src1tgt1.iter290000.npz
[2019-05-22 04:22:12] Saving model weights and runtime parameters to model/model.src1tgt1.npz
[2019-05-22 04:22:16] Saving Adam parameters to model/model.src1tgt1.npz.optimizer.npz
[2019-05-22 04:22:36] [valid] Ep. 3 : Up. 290000 : cross-entropy : 16.765 : new best
[2019-05-22 04:22:48] [valid] Ep. 3 : Up. 290000 : perplexity : 5.74782 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-05-22 04:25:21] [valid] Ep. 3 : Up. 290000 : translation : 28 : stalled 1 times (last best: 28)
[2019-05-22 04:31:34] Ep. 3 : Up. 290500 : Sen. 10,906,648 : Cost 24.87446213 : Time 568.62s : 4209.56 words/s : L.r. 7.0406e-05
[2019-05-22 04:37:40] Ep. 3 : Up. 291000 : Sen. 11,170,184 : Cost 25.28988266 : Time 366.01s : 6448.03 words/s : L.r. 7.0345e-05
[2019-05-22 04:43:51] Ep. 3 : Up. 291500 : Sen. 11,441,238 : Cost 24.80547905 : Time 371.73s : 6426.30 words/s : L.r. 7.0285e-05
[2019-05-22 04:49:56] Ep. 3 : Up. 292000 : Sen. 11,702,700 : Cost 25.48194885 : Time 364.89s : 6461.82 words/s : L.r. 7.0225e-05
[2019-05-22 04:55:58] Ep. 3 : Up. 292500 : Sen. 11,963,229 : Cost 25.17873573 : Time 361.49s : 6423.94 words/s : L.r. 7.0165e-05
[2019-05-22 05:02:08] Ep. 3 : Up. 293000 : Sen. 12,233,206 : Cost 24.82170868 : Time 370.04s : 6433.39 words/s : L.r. 7.0105e-05
[2019-05-22 05:08:17] Ep. 3 : Up. 293500 : Sen. 12,500,327 : Cost 25.08319855 : Time 369.43s : 6439.40 words/s : L.r. 7.0045e-05
[2019-05-22 05:14:20] Ep. 3 : Up. 294000 : Sen. 12,761,741 : Cost 25.32496262 : Time 362.90s : 6461.31 words/s : L.r. 6.9985e-05
[2019-05-22 05:20:30] Ep. 3 : Up. 294500 : Sen. 13,027,462 : Cost 25.25160599 : Time 370.14s : 6423.08 words/s : L.r. 6.9926e-05
[2019-05-22 05:26:39] Ep. 3 : Up. 295000 : Sen. 13,292,955 : Cost 25.30976677 : Time 369.08s : 6457.88 words/s : L.r. 6.9867e-05
[2019-05-22 05:26:39] Saving model weights and runtime parameters to model/model.src1tgt1.npz.orig.npz
[2019-05-22 05:26:43] Saving model weights and runtime parameters to model/model.src1tgt1.iter295000.npz
[2019-05-22 05:26:46] Saving model weights and runtime parameters to model/model.src1tgt1.npz
[2019-05-22 05:26:50] Saving Adam parameters to model/model.src1tgt1.npz.optimizer.npz
[2019-05-22 05:27:10] [valid] Ep. 3 : Up. 295000 : cross-entropy : 16.7234 : new best
[2019-05-22 05:27:22] [valid] Ep. 3 : Up. 295000 : perplexity : 5.72291 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-05-22 05:29:42] [valid] Ep. 3 : Up. 295000 : translation : 28 : stalled 2 times (last best: 28)
[2019-05-22 05:35:51] Ep. 3 : Up. 295500 : Sen. 13,560,968 : Cost 24.90226936 : Time 551.50s : 4304.70 words/s : L.r. 6.9808e-05
[2019-05-22 05:42:00] Ep. 3 : Up. 296000 : Sen. 13,826,434 : Cost 25.34425926 : Time 368.67s : 6461.26 words/s : L.r. 6.9749e-05
[2019-05-22 05:48:10] Ep. 3 : Up. 296500 : Sen. 14,096,915 : Cost 24.80757523 : Time 370.69s : 6440.25 words/s : L.r. 6.9690e-05
[2019-05-22 05:54:16] Ep. 3 : Up. 297000 : Sen. 14,357,843 : Cost 25.55177689 : Time 365.54s : 6464.33 words/s : L.r. 6.9631e-05
[2019-05-22 06:00:23] Ep. 3 : Up. 297500 : Sen. 14,623,117 : Cost 25.12560272 : Time 366.96s : 6443.29 words/s : L.r. 6.9573e-05
[2019-05-22 06:06:30] Ep. 3 : Up. 298000 : Sen. 14,886,585 : Cost 25.20569992 : Time 367.59s : 6421.02 words/s : L.r. 6.9514e-05
[2019-05-22 06:12:38] Ep. 3 : Up. 298500 : Sen. 15,154,319 : Cost 24.88357353 : Time 367.99s : 6436.04 words/s : L.r. 6.9456e-05
[2019-05-22 06:18:47] Ep. 3 : Up. 299000 : Sen. 15,420,868 : Cost 25.17209435 : Time 368.54s : 6460.55 words/s : L.r. 6.9398e-05
[2019-05-22 06:24:49] Ep. 3 : Up. 299500 : Sen. 15,682,818 : Cost 25.05853462 : Time 361.90s : 6440.38 words/s : L.r. 6.9340e-05
[2019-05-22 06:30:55] Ep. 3 : Up. 300000 : Sen. 15,946,018 : Cost 25.09347534 : Time 365.99s : 6407.07 words/s : L.r. 6.9282e-05
[2019-05-22 06:30:55] Saving model weights and runtime parameters to model/model.src1tgt1.npz.orig.npz
[2019-05-22 06:30:59] Saving model weights and runtime parameters to model/model.src1tgt1.iter300000.npz
[2019-05-22 06:31:02] Saving model weights and runtime parameters to model/model.src1tgt1.npz
[2019-05-22 06:31:06] Saving Adam parameters to model/model.src1tgt1.npz.optimizer.npz
[2019-05-22 06:31:25] [valid] Ep. 3 : Up. 300000 : cross-entropy : 16.6923 : new best
[2019-05-22 06:31:38] [valid] Ep. 3 : Up. 300000 : perplexity : 5.70436 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-05-22 06:33:57] [valid] Ep. 3 : Up. 300000 : translation : 28.1 : new best
[2019-05-22 06:40:02] Ep. 3 : Up. 300500 : Sen. 16,211,638 : Cost 25.17863083 : Time 547.41s : 4334.91 words/s : L.r. 6.9224e-05
[2019-05-22 06:46:09] Ep. 3 : Up. 301000 : Sen. 16,475,515 : Cost 25.35462952 : Time 366.44s : 6472.79 words/s : L.r. 6.9167e-05
[2019-05-22 06:52:18] Ep. 3 : Up. 301500 : Sen. 16,746,975 : Cost 24.52847481 : Time 369.11s : 6434.44 words/s : L.r. 6.9109e-05
[2019-05-22 06:58:29] Ep. 3 : Up. 302000 : Sen. 17,013,998 : Cost 25.33260727 : Time 371.64s : 6450.10 words/s : L.r. 6.9052e-05
[2019-05-22 07:04:32] Ep. 3 : Up. 302500 : Sen. 17,276,096 : Cost 25.07638931 : Time 362.54s : 6446.46 words/s : L.r. 6.8995e-05
[2019-05-22 07:10:37] Ep. 3 : Up. 303000 : Sen. 17,537,164 : Cost 25.27414703 : Time 364.63s : 6423.40 words/s : L.r. 6.8938e-05
[2019-05-22 07:16:47] Ep. 3 : Up. 303500 : Sen. 17,805,224 : Cost 25.07341766 : Time 370.09s : 6458.83 words/s : L.r. 6.8881e-05
[2019-05-22 07:22:58] Ep. 3 : Up. 304000 : Sen. 18,075,393 : Cost 24.98117638 : Time 371.14s : 6466.42 words/s : L.r. 6.8825e-05
[2019-05-22 07:29:07] Ep. 3 : Up. 304500 : Sen. 18,340,191 : Cost 25.27760506 : Time 368.98s : 6436.26 words/s : L.r. 6.8768e-05
[2019-05-22 07:35:13] Ep. 3 : Up. 305000 : Sen. 18,604,857 : Cost 24.90084267 : Time 366.27s : 6407.25 words/s : L.r. 6.8712e-05
[2019-05-22 07:35:13] Saving model weights and runtime parameters to model/model.src1tgt1.npz.orig.npz
[2019-05-22 07:35:17] Saving model weights and runtime parameters to model/model.src1tgt1.iter305000.npz
[2019-05-22 07:35:20] Saving model weights and runtime parameters to model/model.src1tgt1.npz
[2019-05-22 07:35:24] Saving Adam parameters to model/model.src1tgt1.npz.optimizer.npz
[2019-05-22 07:35:44] [valid] Ep. 3 : Up. 305000 : cross-entropy : 16.6622 : new best
[2019-05-22 07:35:57] [valid] Ep. 3 : Up. 305000 : perplexity : 5.68651 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-05-22 07:38:14] [valid] Ep. 3 : Up. 305000 : translation : 28.1 : stalled 1 times (last best: 28.1)
[2019-05-22 07:44:22] Ep. 3 : Up. 305500 : Sen. 18,871,532 : Cost 25.14024544 : Time 548.51s : 4342.62 words/s : L.r. 6.8656e-05
[2019-05-22 07:50:27] Ep. 3 : Up. 306000 : Sen. 19,136,252 : Cost 25.14479637 : Time 365.80s : 6468.33 words/s : L.r. 6.8599e-05
[2019-05-22 07:56:33] Ep. 3 : Up. 306500 : Sen. 19,401,018 : Cost 25.03875160 : Time 365.28s : 6439.66 words/s : L.r. 6.8543e-05
[2019-05-22 08:02:45] Ep. 3 : Up. 307000 : Sen. 19,667,837 : Cost 25.36433792 : Time 372.27s : 6455.05 words/s : L.r. 6.8488e-05
[2019-05-22 08:08:54] Ep. 3 : Up. 307500 : Sen. 19,935,906 : Cost 24.64938927 : Time 368.80s : 6393.80 words/s : L.r. 6.8432e-05
[2019-05-22 08:15:03] Ep. 3 : Up. 308000 : Sen. 20,200,639 : Cost 25.32943344 : Time 369.19s : 6453.31 words/s : L.r. 6.8376e-05
[2019-05-22 08:21:09] Ep. 3 : Up. 308500 : Sen. 20,465,692 : Cost 24.73125648 : Time 366.08s : 6380.62 words/s : L.r. 6.8321e-05
[2019-05-22 08:27:16] Ep. 3 : Up. 309000 : Sen. 20,728,979 : Cost 25.27352905 : Time 366.90s : 6444.47 words/s : L.r. 6.8266e-05
[2019-05-22 08:33:29] Ep. 3 : Up. 309500 : Sen. 20,996,547 : Cost 25.21911621 : Time 372.79s : 6432.98 words/s : L.r. 6.8210e-05
[2019-05-22 08:39:43] Ep. 3 : Up. 310000 : Sen. 21,266,451 : Cost 25.27218819 : Time 374.45s : 6476.81 words/s : L.r. 6.8155e-05
[2019-05-22 08:39:43] Saving model weights and runtime parameters to model/model.src1tgt1.npz.orig.npz
[2019-05-22 08:39:47] Saving model weights and runtime parameters to model/model.src1tgt1.iter310000.npz
[2019-05-22 08:39:50] Saving model weights and runtime parameters to model/model.src1tgt1.npz
[2019-05-22 08:39:54] Saving Adam parameters to model/model.src1tgt1.npz.optimizer.npz
[2019-05-22 08:40:14] [valid] Ep. 3 : Up. 310000 : cross-entropy : 16.6408 : new best
[2019-05-22 08:40:26] [valid] Ep. 3 : Up. 310000 : perplexity : 5.67381 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-05-22 08:42:40] [valid] Ep. 3 : Up. 310000 : translation : 28.2 : new best
[2019-05-22 08:48:50] Ep. 3 : Up. 310500 : Sen. 21,536,197 : Cost 24.70252991 : Time 546.89s : 4338.89 words/s : L.r. 6.8101e-05
[2019-05-22 08:54:57] Ep. 3 : Up. 311000 : Sen. 21,795,228 : Cost 25.61630821 : Time 367.23s : 6408.33 words/s : L.r. 6.8046e-05
[2019-05-22 09:01:06] Ep. 3 : Up. 311500 : Sen. 22,062,606 : Cost 24.80879784 : Time 368.29s : 6412.67 words/s : L.r. 6.7991e-05
[2019-05-22 09:07:15] Ep. 3 : Up. 312000 : Sen. 22,328,733 : Cost 25.17682648 : Time 369.42s : 6450.38 words/s : L.r. 6.7937e-05
[2019-05-22 09:13:22] Ep. 3 : Up. 312500 : Sen. 22,593,756 : Cost 25.02705383 : Time 367.43s : 6423.69 words/s : L.r. 6.7882e-05
[2019-05-22 09:19:34] Ep. 3 : Up. 313000 : Sen. 22,861,750 : Cost 24.92713547 : Time 371.44s : 6401.83 words/s : L.r. 6.7828e-05
[2019-05-22 09:25:41] Ep. 3 : Up. 313500 : Sen. 23,127,521 : Cost 24.84797478 : Time 366.84s : 6415.42 words/s : L.r. 6.7774e-05
[2019-05-22 09:31:47] Ep. 3 : Up. 314000 : Sen. 23,387,530 : Cost 25.58041382 : Time 366.44s : 6440.40 words/s : L.r. 6.7720e-05
[2019-05-22 09:37:55] Ep. 3 : Up. 314500 : Sen. 23,655,528 : Cost 24.82582855 : Time 368.30s : 6443.61 words/s : L.r. 6.7666e-05
[2019-05-22 09:43:57] Ep. 3 : Up. 315000 : Sen. 23,916,299 : Cost 25.16484261 : Time 361.33s : 6451.83 words/s : L.r. 6.7612e-05
[2019-05-22 09:43:57] Saving model weights and runtime parameters to model/model.src1tgt1.npz.orig.npz
[2019-05-22 09:44:00] Saving model weights and runtime parameters to model/model.src1tgt1.iter315000.npz
[2019-05-22 09:44:04] Saving model weights and runtime parameters to model/model.src1tgt1.npz
[2019-05-22 09:44:07] Saving Adam parameters to model/model.src1tgt1.npz.optimizer.npz
[2019-05-22 09:44:27] [valid] Ep. 3 : Up. 315000 : cross-entropy : 16.6161 : new best
[2019-05-22 09:44:39] [valid] Ep. 3 : Up. 315000 : perplexity : 5.65921 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-05-22 09:46:48] [valid] Ep. 3 : Up. 315000 : translation : 28.3 : new best
[2019-05-22 09:52:51] Ep. 3 : Up. 315500 : Sen. 24,179,114 : Cost 24.90716934 : Time 534.41s : 4358.13 words/s : L.r. 6.7559e-05
[2019-05-22 09:59:04] Ep. 3 : Up. 316000 : Sen. 24,446,661 : Cost 25.29050064 : Time 373.04s : 6447.70 words/s : L.r. 6.7505e-05
[2019-05-22 10:05:16] Ep. 3 : Up. 316500 : Sen. 24,716,271 : Cost 24.91580200 : Time 371.56s : 6444.31 words/s : L.r. 6.7452e-05
[2019-05-22 10:11:25] Ep. 3 : Up. 317000 : Sen. 24,980,544 : Cost 25.17753410 : Time 368.98s : 6406.04 words/s : L.r. 6.7399e-05
[2019-05-22 10:17:33] Ep. 3 : Up. 317500 : Sen. 25,246,452 : Cost 25.04296494 : Time 367.96s : 6453.94 words/s : L.r. 6.7346e-05
[2019-05-22 10:23:41] Ep. 3 : Up. 318000 : Sen. 25,511,648 : Cost 25.12447357 : Time 368.52s : 6427.50 words/s : L.r. 6.7293e-05
[2019-05-22 10:29:47] Ep. 3 : Up. 318500 : Sen. 25,774,065 : Cost 25.34183311 : Time 365.45s : 6467.33 words/s : L.r. 6.7240e-05
[2019-05-22 10:35:55] Ep. 3 : Up. 319000 : Sen. 26,040,300 : Cost 24.96843719 : Time 368.74s : 6420.33 words/s : L.r. 6.7187e-05
[2019-05-22 10:42:06] Ep. 3 : Up. 319500 : Sen. 26,308,098 : Cost 24.87731743 : Time 370.60s : 6405.34 words/s : L.r. 6.7135e-05
[2019-05-22 10:48:20] Ep. 3 : Up. 320000 : Sen. 26,576,355 : Cost 25.22876549 : Time 374.13s : 6433.13 words/s : L.r. 6.7082e-05
[2019-05-22 10:48:20] Saving model weights and runtime parameters to model/model.src1tgt1.npz.orig.npz
[2019-05-22 10:48:24] Saving model weights and runtime parameters to model/model.src1tgt1.iter320000.npz
[2019-05-22 10:48:27] Saving model weights and runtime parameters to model/model.src1tgt1.npz
[2019-05-22 10:48:31] Saving Adam parameters to model/model.src1tgt1.npz.optimizer.npz
[2019-05-22 10:48:50] [valid] Ep. 3 : Up. 320000 : cross-entropy : 16.602 : new best
[2019-05-22 10:49:03] [valid] Ep. 3 : Up. 320000 : perplexity : 5.65092 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-05-22 10:51:14] [valid] Ep. 3 : Up. 320000 : translation : 28.3 : stalled 1 times (last best: 28.3)
[2019-05-22 10:57:19] Ep. 3 : Up. 320500 : Sen. 26,839,184 : Cost 24.79321861 : Time 538.82s : 4311.32 words/s : L.r. 6.7030e-05
[2019-05-22 11:03:27] Ep. 3 : Up. 321000 : Sen. 27,105,499 : Cost 24.92100334 : Time 368.27s : 6424.10 words/s : L.r. 6.6977e-05
[2019-05-22 11:09:36] Ep. 3 : Up. 321500 : Sen. 27,372,024 : Cost 24.96322632 : Time 368.24s : 6438.22 words/s : L.r. 6.6925e-05
[2019-05-22 11:15:43] Ep. 3 : Up. 322000 : Sen. 27,633,389 : Cost 25.48189354 : Time 367.73s : 6438.18 words/s : L.r. 6.6873e-05
[2019-05-22 11:21:54] Ep. 3 : Up. 322500 : Sen. 27,902,596 : Cost 24.81841087 : Time 370.85s : 6427.07 words/s : L.r. 6.6822e-05
[2019-05-22 11:28:03] Ep. 3 : Up. 323000 : Sen. 28,167,385 : Cost 25.16337395 : Time 369.18s : 6419.12 words/s : L.r. 6.6770e-05
[2019-05-22 11:34:15] Ep. 3 : Up. 323500 : Sen. 28,434,322 : Cost 25.12623596 : Time 371.69s : 6424.50 words/s : L.r. 6.6718e-05
