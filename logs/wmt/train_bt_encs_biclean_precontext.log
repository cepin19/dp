ITERATION 4
[2019-04-02 17:35:49] [marian] Marian v1.7.8 8ee1d02 2019-04-02 17:26:34 +0200
[2019-04-02 17:35:49] [marian] Running on cosmas.lingea.cz as process 128533 with command line:
[2019-04-02 17:35:49] [marian] /home/large/data/models/marian/marian-doc/doc-marian/build/marian --model model/model_bt_encz_bicleaner_precontext.npz --type transformer --train-sets corpus+bicleaner.en.bpe corpus+bicleaner.cz.bpe -e 4 --max-length 100 --vocabs corp/vocab.encs.yml corp/vocab.encs.yml --mini-batch-fit -w 7500 --mini-batch 1000 --maxi-batch 10000 --valid-freq 5000 --save-freq 5000 --disp-freq 500 --valid-metrics ce-mean-words perplexity translation --valid-sets corp/newstest2016-encs-src.en.bpe corp/newstest2016-encs-ref.cs.bpe --valid-script-path ./val.sh --quiet-translation --beam-size 6 --normalize=0.6 --valid-mini-batch 16 --overwrite --keep-best --optimizer-delay 2 --early-stopping 5 --cost-type=ce-mean-words --log model/bt_encz.log --valid-log model/valid.log --enc-depth 6 --dec-depth 6 --transformer-preprocess n --transformer-postprocess da --tied-embeddings-all --dim-emb 1024 --transformer-dim-ffn 4096 --transformer-heads 16 --transformer-dropout 0.1 --transformer-dropout-attention 0.1 --transformer-dropout-ffn 0.1 --label-smoothing 0.1 --learn-rate 0.0002 --lr-warmup 8000 --lr-decay-inv-sqrt 8000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --devices 0 1 --sync-sgd --seed 0 --no-nccl --exponential-smoothing --sqlite -T /tmp
[2019-04-02 17:35:49] [config] after-batches: 0
[2019-04-02 17:35:49] [config] after-epochs: 4
[2019-04-02 17:35:49] [config] allow-unk: false
[2019-04-02 17:35:49] [config] beam-size: 6
[2019-04-02 17:35:49] [config] bert-class-symbol: "[CLS]"
[2019-04-02 17:35:49] [config] bert-mask-symbol: "[MASK]"
[2019-04-02 17:35:49] [config] bert-masking-fraction: 0.15
[2019-04-02 17:35:49] [config] bert-sep-symbol: "[SEP]"
[2019-04-02 17:35:49] [config] bert-train-type-embeddings: true
[2019-04-02 17:35:49] [config] bert-type-vocab-size: 2
[2019-04-02 17:35:49] [config] best-deep: false
[2019-04-02 17:35:49] [config] clip-gemm: 0
[2019-04-02 17:35:49] [config] clip-norm: 5
[2019-04-02 17:35:49] [config] context-enc-depth: 1
[2019-04-02 17:35:49] [config] cost-type: ce-mean-words
[2019-04-02 17:35:49] [config] cpu-threads: 0
[2019-04-02 17:35:49] [config] data-weighting: ""
[2019-04-02 17:35:49] [config] data-weighting-type: sentence
[2019-04-02 17:35:49] [config] dec-cell: gru
[2019-04-02 17:35:49] [config] dec-cell-base-depth: 2
[2019-04-02 17:35:49] [config] dec-cell-high-depth: 1
[2019-04-02 17:35:49] [config] dec-depth: 6
[2019-04-02 17:35:49] [config] devices:
[2019-04-02 17:35:49] [config]   - 0
[2019-04-02 17:35:49] [config]   - 1
[2019-04-02 17:35:49] [config] dim-emb: 1024
[2019-04-02 17:35:49] [config] dim-rnn: 1024
[2019-04-02 17:35:49] [config] dim-vocabs:
[2019-04-02 17:35:49] [config]   - 0
[2019-04-02 17:35:49] [config]   - 0
[2019-04-02 17:35:49] [config] disp-first: 0
[2019-04-02 17:35:49] [config] disp-freq: 500
[2019-04-02 17:35:49] [config] disp-label-counts: false
[2019-04-02 17:35:49] [config] dropout-rnn: 0
[2019-04-02 17:35:49] [config] dropout-src: 0
[2019-04-02 17:35:49] [config] dropout-trg: 0
[2019-04-02 17:35:49] [config] dump-config: ""
[2019-04-02 17:35:49] [config] early-stopping: 5
[2019-04-02 17:35:49] [config] embedding-fix-src: false
[2019-04-02 17:35:49] [config] embedding-fix-trg: false
[2019-04-02 17:35:49] [config] embedding-normalization: false
[2019-04-02 17:35:49] [config] embedding-vectors:
[2019-04-02 17:35:49] [config]   []
[2019-04-02 17:35:49] [config] enc-cell: gru
[2019-04-02 17:35:49] [config] enc-cell-depth: 1
[2019-04-02 17:35:49] [config] enc-depth: 6
[2019-04-02 17:35:49] [config] enc-type: bidirectional
[2019-04-02 17:35:49] [config] exponential-smoothing: 0.0001
[2019-04-02 17:35:49] [config] freeze: false
[2019-04-02 17:35:49] [config] grad-dropping-momentum: 0
[2019-04-02 17:35:49] [config] grad-dropping-rate: 0
[2019-04-02 17:35:49] [config] grad-dropping-warmup: 100
[2019-04-02 17:35:49] [config] guided-alignment: none
[2019-04-02 17:35:49] [config] guided-alignment-cost: mse
[2019-04-02 17:35:49] [config] guided-alignment-weight: 0.1
[2019-04-02 17:35:49] [config] hier-att: false
[2019-04-02 17:35:49] [config] ignore-model-config: false
[2019-04-02 17:35:49] [config] input-types:
[2019-04-02 17:35:49] [config]   []
[2019-04-02 17:35:49] [config] interpolate-env-vars: false
[2019-04-02 17:35:49] [config] keep-best: true
[2019-04-02 17:35:49] [config] label-smoothing: 0.1
[2019-04-02 17:35:49] [config] layer-normalization: false
[2019-04-02 17:35:49] [config] learn-rate: 0.0002
[2019-04-02 17:35:49] [config] log: model/bt_encz.log
[2019-04-02 17:35:49] [config] log-level: info
[2019-04-02 17:35:49] [config] log-time-zone: ""
[2019-04-02 17:35:49] [config] lr-decay: 0
[2019-04-02 17:35:49] [config] lr-decay-freq: 50000
[2019-04-02 17:35:49] [config] lr-decay-inv-sqrt:
[2019-04-02 17:35:49] [config]   - 8000
[2019-04-02 17:35:49] [config] lr-decay-repeat-warmup: false
[2019-04-02 17:35:49] [config] lr-decay-reset-optimizer: false
[2019-04-02 17:35:49] [config] lr-decay-start:
[2019-04-02 17:35:49] [config]   - 10
[2019-04-02 17:35:49] [config]   - 1
[2019-04-02 17:35:49] [config] lr-decay-strategy: epoch+stalled
[2019-04-02 17:35:49] [config] lr-report: true
[2019-04-02 17:35:49] [config] lr-warmup: 8000
[2019-04-02 17:35:49] [config] lr-warmup-at-reload: false
[2019-04-02 17:35:49] [config] lr-warmup-cycle: false
[2019-04-02 17:35:49] [config] lr-warmup-start-rate: 0
[2019-04-02 17:35:49] [config] max-length: 100
[2019-04-02 17:35:49] [config] max-length-crop: false
[2019-04-02 17:35:49] [config] max-length-factor: 3
[2019-04-02 17:35:49] [config] maxi-batch: 10000
[2019-04-02 17:35:49] [config] maxi-batch-sort: trg
[2019-04-02 17:35:49] [config] mini-batch: 1000
[2019-04-02 17:35:49] [config] mini-batch-fit: true
[2019-04-02 17:35:49] [config] mini-batch-fit-step: 10
[2019-04-02 17:35:49] [config] mini-batch-overstuff: 1
[2019-04-02 17:35:49] [config] mini-batch-track-lr: false
[2019-04-02 17:35:49] [config] mini-batch-understuff: 1
[2019-04-02 17:35:49] [config] mini-batch-warmup: 0
[2019-04-02 17:35:49] [config] mini-batch-words: 0
[2019-04-02 17:35:49] [config] mini-batch-words-ref: 0
[2019-04-02 17:35:49] [config] model: model/model_bt_encz_bicleaner_precontext.npz
[2019-04-02 17:35:49] [config] multi-loss-type: sum
[2019-04-02 17:35:49] [config] multi-node: false
[2019-04-02 17:35:49] [config] multi-node-overlap: true
[2019-04-02 17:35:49] [config] n-best: false
[2019-04-02 17:35:49] [config] no-nccl: true
[2019-04-02 17:35:49] [config] no-reload: false
[2019-04-02 17:35:49] [config] no-restore-corpus: false
[2019-04-02 17:35:49] [config] no-shuffle: false
[2019-04-02 17:35:49] [config] normalize: 0.6
[2019-04-02 17:35:49] [config] num-devices: 0
[2019-04-02 17:35:49] [config] optimizer: adam
[2019-04-02 17:35:49] [config] optimizer-delay: 2
[2019-04-02 17:35:49] [config] optimizer-params:
[2019-04-02 17:35:49] [config]   - 0.9
[2019-04-02 17:35:49] [config]   - 0.98
[2019-04-02 17:35:49] [config]   - 1e-09
[2019-04-02 17:35:49] [config] overwrite: true
[2019-04-02 17:35:49] [config] pretrained-model: ""
[2019-04-02 17:35:49] [config] quiet: false
[2019-04-02 17:35:49] [config] quiet-translation: true
[2019-04-02 17:35:49] [config] relative-paths: false
[2019-04-02 17:35:49] [config] right-left: false
[2019-04-02 17:35:49] [config] save-freq: 5000
[2019-04-02 17:35:49] [config] seed: 0
[2019-04-02 17:35:49] [config] shuffle-in-ram: false
[2019-04-02 17:35:49] [config] skip: false
[2019-04-02 17:35:49] [config] sqlite: temporary
[2019-04-02 17:35:49] [config] sqlite-drop: false
[2019-04-02 17:35:49] [config] sync-sgd: true
[2019-04-02 17:35:49] [config] tempdir: /tmp
[2019-04-02 17:35:49] [config] tied-embeddings: false
[2019-04-02 17:35:49] [config] tied-embeddings-all: true
[2019-04-02 17:35:49] [config] tied-embeddings-src: false
[2019-04-02 17:35:49] [config] train-sets:
[2019-04-02 17:35:49] [config]   - corpus+bicleaner.en.bpe
[2019-04-02 17:35:49] [config]   - corpus+bicleaner.cz.bpe
[2019-04-02 17:35:49] [config] transformer-aan-activation: swish
[2019-04-02 17:35:49] [config] transformer-aan-depth: 2
[2019-04-02 17:35:49] [config] transformer-aan-nogate: false
[2019-04-02 17:35:49] [config] transformer-decoder-autoreg: self-attention
[2019-04-02 17:35:49] [config] transformer-dim-aan: 2048
[2019-04-02 17:35:49] [config] transformer-dim-ffn: 4096
[2019-04-02 17:35:49] [config] transformer-dropout: 0.1
[2019-04-02 17:35:49] [config] transformer-dropout-attention: 0.1
[2019-04-02 17:35:49] [config] transformer-dropout-ffn: 0.1
[2019-04-02 17:35:49] [config] transformer-ffn-activation: swish
[2019-04-02 17:35:49] [config] transformer-ffn-depth: 2
[2019-04-02 17:35:49] [config] transformer-guided-alignment-layer: last
[2019-04-02 17:35:49] [config] transformer-heads: 16
[2019-04-02 17:35:49] [config] transformer-no-projection: false
[2019-04-02 17:35:49] [config] transformer-postprocess: da
[2019-04-02 17:35:49] [config] transformer-postprocess-emb: d
[2019-04-02 17:35:49] [config] transformer-preprocess: n
[2019-04-02 17:35:49] [config] transformer-tied-layers:
[2019-04-02 17:35:49] [config]   []
[2019-04-02 17:35:49] [config] transformer-train-position-embeddings: false
[2019-04-02 17:35:49] [config] type: transformer
[2019-04-02 17:35:49] [config] ulr: false
[2019-04-02 17:35:49] [config] ulr-dim-emb: 0
[2019-04-02 17:35:49] [config] ulr-dropout: 0
[2019-04-02 17:35:49] [config] ulr-keys-vectors: ""
[2019-04-02 17:35:49] [config] ulr-query-vectors: ""
[2019-04-02 17:35:49] [config] ulr-softmax-temperature: 1
[2019-04-02 17:35:49] [config] ulr-trainable-transformation: false
[2019-04-02 17:35:49] [config] valid-freq: 5000
[2019-04-02 17:35:49] [config] valid-log: model/valid.log
[2019-04-02 17:35:49] [config] valid-max-length: 1000
[2019-04-02 17:35:49] [config] valid-metrics:
[2019-04-02 17:35:49] [config]   - ce-mean-words
[2019-04-02 17:35:49] [config]   - perplexity
[2019-04-02 17:35:49] [config]   - translation
[2019-04-02 17:35:49] [config] valid-mini-batch: 16
[2019-04-02 17:35:49] [config] valid-script-path: ./val.sh
[2019-04-02 17:35:49] [config] valid-sets:
[2019-04-02 17:35:49] [config]   - corp/newstest2016-encs-src.en.bpe
[2019-04-02 17:35:49] [config]   - corp/newstest2016-encs-ref.cs.bpe
[2019-04-02 17:35:49] [config] valid-translation-output: ""
[2019-04-02 17:35:49] [config] vocabs:
[2019-04-02 17:35:49] [config]   - corp/vocab.encs.yml
[2019-04-02 17:35:49] [config]   - corp/vocab.encs.yml
[2019-04-02 17:35:49] [config] word-penalty: 0
[2019-04-02 17:35:49] [config] workspace: 7500
[2019-04-02 17:35:49] [config] Model is being created with Marian v1.7.8 8ee1d02 2019-04-02 17:26:34 +0200
[2019-04-02 17:35:49] Using synchronous training
[2019-04-02 17:35:49] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.yml
[2019-04-02 17:35:50] [data] Setting vocabulary size for input 0 to 34028
[2019-04-02 17:35:50] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.yml
[2019-04-02 17:35:50] [data] Setting vocabulary size for input 1 to 34028
[2019-04-02 17:35:50] [sqlite] Creating temporary database in /tmp
[2019-04-02 17:35:52] [sqlite] Inserted 1000000 lines
[2019-04-02 17:35:54] [sqlite] Inserted 2000000 lines
[2019-04-02 17:35:59] [sqlite] Inserted 4000000 lines
[2019-04-02 17:36:07] [sqlite] Inserted 8000000 lines
[2019-04-02 17:36:25] [sqlite] Inserted 16000000 lines
[2019-04-02 17:37:09] [sqlite] Inserted 32000000 lines
[2019-04-02 17:37:36] [sqlite] Inserted 43731951 lines
[2019-04-02 17:37:36] [sqlite] Creating primary index
[2019-04-02 17:38:22] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-04-02 17:38:22] [batching] Collecting statistics for batch fitting with step size 10
[2019-04-02 17:38:24] [memory] Extending reserved space to 7552 MB (device gpu0)
[2019-04-02 17:38:24] [memory] Extending reserved space to 7552 MB (device gpu1)
[2019-04-02 17:38:25] [comm] NCCL communicator overridden
[2019-04-02 17:38:25] [training] Using 2 GPUs
[2019-04-02 17:38:25] [memory] Reserving 805 MB, device gpu0
[2019-04-02 17:38:25] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-04-02 17:38:25] [memory] Reserving 805 MB, device gpu0
[2019-04-02 17:38:36] [batching] Done. Typical MB size is 9044 target words
[2019-04-02 17:38:36] [memory] Extending reserved space to 7552 MB (device gpu0)
[2019-04-02 17:38:36] [memory] Extending reserved space to 7552 MB (device gpu1)
[2019-04-02 17:38:36] [comm] NCCL communicator overridden
[2019-04-02 17:38:36] [training] Using 2 GPUs
[2019-04-02 17:38:36] Training started
[2019-04-02 17:38:36] [sqlite] Selecting shuffled data
tcmalloc: large alloc 1342177280 bytes == 0xecd28000 @ 
[2019-04-02 17:42:37] [training] Batches are processed as 1 process(es) x 2 devices/process
[2019-04-02 17:42:37] [memory] Reserving 805 MB, device gpu1
[2019-04-02 17:42:37] [memory] Reserving 805 MB, device gpu0
[2019-04-02 17:42:37] [memory] Reserving 805 MB, device gpu0
[2019-04-02 17:42:37] [memory] Reserving 805 MB, device gpu1
[2019-04-02 17:42:38] [memory] Reserving 402 MB, device gpu0
[2019-04-02 17:42:38] [memory] Reserving 402 MB, device gpu1
[2019-04-02 17:42:38] [memory] Reserving 402 MB, device gpu0
[2019-04-02 17:42:38] [memory] Reserving 402 MB, device gpu1
[2019-04-02 17:42:39] [memory] Reserving 805 MB, device gpu0
[2019-04-02 17:42:39] [memory] Reserving 805 MB, device gpu1
tcmalloc: large alloc 1342177280 bytes == 0x7f67c2000000 @ 
[2019-04-02 17:52:43] Ep. 1 : Up. 500 : Sen. 237,161 : Cost 180.53089905 : Time 861.24s : 4510.66 words/s : L.r. 1.2500e-05
[2019-04-02 18:03:01] Ep. 1 : Up. 1000 : Sen. 473,910 : Cost 3713.58691406 : Time 617.71s : 6270.57 words/s : L.r. 2.5000e-05
[2019-04-02 18:13:14] Ep. 1 : Up. 1500 : Sen. 696,136 : Cost 2745244.50000000 : Time 612.96s : 6298.38 words/s : L.r. 3.7500e-05
[2019-04-02 18:23:27] Ep. 1 : Up. 2000 : Sen. 924,761 : Cost 370789744640.00000000 : Time 613.29s : 6278.77 words/s : L.r. 5.0000e-05
[2019-04-02 18:33:44] Ep. 1 : Up. 2500 : Sen. 1,159,621 : Cost 609551777792.00000000 : Time 617.52s : 6296.15 words/s : L.r. 6.2500e-05
[2019-04-02 18:44:00] Ep. 1 : Up. 3000 : Sen. 1,391,360 : Cost 610306949120.00000000 : Time 615.47s : 6267.05 words/s : L.r. 7.5000e-05
[2019-04-02 18:54:13] Ep. 1 : Up. 3500 : Sen. 1,629,322 : Cost 610055946240.00000000 : Time 613.08s : 6206.37 words/s : L.r. 8.7500e-05
[2019-04-02 19:04:24] Ep. 1 : Up. 4000 : Sen. 1,857,938 : Cost 610719694848.00000000 : Time 611.17s : 6274.46 words/s : L.r. 1.0000e-04
[2019-04-02 19:14:46] Ep. 1 : Up. 4500 : Sen. 2,096,614 : Cost 610573680640.00000000 : Time 622.11s : 6255.51 words/s : L.r. 1.1250e-04
[2019-04-02 19:24:58] Ep. 1 : Up. 5000 : Sen. 2,327,066 : Cost 608736051200.00000000 : Time 611.71s : 6233.81 words/s : L.r. 1.2500e-04
[2019-04-02 19:24:58] Saving model weights and runtime parameters to model/model_bt_encz_bicleaner_precontext.npz.orig.npz
[2019-04-02 19:25:00] Saving model weights and runtime parameters to model/model_bt_encz_bicleaner_precontext.npz
[2019-04-02 19:25:03] Saving Adam parameters to model/model_bt_encz_bicleaner_precontext.npz.optimizer.npz
[2019-04-02 19:25:13] Saving model weights and runtime parameters to model/model_bt_encz_bicleaner_precontext.npz.best-ce-mean-words.npz
[2019-04-02 19:25:16] [valid] Ep. 1 : Up. 5000 : ce-mean-words : 7.68361e+11 : new best
[2019-04-02 19:25:20] [valid] Ep. 1 : Up. 5000 : perplexity : inf : stalled 1 times (last best: 3.40282e+38)
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-02 19:31:46] Saving model weights and runtime parameters to model/model_bt_encz_bicleaner_precontext.npz.best-translation.npz
[2019-04-02 19:31:49] [valid] Ep. 1 : Up. 5000 : translation : 0 : new best
[2019-04-02 19:42:00] Ep. 1 : Up. 5500 : Sen. 2,549,783 : Cost 608966803456.00000000 : Time 1021.89s : 3733.99 words/s : L.r. 1.3750e-04
[2019-04-02 19:52:03] Ep. 1 : Up. 6000 : Sen. 2,781,661 : Cost 611355656192.00000000 : Time 603.65s : 6267.90 words/s : L.r. 1.5000e-04
[2019-04-02 20:02:12] Ep. 1 : Up. 6500 : Sen. 2,996,637 : Cost 602287833088.00000000 : Time 608.55s : 6225.75 words/s : L.r. 1.6250e-04
[2019-04-02 20:12:27] Ep. 1 : Up. 7000 : Sen. 3,228,595 : Cost 610155429888.00000000 : Time 615.49s : 6298.08 words/s : L.r. 1.7500e-04
[2019-04-02 20:22:30] Ep. 1 : Up. 7500 : Sen. 3,444,313 : Cost 603176239104.00000000 : Time 602.11s : 6213.17 words/s : L.r. 1.8750e-04
[2019-04-02 20:32:51] Ep. 1 : Up. 8000 : Sen. 3,673,027 : Cost 608491077632.00000000 : Time 621.42s : 6301.08 words/s : L.r. 2.0000e-04
[2019-04-02 20:43:03] Ep. 1 : Up. 8500 : Sen. 3,898,571 : Cost 604230975488.00000000 : Time 611.62s : 6223.75 words/s : L.r. 1.9403e-04
[2019-04-02 20:53:18] Ep. 1 : Up. 9000 : Sen. 4,129,244 : Cost 607717359616.00000000 : Time 615.04s : 6269.06 words/s : L.r. 1.8856e-04
[2019-04-02 21:03:39] Ep. 1 : Up. 9500 : Sen. 4,349,897 : Cost 607173083136.00000000 : Time 621.53s : 6297.84 words/s : L.r. 1.8353e-04
[2019-04-02 21:14:00] Ep. 1 : Up. 10000 : Sen. 4,580,628 : Cost 607367331840.00000000 : Time 620.49s : 6282.60 words/s : L.r. 1.7889e-04
[2019-04-02 21:14:00] Saving model weights and runtime parameters to model/model_bt_encz_bicleaner_precontext.npz.orig.npz
[2019-04-02 21:14:05] Saving model weights and runtime parameters to model/model_bt_encz_bicleaner_precontext.npz
[2019-04-02 21:14:10] Saving Adam parameters to model/model_bt_encz_bicleaner_precontext.npz.optimizer.npz
[2019-04-02 21:14:26] [valid] Ep. 1 : Up. 10000 : ce-mean-words : 7.68478e+11 : stalled 1 times (last best: 7.68361e+11)
[2019-04-02 21:14:30] [valid] Ep. 1 : Up. 10000 : perplexity : inf : stalled 2 times (last best: 3.40282e+38)
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-02 21:20:56] [valid] Ep. 1 : Up. 10000 : translation : 0 : stalled 1 times (last best: 0)
[2019-04-02 21:31:11] Ep. 1 : Up. 10500 : Sen. 4,804,501 : Cost 604929523712.00000000 : Time 1030.90s : 3747.03 words/s : L.r. 1.7457e-04
[2019-04-02 21:41:27] Ep. 1 : Up. 11000 : Sen. 5,032,037 : Cost 607922552832.00000000 : Time 615.93s : 6259.61 words/s : L.r. 1.7056e-04
[2019-04-02 21:51:39] Ep. 1 : Up. 11500 : Sen. 5,258,008 : Cost 607598018560.00000000 : Time 612.64s : 6270.60 words/s : L.r. 1.6681e-04
[2019-04-02 22:01:45] Ep. 1 : Up. 12000 : Sen. 5,486,056 : Cost 605625122816.00000000 : Time 606.13s : 6216.91 words/s : L.r. 1.6330e-04
[2019-04-02 22:12:00] Ep. 1 : Up. 12500 : Sen. 5,720,916 : Cost 612159913984.00000000 : Time 614.87s : 6269.11 words/s : L.r. 1.6000e-04
[2019-04-02 22:22:11] Ep. 1 : Up. 13000 : Sen. 5,959,636 : Cost 610276737024.00000000 : Time 610.66s : 6264.00 words/s : L.r. 1.5689e-04
[2019-04-02 22:32:30] Ep. 1 : Up. 13500 : Sen. 6,187,683 : Cost 605646422016.00000000 : Time 619.64s : 6247.81 words/s : L.r. 1.5396e-04
[2019-04-02 22:42:45] Ep. 1 : Up. 14000 : Sen. 6,423,222 : Cost 612062527488.00000000 : Time 614.83s : 6307.67 words/s : L.r. 1.5119e-04
[2019-04-02 22:52:54] Ep. 1 : Up. 14500 : Sen. 6,644,157 : Cost 602730921984.00000000 : Time 608.33s : 6243.40 words/s : L.r. 1.4856e-04
[2019-04-02 23:03:00] Ep. 1 : Up. 15000 : Sen. 6,881,622 : Cost 611896786944.00000000 : Time 606.59s : 6248.72 words/s : L.r. 1.4606e-04
[2019-04-02 23:03:00] Saving model weights and runtime parameters to model/model_bt_encz_bicleaner_precontext.npz.orig.npz
[2019-04-02 23:03:05] Saving model weights and runtime parameters to model/model_bt_encz_bicleaner_precontext.npz
[2019-04-02 23:03:10] Saving Adam parameters to model/model_bt_encz_bicleaner_precontext.npz.optimizer.npz
[2019-04-02 23:03:25] [valid] Ep. 1 : Up. 15000 : ce-mean-words : 7.68478e+11 : stalled 2 times (last best: 7.68361e+11)
[2019-04-02 23:03:29] [valid] Ep. 1 : Up. 15000 : perplexity : inf : stalled 3 times (last best: 3.40282e+38)
