[2019-04-16 18:46:22] [marian] Marian v1.7.8 1e91cce 2019-04-04 17:46:39 +0200
[2019-04-16 18:46:22] [marian] Running on cosmas.lingea.cz as process 106421 with command line:
[2019-04-16 18:46:22] [marian] /home/large/data/models/marian/marian-doc/doc-marian-cosmas/build/marian --model model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext_nofreeze.npz --pretrained-model model/model_base_encz2.npz --type transformer-context --train-sets corpus.docs.cs.bpe corpus.docs.en.bpe.src corpus.docs.cs.bpe -e 1 --max-length 95 --vocabs corp/vocab.encs.yml corp/vocab.encs.yml corp/vocab.encs.yml --mini-batch-fit -w 9000 --mini-batch 1000 --maxi-batch 1000 --valid-freq 2000 --save-freq 2000 --disp-freq 100 --embedding-fix-src --embedding-fix-trg --valid-metrics ce-mean-words perplexity translation --valid-sets newstest2016.docs.cs.bpe newstest2016.docs.src newstest2016.docs.cs.bpe --valid-script-path ./val.sh --quiet-translation --beam-size 6 --normalize=0.6 --valid-mini-batch 16 --overwrite --keep-best --early-stopping 15 --cost-type=ce-mean-words --log model/bt_encz.log --valid-log model/valid.log --transformer-heads 8 --enc-depth 6 --dec-depth 6 --context-enc-depth 6 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --optimizer-delay 4 --devices 2 3 --sync-sgd --seed 1111 --exponential-smoothing
[2019-04-16 18:46:22] [config] after-batches: 0
[2019-04-16 18:46:22] [config] after-epochs: 1
[2019-04-16 18:46:22] [config] allow-unk: false
[2019-04-16 18:46:22] [config] beam-size: 6
[2019-04-16 18:46:22] [config] bert-class-symbol: "[CLS]"
[2019-04-16 18:46:22] [config] bert-mask-symbol: "[MASK]"
[2019-04-16 18:46:22] [config] bert-masking-fraction: 0.15
[2019-04-16 18:46:22] [config] bert-sep-symbol: "[SEP]"
[2019-04-16 18:46:22] [config] bert-train-type-embeddings: true
[2019-04-16 18:46:22] [config] bert-type-vocab-size: 2
[2019-04-16 18:46:22] [config] best-deep: false
[2019-04-16 18:46:22] [config] clip-gemm: 0
[2019-04-16 18:46:22] [config] clip-norm: 5
[2019-04-16 18:46:22] [config] context-enc-depth: 6
[2019-04-16 18:46:22] [config] cost-type: ce-mean-words
[2019-04-16 18:46:22] [config] cpu-threads: 0
[2019-04-16 18:46:22] [config] data-weighting: ""
[2019-04-16 18:46:22] [config] data-weighting-type: sentence
[2019-04-16 18:46:22] [config] dec-cell: gru
[2019-04-16 18:46:22] [config] dec-cell-base-depth: 2
[2019-04-16 18:46:22] [config] dec-cell-high-depth: 1
[2019-04-16 18:46:22] [config] dec-depth: 6
[2019-04-16 18:46:22] [config] devices:
[2019-04-16 18:46:22] [config]   - 2
[2019-04-16 18:46:22] [config]   - 3
[2019-04-16 18:46:22] [config] dim-emb: 512
[2019-04-16 18:46:22] [config] dim-rnn: 1024
[2019-04-16 18:46:22] [config] dim-vocabs:
[2019-04-16 18:46:22] [config]   - 0
[2019-04-16 18:46:22] [config]   - 0
[2019-04-16 18:46:22] [config] disp-first: 0
[2019-04-16 18:46:22] [config] disp-freq: 100
[2019-04-16 18:46:22] [config] disp-label-counts: false
[2019-04-16 18:46:22] [config] dropout-rnn: 0
[2019-04-16 18:46:22] [config] dropout-src: 0
[2019-04-16 18:46:22] [config] dropout-trg: 0
[2019-04-16 18:46:22] [config] dump-config: ""
[2019-04-16 18:46:22] [config] early-stopping: 15
[2019-04-16 18:46:22] [config] embedding-fix-src: true
[2019-04-16 18:46:22] [config] embedding-fix-trg: true
[2019-04-16 18:46:22] [config] embedding-normalization: false
[2019-04-16 18:46:22] [config] embedding-vectors:
[2019-04-16 18:46:22] [config]   []
[2019-04-16 18:46:22] [config] enc-cell: gru
[2019-04-16 18:46:22] [config] enc-cell-depth: 1
[2019-04-16 18:46:22] [config] enc-depth: 6
[2019-04-16 18:46:22] [config] enc-type: bidirectional
[2019-04-16 18:46:22] [config] exponential-smoothing: 0.0001
[2019-04-16 18:46:22] [config] freeze: false
[2019-04-16 18:46:22] [config] grad-dropping-momentum: 0
[2019-04-16 18:46:22] [config] grad-dropping-rate: 0
[2019-04-16 18:46:22] [config] grad-dropping-warmup: 100
[2019-04-16 18:46:22] [config] guided-alignment: none
[2019-04-16 18:46:22] [config] guided-alignment-cost: mse
[2019-04-16 18:46:22] [config] guided-alignment-weight: 0.1
[2019-04-16 18:46:22] [config] hier-att: false
[2019-04-16 18:46:22] [config] ignore-model-config: false
[2019-04-16 18:46:22] [config] input-types:
[2019-04-16 18:46:22] [config]   []
[2019-04-16 18:46:22] [config] interpolate-env-vars: false
[2019-04-16 18:46:22] [config] keep-best: true
[2019-04-16 18:46:22] [config] label-smoothing: 0.1
[2019-04-16 18:46:22] [config] layer-normalization: false
[2019-04-16 18:46:22] [config] learn-rate: 0.0003
[2019-04-16 18:46:22] [config] log: model/bt_encz.log
[2019-04-16 18:46:22] [config] log-level: info
[2019-04-16 18:46:22] [config] log-time-zone: ""
[2019-04-16 18:46:22] [config] lr-decay: 0
[2019-04-16 18:46:22] [config] lr-decay-freq: 50000
[2019-04-16 18:46:22] [config] lr-decay-inv-sqrt:
[2019-04-16 18:46:22] [config]   - 16000
[2019-04-16 18:46:22] [config] lr-decay-repeat-warmup: false
[2019-04-16 18:46:22] [config] lr-decay-reset-optimizer: false
[2019-04-16 18:46:22] [config] lr-decay-start:
[2019-04-16 18:46:22] [config]   - 10
[2019-04-16 18:46:22] [config]   - 1
[2019-04-16 18:46:22] [config] lr-decay-strategy: epoch+stalled
[2019-04-16 18:46:22] [config] lr-report: true
[2019-04-16 18:46:22] [config] lr-warmup: 16000
[2019-04-16 18:46:22] [config] lr-warmup-at-reload: false
[2019-04-16 18:46:22] [config] lr-warmup-cycle: false
[2019-04-16 18:46:22] [config] lr-warmup-start-rate: 0
[2019-04-16 18:46:22] [config] max-length: 95
[2019-04-16 18:46:22] [config] max-length-crop: false
[2019-04-16 18:46:22] [config] max-length-factor: 3
[2019-04-16 18:46:22] [config] maxi-batch: 1000
[2019-04-16 18:46:22] [config] maxi-batch-sort: trg
[2019-04-16 18:46:22] [config] mini-batch: 1000
[2019-04-16 18:46:22] [config] mini-batch-fit: true
[2019-04-16 18:46:22] [config] mini-batch-fit-step: 10
[2019-04-16 18:46:22] [config] mini-batch-overstuff: 1
[2019-04-16 18:46:22] [config] mini-batch-track-lr: false
[2019-04-16 18:46:22] [config] mini-batch-understuff: 1
[2019-04-16 18:46:22] [config] mini-batch-warmup: 0
[2019-04-16 18:46:22] [config] mini-batch-words: 0
[2019-04-16 18:46:22] [config] mini-batch-words-ref: 0
[2019-04-16 18:46:22] [config] model: model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext_nofreeze.npz
[2019-04-16 18:46:22] [config] multi-loss-type: sum
[2019-04-16 18:46:22] [config] multi-node: false
[2019-04-16 18:46:22] [config] multi-node-overlap: true
[2019-04-16 18:46:22] [config] n-best: false
[2019-04-16 18:46:22] [config] no-nccl: false
[2019-04-16 18:46:22] [config] no-reload: false
[2019-04-16 18:46:22] [config] no-restore-corpus: false
[2019-04-16 18:46:22] [config] no-shuffle: false
[2019-04-16 18:46:22] [config] normalize: 0.6
[2019-04-16 18:46:22] [config] num-devices: 0
[2019-04-16 18:46:22] [config] optimizer: adam
[2019-04-16 18:46:22] [config] optimizer-delay: 4
[2019-04-16 18:46:22] [config] optimizer-params:
[2019-04-16 18:46:22] [config]   - 0.9
[2019-04-16 18:46:22] [config]   - 0.98
[2019-04-16 18:46:22] [config]   - 1e-09
[2019-04-16 18:46:22] [config] overwrite: true
[2019-04-16 18:46:22] [config] pretrained-model: model/model_base_encz2.npz
[2019-04-16 18:46:22] [config] quiet: false
[2019-04-16 18:46:22] [config] quiet-translation: true
[2019-04-16 18:46:22] [config] relative-paths: false
[2019-04-16 18:46:22] [config] right-left: false
[2019-04-16 18:46:22] [config] save-freq: 2000
[2019-04-16 18:46:22] [config] seed: 1111
[2019-04-16 18:46:22] [config] shuffle-in-ram: false
[2019-04-16 18:46:22] [config] skip: false
[2019-04-16 18:46:22] [config] sqlite: ""
[2019-04-16 18:46:22] [config] sqlite-drop: false
[2019-04-16 18:46:22] [config] sync-sgd: true
[2019-04-16 18:46:22] [config] tempdir: /tmp
[2019-04-16 18:46:22] [config] tied-embeddings: false
[2019-04-16 18:46:22] [config] tied-embeddings-all: true
[2019-04-16 18:46:22] [config] tied-embeddings-src: false
[2019-04-16 18:46:22] [config] train-sets:
[2019-04-16 18:46:22] [config]   - corpus.docs.cs.bpe
[2019-04-16 18:46:22] [config]   - corpus.docs.en.bpe.src
[2019-04-16 18:46:22] [config]   - corpus.docs.cs.bpe
[2019-04-16 18:46:22] [config] transformer-aan-activation: swish
[2019-04-16 18:46:22] [config] transformer-aan-depth: 2
[2019-04-16 18:46:22] [config] transformer-aan-nogate: false
[2019-04-16 18:46:22] [config] transformer-decoder-autoreg: self-attention
[2019-04-16 18:46:22] [config] transformer-dim-aan: 2048
[2019-04-16 18:46:22] [config] transformer-dim-ffn: 2048
[2019-04-16 18:46:22] [config] transformer-dropout: 0.1
[2019-04-16 18:46:22] [config] transformer-dropout-attention: 0
[2019-04-16 18:46:22] [config] transformer-dropout-ffn: 0
[2019-04-16 18:46:22] [config] transformer-ffn-activation: swish
[2019-04-16 18:46:22] [config] transformer-ffn-depth: 2
[2019-04-16 18:46:22] [config] transformer-guided-alignment-layer: last
[2019-04-16 18:46:22] [config] transformer-heads: 8
[2019-04-16 18:46:22] [config] transformer-no-projection: false
[2019-04-16 18:46:22] [config] transformer-postprocess: dan
[2019-04-16 18:46:22] [config] transformer-postprocess-emb: d
[2019-04-16 18:46:22] [config] transformer-preprocess: ""
[2019-04-16 18:46:22] [config] transformer-tied-layers:
[2019-04-16 18:46:22] [config]   []
[2019-04-16 18:46:22] [config] transformer-train-position-embeddings: false
[2019-04-16 18:46:22] [config] type: transformer-context
[2019-04-16 18:46:22] [config] ulr: false
[2019-04-16 18:46:22] [config] ulr-dim-emb: 0
[2019-04-16 18:46:22] [config] ulr-dropout: 0
[2019-04-16 18:46:22] [config] ulr-keys-vectors: ""
[2019-04-16 18:46:22] [config] ulr-query-vectors: ""
[2019-04-16 18:46:22] [config] ulr-softmax-temperature: 1
[2019-04-16 18:46:22] [config] ulr-trainable-transformation: false
[2019-04-16 18:46:22] [config] valid-freq: 2000
[2019-04-16 18:46:22] [config] valid-log: model/valid.log
[2019-04-16 18:46:22] [config] valid-max-length: 1000
[2019-04-16 18:46:22] [config] valid-metrics:
[2019-04-16 18:46:22] [config]   - ce-mean-words
[2019-04-16 18:46:22] [config]   - perplexity
[2019-04-16 18:46:22] [config]   - translation
[2019-04-16 18:46:22] [config] valid-mini-batch: 16
[2019-04-16 18:46:22] [config] valid-script-path: ./val.sh
[2019-04-16 18:46:22] [config] valid-sets:
[2019-04-16 18:46:22] [config]   - newstest2016.docs.cs.bpe
[2019-04-16 18:46:22] [config]   - newstest2016.docs.src
[2019-04-16 18:46:22] [config]   - newstest2016.docs.cs.bpe
[2019-04-16 18:46:22] [config] valid-translation-output: ""
[2019-04-16 18:46:22] [config] vocabs:
[2019-04-16 18:46:22] [config]   - corp/vocab.encs.yml
[2019-04-16 18:46:22] [config]   - corp/vocab.encs.yml
[2019-04-16 18:46:22] [config]   - corp/vocab.encs.yml
[2019-04-16 18:46:22] [config] word-penalty: 0
[2019-04-16 18:46:22] [config] workspace: 9000
[2019-04-16 18:46:22] [config] Model is being created with Marian v1.7.8 1e91cce 2019-04-04 17:46:39 +0200
[2019-04-16 18:46:22] Using synchronous training
[2019-04-16 18:46:22] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.yml
[2019-04-16 18:46:22] [data] Setting vocabulary size for input 0 to 34028
[2019-04-16 18:46:22] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.yml
[2019-04-16 18:46:22] [data] Setting vocabulary size for input 1 to 34028
[2019-04-16 18:46:22] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.yml
[2019-04-16 18:46:22] [data] Setting vocabulary size for input 2 to 34028
[2019-04-16 18:46:22] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-04-16 18:46:22] [batching] Collecting statistics for batch fitting with step size 10
[2019-04-16 18:46:24] [memory] Extending reserved space to 9088 MB (device gpu2)
[2019-04-16 18:46:25] [memory] Extending reserved space to 9088 MB (device gpu3)
[2019-04-16 18:46:25] [comm] Using NCCL 2.4.2 for GPU communication
[2019-04-16 18:46:25] [comm] NCCLCommunicator constructed successfully.
[2019-04-16 18:46:25] [training] Using 2 GPUs
[2019-04-16 18:46:25] [memory] Reserving 379 MB, device gpu2
[2019-04-16 18:46:25] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-04-16 18:46:25] [memory] Reserving 379 MB, device gpu2
[2019-04-16 18:46:39] [batching] Done. Typical MB size is 29080 target words
[2019-04-16 18:46:39] [memory] Extending reserved space to 9088 MB (device gpu2)
[2019-04-16 18:46:39] [memory] Extending reserved space to 9088 MB (device gpu3)
[2019-04-16 18:46:39] [comm] Using NCCL 2.4.2 for GPU communication
[2019-04-16 18:46:39] [comm] NCCLCommunicator constructed successfully.
[2019-04-16 18:46:39] [training] Using 2 GPUs
[2019-04-16 18:46:39] [training] Initializing model weights with the pre-trained model model/model_base_encz2.npz
[2019-04-16 18:46:39] Loading model from model/model_base_encz2.npz
[2019-04-16 18:46:40] Loading model from model/model_base_encz2.npz
[2019-04-16 18:46:40] Training started
[2019-04-16 18:46:40] [data] Shuffling data
tcmalloc: large alloc 1073741824 bytes == 0x1bedd4000 @ 
tcmalloc: large alloc 2147483648 bytes == 0x7fc007300000 @ 
tcmalloc: large alloc 2147483648 bytes == 0x7fbf87300000 @ 
tcmalloc: large alloc 2147483648 bytes == 0x7fba68000000 @ 
[2019-04-16 18:47:01] [data] Done reading 57951104 sentences
[2019-04-16 18:50:31] [data] Done shuffling 57951104 sentences to temp files
[2019-04-16 18:50:57] [training] Batches are processed as 1 process(es) x 2 devices/process
[2019-04-16 18:50:57] [memory] Reserving 379 MB, device gpu2
[2019-04-16 18:50:57] [memory] Reserving 379 MB, device gpu3
[2019-04-16 18:50:58] [memory] Reserving 379 MB, device gpu3
[2019-04-16 18:50:58] [memory] Reserving 379 MB, device gpu2
[2019-04-16 18:50:58] [memory] Reserving 189 MB, device gpu2
[2019-04-16 18:50:58] [memory] Reserving 189 MB, device gpu3
[2019-04-16 18:50:59] [memory] Reserving 379 MB, device gpu3
[2019-04-16 18:50:59] [memory] Reserving 379 MB, device gpu2
[2019-04-16 18:53:35] Ep. 1 : Up. 100 : Sen. 138,106 : Cost 9.58487225 : Time 432.52s : 4893.42 words/s : L.r. 1.8750e-06
[2019-04-16 18:56:20] Ep. 1 : Up. 200 : Sen. 281,773 : Cost 8.52099228 : Time 165.55s : 13070.56 words/s : L.r. 3.7500e-06
[2019-04-16 18:59:03] Ep. 1 : Up. 300 : Sen. 424,144 : Cost 8.17841434 : Time 162.65s : 12899.06 words/s : L.r. 5.6250e-06
[2019-04-16 19:01:42] Ep. 1 : Up. 400 : Sen. 568,312 : Cost 7.68298960 : Time 159.43s : 12967.76 words/s : L.r. 7.5000e-06
[2019-04-16 19:04:30] Ep. 1 : Up. 500 : Sen. 706,967 : Cost 6.36183596 : Time 167.41s : 13028.55 words/s : L.r. 9.3750e-06
[2019-04-16 19:07:12] Ep. 1 : Up. 600 : Sen. 850,308 : Cost 5.29131126 : Time 162.16s : 12957.99 words/s : L.r. 1.1250e-05
[2019-04-16 19:09:52] Ep. 1 : Up. 700 : Sen. 976,325 : Cost 3.70142150 : Time 160.00s : 12890.18 words/s : L.r. 1.3125e-05
[2019-04-16 19:12:34] Ep. 1 : Up. 800 : Sen. 1,114,493 : Cost 3.06289744 : Time 162.09s : 12934.55 words/s : L.r. 1.5000e-05
[2019-04-16 19:15:15] Ep. 1 : Up. 900 : Sen. 1,254,737 : Cost 2.92073393 : Time 161.13s : 12945.58 words/s : L.r. 1.6875e-05
[2019-04-16 19:17:59] Ep. 1 : Up. 1000 : Sen. 1,390,130 : Cost 2.82790995 : Time 163.89s : 12867.53 words/s : L.r. 1.8750e-05
[2019-04-16 19:20:39] Ep. 1 : Up. 1100 : Sen. 1,529,372 : Cost 2.79601812 : Time 159.61s : 12984.06 words/s : L.r. 2.0625e-05
[2019-04-16 19:23:21] Ep. 1 : Up. 1200 : Sen. 1,665,563 : Cost 2.70966792 : Time 162.36s : 12941.43 words/s : L.r. 2.2500e-05
[2019-04-16 19:26:13] Ep. 1 : Up. 1300 : Sen. 1,811,704 : Cost 2.70229173 : Time 172.15s : 13048.40 words/s : L.r. 2.4375e-05
[2019-04-16 19:28:53] Ep. 1 : Up. 1400 : Sen. 1,949,919 : Cost 2.70887232 : Time 159.71s : 12863.61 words/s : L.r. 2.6250e-05
[2019-04-16 19:31:35] Ep. 1 : Up. 1500 : Sen. 2,071,832 : Cost 2.68072772 : Time 162.14s : 12894.50 words/s : L.r. 2.8125e-05
[2019-04-16 19:34:14] Ep. 1 : Up. 1600 : Sen. 2,204,214 : Cost 2.67936707 : Time 158.99s : 12791.59 words/s : L.r. 3.0000e-05
[2019-04-16 19:36:58] Ep. 1 : Up. 1700 : Sen. 2,340,786 : Cost 2.67744851 : Time 164.09s : 12933.35 words/s : L.r. 3.1875e-05
[2019-04-16 19:39:44] Ep. 1 : Up. 1800 : Sen. 2,489,736 : Cost 2.65139365 : Time 165.39s : 13270.69 words/s : L.r. 3.3750e-05
[2019-04-16 19:42:28] Ep. 1 : Up. 1900 : Sen. 2,623,976 : Cost 2.65005016 : Time 164.40s : 13009.11 words/s : L.r. 3.5625e-05
[2019-04-16 19:45:13] Ep. 1 : Up. 2000 : Sen. 2,764,907 : Cost 2.64481163 : Time 164.97s : 12953.43 words/s : L.r. 3.7500e-05
[2019-04-16 19:45:13] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext_nofreeze.npz.orig.npz
[2019-04-16 19:45:16] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext_nofreeze.npz
[2019-04-16 19:45:18] Saving Adam parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext_nofreeze.npz.optimizer.npz
[2019-04-16 19:45:26] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext_nofreeze.npz.best-ce-mean-words.npz
[2019-04-16 19:45:27] [valid] Ep. 1 : Up. 2000 : ce-mean-words : 1.53897 : new best
[2019-04-16 19:45:30] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext_nofreeze.npz.best-perplexity.npz
[2019-04-16 19:45:32] [valid] Ep. 1 : Up. 2000 : perplexity : 4.65977 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-16 19:46:14] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext_nofreeze.npz.best-translation.npz
[2019-04-16 19:46:15] [valid] Ep. 1 : Up. 2000 : translation : 26.29 : new best
[2019-04-16 19:49:00] Ep. 1 : Up. 2100 : Sen. 2,912,278 : Cost 2.62229109 : Time 226.90s : 9294.35 words/s : L.r. 3.9375e-05
[2019-04-16 19:51:42] Ep. 1 : Up. 2200 : Sen. 3,055,421 : Cost 2.65063524 : Time 161.68s : 12888.49 words/s : L.r. 4.1250e-05
[2019-04-16 19:54:24] Ep. 1 : Up. 2300 : Sen. 3,199,380 : Cost 2.64591074 : Time 162.32s : 12963.30 words/s : L.r. 4.3125e-05
[2019-04-16 19:57:11] Ep. 1 : Up. 2400 : Sen. 3,334,883 : Cost 2.59802675 : Time 167.12s : 12954.09 words/s : L.r. 4.5000e-05
[2019-04-16 19:59:48] Ep. 1 : Up. 2500 : Sen. 3,485,622 : Cost 2.66422868 : Time 156.61s : 12909.16 words/s : L.r. 4.6875e-05
[2019-04-16 20:02:38] Ep. 1 : Up. 2600 : Sen. 3,629,860 : Cost 2.57080626 : Time 169.98s : 12882.47 words/s : L.r. 4.8750e-05
[2019-04-16 20:05:25] Ep. 1 : Up. 2700 : Sen. 3,780,056 : Cost 2.57716441 : Time 167.72s : 12967.58 words/s : L.r. 5.0625e-05
[2019-04-16 20:08:04] Ep. 1 : Up. 2800 : Sen. 3,903,741 : Cost 2.59672332 : Time 158.42s : 12721.06 words/s : L.r. 5.2500e-05
[2019-04-16 20:10:48] Ep. 1 : Up. 2900 : Sen. 4,038,659 : Cost 2.63450956 : Time 164.34s : 12956.70 words/s : L.r. 5.4375e-05
[2019-04-16 20:13:29] Ep. 1 : Up. 3000 : Sen. 4,166,200 : Cost 2.60688996 : Time 161.25s : 12954.33 words/s : L.r. 5.6250e-05
[2019-04-16 20:16:11] Ep. 1 : Up. 3100 : Sen. 4,279,286 : Cost 2.53745174 : Time 161.32s : 12866.26 words/s : L.r. 5.8125e-05
[2019-04-16 20:18:59] Ep. 1 : Up. 3200 : Sen. 4,425,529 : Cost 2.57870054 : Time 168.47s : 13074.56 words/s : L.r. 6.0000e-05
[2019-04-16 20:21:43] Ep. 1 : Up. 3300 : Sen. 4,568,484 : Cost 2.56848502 : Time 164.03s : 12864.15 words/s : L.r. 6.1875e-05
[2019-04-16 20:24:34] Ep. 1 : Up. 3400 : Sen. 4,712,759 : Cost 2.57524276 : Time 170.61s : 12978.27 words/s : L.r. 6.3750e-05
[2019-04-16 20:27:12] Ep. 1 : Up. 3500 : Sen. 4,842,315 : Cost 2.54243040 : Time 158.25s : 12624.07 words/s : L.r. 6.5625e-05
[2019-04-16 20:29:55] Ep. 1 : Up. 3600 : Sen. 5,004,048 : Cost 2.56442022 : Time 163.44s : 12903.34 words/s : L.r. 6.7500e-05
[2019-04-16 20:32:43] Ep. 1 : Up. 3700 : Sen. 5,143,564 : Cost 2.55142808 : Time 167.57s : 13082.65 words/s : L.r. 6.9375e-05
[2019-04-16 20:35:31] Ep. 1 : Up. 3800 : Sen. 5,278,783 : Cost 2.53905725 : Time 168.35s : 13063.41 words/s : L.r. 7.1250e-05
[2019-04-16 20:38:12] Ep. 1 : Up. 3900 : Sen. 5,410,282 : Cost 2.55413103 : Time 160.60s : 12770.05 words/s : L.r. 7.3125e-05
[2019-04-16 20:41:00] Ep. 1 : Up. 4000 : Sen. 5,551,008 : Cost 2.50040317 : Time 167.97s : 12973.11 words/s : L.r. 7.5000e-05
[2019-04-16 20:41:00] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext_nofreeze.npz.orig.npz
[2019-04-16 20:41:03] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext_nofreeze.npz
[2019-04-16 20:41:07] Saving Adam parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext_nofreeze.npz.optimizer.npz
[2019-04-16 20:41:16] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext_nofreeze.npz.best-ce-mean-words.npz
[2019-04-16 20:41:19] [valid] Ep. 1 : Up. 4000 : ce-mean-words : 1.46193 : new best
[2019-04-16 20:41:22] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext_nofreeze.npz.best-perplexity.npz
[2019-04-16 20:41:24] [valid] Ep. 1 : Up. 4000 : perplexity : 4.31429 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-16 20:42:07] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext_nofreeze.npz.best-translation.npz
[2019-04-16 20:42:09] [valid] Ep. 1 : Up. 4000 : translation : 27.79 : new best
[2019-04-16 20:44:51] Ep. 1 : Up. 4100 : Sen. 5,683,929 : Cost 2.55667472 : Time 231.14s : 8911.86 words/s : L.r. 7.6875e-05
[2019-04-16 20:47:33] Ep. 1 : Up. 4200 : Sen. 5,826,461 : Cost 2.55346036 : Time 161.48s : 12792.24 words/s : L.r. 7.8750e-05
[2019-04-16 20:50:13] Ep. 1 : Up. 4300 : Sen. 5,973,104 : Cost 2.51089334 : Time 160.07s : 12936.86 words/s : L.r. 8.0625e-05
[2019-04-16 20:52:57] Ep. 1 : Up. 4400 : Sen. 6,129,153 : Cost 2.43599629 : Time 164.27s : 12758.23 words/s : L.r. 8.2500e-05
[2019-04-16 20:55:45] Ep. 1 : Up. 4500 : Sen. 6,262,133 : Cost 2.51491666 : Time 167.68s : 12823.10 words/s : L.r. 8.4375e-05
[2019-04-16 20:58:34] Ep. 1 : Up. 4600 : Sen. 6,396,928 : Cost 2.51052284 : Time 169.31s : 13061.88 words/s : L.r. 8.6250e-05
[2019-04-16 21:01:11] Ep. 1 : Up. 4700 : Sen. 6,529,247 : Cost 2.52911067 : Time 156.69s : 12769.17 words/s : L.r. 8.8125e-05
[2019-04-16 21:03:54] Ep. 1 : Up. 4800 : Sen. 6,651,330 : Cost 2.51825809 : Time 163.02s : 12957.93 words/s : L.r. 9.0000e-05
[2019-04-16 21:06:38] Ep. 1 : Up. 4900 : Sen. 6,795,866 : Cost 2.47204757 : Time 164.35s : 12997.03 words/s : L.r. 9.1875e-05
[2019-04-16 21:09:24] Ep. 1 : Up. 5000 : Sen. 6,959,625 : Cost 2.48788571 : Time 166.13s : 12863.21 words/s : L.r. 9.3750e-05
[2019-04-16 21:12:04] Ep. 1 : Up. 5100 : Sen. 7,075,870 : Cost 2.53213024 : Time 159.78s : 12923.08 words/s : L.r. 9.5625e-05
[2019-04-16 21:14:45] Ep. 1 : Up. 5200 : Sen. 7,218,943 : Cost 2.47657108 : Time 160.90s : 12979.22 words/s : L.r. 9.7500e-05
[2019-04-16 21:17:32] Ep. 1 : Up. 5300 : Sen. 7,362,864 : Cost 2.45110297 : Time 166.90s : 12847.67 words/s : L.r. 9.9375e-05
[2019-04-16 21:20:16] Ep. 1 : Up. 5400 : Sen. 7,502,833 : Cost 2.49227428 : Time 164.10s : 13058.78 words/s : L.r. 1.0125e-04
[2019-04-16 21:22:58] Ep. 1 : Up. 5500 : Sen. 7,649,564 : Cost 2.48356652 : Time 162.19s : 12958.38 words/s : L.r. 1.0313e-04
[2019-04-16 21:25:38] Ep. 1 : Up. 5600 : Sen. 7,768,863 : Cost 2.44206071 : Time 160.14s : 12799.83 words/s : L.r. 1.0500e-04
[2019-04-16 21:28:23] Ep. 1 : Up. 5700 : Sen. 7,922,942 : Cost 2.45947528 : Time 164.78s : 12946.42 words/s : L.r. 1.0687e-04
[2019-04-16 21:31:12] Ep. 1 : Up. 5800 : Sen. 8,068,488 : Cost 2.45058680 : Time 169.33s : 12874.55 words/s : L.r. 1.0875e-04
[2019-04-16 21:33:50] Ep. 1 : Up. 5900 : Sen. 8,198,412 : Cost 2.47237110 : Time 157.98s : 12762.25 words/s : L.r. 1.1063e-04
[2019-04-16 21:36:24] Ep. 1 : Up. 6000 : Sen. 8,351,676 : Cost 2.38071036 : Time 154.05s : 12751.72 words/s : L.r. 1.1250e-04
[2019-04-16 21:36:24] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext_nofreeze.npz.orig.npz
[2019-04-16 21:36:28] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext_nofreeze.npz
[2019-04-16 21:36:31] Saving Adam parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext_nofreeze.npz.optimizer.npz
[2019-04-16 21:36:40] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext_nofreeze.npz.best-ce-mean-words.npz
[2019-04-16 21:36:43] [valid] Ep. 1 : Up. 6000 : ce-mean-words : 1.39725 : new best
[2019-04-16 21:36:46] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext_nofreeze.npz.best-perplexity.npz
[2019-04-16 21:36:48] [valid] Ep. 1 : Up. 6000 : perplexity : 4.04407 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-16 21:37:29] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext_nofreeze.npz.best-translation.npz
[2019-04-16 21:37:31] [valid] Ep. 1 : Up. 6000 : translation : 29.62 : new best
[2019-04-16 21:40:21] Ep. 1 : Up. 6100 : Sen. 8,467,841 : Cost 2.42649317 : Time 236.89s : 9293.61 words/s : L.r. 1.1438e-04
[2019-04-16 21:43:09] Ep. 1 : Up. 6200 : Sen. 8,616,249 : Cost 2.41110158 : Time 167.49s : 13024.56 words/s : L.r. 1.1625e-04
[2019-04-16 21:45:50] Ep. 1 : Up. 6300 : Sen. 8,748,053 : Cost 2.39664578 : Time 161.01s : 13003.20 words/s : L.r. 1.1813e-04
[2019-04-16 21:48:32] Ep. 1 : Up. 6400 : Sen. 8,889,746 : Cost 2.37225723 : Time 162.73s : 12862.40 words/s : L.r. 1.2000e-04
[2019-04-16 21:51:15] Ep. 1 : Up. 6500 : Sen. 9,027,468 : Cost 2.38336039 : Time 162.39s : 12991.32 words/s : L.r. 1.2188e-04
[2019-04-16 21:54:05] Ep. 1 : Up. 6600 : Sen. 9,176,064 : Cost 2.28449416 : Time 170.60s : 12905.59 words/s : L.r. 1.2375e-04
[2019-04-16 21:56:40] Ep. 1 : Up. 6700 : Sen. 9,311,119 : Cost 2.31557965 : Time 154.29s : 12825.77 words/s : L.r. 1.2562e-04
[2019-04-16 21:59:29] Ep. 1 : Up. 6800 : Sen. 9,449,408 : Cost 2.22651291 : Time 169.67s : 12972.43 words/s : L.r. 1.2750e-04
[2019-04-16 22:02:11] Ep. 1 : Up. 6900 : Sen. 9,583,052 : Cost 2.18749475 : Time 161.47s : 12922.03 words/s : L.r. 1.2938e-04
[2019-04-16 22:04:55] Ep. 1 : Up. 7000 : Sen. 9,722,178 : Cost 2.15678263 : Time 164.75s : 13011.28 words/s : L.r. 1.3125e-04
[2019-04-16 22:07:39] Ep. 1 : Up. 7100 : Sen. 9,861,039 : Cost 2.11529732 : Time 163.11s : 12962.04 words/s : L.r. 1.3313e-04
[2019-04-16 22:10:21] Ep. 1 : Up. 7200 : Sen. 10,010,688 : Cost 2.02939487 : Time 162.03s : 12950.41 words/s : L.r. 1.3500e-04
[2019-04-16 22:13:09] Ep. 1 : Up. 7300 : Sen. 10,145,093 : Cost 2.04249048 : Time 168.03s : 12919.20 words/s : L.r. 1.3688e-04
[2019-04-16 22:15:50] Ep. 1 : Up. 7400 : Sen. 10,268,730 : Cost 2.02523851 : Time 161.37s : 12987.83 words/s : L.r. 1.3875e-04
[2019-04-16 22:18:33] Ep. 1 : Up. 7500 : Sen. 10,422,037 : Cost 1.93051732 : Time 163.37s : 12921.63 words/s : L.r. 1.4063e-04
[2019-04-16 22:21:19] Ep. 1 : Up. 7600 : Sen. 10,570,193 : Cost 1.90747988 : Time 165.57s : 12886.65 words/s : L.r. 1.4250e-04
[2019-04-16 22:24:01] Ep. 1 : Up. 7700 : Sen. 10,721,432 : Cost 1.89745724 : Time 162.17s : 12916.38 words/s : L.r. 1.4438e-04
[2019-04-16 22:26:42] Ep. 1 : Up. 7800 : Sen. 10,858,305 : Cost 1.90375948 : Time 160.54s : 12984.51 words/s : L.r. 1.4625e-04
[2019-04-16 22:29:23] Ep. 1 : Up. 7900 : Sen. 10,985,460 : Cost 1.89367819 : Time 161.07s : 12907.55 words/s : L.r. 1.4813e-04
[2019-04-16 22:32:10] Ep. 1 : Up. 8000 : Sen. 11,126,799 : Cost 1.86398220 : Time 167.43s : 12930.62 words/s : L.r. 1.5000e-04
[2019-04-16 22:32:10] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext_nofreeze.npz.orig.npz
[2019-04-16 22:32:14] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext_nofreeze.npz
[2019-04-16 22:32:17] Saving Adam parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext_nofreeze.npz.optimizer.npz
[2019-04-16 22:32:27] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext_nofreeze.npz.best-ce-mean-words.npz
[2019-04-16 22:32:29] [valid] Ep. 1 : Up. 8000 : ce-mean-words : 0.837397 : new best
[2019-04-16 22:32:32] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext_nofreeze.npz.best-perplexity.npz
[2019-04-16 22:32:34] [valid] Ep. 1 : Up. 8000 : perplexity : 2.31034 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-16 22:33:14] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext_nofreeze.npz.best-translation.npz
[2019-04-16 22:33:16] [valid] Ep. 1 : Up. 8000 : translation : 53.29 : new best
[2019-04-16 22:36:00] Ep. 1 : Up. 8100 : Sen. 11,256,265 : Cost 1.81321156 : Time 229.80s : 9367.66 words/s : L.r. 1.5188e-04
[2019-04-16 22:38:47] Ep. 1 : Up. 8200 : Sen. 11,381,872 : Cost 1.83117390 : Time 166.82s : 13026.46 words/s : L.r. 1.5375e-04
[2019-04-16 22:41:32] Ep. 1 : Up. 8300 : Sen. 11,528,711 : Cost 1.78289235 : Time 165.27s : 12857.55 words/s : L.r. 1.5563e-04
[2019-04-16 22:44:12] Ep. 1 : Up. 8400 : Sen. 11,664,537 : Cost 1.78231585 : Time 159.92s : 12503.31 words/s : L.r. 1.5750e-04
[2019-04-16 22:46:52] Ep. 1 : Up. 8500 : Sen. 11,801,314 : Cost 1.74966908 : Time 159.94s : 12796.37 words/s : L.r. 1.5938e-04
[2019-04-16 22:49:36] Ep. 1 : Up. 8600 : Sen. 11,960,610 : Cost 1.69586062 : Time 163.56s : 13101.00 words/s : L.r. 1.6125e-04
[2019-04-16 22:52:19] Ep. 1 : Up. 8700 : Sen. 12,093,505 : Cost 1.73669708 : Time 163.25s : 13076.66 words/s : L.r. 1.6313e-04
[2019-04-16 22:55:04] Ep. 1 : Up. 8800 : Sen. 12,238,268 : Cost 1.73194456 : Time 164.82s : 13076.01 words/s : L.r. 1.6500e-04
[2019-04-16 22:57:46] Ep. 1 : Up. 8900 : Sen. 12,363,455 : Cost 1.70247686 : Time 161.92s : 12919.36 words/s : L.r. 1.6688e-04
[2019-04-16 23:00:31] Ep. 1 : Up. 9000 : Sen. 12,496,609 : Cost 1.67568231 : Time 165.49s : 12975.03 words/s : L.r. 1.6875e-04
[2019-04-16 23:03:11] Ep. 1 : Up. 9100 : Sen. 12,616,320 : Cost 1.66363645 : Time 160.49s : 12786.18 words/s : L.r. 1.7063e-04
[2019-04-16 23:05:55] Ep. 1 : Up. 9200 : Sen. 12,788,229 : Cost 1.60846472 : Time 163.97s : 12912.07 words/s : L.r. 1.7250e-04
[2019-04-16 23:08:41] Ep. 1 : Up. 9300 : Sen. 12,931,355 : Cost 1.65053380 : Time 166.00s : 13070.43 words/s : L.r. 1.7438e-04
[2019-04-16 23:11:24] Ep. 1 : Up. 9400 : Sen. 13,071,077 : Cost 1.61002326 : Time 162.34s : 12880.06 words/s : L.r. 1.7625e-04
[2019-04-16 23:14:04] Ep. 1 : Up. 9500 : Sen. 13,197,851 : Cost 1.64130521 : Time 160.06s : 12741.47 words/s : L.r. 1.7813e-04
[2019-04-16 23:16:47] Ep. 1 : Up. 9600 : Sen. 13,325,805 : Cost 1.62189353 : Time 163.61s : 13042.29 words/s : L.r. 1.8000e-04
[2019-04-16 23:19:35] Ep. 1 : Up. 9700 : Sen. 13,456,604 : Cost 1.61630714 : Time 167.18s : 13135.33 words/s : L.r. 1.8188e-04
[2019-04-16 23:22:18] Ep. 1 : Up. 9800 : Sen. 13,598,089 : Cost 1.59589899 : Time 163.05s : 12834.75 words/s : L.r. 1.8375e-04
[2019-04-16 23:24:59] Ep. 1 : Up. 9900 : Sen. 13,744,605 : Cost 1.62716341 : Time 161.07s : 12805.53 words/s : L.r. 1.8563e-04
[2019-04-16 23:27:46] Ep. 1 : Up. 10000 : Sen. 13,914,613 : Cost 1.57393610 : Time 166.86s : 12930.67 words/s : L.r. 1.8750e-04
[2019-04-16 23:27:46] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext_nofreeze.npz.orig.npz
[2019-04-16 23:27:49] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext_nofreeze.npz
[2019-04-16 23:27:52] Saving Adam parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext_nofreeze.npz.optimizer.npz
[2019-04-16 23:28:02] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext_nofreeze.npz.best-ce-mean-words.npz
[2019-04-16 23:28:04] [valid] Ep. 1 : Up. 10000 : ce-mean-words : 0.220758 : new best
[2019-04-16 23:28:07] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext_nofreeze.npz.best-perplexity.npz
[2019-04-16 23:28:09] [valid] Ep. 1 : Up. 10000 : perplexity : 1.24702 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-16 23:28:48] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext_nofreeze.npz.best-translation.npz
[2019-04-16 23:28:50] [valid] Ep. 1 : Up. 10000 : translation : 87.99 : new best
[2019-04-16 23:31:34] Ep. 1 : Up. 10100 : Sen. 14,045,687 : Cost 1.60088503 : Time 228.81s : 9307.42 words/s : L.r. 1.8938e-04
[2019-04-16 23:34:20] Ep. 1 : Up. 10200 : Sen. 14,191,445 : Cost 1.57833910 : Time 165.26s : 12941.80 words/s : L.r. 1.9125e-04
[2019-04-16 23:36:59] Ep. 1 : Up. 10300 : Sen. 14,334,844 : Cost 1.54888380 : Time 158.88s : 12820.64 words/s : L.r. 1.9313e-04
[2019-04-16 23:39:46] Ep. 1 : Up. 10400 : Sen. 14,474,578 : Cost 1.55175018 : Time 167.87s : 13161.81 words/s : L.r. 1.9500e-04
[2019-04-16 23:42:27] Ep. 1 : Up. 10500 : Sen. 14,611,980 : Cost 1.54111433 : Time 160.35s : 12897.66 words/s : L.r. 1.9688e-04
[2019-04-16 23:45:13] Ep. 1 : Up. 10600 : Sen. 14,753,604 : Cost 1.52822292 : Time 166.47s : 13171.64 words/s : L.r. 1.9875e-04
[2019-04-16 23:47:53] Ep. 1 : Up. 10700 : Sen. 14,888,292 : Cost 1.52616131 : Time 159.30s : 12944.57 words/s : L.r. 2.0062e-04
[2019-04-16 23:50:38] Ep. 1 : Up. 10800 : Sen. 15,026,936 : Cost 1.51091123 : Time 165.80s : 13092.12 words/s : L.r. 2.0250e-04
[2019-04-16 23:53:18] Ep. 1 : Up. 10900 : Sen. 15,172,391 : Cost 1.52376425 : Time 159.72s : 12850.11 words/s : L.r. 2.0437e-04
[2019-04-16 23:56:05] Ep. 1 : Up. 11000 : Sen. 15,310,533 : Cost 1.51769984 : Time 166.74s : 13073.01 words/s : L.r. 2.0625e-04
[2019-04-16 23:58:45] Ep. 1 : Up. 11100 : Sen. 15,453,897 : Cost 1.50527489 : Time 160.21s : 12807.26 words/s : L.r. 2.0813e-04
[2019-04-17 00:01:24] Ep. 1 : Up. 11200 : Sen. 15,594,674 : Cost 1.50381839 : Time 159.22s : 12766.78 words/s : L.r. 2.1000e-04
[2019-04-17 00:04:12] Ep. 1 : Up. 11300 : Sen. 15,732,218 : Cost 1.49424696 : Time 167.71s : 13027.23 words/s : L.r. 2.1188e-04
[2019-04-17 00:06:58] Ep. 1 : Up. 11400 : Sen. 15,841,557 : Cost 1.51261723 : Time 165.86s : 13022.78 words/s : L.r. 2.1375e-04
[2019-04-17 00:09:43] Ep. 1 : Up. 11500 : Sen. 16,001,648 : Cost 1.49077380 : Time 165.40s : 13026.38 words/s : L.r. 2.1563e-04
[2019-04-17 00:12:24] Ep. 1 : Up. 11600 : Sen. 16,146,083 : Cost 1.48969209 : Time 160.89s : 13015.53 words/s : L.r. 2.1750e-04
[2019-04-17 00:15:11] Ep. 1 : Up. 11700 : Sen. 16,282,572 : Cost 1.48111880 : Time 167.28s : 12941.67 words/s : L.r. 2.1938e-04
[2019-04-17 00:17:50] Ep. 1 : Up. 11800 : Sen. 16,403,868 : Cost 1.49025118 : Time 158.70s : 12833.73 words/s : L.r. 2.2125e-04
[2019-04-17 00:20:36] Ep. 1 : Up. 11900 : Sen. 16,564,723 : Cost 1.48178029 : Time 165.92s : 13026.25 words/s : L.r. 2.2312e-04
[2019-04-17 00:23:27] Ep. 1 : Up. 12000 : Sen. 16,715,779 : Cost 1.48934805 : Time 170.50s : 13143.41 words/s : L.r. 2.2500e-04
[2019-04-17 00:23:27] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext_nofreeze.npz.orig.npz
[2019-04-17 00:23:30] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext_nofreeze.npz
[2019-04-17 00:23:33] Saving Adam parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext_nofreeze.npz.optimizer.npz
[2019-04-17 00:23:42] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext_nofreeze.npz.best-ce-mean-words.npz
[2019-04-17 00:23:44] [valid] Ep. 1 : Up. 12000 : ce-mean-words : 0.0771639 : new best
[2019-04-17 00:23:47] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext_nofreeze.npz.best-perplexity.npz
[2019-04-17 00:23:49] [valid] Ep. 1 : Up. 12000 : perplexity : 1.08022 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-17 00:24:27] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext_nofreeze.npz.best-translation.npz
[2019-04-17 00:24:29] [valid] Ep. 1 : Up. 12000 : translation : 96.61 : new best
[2019-04-17 00:27:11] Ep. 1 : Up. 12100 : Sen. 16,845,883 : Cost 1.48385656 : Time 224.09s : 9233.21 words/s : L.r. 2.2688e-04
[2019-04-17 00:29:48] Ep. 1 : Up. 12200 : Sen. 16,973,669 : Cost 1.48385847 : Time 157.61s : 12869.49 words/s : L.r. 2.2875e-04
[2019-04-17 00:32:39] Ep. 1 : Up. 12300 : Sen. 17,129,311 : Cost 1.47300553 : Time 171.12s : 13046.23 words/s : L.r. 2.3063e-04
[2019-04-17 00:35:19] Ep. 1 : Up. 12400 : Sen. 17,264,661 : Cost 1.47001636 : Time 159.88s : 12844.54 words/s : L.r. 2.3250e-04
[2019-04-17 00:38:02] Ep. 1 : Up. 12500 : Sen. 17,406,981 : Cost 1.47756720 : Time 162.84s : 12822.39 words/s : L.r. 2.3438e-04
[2019-04-17 00:40:45] Ep. 1 : Up. 12600 : Sen. 17,523,020 : Cost 1.47072947 : Time 162.96s : 13099.03 words/s : L.r. 2.3625e-04
[2019-04-17 00:43:24] Ep. 1 : Up. 12700 : Sen. 17,663,909 : Cost 1.46927798 : Time 159.13s : 12915.36 words/s : L.r. 2.3813e-04
[2019-04-17 00:46:03] Ep. 1 : Up. 12800 : Sen. 17,811,498 : Cost 1.46616900 : Time 158.73s : 12796.87 words/s : L.r. 2.4000e-04
[2019-04-17 00:48:49] Ep. 1 : Up. 12900 : Sen. 17,946,617 : Cost 1.46781945 : Time 166.44s : 12921.51 words/s : L.r. 2.4188e-04
[2019-04-17 00:51:39] Ep. 1 : Up. 13000 : Sen. 18,103,882 : Cost 1.45278299 : Time 169.43s : 13148.17 words/s : L.r. 2.4375e-04
[2019-04-17 00:54:24] Ep. 1 : Up. 13100 : Sen. 18,251,504 : Cost 1.46903598 : Time 164.73s : 12681.61 words/s : L.r. 2.4563e-04
train_bt_encs_biclean+bt_noise.cosmas_doc_6l_from_base_refcontext_nofreeze.sh: line 29: 106421 Terminated              $marian/marian --model model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext_nofreeze.npz --pretrained-model model/model_base_encz2.npz --type transformer-context --train-sets corpus.docs.cs.bpe corpus.docs.en.bpe.src corpus.docs.cs.bpe -e 1 --max-length 95 --vocabs corp/vocab.encs.yml corp/vocab.encs.yml corp/vocab.encs.yml --mini-batch-fit -w 9000 --mini-batch 1000 --maxi-batch 1000 --valid-freq 2000 --save-freq 2000 --disp-freq 100 --embedding-fix-src --embedding-fix-trg --valid-metrics ce-mean-words perplexity translation --valid-sets newstest2016.docs.cs.bpe newstest2016.docs.src newstest2016.docs.cs.bpe --valid-script-path ./val.sh --quiet-translation --beam-size 6 --normalize=0.6 --valid-mini-batch 16 --overwrite --keep-best --early-stopping 15 --cost-type=ce-mean-words --log model/bt_encz.log --valid-log model/valid.log --transformer-heads 8 --enc-depth 6 --dec-depth 6 --context-enc-depth 6 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --optimizer-delay 4 --devices 2 3 --sync-sgd --seed 1111 --exponential-smoothing
