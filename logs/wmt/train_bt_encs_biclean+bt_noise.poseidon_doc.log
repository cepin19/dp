[2019-04-14 22:51:29] [marian] Marian v1.7.8 eeb05e5 2019-04-14 22:45:14 +0200
[2019-04-14 22:51:29] [marian] Running on poseidon.lingea.cz as process 29443 with command line:
[2019-04-14 22:51:29] [marian] /home/large/data/models/marian/marian-doc/doc-marian-poseidon/build/marian --model model/model_bt_noise_encz_bicleaner_poseidon_doc_fix_emb.npz --pretrained-model model/model_bt_noise_encz_bicleaner.npz.best-translation.npz --type transformer-context --train-sets corpus.docs.en.bpe.src_prev corpus.docs.en.bpe.src corpus.docs.cs.bpe -e 1 --max-length 100 --vocabs corp/vocab.encs.yml corp/vocab.encs.yml corp/vocab.encs.yml --mini-batch-fit -w 6000 --mini-batch 1000 --maxi-batch 1000 --freeze --valid-freq 2000 --save-freq 2000 --disp-freq 100 --embedding-fix-src --embedding-fix-trg --valid-metrics ce-mean-words perplexity translation --valid-sets newstest2016.docs.src_prev newstest2016.docs.src newstest2016.docs.cs.bpe --valid-script-path ./val.sh --quiet-translation --beam-size 6 --normalize=0.6 --valid-mini-batch 16 --overwrite --keep-best --optimizer-delay 16 --early-stopping 15 --cost-type=ce-mean-words --log model/bt_encz.log --valid-log model/valid.log --enc-depth 6 --dec-depth 6 --transformer-preprocess n --transformer-postprocess da --tied-embeddings-all --dim-emb 1024 --transformer-dim-ffn 4096 --transformer-heads 16 --transformer-dropout 0.1 --transformer-dropout-attention 0.1 --transformer-dropout-ffn 0.1 --label-smoothing 0.1 --learn-rate 0.0002 --lr-warmup 8000 --lr-decay-inv-sqrt 8000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --devices 0 1 --no-nccl --sync-sgd --seed 0 --exponential-smoothing --sqlite -T /home/tmp/tmp
[2019-04-14 22:51:29] [config] after-batches: 0
[2019-04-14 22:51:29] [config] after-epochs: 1
[2019-04-14 22:51:29] [config] allow-unk: false
[2019-04-14 22:51:29] [config] beam-size: 6
[2019-04-14 22:51:29] [config] bert-class-symbol: "[CLS]"
[2019-04-14 22:51:29] [config] bert-mask-symbol: "[MASK]"
[2019-04-14 22:51:29] [config] bert-masking-fraction: 0.15
[2019-04-14 22:51:29] [config] bert-sep-symbol: "[SEP]"
[2019-04-14 22:51:29] [config] bert-train-type-embeddings: true
[2019-04-14 22:51:29] [config] bert-type-vocab-size: 2
[2019-04-14 22:51:29] [config] best-deep: false
[2019-04-14 22:51:29] [config] clip-gemm: 0
[2019-04-14 22:51:29] [config] clip-norm: 5
[2019-04-14 22:51:29] [config] context-enc-depth: 1
[2019-04-14 22:51:29] [config] cost-type: ce-mean-words
[2019-04-14 22:51:29] [config] cpu-threads: 0
[2019-04-14 22:51:29] [config] data-weighting: ""
[2019-04-14 22:51:29] [config] data-weighting-type: sentence
[2019-04-14 22:51:29] [config] dec-cell: gru
[2019-04-14 22:51:29] [config] dec-cell-base-depth: 2
[2019-04-14 22:51:29] [config] dec-cell-high-depth: 1
[2019-04-14 22:51:29] [config] dec-depth: 6
[2019-04-14 22:51:29] [config] devices:
[2019-04-14 22:51:29] [config]   - 0
[2019-04-14 22:51:29] [config]   - 1
[2019-04-14 22:51:29] [config] dim-emb: 1024
[2019-04-14 22:51:29] [config] dim-rnn: 1024
[2019-04-14 22:51:29] [config] dim-vocabs:
[2019-04-14 22:51:29] [config]   - 0
[2019-04-14 22:51:29] [config]   - 0
[2019-04-14 22:51:29] [config] disp-first: 0
[2019-04-14 22:51:29] [config] disp-freq: 100
[2019-04-14 22:51:29] [config] disp-label-counts: false
[2019-04-14 22:51:29] [config] dropout-rnn: 0
[2019-04-14 22:51:29] [config] dropout-src: 0
[2019-04-14 22:51:29] [config] dropout-trg: 0
[2019-04-14 22:51:29] [config] dump-config: ""
[2019-04-14 22:51:29] [config] early-stopping: 15
[2019-04-14 22:51:29] [config] embedding-fix-src: true
[2019-04-14 22:51:29] [config] embedding-fix-trg: true
[2019-04-14 22:51:29] [config] embedding-normalization: false
[2019-04-14 22:51:29] [config] embedding-vectors:
[2019-04-14 22:51:29] [config]   []
[2019-04-14 22:51:29] [config] enc-cell: gru
[2019-04-14 22:51:29] [config] enc-cell-depth: 1
[2019-04-14 22:51:29] [config] enc-depth: 6
[2019-04-14 22:51:29] [config] enc-type: bidirectional
[2019-04-14 22:51:29] [config] exponential-smoothing: 0.0001
[2019-04-14 22:51:29] [config] freeze: true
[2019-04-14 22:51:29] [config] grad-dropping-momentum: 0
[2019-04-14 22:51:29] [config] grad-dropping-rate: 0
[2019-04-14 22:51:29] [config] grad-dropping-warmup: 100
[2019-04-14 22:51:29] [config] guided-alignment: none
[2019-04-14 22:51:29] [config] guided-alignment-cost: mse
[2019-04-14 22:51:29] [config] guided-alignment-weight: 0.1
[2019-04-14 22:51:29] [config] hier-att: false
[2019-04-14 22:51:29] [config] ignore-model-config: false
[2019-04-14 22:51:29] [config] input-types:
[2019-04-14 22:51:29] [config]   []
[2019-04-14 22:51:29] [config] interpolate-env-vars: false
[2019-04-14 22:51:29] [config] keep-best: true
[2019-04-14 22:51:29] [config] label-smoothing: 0.1
[2019-04-14 22:51:29] [config] layer-normalization: false
[2019-04-14 22:51:29] [config] learn-rate: 0.0002
[2019-04-14 22:51:29] [config] log: model/bt_encz.log
[2019-04-14 22:51:29] [config] log-level: info
[2019-04-14 22:51:29] [config] log-time-zone: ""
[2019-04-14 22:51:29] [config] lr-decay: 0
[2019-04-14 22:51:29] [config] lr-decay-freq: 50000
[2019-04-14 22:51:29] [config] lr-decay-inv-sqrt:
[2019-04-14 22:51:29] [config]   - 8000
[2019-04-14 22:51:29] [config] lr-decay-repeat-warmup: false
[2019-04-14 22:51:29] [config] lr-decay-reset-optimizer: false
[2019-04-14 22:51:29] [config] lr-decay-start:
[2019-04-14 22:51:29] [config]   - 10
[2019-04-14 22:51:29] [config]   - 1
[2019-04-14 22:51:29] [config] lr-decay-strategy: epoch+stalled
[2019-04-14 22:51:29] [config] lr-report: true
[2019-04-14 22:51:29] [config] lr-warmup: 8000
[2019-04-14 22:51:29] [config] lr-warmup-at-reload: false
[2019-04-14 22:51:29] [config] lr-warmup-cycle: false
[2019-04-14 22:51:29] [config] lr-warmup-start-rate: 0
[2019-04-14 22:51:29] [config] max-length: 100
[2019-04-14 22:51:29] [config] max-length-crop: false
[2019-04-14 22:51:29] [config] max-length-factor: 3
[2019-04-14 22:51:29] [config] maxi-batch: 1000
[2019-04-14 22:51:29] [config] maxi-batch-sort: trg
[2019-04-14 22:51:29] [config] mini-batch: 1000
[2019-04-14 22:51:29] [config] mini-batch-fit: true
[2019-04-14 22:51:29] [config] mini-batch-fit-step: 10
[2019-04-14 22:51:29] [config] mini-batch-overstuff: 1
[2019-04-14 22:51:29] [config] mini-batch-track-lr: false
[2019-04-14 22:51:29] [config] mini-batch-understuff: 1
[2019-04-14 22:51:29] [config] mini-batch-warmup: 0
[2019-04-14 22:51:29] [config] mini-batch-words: 0
[2019-04-14 22:51:29] [config] mini-batch-words-ref: 0
[2019-04-14 22:51:29] [config] model: model/model_bt_noise_encz_bicleaner_poseidon_doc_fix_emb.npz
[2019-04-14 22:51:29] [config] multi-loss-type: sum
[2019-04-14 22:51:29] [config] multi-node: false
[2019-04-14 22:51:29] [config] multi-node-overlap: true
[2019-04-14 22:51:29] [config] n-best: false
[2019-04-14 22:51:29] [config] no-nccl: true
[2019-04-14 22:51:29] [config] no-reload: false
[2019-04-14 22:51:29] [config] no-restore-corpus: false
[2019-04-14 22:51:29] [config] no-shuffle: false
[2019-04-14 22:51:29] [config] normalize: 0.6
[2019-04-14 22:51:29] [config] num-devices: 0
[2019-04-14 22:51:29] [config] optimizer: adam
[2019-04-14 22:51:29] [config] optimizer-delay: 16
[2019-04-14 22:51:29] [config] optimizer-params:
[2019-04-14 22:51:29] [config]   - 0.9
[2019-04-14 22:51:29] [config]   - 0.98
[2019-04-14 22:51:29] [config]   - 1e-09
[2019-04-14 22:51:29] [config] overwrite: true
[2019-04-14 22:51:29] [config] pretrained-model: model/model_bt_noise_encz_bicleaner.npz.best-translation.npz
[2019-04-14 22:51:29] [config] quiet: false
[2019-04-14 22:51:29] [config] quiet-translation: true
[2019-04-14 22:51:29] [config] relative-paths: false
[2019-04-14 22:51:29] [config] right-left: false
[2019-04-14 22:51:29] [config] save-freq: 2000
[2019-04-14 22:51:29] [config] seed: 0
[2019-04-14 22:51:29] [config] shuffle-in-ram: false
[2019-04-14 22:51:29] [config] skip: false
[2019-04-14 22:51:29] [config] sqlite: temporary
[2019-04-14 22:51:29] [config] sqlite-drop: false
[2019-04-14 22:51:29] [config] sync-sgd: true
[2019-04-14 22:51:29] [config] tempdir: /home/tmp/tmp
[2019-04-14 22:51:29] [config] tied-embeddings: false
[2019-04-14 22:51:29] [config] tied-embeddings-all: true
[2019-04-14 22:51:29] [config] tied-embeddings-src: false
[2019-04-14 22:51:29] [config] train-sets:
[2019-04-14 22:51:29] [config]   - corpus.docs.en.bpe.src_prev
[2019-04-14 22:51:29] [config]   - corpus.docs.en.bpe.src
[2019-04-14 22:51:29] [config]   - corpus.docs.cs.bpe
[2019-04-14 22:51:29] [config] transformer-aan-activation: swish
[2019-04-14 22:51:29] [config] transformer-aan-depth: 2
[2019-04-14 22:51:29] [config] transformer-aan-nogate: false
[2019-04-14 22:51:29] [config] transformer-decoder-autoreg: self-attention
[2019-04-14 22:51:29] [config] transformer-dim-aan: 2048
[2019-04-14 22:51:29] [config] transformer-dim-ffn: 4096
[2019-04-14 22:51:29] [config] transformer-dropout: 0.1
[2019-04-14 22:51:29] [config] transformer-dropout-attention: 0.1
[2019-04-14 22:51:29] [config] transformer-dropout-ffn: 0.1
[2019-04-14 22:51:29] [config] transformer-ffn-activation: swish
[2019-04-14 22:51:29] [config] transformer-ffn-depth: 2
[2019-04-14 22:51:29] [config] transformer-guided-alignment-layer: last
[2019-04-14 22:51:29] [config] transformer-heads: 16
[2019-04-14 22:51:29] [config] transformer-no-projection: false
[2019-04-14 22:51:29] [config] transformer-postprocess: da
[2019-04-14 22:51:29] [config] transformer-postprocess-emb: d
[2019-04-14 22:51:29] [config] transformer-preprocess: n
[2019-04-14 22:51:29] [config] transformer-tied-layers:
[2019-04-14 22:51:29] [config]   []
[2019-04-14 22:51:29] [config] transformer-train-position-embeddings: false
[2019-04-14 22:51:29] [config] type: transformer-context
[2019-04-14 22:51:29] [config] ulr: false
[2019-04-14 22:51:29] [config] ulr-dim-emb: 0
[2019-04-14 22:51:29] [config] ulr-dropout: 0
[2019-04-14 22:51:29] [config] ulr-keys-vectors: ""
[2019-04-14 22:51:29] [config] ulr-query-vectors: ""
[2019-04-14 22:51:29] [config] ulr-softmax-temperature: 1
[2019-04-14 22:51:29] [config] ulr-trainable-transformation: false
[2019-04-14 22:51:29] [config] valid-freq: 2000
[2019-04-14 22:51:29] [config] valid-log: model/valid.log
[2019-04-14 22:51:29] [config] valid-max-length: 1000
[2019-04-14 22:51:29] [config] valid-metrics:
[2019-04-14 22:51:29] [config]   - ce-mean-words
[2019-04-14 22:51:29] [config]   - perplexity
[2019-04-14 22:51:29] [config]   - translation
[2019-04-14 22:51:29] [config] valid-mini-batch: 16
[2019-04-14 22:51:29] [config] valid-script-path: ./val.sh
[2019-04-14 22:51:29] [config] valid-sets:
[2019-04-14 22:51:29] [config]   - newstest2016.docs.src_prev
[2019-04-14 22:51:29] [config]   - newstest2016.docs.src
[2019-04-14 22:51:29] [config]   - newstest2016.docs.cs.bpe
[2019-04-14 22:51:29] [config] valid-translation-output: ""
[2019-04-14 22:51:29] [config] vocabs:
[2019-04-14 22:51:29] [config]   - corp/vocab.encs.yml
[2019-04-14 22:51:29] [config]   - corp/vocab.encs.yml
[2019-04-14 22:51:29] [config]   - corp/vocab.encs.yml
[2019-04-14 22:51:29] [config] word-penalty: 0
[2019-04-14 22:51:29] [config] workspace: 6000
[2019-04-14 22:51:29] [config] Model is being created with Marian v1.7.8 eeb05e5 2019-04-14 22:45:14 +0200
[2019-04-14 22:51:29] Using synchronous training
[2019-04-14 22:51:29] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.yml
[2019-04-14 22:51:30] [data] Setting vocabulary size for input 0 to 34028
[2019-04-14 22:51:30] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.yml
[2019-04-14 22:51:30] [data] Setting vocabulary size for input 1 to 34028
[2019-04-14 22:51:30] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.yml
[2019-04-14 22:51:30] [data] Setting vocabulary size for input 2 to 34028
[2019-04-14 22:51:30] [sqlite] Creating temporary database in /home/tmp/tmp
[2019-04-14 22:51:34] [sqlite] Inserted 1000000 lines
[2019-04-14 22:51:38] [sqlite] Inserted 2000000 lines
[2019-04-14 22:51:45] [sqlite] Inserted 4000000 lines
[2019-04-14 22:52:00] [sqlite] Inserted 8000000 lines
[2019-04-14 22:52:37] [sqlite] Inserted 16000000 lines
[2019-04-14 22:53:45] [sqlite] Inserted 32000000 lines
[2019-04-14 22:55:38] [sqlite] Inserted 57951104 lines
[2019-04-14 22:55:38] [sqlite] Creating primary index
[2019-04-14 22:57:22] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-04-14 22:57:22] [batching] Collecting statistics for batch fitting with step size 10
[2019-04-14 22:57:23] [memory] Extending reserved space to 6016 MB (device gpu0)
[2019-04-14 22:57:25] [memory] Extending reserved space to 6016 MB (device gpu1)
[2019-04-14 22:57:25] [comm] NCCL communicator overridden
[2019-04-14 22:57:25] [training] Using 2 GPUs
[2019-04-14 22:57:25] [memory] Reserving 1142 MB, device gpu0
[2019-04-14 22:57:25] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-04-14 22:57:28] [memory] Reserving 1142 MB, device gpu0
[2019-04-14 22:57:33] [batching] Done. Typical MB size is 32864 target words
[2019-04-14 22:57:33] [memory] Extending reserved space to 6016 MB (device gpu0)
[2019-04-14 22:57:33] [memory] Extending reserved space to 6016 MB (device gpu1)
[2019-04-14 22:57:33] [comm] NCCL communicator overridden
[2019-04-14 22:57:33] [training] Using 2 GPUs
[2019-04-14 22:57:33] [training] Initializing model weights with the pre-trained model model/model_bt_noise_encz_bicleaner.npz.best-translation.npz
[2019-04-14 22:57:33] Loading model from model/model_bt_noise_encz_bicleaner.npz.best-translation.npz
[2019-04-14 22:57:41] Loading model from model/model_bt_noise_encz_bicleaner.npz.best-translation.npz
[2019-04-14 22:57:43] Training started
[2019-04-14 22:57:43] [sqlite] Selecting shuffled data
[2019-04-14 23:02:10] [training] Batches are processed as 1 process(es) x 2 devices/process
[2019-04-14 23:02:10] [memory] Reserving 1142 MB, device gpu1
[2019-04-14 23:02:10] [memory] Reserving 1142 MB, device gpu0
[2019-04-14 23:02:10] [memory] Reserving 1142 MB, device gpu1
[2019-04-14 23:02:10] [memory] Reserving 1142 MB, device gpu0
[2019-04-14 23:02:11] [memory] Reserving 571 MB, device gpu0
[2019-04-14 23:02:11] [memory] Reserving 571 MB, device gpu1
[2019-04-14 23:02:12] [memory] Reserving 571 MB, device gpu0
[2019-04-14 23:02:12] [memory] Reserving 571 MB, device gpu1
[2019-04-14 23:02:12] [memory] Reserving 1142 MB, device gpu1
[2019-04-14 23:02:12] [memory] Reserving 1142 MB, device gpu0
[2019-04-14 23:05:37] Ep. 1 : Up. 100 : Sen. 58,137 : Cost 9.28254604 : Time 495.23s : 1522.18 words/s : L.r. 2.5000e-06
[2019-04-14 23:08:57] Ep. 1 : Up. 200 : Sen. 99,271 : Cost 8.60025501 : Time 199.89s : 3548.46 words/s : L.r. 5.0000e-06
[2019-04-14 23:12:23] Ep. 1 : Up. 300 : Sen. 150,046 : Cost 8.41786385 : Time 206.19s : 3797.45 words/s : L.r. 7.5000e-06
[2019-04-14 23:15:43] Ep. 1 : Up. 400 : Sen. 189,638 : Cost 8.52677345 : Time 199.59s : 3571.34 words/s : L.r. 1.0000e-05
[2019-04-14 23:19:06] Ep. 1 : Up. 500 : Sen. 239,004 : Cost 8.33601856 : Time 202.92s : 3590.40 words/s : L.r. 1.2500e-05
[2019-04-14 23:22:31] Ep. 1 : Up. 600 : Sen. 289,505 : Cost 8.30369854 : Time 205.51s : 3690.57 words/s : L.r. 1.5000e-05
[2019-04-14 23:25:51] Ep. 1 : Up. 700 : Sen. 335,174 : Cost 8.28261375 : Time 199.87s : 3513.13 words/s : L.r. 1.7500e-05
[2019-04-14 23:29:23] Ep. 1 : Up. 800 : Sen. 388,207 : Cost 8.23041344 : Time 211.81s : 3968.94 words/s : L.r. 2.0000e-05
[2019-04-14 23:32:44] Ep. 1 : Up. 900 : Sen. 435,807 : Cost 8.21258354 : Time 201.37s : 3597.51 words/s : L.r. 2.2500e-05
[2019-04-14 23:36:01] Ep. 1 : Up. 1000 : Sen. 478,523 : Cost 8.26961899 : Time 196.27s : 3500.55 words/s : L.r. 2.5000e-05
[2019-04-14 23:39:25] Ep. 1 : Up. 1100 : Sen. 526,866 : Cost 8.20607090 : Time 204.67s : 3645.13 words/s : L.r. 2.7500e-05
[2019-04-14 23:42:45] Ep. 1 : Up. 1200 : Sen. 574,271 : Cost 8.18912792 : Time 200.20s : 3508.24 words/s : L.r. 3.0000e-05
[2019-04-14 23:46:24] Ep. 1 : Up. 1300 : Sen. 638,289 : Cost 8.10226154 : Time 218.84s : 4142.58 words/s : L.r. 3.2500e-05
[2019-04-14 23:49:43] Ep. 1 : Up. 1400 : Sen. 683,849 : Cost 8.17865086 : Time 198.97s : 3476.34 words/s : L.r. 3.5000e-05
[2019-04-14 23:53:03] Ep. 1 : Up. 1500 : Sen. 726,477 : Cost 8.19539642 : Time 199.95s : 3650.17 words/s : L.r. 3.7500e-05
[2019-04-14 23:56:44] Ep. 1 : Up. 1600 : Sen. 798,329 : Cost 8.01390076 : Time 221.28s : 4188.75 words/s : L.r. 4.0000e-05
[2019-04-15 00:00:12] Ep. 1 : Up. 1700 : Sen. 855,096 : Cost 8.13063431 : Time 207.14s : 3845.00 words/s : L.r. 4.2500e-05
[2019-04-15 00:03:35] Ep. 1 : Up. 1800 : Sen. 904,628 : Cost 8.16537952 : Time 203.53s : 3679.15 words/s : L.r. 4.5000e-05
[2019-04-15 00:06:59] Ep. 1 : Up. 1900 : Sen. 949,651 : Cost 8.24360180 : Time 204.38s : 3688.45 words/s : L.r. 4.7500e-05
[2019-04-15 00:10:23] Ep. 1 : Up. 2000 : Sen. 994,538 : Cost 8.25186825 : Time 203.28s : 3659.13 words/s : L.r. 5.0000e-05
[2019-04-15 00:10:23] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_poseidon_doc_fix_emb.npz.orig.npz
[2019-04-15 00:10:52] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_poseidon_doc_fix_emb.npz
[2019-04-15 00:11:21] Saving Adam parameters to model/model_bt_noise_encz_bicleaner_poseidon_doc_fix_emb.npz.optimizer.npz
[2019-04-15 00:12:11] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_poseidon_doc_fix_emb.npz.best-ce-mean-words.npz
[2019-04-15 00:12:30] [valid] Ep. 1 : Up. 2000 : ce-mean-words : 8.23606 : new best
[2019-04-15 00:12:36] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_poseidon_doc_fix_emb.npz.best-perplexity.npz
[2019-04-15 00:12:54] [valid] Ep. 1 : Up. 2000 : perplexity : 3774.62 : new best
train_bt_encs_biclean+bt_noise.poseidon_doc.sh: line 28: 29443 Terminated              $marian/marian --model model/model_bt_noise_encz_bicleaner_poseidon_doc_fix_emb.npz --pretrained-model model/model_bt_noise_encz_bicleaner.npz.best-translation.npz --type transformer-context --train-sets corpus.docs.en.bpe.src_prev corpus.docs.en.bpe.src corpus.docs.cs.bpe -e 1 --max-length 100 --vocabs corp/vocab.encs.yml corp/vocab.encs.yml corp/vocab.encs.yml --mini-batch-fit -w 6000 --mini-batch 1000 --maxi-batch 1000 --freeze --valid-freq 2000 --save-freq 2000 --disp-freq 100 --embedding-fix-src --embedding-fix-trg --valid-metrics ce-mean-words perplexity translation --valid-sets newstest2016.docs.src_prev newstest2016.docs.src newstest2016.docs.cs.bpe --valid-script-path ./val.sh --quiet-translation --beam-size 6 --normalize=0.6 --valid-mini-batch 16 --overwrite --keep-best --optimizer-delay 16 --early-stopping 15 --cost-type=ce-mean-words --log model/bt_encz.log --valid-log model/valid.log --enc-depth 6 --dec-depth 6 --transformer-preprocess n --transformer-postprocess da --tied-embeddings-all --dim-emb 1024 --transformer-dim-ffn 4096 --transformer-heads 16 --transformer-dropout 0.1 --transformer-dropout-attention 0.1 --transformer-dropout-ffn 0.1 --label-smoothing 0.1 --learn-rate 0.0002 --lr-warmup 8000 --lr-decay-inv-sqrt 8000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --devices 0 1 --no-nccl --sync-sgd --seed 0 --exponential-smoothing --sqlite -T /home/tmp/tmp
