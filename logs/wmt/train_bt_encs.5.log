ITERATION 4
[2019-03-31 05:30:16] [marian] Marian v1.7.6 9cc5b17 2018-12-14 15:11:34 -0800
[2019-03-31 05:30:16] [marian] Running on spider3.lingea.cz as process 11568 with command line:
[2019-03-31 05:30:16] [marian] /home/big_maggie/usr/marian_spider/marian_1.7.6/marian-dev/build/marian --model model/model_bt_encz.npz --type transformer --train-sets corpus+paracrawl.2M.en.bpe corpus+paracrawl.2M.cz.bpe -e 4 --max-length 100 --vocabs corp/vocab.encs.yml corp/vocab.encs.yml --mini-batch-fit -w 8600 --mini-batch 1000 --maxi-batch 10000 --valid-freq 5000 --save-freq 5000 --disp-freq 500 --valid-metrics ce-mean-words perplexity translation --valid-sets corp/newstest2016-encs-src.en.bpe corp/newstest2016-encs-ref.cs.bpe --valid-script-path ./val.sh --quiet-translation --beam-size 6 --normalize=0.6 --valid-mini-batch 16 --overwrite --keep-best --optimizer-delay 4 --early-stopping 15 --cost-type=ce-mean-words --log model/bt_encz.log --valid-log model/valid.log --enc-depth 6 --dec-depth 6 --transformer-preprocess n --transformer-postprocess da --tied-embeddings-all --dim-emb 1024 --transformer-dim-ffn 4096 --transformer-heads 16 --transformer-dropout 0.1 --transformer-dropout-attention 0.1 --transformer-dropout-ffn 0.1 --label-smoothing 0.1 --learn-rate 0.0002 --lr-warmup 8000 --lr-decay-inv-sqrt 8000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --devices 0 1 --sync-sgd --seed 0 --no-nccl --exponential-smoothing --sqlite -T /tmp
[2019-03-31 05:30:17] [config] after-batches: 0
[2019-03-31 05:30:17] [config] after-epochs: 4
[2019-03-31 05:30:17] [config] allow-unk: false
[2019-03-31 05:30:17] [config] beam-size: 6
[2019-03-31 05:30:17] [config] best-deep: false
[2019-03-31 05:30:17] [config] clip-gemm: 0
[2019-03-31 05:30:17] [config] clip-norm: 5
[2019-03-31 05:30:17] [config] cost-type: ce-mean-words
[2019-03-31 05:30:17] [config] cpu-threads: 0
[2019-03-31 05:30:17] [config] data-weighting-type: sentence
[2019-03-31 05:30:17] [config] dec-cell: gru
[2019-03-31 05:30:17] [config] dec-cell-base-depth: 2
[2019-03-31 05:30:17] [config] dec-cell-high-depth: 1
[2019-03-31 05:30:17] [config] dec-depth: 6
[2019-03-31 05:30:17] [config] devices:
[2019-03-31 05:30:17] [config]   - 0
[2019-03-31 05:30:17] [config]   - 1
[2019-03-31 05:30:17] [config] dim-emb: 1024
[2019-03-31 05:30:17] [config] dim-rnn: 1024
[2019-03-31 05:30:17] [config] dim-vocabs:
[2019-03-31 05:30:17] [config]   - 34028
[2019-03-31 05:30:17] [config]   - 34028
[2019-03-31 05:30:17] [config] disp-first: 0
[2019-03-31 05:30:17] [config] disp-freq: 500
[2019-03-31 05:30:17] [config] disp-label-counts: false
[2019-03-31 05:30:17] [config] dropout-rnn: 0
[2019-03-31 05:30:17] [config] dropout-src: 0
[2019-03-31 05:30:17] [config] dropout-trg: 0
[2019-03-31 05:30:17] [config] early-stopping: 15
[2019-03-31 05:30:17] [config] embedding-fix-src: false
[2019-03-31 05:30:17] [config] embedding-fix-trg: false
[2019-03-31 05:30:17] [config] embedding-normalization: false
[2019-03-31 05:30:17] [config] enc-cell: gru
[2019-03-31 05:30:17] [config] enc-cell-depth: 1
[2019-03-31 05:30:17] [config] enc-depth: 6
[2019-03-31 05:30:17] [config] enc-type: bidirectional
[2019-03-31 05:30:17] [config] exponential-smoothing: 0.0001
[2019-03-31 05:30:17] [config] grad-dropping-momentum: 0
[2019-03-31 05:30:17] [config] grad-dropping-rate: 0
[2019-03-31 05:30:17] [config] grad-dropping-warmup: 100
[2019-03-31 05:30:17] [config] guided-alignment: none
[2019-03-31 05:30:17] [config] guided-alignment-cost: mse
[2019-03-31 05:30:17] [config] guided-alignment-weight: 0.1
[2019-03-31 05:30:17] [config] ignore-model-config: false
[2019-03-31 05:30:17] [config] interpolate-env-vars: false
[2019-03-31 05:30:17] [config] keep-best: true
[2019-03-31 05:30:17] [config] label-smoothing: 0.1
[2019-03-31 05:30:17] [config] layer-normalization: false
[2019-03-31 05:30:17] [config] learn-rate: 0.0002
[2019-03-31 05:30:17] [config] log: model/bt_encz.log
[2019-03-31 05:30:17] [config] log-level: info
[2019-03-31 05:30:17] [config] lr-decay: 0
[2019-03-31 05:30:17] [config] lr-decay-freq: 50000
[2019-03-31 05:30:17] [config] lr-decay-inv-sqrt: 8000
[2019-03-31 05:30:17] [config] lr-decay-repeat-warmup: false
[2019-03-31 05:30:17] [config] lr-decay-reset-optimizer: false
[2019-03-31 05:30:17] [config] lr-decay-start:
[2019-03-31 05:30:17] [config]   - 10
[2019-03-31 05:30:17] [config]   - 1
[2019-03-31 05:30:17] [config] lr-decay-strategy: epoch+stalled
[2019-03-31 05:30:17] [config] lr-report: true
[2019-03-31 05:30:17] [config] lr-warmup: 8000
[2019-03-31 05:30:17] [config] lr-warmup-at-reload: false
[2019-03-31 05:30:17] [config] lr-warmup-cycle: false
[2019-03-31 05:30:17] [config] lr-warmup-start-rate: 0
[2019-03-31 05:30:17] [config] max-length: 100
[2019-03-31 05:30:17] [config] max-length-crop: false
[2019-03-31 05:30:17] [config] max-length-factor: 3
[2019-03-31 05:30:17] [config] maxi-batch: 10000
[2019-03-31 05:30:17] [config] maxi-batch-sort: trg
[2019-03-31 05:30:17] [config] mini-batch: 1000
[2019-03-31 05:30:17] [config] mini-batch-fit: true
[2019-03-31 05:30:17] [config] mini-batch-fit-step: 10
[2019-03-31 05:30:17] [config] mini-batch-words: 0
[2019-03-31 05:30:17] [config] model: model/model_bt_encz.npz
[2019-03-31 05:30:17] [config] multi-node: false
[2019-03-31 05:30:17] [config] multi-node-overlap: true
[2019-03-31 05:30:17] [config] n-best: false
[2019-03-31 05:30:17] [config] no-nccl: true
[2019-03-31 05:30:17] [config] no-reload: false
[2019-03-31 05:30:17] [config] no-restore-corpus: false
[2019-03-31 05:30:17] [config] no-shuffle: false
[2019-03-31 05:30:17] [config] normalize: 0.6
[2019-03-31 05:30:17] [config] optimizer: adam
[2019-03-31 05:30:17] [config] optimizer-delay: 4
[2019-03-31 05:30:17] [config] optimizer-params:
[2019-03-31 05:30:17] [config]   - 0.9
[2019-03-31 05:30:17] [config]   - 0.98
[2019-03-31 05:30:17] [config]   - 1e-09
[2019-03-31 05:30:17] [config] overwrite: true
[2019-03-31 05:30:17] [config] quiet: false
[2019-03-31 05:30:17] [config] quiet-translation: true
[2019-03-31 05:30:17] [config] relative-paths: false
[2019-03-31 05:30:17] [config] right-left: false
[2019-03-31 05:30:17] [config] save-freq: 5000
[2019-03-31 05:30:17] [config] seed: 0
[2019-03-31 05:30:17] [config] sentencepiece-alphas:
[2019-03-31 05:30:17] [config]   []
[2019-03-31 05:30:17] [config] sentencepiece-max-lines: 10000000
[2019-03-31 05:30:17] [config] sentencepiece-options: ""
[2019-03-31 05:30:17] [config] shuffle-in-ram: false
[2019-03-31 05:30:17] [config] skip: false
[2019-03-31 05:30:17] [config] sqlite: temporary
[2019-03-31 05:30:17] [config] sqlite-drop: false
[2019-03-31 05:30:17] [config] sync-sgd: true
[2019-03-31 05:30:17] [config] tempdir: /tmp
[2019-03-31 05:30:17] [config] tied-embeddings: false
[2019-03-31 05:30:17] [config] tied-embeddings-all: true
[2019-03-31 05:30:17] [config] tied-embeddings-src: false
[2019-03-31 05:30:17] [config] train-sets:
[2019-03-31 05:30:17] [config]   - corpus+paracrawl.2M.en.bpe
[2019-03-31 05:30:17] [config]   - corpus+paracrawl.2M.cz.bpe
[2019-03-31 05:30:17] [config] transformer-aan-activation: swish
[2019-03-31 05:30:17] [config] transformer-aan-depth: 2
[2019-03-31 05:30:17] [config] transformer-aan-nogate: false
[2019-03-31 05:30:17] [config] transformer-decoder-autoreg: self-attention
[2019-03-31 05:30:17] [config] transformer-dim-aan: 2048
[2019-03-31 05:30:17] [config] transformer-dim-ffn: 4096
[2019-03-31 05:30:17] [config] transformer-dropout: 0.1
[2019-03-31 05:30:17] [config] transformer-dropout-attention: 0.1
[2019-03-31 05:30:17] [config] transformer-dropout-ffn: 0.1
[2019-03-31 05:30:17] [config] transformer-ffn-activation: swish
[2019-03-31 05:30:17] [config] transformer-ffn-depth: 2
[2019-03-31 05:30:17] [config] transformer-guided-alignment-layer: last
[2019-03-31 05:30:17] [config] transformer-heads: 16
[2019-03-31 05:30:17] [config] transformer-no-projection: false
[2019-03-31 05:30:17] [config] transformer-postprocess: da
[2019-03-31 05:30:17] [config] transformer-postprocess-emb: d
[2019-03-31 05:30:17] [config] transformer-preprocess: n
[2019-03-31 05:30:17] [config] transformer-tied-layers:
[2019-03-31 05:30:17] [config]   []
[2019-03-31 05:30:17] [config] type: transformer
[2019-03-31 05:30:17] [config] ulr: false
[2019-03-31 05:30:17] [config] ulr-dim-emb: 0
[2019-03-31 05:30:17] [config] ulr-dropout: 0
[2019-03-31 05:30:17] [config] ulr-keys-vectors: ""
[2019-03-31 05:30:17] [config] ulr-query-vectors: ""
[2019-03-31 05:30:17] [config] ulr-softmax-temperature: 1
[2019-03-31 05:30:17] [config] ulr-trainable-transformation: false
[2019-03-31 05:30:17] [config] valid-freq: 5000
[2019-03-31 05:30:17] [config] valid-log: model/valid.log
[2019-03-31 05:30:17] [config] valid-max-length: 1000
[2019-03-31 05:30:17] [config] valid-metrics:
[2019-03-31 05:30:17] [config]   - ce-mean-words
[2019-03-31 05:30:17] [config]   - perplexity
[2019-03-31 05:30:17] [config]   - translation
[2019-03-31 05:30:17] [config] valid-mini-batch: 16
[2019-03-31 05:30:17] [config] valid-script-path: ./val.sh
[2019-03-31 05:30:17] [config] valid-sets:
[2019-03-31 05:30:17] [config]   - corp/newstest2016-encs-src.en.bpe
[2019-03-31 05:30:17] [config]   - corp/newstest2016-encs-ref.cs.bpe
[2019-03-31 05:30:17] [config] version: v1.7.6 9cc5b17 2018-12-14 15:11:34 -0800
[2019-03-31 05:30:17] [config] vocabs:
[2019-03-31 05:30:17] [config]   - corp/vocab.encs.yml
[2019-03-31 05:30:17] [config]   - corp/vocab.encs.yml
[2019-03-31 05:30:17] [config] word-penalty: 0
[2019-03-31 05:30:17] [config] workspace: 8600
[2019-03-31 05:30:17] [config] Loaded model has been created with Marian v1.7.6 9cc5b17 2018-12-14 15:11:34 -0800
[2019-03-31 05:30:17] Using synchronous training
[2019-03-31 05:30:17] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.yml
[2019-03-31 05:30:17] [data] Setting vocabulary size for input 0 to 34028
[2019-03-31 05:30:17] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.yml
[2019-03-31 05:30:18] [data] Setting vocabulary size for input 1 to 34028
[2019-03-31 05:30:18] [sqlite] Creating temporary database in /tmp
[2019-03-31 05:30:24] [sqlite] Inserted 1000000 lines
[2019-03-31 05:30:28] [sqlite] Inserted 2000000 lines
[2019-03-31 05:30:39] [sqlite] Inserted 4000000 lines
[2019-03-31 05:31:17] [sqlite] Inserted 8000000 lines
[2019-03-31 05:32:40] [sqlite] Inserted 16000000 lines
[2019-03-31 05:35:42] [sqlite] Inserted 32000000 lines
[2019-03-31 05:37:23] [sqlite] Inserted 41438108 lines
[2019-03-31 05:37:23] [sqlite] Creating primary index
[2019-03-31 05:47:28] [batching] Collecting statistics for batch fitting with step size 10
[2019-03-31 05:47:28] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-03-31 05:47:30] [memory] Extending reserved space to 8704 MB (device gpu0)
[2019-03-31 05:47:31] Error: CUDA error 2 'out of memory' - /home/big_maggie/usr/marian_spider/marian_1.7.6/marian-dev/src/tensors/gpu/device.cu:38: cudaMalloc(&data_, size)
[2019-03-31 05:47:31] Error: Aborted from virtual void marian::gpu::Device::reserve(size_t) in /home/big_maggie/usr/marian_spider/marian_1.7.6/marian-dev/src/tensors/gpu/device.cu:38

[CALL STACK]
[0xa50f57]                                                            
[0x755b28]                                                            
[0x47ec84]                                                            
[0x505a1a]                                                            
[0x44d72d]                                                            
[0x421b70]                                                            
[0x7fcfe3881b35]    __libc_start_main                                  + 0xf5
[0x44a19c]                                                            

train_bt_encs.sh: line 2: 11568 Aborted                 (core dumped) $marian/marian --model model/model_bt_encz.npz --type transformer --train-sets corpus+paracrawl.2M.en.bpe corpus+paracrawl.2M.cz.bpe -e $e --max-length 100 --vocabs corp/vocab.encs.yml corp/vocab.encs.yml --mini-batch-fit -w 8600 --mini-batch 1000 --maxi-batch 10000 --valid-freq 5000 --save-freq 5000 --disp-freq 500 --valid-metrics ce-mean-words perplexity translation --valid-sets corp/newstest2016-encs-src.en.bpe corp/newstest2016-encs-ref.cs.bpe --valid-script-path ./val.sh --quiet-translation --beam-size 6 --normalize=0.6 --valid-mini-batch 16 --overwrite --keep-best --optimizer-delay 4 --early-stopping 15 --cost-type=ce-mean-words --log model/bt_encz.log --valid-log model/valid.log --enc-depth 6 --dec-depth 6 --transformer-preprocess n --transformer-postprocess da --tied-embeddings-all --dim-emb 1024 --transformer-dim-ffn 4096 --transformer-heads 16 --transformer-dropout 0.1 --transformer-dropout-attention 0.1 --transformer-dropout-ffn 0.1 --label-smoothing 0.1 --learn-rate 0.0002 --lr-warmup 8000 --lr-decay-inv-sqrt 8000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --devices 0 1 --sync-sgd --seed 0 --no-nccl --exponential-smoothing --sqlite -T /tmp
rm: cannot remove ‘model/model_bt_encz.npz.yml’: No such file or directory
[2019-03-31 05:47:42] [marian] Marian v1.7.6 9cc5b17 2018-12-14 15:11:34 -0800
[2019-03-31 05:47:42] [marian] Running on spider3.lingea.cz as process 11841 with command line:
[2019-03-31 05:47:42] [marian] /home/big_maggie/usr/marian_spider/marian_1.7.6/marian-dev/build/marian --model model/model_bt_encz.npz --type transformer --train-sets bt.encz.en.bpe bt.encz.cz.bpe -e 5 --max-length 100 --vocabs corp/vocab.encs.yml corp/vocab.encs.yml --mini-batch-fit -w 8600 --mini-batch 1000 --maxi-batch 10000 --valid-freq 5000 --save-freq 5000 --disp-freq 500 --optimizer-delay 4 --valid-metrics ce-mean-words perplexity translation --valid-sets corp/newstest2016-encs-src.en.bpe corp/newstest2016-encs-ref.cs.bpe --valid-script-path ./val.sh --quiet-translation --beam-size 6 --normalize=0.6 --valid-mini-batch 16 --overwrite --keep-best --early-stopping 15 --cost-type=ce-mean-words --log model/bt_encz.log --valid-log model/valid.log --enc-depth 6 --dec-depth 6 --transformer-preprocess n --transformer-postprocess da --tied-embeddings-all --dim-emb 1024 --transformer-dim-ffn 4096 --transformer-heads 16 --transformer-dropout 0.1 --transformer-dropout-attention 0.1 --transformer-dropout-ffn 0.1 --label-smoothing 0.1 --learn-rate 0.0002 --lr-warmup 8000 --lr-decay-inv-sqrt 8000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --devices 0 1 --sync-sgd --seed 0 --no-nccl --exponential-smoothing --sqlite -T /tmp
[2019-03-31 05:47:43] [config] after-batches: 0
[2019-03-31 05:47:43] [config] after-epochs: 5
[2019-03-31 05:47:43] [config] allow-unk: false
[2019-03-31 05:47:43] [config] beam-size: 6
[2019-03-31 05:47:43] [config] best-deep: false
[2019-03-31 05:47:43] [config] clip-gemm: 0
[2019-03-31 05:47:43] [config] clip-norm: 5
[2019-03-31 05:47:43] [config] cost-type: ce-mean-words
[2019-03-31 05:47:43] [config] cpu-threads: 0
[2019-03-31 05:47:43] [config] data-weighting-type: sentence
[2019-03-31 05:47:43] [config] dec-cell: gru
[2019-03-31 05:47:43] [config] dec-cell-base-depth: 2
[2019-03-31 05:47:43] [config] dec-cell-high-depth: 1
[2019-03-31 05:47:43] [config] dec-depth: 6
[2019-03-31 05:47:43] [config] devices:
[2019-03-31 05:47:43] [config]   - 0
[2019-03-31 05:47:43] [config]   - 1
[2019-03-31 05:47:43] [config] dim-emb: 1024
[2019-03-31 05:47:43] [config] dim-rnn: 1024
[2019-03-31 05:47:43] [config] dim-vocabs:
[2019-03-31 05:47:43] [config]   - 34028
[2019-03-31 05:47:43] [config]   - 34028
[2019-03-31 05:47:43] [config] disp-first: 0
[2019-03-31 05:47:43] [config] disp-freq: 500
[2019-03-31 05:47:43] [config] disp-label-counts: false
[2019-03-31 05:47:43] [config] dropout-rnn: 0
[2019-03-31 05:47:43] [config] dropout-src: 0
[2019-03-31 05:47:43] [config] dropout-trg: 0
[2019-03-31 05:47:43] [config] early-stopping: 15
[2019-03-31 05:47:43] [config] embedding-fix-src: false
[2019-03-31 05:47:43] [config] embedding-fix-trg: false
[2019-03-31 05:47:43] [config] embedding-normalization: false
[2019-03-31 05:47:43] [config] enc-cell: gru
[2019-03-31 05:47:43] [config] enc-cell-depth: 1
[2019-03-31 05:47:43] [config] enc-depth: 6
[2019-03-31 05:47:43] [config] enc-type: bidirectional
[2019-03-31 05:47:43] [config] exponential-smoothing: 0.0001
[2019-03-31 05:47:43] [config] grad-dropping-momentum: 0
[2019-03-31 05:47:43] [config] grad-dropping-rate: 0
[2019-03-31 05:47:43] [config] grad-dropping-warmup: 100
[2019-03-31 05:47:43] [config] guided-alignment: none
[2019-03-31 05:47:43] [config] guided-alignment-cost: mse
[2019-03-31 05:47:43] [config] guided-alignment-weight: 0.1
[2019-03-31 05:47:43] [config] ignore-model-config: false
[2019-03-31 05:47:43] [config] interpolate-env-vars: false
[2019-03-31 05:47:43] [config] keep-best: true
[2019-03-31 05:47:43] [config] label-smoothing: 0.1
[2019-03-31 05:47:43] [config] layer-normalization: false
[2019-03-31 05:47:43] [config] learn-rate: 0.0002
[2019-03-31 05:47:43] [config] log: model/bt_encz.log
[2019-03-31 05:47:43] [config] log-level: info
[2019-03-31 05:47:43] [config] lr-decay: 0
[2019-03-31 05:47:43] [config] lr-decay-freq: 50000
[2019-03-31 05:47:43] [config] lr-decay-inv-sqrt: 8000
[2019-03-31 05:47:43] [config] lr-decay-repeat-warmup: false
[2019-03-31 05:47:43] [config] lr-decay-reset-optimizer: false
[2019-03-31 05:47:43] [config] lr-decay-start:
[2019-03-31 05:47:43] [config]   - 10
[2019-03-31 05:47:43] [config]   - 1
[2019-03-31 05:47:43] [config] lr-decay-strategy: epoch+stalled
[2019-03-31 05:47:43] [config] lr-report: true
[2019-03-31 05:47:43] [config] lr-warmup: 8000
[2019-03-31 05:47:43] [config] lr-warmup-at-reload: false
[2019-03-31 05:47:43] [config] lr-warmup-cycle: false
[2019-03-31 05:47:43] [config] lr-warmup-start-rate: 0
[2019-03-31 05:47:43] [config] max-length: 100
[2019-03-31 05:47:43] [config] max-length-crop: false
[2019-03-31 05:47:43] [config] max-length-factor: 3
[2019-03-31 05:47:43] [config] maxi-batch: 10000
[2019-03-31 05:47:43] [config] maxi-batch-sort: trg
[2019-03-31 05:47:43] [config] mini-batch: 1000
[2019-03-31 05:47:43] [config] mini-batch-fit: true
[2019-03-31 05:47:43] [config] mini-batch-fit-step: 10
[2019-03-31 05:47:43] [config] mini-batch-words: 0
[2019-03-31 05:47:43] [config] model: model/model_bt_encz.npz
[2019-03-31 05:47:43] [config] multi-node: false
[2019-03-31 05:47:43] [config] multi-node-overlap: true
[2019-03-31 05:47:43] [config] n-best: false
[2019-03-31 05:47:43] [config] no-nccl: true
[2019-03-31 05:47:43] [config] no-reload: false
[2019-03-31 05:47:43] [config] no-restore-corpus: false
[2019-03-31 05:47:43] [config] no-shuffle: false
[2019-03-31 05:47:43] [config] normalize: 0.6
[2019-03-31 05:47:43] [config] optimizer: adam
[2019-03-31 05:47:43] [config] optimizer-delay: 4
[2019-03-31 05:47:43] [config] optimizer-params:
[2019-03-31 05:47:43] [config]   - 0.9
[2019-03-31 05:47:43] [config]   - 0.98
[2019-03-31 05:47:43] [config]   - 1e-09
[2019-03-31 05:47:43] [config] overwrite: true
[2019-03-31 05:47:43] [config] quiet: false
[2019-03-31 05:47:43] [config] quiet-translation: true
[2019-03-31 05:47:43] [config] relative-paths: false
[2019-03-31 05:47:43] [config] right-left: false
[2019-03-31 05:47:43] [config] save-freq: 5000
[2019-03-31 05:47:43] [config] seed: 0
[2019-03-31 05:47:43] [config] sentencepiece-alphas:
[2019-03-31 05:47:43] [config]   []
[2019-03-31 05:47:43] [config] sentencepiece-max-lines: 10000000
[2019-03-31 05:47:43] [config] sentencepiece-options: ""
[2019-03-31 05:47:43] [config] shuffle-in-ram: false
[2019-03-31 05:47:43] [config] skip: false
[2019-03-31 05:47:43] [config] sqlite: temporary
[2019-03-31 05:47:43] [config] sqlite-drop: false
[2019-03-31 05:47:43] [config] sync-sgd: true
[2019-03-31 05:47:43] [config] tempdir: /tmp
[2019-03-31 05:47:43] [config] tied-embeddings: false
[2019-03-31 05:47:43] [config] tied-embeddings-all: true
[2019-03-31 05:47:43] [config] tied-embeddings-src: false
[2019-03-31 05:47:43] [config] train-sets:
[2019-03-31 05:47:43] [config]   - bt.encz.en.bpe
[2019-03-31 05:47:43] [config]   - bt.encz.cz.bpe
[2019-03-31 05:47:43] [config] transformer-aan-activation: swish
[2019-03-31 05:47:43] [config] transformer-aan-depth: 2
[2019-03-31 05:47:43] [config] transformer-aan-nogate: false
[2019-03-31 05:47:43] [config] transformer-decoder-autoreg: self-attention
[2019-03-31 05:47:43] [config] transformer-dim-aan: 2048
[2019-03-31 05:47:43] [config] transformer-dim-ffn: 4096
[2019-03-31 05:47:43] [config] transformer-dropout: 0.1
[2019-03-31 05:47:43] [config] transformer-dropout-attention: 0.1
[2019-03-31 05:47:43] [config] transformer-dropout-ffn: 0.1
[2019-03-31 05:47:43] [config] transformer-ffn-activation: swish
[2019-03-31 05:47:43] [config] transformer-ffn-depth: 2
[2019-03-31 05:47:43] [config] transformer-guided-alignment-layer: last
[2019-03-31 05:47:43] [config] transformer-heads: 16
[2019-03-31 05:47:43] [config] transformer-no-projection: false
[2019-03-31 05:47:43] [config] transformer-postprocess: da
[2019-03-31 05:47:43] [config] transformer-postprocess-emb: d
[2019-03-31 05:47:43] [config] transformer-preprocess: n
[2019-03-31 05:47:43] [config] transformer-tied-layers:
[2019-03-31 05:47:43] [config]   []
[2019-03-31 05:47:43] [config] type: transformer
[2019-03-31 05:47:43] [config] ulr: false
[2019-03-31 05:47:43] [config] ulr-dim-emb: 0
[2019-03-31 05:47:43] [config] ulr-dropout: 0
[2019-03-31 05:47:43] [config] ulr-keys-vectors: ""
[2019-03-31 05:47:43] [config] ulr-query-vectors: ""
[2019-03-31 05:47:43] [config] ulr-softmax-temperature: 1
[2019-03-31 05:47:43] [config] ulr-trainable-transformation: false
[2019-03-31 05:47:43] [config] valid-freq: 5000
[2019-03-31 05:47:43] [config] valid-log: model/valid.log
[2019-03-31 05:47:43] [config] valid-max-length: 1000
[2019-03-31 05:47:43] [config] valid-metrics:
[2019-03-31 05:47:43] [config]   - ce-mean-words
[2019-03-31 05:47:43] [config]   - perplexity
[2019-03-31 05:47:43] [config]   - translation
[2019-03-31 05:47:43] [config] valid-mini-batch: 16
[2019-03-31 05:47:43] [config] valid-script-path: ./val.sh
[2019-03-31 05:47:43] [config] valid-sets:
[2019-03-31 05:47:43] [config]   - corp/newstest2016-encs-src.en.bpe
[2019-03-31 05:47:43] [config]   - corp/newstest2016-encs-ref.cs.bpe
[2019-03-31 05:47:43] [config] version: v1.7.6 9cc5b17 2018-12-14 15:11:34 -0800
[2019-03-31 05:47:43] [config] vocabs:
[2019-03-31 05:47:43] [config]   - corp/vocab.encs.yml
[2019-03-31 05:47:43] [config]   - corp/vocab.encs.yml
[2019-03-31 05:47:43] [config] word-penalty: 0
[2019-03-31 05:47:43] [config] workspace: 8600
[2019-03-31 05:47:43] [config] Loaded model has been created with Marian v1.7.6 9cc5b17 2018-12-14 15:11:34 -0800
[2019-03-31 05:47:43] Using synchronous training
[2019-03-31 05:47:43] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.yml
[2019-03-31 05:47:44] [data] Setting vocabulary size for input 0 to 34028
[2019-03-31 05:47:44] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.yml
[2019-03-31 05:47:44] [data] Setting vocabulary size for input 1 to 34028
[2019-03-31 05:47:44] [sqlite] Creating temporary database in /tmp
[2019-03-31 05:47:49] [sqlite] Inserted 1000000 lines
[2019-03-31 05:47:54] [sqlite] Inserted 2000000 lines
[2019-03-31 05:48:02] [sqlite] Inserted 4000000 lines
[2019-03-31 05:48:18] [sqlite] Inserted 8000000 lines
[2019-03-31 05:49:35] [sqlite] Inserted 16000000 lines
[2019-03-31 05:53:44] [sqlite] Inserted 32000000 lines
[2019-03-31 06:00:14] [sqlite] Inserted 49633032 lines
[2019-03-31 06:00:14] [sqlite] Creating primary index
[2019-03-31 06:10:19] [batching] Collecting statistics for batch fitting with step size 10
[2019-03-31 06:10:19] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-03-31 06:10:22] [memory] Extending reserved space to 8704 MB (device gpu0)
[2019-03-31 06:10:23] Error: CUDA error 2 'out of memory' - /home/big_maggie/usr/marian_spider/marian_1.7.6/marian-dev/src/tensors/gpu/device.cu:38: cudaMalloc(&data_, size)
[2019-03-31 06:10:23] Error: Aborted from virtual void marian::gpu::Device::reserve(size_t) in /home/big_maggie/usr/marian_spider/marian_1.7.6/marian-dev/src/tensors/gpu/device.cu:38

[CALL STACK]
[0xa50f57]                                                            
[0x755b28]                                                            
[0x47ec84]                                                            
[0x505a1a]                                                            
[0x44d72d]                                                            
[0x421b70]                                                            
[0x7f13617e9b35]    __libc_start_main                                  + 0xf5
[0x44a19c]                                                            

train_bt_encs.sh: line 2: 11841 Aborted                 (core dumped) $marian/marian --model model/model_bt_encz.npz --type transformer --train-sets bt.encz.en.bpe bt.encz.cz.bpe -e $i --max-length 100 --vocabs corp/vocab.encs.yml corp/vocab.encs.yml --mini-batch-fit -w 8600 --mini-batch 1000 --maxi-batch 10000 --valid-freq 5000 --save-freq 5000 --disp-freq 500 --optimizer-delay 4 --valid-metrics ce-mean-words perplexity translation --valid-sets corp/newstest2016-encs-src.en.bpe corp/newstest2016-encs-ref.cs.bpe --valid-script-path ./val.sh --quiet-translation --beam-size 6 --normalize=0.6 --valid-mini-batch 16 --overwrite --keep-best --early-stopping 15 --cost-type=ce-mean-words --log model/bt_encz.log --valid-log model/valid.log --enc-depth 6 --dec-depth 6 --transformer-preprocess n --transformer-postprocess da --tied-embeddings-all --dim-emb 1024 --transformer-dim-ffn 4096 --transformer-heads 16 --transformer-dropout 0.1 --transformer-dropout-attention 0.1 --transformer-dropout-ffn 0.1 --label-smoothing 0.1 --learn-rate 0.0002 --lr-warmup 8000 --lr-decay-inv-sqrt 8000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --devices 0 1 --sync-sgd --seed 0 --no-nccl --exponential-smoothing --sqlite -T /tmp
rm: cannot remove ‘model/model_bt_encz.npz.yml’: No such file or directory
ITERATION 5
[2019-03-31 06:10:35] [marian] Marian v1.7.6 9cc5b17 2018-12-14 15:11:34 -0800
[2019-03-31 06:10:35] [marian] Running on spider3.lingea.cz as process 12209 with command line:
[2019-03-31 06:10:35] [marian] /home/big_maggie/usr/marian_spider/marian_1.7.6/marian-dev/build/marian --model model/model_bt_encz.npz --type transformer --train-sets corpus+paracrawl.2M.en.bpe corpus+paracrawl.2M.cz.bpe -e 5 --max-length 100 --vocabs corp/vocab.encs.yml corp/vocab.encs.yml --mini-batch-fit -w 8600 --mini-batch 1000 --maxi-batch 10000 --valid-freq 5000 --save-freq 5000 --disp-freq 500 --valid-metrics ce-mean-words perplexity translation --valid-sets corp/newstest2016-encs-src.en.bpe corp/newstest2016-encs-ref.cs.bpe --valid-script-path ./val.sh --quiet-translation --beam-size 6 --normalize=0.6 --valid-mini-batch 16 --overwrite --keep-best --optimizer-delay 4 --early-stopping 15 --cost-type=ce-mean-words --log model/bt_encz.log --valid-log model/valid.log --enc-depth 6 --dec-depth 6 --transformer-preprocess n --transformer-postprocess da --tied-embeddings-all --dim-emb 1024 --transformer-dim-ffn 4096 --transformer-heads 16 --transformer-dropout 0.1 --transformer-dropout-attention 0.1 --transformer-dropout-ffn 0.1 --label-smoothing 0.1 --learn-rate 0.0002 --lr-warmup 8000 --lr-decay-inv-sqrt 8000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --devices 0 1 --sync-sgd --seed 0 --no-nccl --exponential-smoothing --sqlite -T /tmp
[2019-03-31 06:10:36] [config] after-batches: 0
[2019-03-31 06:10:36] [config] after-epochs: 5
[2019-03-31 06:10:36] [config] allow-unk: false
[2019-03-31 06:10:36] [config] beam-size: 6
[2019-03-31 06:10:36] [config] best-deep: false
[2019-03-31 06:10:36] [config] clip-gemm: 0
[2019-03-31 06:10:36] [config] clip-norm: 5
[2019-03-31 06:10:36] [config] cost-type: ce-mean-words
[2019-03-31 06:10:36] [config] cpu-threads: 0
[2019-03-31 06:10:36] [config] data-weighting-type: sentence
[2019-03-31 06:10:36] [config] dec-cell: gru
[2019-03-31 06:10:36] [config] dec-cell-base-depth: 2
[2019-03-31 06:10:36] [config] dec-cell-high-depth: 1
[2019-03-31 06:10:36] [config] dec-depth: 6
[2019-03-31 06:10:36] [config] devices:
[2019-03-31 06:10:36] [config]   - 0
[2019-03-31 06:10:36] [config]   - 1
[2019-03-31 06:10:36] [config] dim-emb: 1024
[2019-03-31 06:10:36] [config] dim-rnn: 1024
[2019-03-31 06:10:36] [config] dim-vocabs:
[2019-03-31 06:10:36] [config]   - 34028
[2019-03-31 06:10:36] [config]   - 34028
[2019-03-31 06:10:36] [config] disp-first: 0
[2019-03-31 06:10:36] [config] disp-freq: 500
[2019-03-31 06:10:36] [config] disp-label-counts: false
[2019-03-31 06:10:36] [config] dropout-rnn: 0
[2019-03-31 06:10:36] [config] dropout-src: 0
[2019-03-31 06:10:36] [config] dropout-trg: 0
[2019-03-31 06:10:36] [config] early-stopping: 15
[2019-03-31 06:10:36] [config] embedding-fix-src: false
[2019-03-31 06:10:36] [config] embedding-fix-trg: false
[2019-03-31 06:10:36] [config] embedding-normalization: false
[2019-03-31 06:10:36] [config] enc-cell: gru
[2019-03-31 06:10:36] [config] enc-cell-depth: 1
[2019-03-31 06:10:36] [config] enc-depth: 6
[2019-03-31 06:10:36] [config] enc-type: bidirectional
[2019-03-31 06:10:36] [config] exponential-smoothing: 0.0001
[2019-03-31 06:10:36] [config] grad-dropping-momentum: 0
[2019-03-31 06:10:36] [config] grad-dropping-rate: 0
[2019-03-31 06:10:36] [config] grad-dropping-warmup: 100
[2019-03-31 06:10:36] [config] guided-alignment: none
[2019-03-31 06:10:36] [config] guided-alignment-cost: mse
[2019-03-31 06:10:36] [config] guided-alignment-weight: 0.1
[2019-03-31 06:10:36] [config] ignore-model-config: false
[2019-03-31 06:10:36] [config] interpolate-env-vars: false
[2019-03-31 06:10:36] [config] keep-best: true
[2019-03-31 06:10:36] [config] label-smoothing: 0.1
[2019-03-31 06:10:36] [config] layer-normalization: false
[2019-03-31 06:10:36] [config] learn-rate: 0.0002
[2019-03-31 06:10:36] [config] log: model/bt_encz.log
[2019-03-31 06:10:36] [config] log-level: info
[2019-03-31 06:10:36] [config] lr-decay: 0
[2019-03-31 06:10:36] [config] lr-decay-freq: 50000
[2019-03-31 06:10:36] [config] lr-decay-inv-sqrt: 8000
[2019-03-31 06:10:36] [config] lr-decay-repeat-warmup: false
[2019-03-31 06:10:36] [config] lr-decay-reset-optimizer: false
[2019-03-31 06:10:36] [config] lr-decay-start:
[2019-03-31 06:10:36] [config]   - 10
[2019-03-31 06:10:36] [config]   - 1
[2019-03-31 06:10:36] [config] lr-decay-strategy: epoch+stalled
[2019-03-31 06:10:36] [config] lr-report: true
[2019-03-31 06:10:36] [config] lr-warmup: 8000
[2019-03-31 06:10:36] [config] lr-warmup-at-reload: false
[2019-03-31 06:10:36] [config] lr-warmup-cycle: false
[2019-03-31 06:10:36] [config] lr-warmup-start-rate: 0
[2019-03-31 06:10:36] [config] max-length: 100
[2019-03-31 06:10:36] [config] max-length-crop: false
[2019-03-31 06:10:36] [config] max-length-factor: 3
[2019-03-31 06:10:36] [config] maxi-batch: 10000
[2019-03-31 06:10:36] [config] maxi-batch-sort: trg
[2019-03-31 06:10:36] [config] mini-batch: 1000
[2019-03-31 06:10:36] [config] mini-batch-fit: true
[2019-03-31 06:10:36] [config] mini-batch-fit-step: 10
[2019-03-31 06:10:36] [config] mini-batch-words: 0
[2019-03-31 06:10:36] [config] model: model/model_bt_encz.npz
[2019-03-31 06:10:36] [config] multi-node: false
[2019-03-31 06:10:36] [config] multi-node-overlap: true
[2019-03-31 06:10:36] [config] n-best: false
[2019-03-31 06:10:36] [config] no-nccl: true
[2019-03-31 06:10:36] [config] no-reload: false
[2019-03-31 06:10:36] [config] no-restore-corpus: false
[2019-03-31 06:10:36] [config] no-shuffle: false
[2019-03-31 06:10:36] [config] normalize: 0.6
[2019-03-31 06:10:36] [config] optimizer: adam
[2019-03-31 06:10:36] [config] optimizer-delay: 4
[2019-03-31 06:10:36] [config] optimizer-params:
[2019-03-31 06:10:36] [config]   - 0.9
[2019-03-31 06:10:36] [config]   - 0.98
[2019-03-31 06:10:36] [config]   - 1e-09
[2019-03-31 06:10:36] [config] overwrite: true
[2019-03-31 06:10:36] [config] quiet: false
[2019-03-31 06:10:36] [config] quiet-translation: true
[2019-03-31 06:10:36] [config] relative-paths: false
[2019-03-31 06:10:36] [config] right-left: false
[2019-03-31 06:10:36] [config] save-freq: 5000
[2019-03-31 06:10:36] [config] seed: 0
[2019-03-31 06:10:36] [config] sentencepiece-alphas:
[2019-03-31 06:10:36] [config]   []
[2019-03-31 06:10:36] [config] sentencepiece-max-lines: 10000000
[2019-03-31 06:10:36] [config] sentencepiece-options: ""
[2019-03-31 06:10:36] [config] shuffle-in-ram: false
[2019-03-31 06:10:36] [config] skip: false
[2019-03-31 06:10:36] [config] sqlite: temporary
[2019-03-31 06:10:36] [config] sqlite-drop: false
[2019-03-31 06:10:36] [config] sync-sgd: true
[2019-03-31 06:10:36] [config] tempdir: /tmp
[2019-03-31 06:10:36] [config] tied-embeddings: false
[2019-03-31 06:10:36] [config] tied-embeddings-all: true
[2019-03-31 06:10:36] [config] tied-embeddings-src: false
[2019-03-31 06:10:36] [config] train-sets:
[2019-03-31 06:10:36] [config]   - corpus+paracrawl.2M.en.bpe
[2019-03-31 06:10:36] [config]   - corpus+paracrawl.2M.cz.bpe
[2019-03-31 06:10:36] [config] transformer-aan-activation: swish
[2019-03-31 06:10:36] [config] transformer-aan-depth: 2
[2019-03-31 06:10:36] [config] transformer-aan-nogate: false
[2019-03-31 06:10:36] [config] transformer-decoder-autoreg: self-attention
[2019-03-31 06:10:36] [config] transformer-dim-aan: 2048
[2019-03-31 06:10:36] [config] transformer-dim-ffn: 4096
[2019-03-31 06:10:36] [config] transformer-dropout: 0.1
[2019-03-31 06:10:36] [config] transformer-dropout-attention: 0.1
[2019-03-31 06:10:36] [config] transformer-dropout-ffn: 0.1
[2019-03-31 06:10:36] [config] transformer-ffn-activation: swish
[2019-03-31 06:10:36] [config] transformer-ffn-depth: 2
[2019-03-31 06:10:36] [config] transformer-guided-alignment-layer: last
[2019-03-31 06:10:36] [config] transformer-heads: 16
[2019-03-31 06:10:36] [config] transformer-no-projection: false
[2019-03-31 06:10:36] [config] transformer-postprocess: da
[2019-03-31 06:10:36] [config] transformer-postprocess-emb: d
[2019-03-31 06:10:36] [config] transformer-preprocess: n
[2019-03-31 06:10:36] [config] transformer-tied-layers:
[2019-03-31 06:10:36] [config]   []
[2019-03-31 06:10:36] [config] type: transformer
[2019-03-31 06:10:36] [config] ulr: false
[2019-03-31 06:10:36] [config] ulr-dim-emb: 0
[2019-03-31 06:10:36] [config] ulr-dropout: 0
[2019-03-31 06:10:36] [config] ulr-keys-vectors: ""
[2019-03-31 06:10:36] [config] ulr-query-vectors: ""
[2019-03-31 06:10:36] [config] ulr-softmax-temperature: 1
[2019-03-31 06:10:36] [config] ulr-trainable-transformation: false
[2019-03-31 06:10:36] [config] valid-freq: 5000
[2019-03-31 06:10:36] [config] valid-log: model/valid.log
[2019-03-31 06:10:36] [config] valid-max-length: 1000
[2019-03-31 06:10:36] [config] valid-metrics:
[2019-03-31 06:10:36] [config]   - ce-mean-words
[2019-03-31 06:10:36] [config]   - perplexity
[2019-03-31 06:10:36] [config]   - translation
[2019-03-31 06:10:36] [config] valid-mini-batch: 16
[2019-03-31 06:10:36] [config] valid-script-path: ./val.sh
[2019-03-31 06:10:36] [config] valid-sets:
[2019-03-31 06:10:36] [config]   - corp/newstest2016-encs-src.en.bpe
[2019-03-31 06:10:36] [config]   - corp/newstest2016-encs-ref.cs.bpe
[2019-03-31 06:10:36] [config] version: v1.7.6 9cc5b17 2018-12-14 15:11:34 -0800
[2019-03-31 06:10:36] [config] vocabs:
[2019-03-31 06:10:36] [config]   - corp/vocab.encs.yml
[2019-03-31 06:10:36] [config]   - corp/vocab.encs.yml
[2019-03-31 06:10:36] [config] word-penalty: 0
[2019-03-31 06:10:36] [config] workspace: 8600
[2019-03-31 06:10:36] [config] Loaded model has been created with Marian v1.7.6 9cc5b17 2018-12-14 15:11:34 -0800
[2019-03-31 06:10:36] Using synchronous training
[2019-03-31 06:10:36] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.yml
[2019-03-31 06:10:36] [data] Setting vocabulary size for input 0 to 34028
[2019-03-31 06:10:36] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.yml
[2019-03-31 06:10:37] [data] Setting vocabulary size for input 1 to 34028
[2019-03-31 06:10:37] [sqlite] Creating temporary database in /tmp
[2019-03-31 06:10:40] [sqlite] Inserted 1000000 lines
[2019-03-31 06:10:44] [sqlite] Inserted 2000000 lines
[2019-03-31 06:10:50] [sqlite] Inserted 4000000 lines
[2019-03-31 06:11:04] [sqlite] Inserted 8000000 lines
[2019-03-31 06:11:30] [sqlite] Inserted 16000000 lines
[2019-03-31 06:14:01] [sqlite] Inserted 32000000 lines
[2019-03-31 06:15:43] [sqlite] Inserted 41438108 lines
[2019-03-31 06:15:43] [sqlite] Creating primary index
[2019-03-31 06:19:05] [batching] Collecting statistics for batch fitting with step size 10
[2019-03-31 06:19:05] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-03-31 06:19:10] [memory] Extending reserved space to 8704 MB (device gpu0)
[2019-03-31 06:19:11] Error: CUDA error 2 'out of memory' - /home/big_maggie/usr/marian_spider/marian_1.7.6/marian-dev/src/tensors/gpu/device.cu:38: cudaMalloc(&data_, size)
[2019-03-31 06:19:11] Error: Aborted from virtual void marian::gpu::Device::reserve(size_t) in /home/big_maggie/usr/marian_spider/marian_1.7.6/marian-dev/src/tensors/gpu/device.cu:38

[CALL STACK]
[0xa50f57]                                                            
[0x755b28]                                                            
[0x47ec84]                                                            
[0x505a1a]                                                            
[0x44d72d]                                                            
[0x421b70]                                                            
[0x7f3ca4319b35]    __libc_start_main                                  + 0xf5
[0x44a19c]                                                            

train_bt_encs.sh: line 2: 12209 Aborted                 (core dumped) $marian/marian --model model/model_bt_encz.npz --type transformer --train-sets corpus+paracrawl.2M.en.bpe corpus+paracrawl.2M.cz.bpe -e $e --max-length 100 --vocabs corp/vocab.encs.yml corp/vocab.encs.yml --mini-batch-fit -w 8600 --mini-batch 1000 --maxi-batch 10000 --valid-freq 5000 --save-freq 5000 --disp-freq 500 --valid-metrics ce-mean-words perplexity translation --valid-sets corp/newstest2016-encs-src.en.bpe corp/newstest2016-encs-ref.cs.bpe --valid-script-path ./val.sh --quiet-translation --beam-size 6 --normalize=0.6 --valid-mini-batch 16 --overwrite --keep-best --optimizer-delay 4 --early-stopping 15 --cost-type=ce-mean-words --log model/bt_encz.log --valid-log model/valid.log --enc-depth 6 --dec-depth 6 --transformer-preprocess n --transformer-postprocess da --tied-embeddings-all --dim-emb 1024 --transformer-dim-ffn 4096 --transformer-heads 16 --transformer-dropout 0.1 --transformer-dropout-attention 0.1 --transformer-dropout-ffn 0.1 --label-smoothing 0.1 --learn-rate 0.0002 --lr-warmup 8000 --lr-decay-inv-sqrt 8000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --devices 0 1 --sync-sgd --seed 0 --no-nccl --exponential-smoothing --sqlite -T /tmp
rm: cannot remove ‘model/model_bt_encz.npz.yml’: No such file or directory
[2019-03-31 06:19:22] [marian] Marian v1.7.6 9cc5b17 2018-12-14 15:11:34 -0800
[2019-03-31 06:19:22] [marian] Running on spider3.lingea.cz as process 12343 with command line:
[2019-03-31 06:19:22] [marian] /home/big_maggie/usr/marian_spider/marian_1.7.6/marian-dev/build/marian --model model/model_bt_encz.npz --type transformer --train-sets bt.encz.en.bpe bt.encz.cz.bpe -e 6 --max-length 100 --vocabs corp/vocab.encs.yml corp/vocab.encs.yml --mini-batch-fit -w 8600 --mini-batch 1000 --maxi-batch 10000 --valid-freq 5000 --save-freq 5000 --disp-freq 500 --optimizer-delay 4 --valid-metrics ce-mean-words perplexity translation --valid-sets corp/newstest2016-encs-src.en.bpe corp/newstest2016-encs-ref.cs.bpe --valid-script-path ./val.sh --quiet-translation --beam-size 6 --normalize=0.6 --valid-mini-batch 16 --overwrite --keep-best --early-stopping 15 --cost-type=ce-mean-words --log model/bt_encz.log --valid-log model/valid.log --enc-depth 6 --dec-depth 6 --transformer-preprocess n --transformer-postprocess da --tied-embeddings-all --dim-emb 1024 --transformer-dim-ffn 4096 --transformer-heads 16 --transformer-dropout 0.1 --transformer-dropout-attention 0.1 --transformer-dropout-ffn 0.1 --label-smoothing 0.1 --learn-rate 0.0002 --lr-warmup 8000 --lr-decay-inv-sqrt 8000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --devices 0 1 --sync-sgd --seed 0 --no-nccl --exponential-smoothing --sqlite -T /tmp
[2019-03-31 06:19:23] [config] after-batches: 0
[2019-03-31 06:19:23] [config] after-epochs: 6
[2019-03-31 06:19:23] [config] allow-unk: false
[2019-03-31 06:19:23] [config] beam-size: 6
[2019-03-31 06:19:23] [config] best-deep: false
[2019-03-31 06:19:23] [config] clip-gemm: 0
[2019-03-31 06:19:23] [config] clip-norm: 5
[2019-03-31 06:19:23] [config] cost-type: ce-mean-words
[2019-03-31 06:19:23] [config] cpu-threads: 0
[2019-03-31 06:19:23] [config] data-weighting-type: sentence
[2019-03-31 06:19:23] [config] dec-cell: gru
[2019-03-31 06:19:23] [config] dec-cell-base-depth: 2
[2019-03-31 06:19:23] [config] dec-cell-high-depth: 1
[2019-03-31 06:19:23] [config] dec-depth: 6
[2019-03-31 06:19:23] [config] devices:
[2019-03-31 06:19:23] [config]   - 0
[2019-03-31 06:19:23] [config]   - 1
[2019-03-31 06:19:23] [config] dim-emb: 1024
[2019-03-31 06:19:23] [config] dim-rnn: 1024
[2019-03-31 06:19:23] [config] dim-vocabs:
[2019-03-31 06:19:23] [config]   - 34028
[2019-03-31 06:19:23] [config]   - 34028
[2019-03-31 06:19:23] [config] disp-first: 0
[2019-03-31 06:19:23] [config] disp-freq: 500
[2019-03-31 06:19:23] [config] disp-label-counts: false
[2019-03-31 06:19:23] [config] dropout-rnn: 0
[2019-03-31 06:19:23] [config] dropout-src: 0
[2019-03-31 06:19:23] [config] dropout-trg: 0
[2019-03-31 06:19:23] [config] early-stopping: 15
[2019-03-31 06:19:23] [config] embedding-fix-src: false
[2019-03-31 06:19:23] [config] embedding-fix-trg: false
[2019-03-31 06:19:23] [config] embedding-normalization: false
[2019-03-31 06:19:23] [config] enc-cell: gru
[2019-03-31 06:19:23] [config] enc-cell-depth: 1
[2019-03-31 06:19:23] [config] enc-depth: 6
[2019-03-31 06:19:23] [config] enc-type: bidirectional
[2019-03-31 06:19:23] [config] exponential-smoothing: 0.0001
[2019-03-31 06:19:23] [config] grad-dropping-momentum: 0
[2019-03-31 06:19:23] [config] grad-dropping-rate: 0
[2019-03-31 06:19:23] [config] grad-dropping-warmup: 100
[2019-03-31 06:19:23] [config] guided-alignment: none
[2019-03-31 06:19:23] [config] guided-alignment-cost: mse
[2019-03-31 06:19:23] [config] guided-alignment-weight: 0.1
[2019-03-31 06:19:23] [config] ignore-model-config: false
[2019-03-31 06:19:23] [config] interpolate-env-vars: false
[2019-03-31 06:19:23] [config] keep-best: true
[2019-03-31 06:19:23] [config] label-smoothing: 0.1
[2019-03-31 06:19:23] [config] layer-normalization: false
[2019-03-31 06:19:23] [config] learn-rate: 0.0002
[2019-03-31 06:19:23] [config] log: model/bt_encz.log
[2019-03-31 06:19:23] [config] log-level: info
[2019-03-31 06:19:23] [config] lr-decay: 0
[2019-03-31 06:19:23] [config] lr-decay-freq: 50000
[2019-03-31 06:19:23] [config] lr-decay-inv-sqrt: 8000
[2019-03-31 06:19:23] [config] lr-decay-repeat-warmup: false
[2019-03-31 06:19:23] [config] lr-decay-reset-optimizer: false
[2019-03-31 06:19:23] [config] lr-decay-start:
[2019-03-31 06:19:23] [config]   - 10
[2019-03-31 06:19:23] [config]   - 1
[2019-03-31 06:19:23] [config] lr-decay-strategy: epoch+stalled
[2019-03-31 06:19:23] [config] lr-report: true
[2019-03-31 06:19:23] [config] lr-warmup: 8000
[2019-03-31 06:19:23] [config] lr-warmup-at-reload: false
[2019-03-31 06:19:23] [config] lr-warmup-cycle: false
[2019-03-31 06:19:23] [config] lr-warmup-start-rate: 0
[2019-03-31 06:19:23] [config] max-length: 100
[2019-03-31 06:19:23] [config] max-length-crop: false
[2019-03-31 06:19:23] [config] max-length-factor: 3
[2019-03-31 06:19:23] [config] maxi-batch: 10000
[2019-03-31 06:19:23] [config] maxi-batch-sort: trg
[2019-03-31 06:19:23] [config] mini-batch: 1000
[2019-03-31 06:19:23] [config] mini-batch-fit: true
[2019-03-31 06:19:23] [config] mini-batch-fit-step: 10
[2019-03-31 06:19:23] [config] mini-batch-words: 0
[2019-03-31 06:19:23] [config] model: model/model_bt_encz.npz
[2019-03-31 06:19:23] [config] multi-node: false
[2019-03-31 06:19:23] [config] multi-node-overlap: true
[2019-03-31 06:19:23] [config] n-best: false
[2019-03-31 06:19:23] [config] no-nccl: true
[2019-03-31 06:19:23] [config] no-reload: false
[2019-03-31 06:19:23] [config] no-restore-corpus: false
[2019-03-31 06:19:23] [config] no-shuffle: false
[2019-03-31 06:19:23] [config] normalize: 0.6
[2019-03-31 06:19:23] [config] optimizer: adam
[2019-03-31 06:19:23] [config] optimizer-delay: 4
[2019-03-31 06:19:23] [config] optimizer-params:
[2019-03-31 06:19:23] [config]   - 0.9
[2019-03-31 06:19:23] [config]   - 0.98
[2019-03-31 06:19:23] [config]   - 1e-09
[2019-03-31 06:19:23] [config] overwrite: true
[2019-03-31 06:19:23] [config] quiet: false
[2019-03-31 06:19:23] [config] quiet-translation: true
[2019-03-31 06:19:23] [config] relative-paths: false
[2019-03-31 06:19:23] [config] right-left: false
[2019-03-31 06:19:23] [config] save-freq: 5000
[2019-03-31 06:19:23] [config] seed: 0
[2019-03-31 06:19:23] [config] sentencepiece-alphas:
[2019-03-31 06:19:23] [config]   []
[2019-03-31 06:19:23] [config] sentencepiece-max-lines: 10000000
[2019-03-31 06:19:23] [config] sentencepiece-options: ""
[2019-03-31 06:19:23] [config] shuffle-in-ram: false
[2019-03-31 06:19:23] [config] skip: false
[2019-03-31 06:19:23] [config] sqlite: temporary
[2019-03-31 06:19:23] [config] sqlite-drop: false
[2019-03-31 06:19:23] [config] sync-sgd: true
[2019-03-31 06:19:23] [config] tempdir: /tmp
[2019-03-31 06:19:23] [config] tied-embeddings: false
[2019-03-31 06:19:23] [config] tied-embeddings-all: true
[2019-03-31 06:19:23] [config] tied-embeddings-src: false
[2019-03-31 06:19:23] [config] train-sets:
[2019-03-31 06:19:23] [config]   - bt.encz.en.bpe
[2019-03-31 06:19:23] [config]   - bt.encz.cz.bpe
[2019-03-31 06:19:23] [config] transformer-aan-activation: swish
[2019-03-31 06:19:23] [config] transformer-aan-depth: 2
[2019-03-31 06:19:23] [config] transformer-aan-nogate: false
[2019-03-31 06:19:23] [config] transformer-decoder-autoreg: self-attention
[2019-03-31 06:19:23] [config] transformer-dim-aan: 2048
[2019-03-31 06:19:23] [config] transformer-dim-ffn: 4096
[2019-03-31 06:19:23] [config] transformer-dropout: 0.1
[2019-03-31 06:19:23] [config] transformer-dropout-attention: 0.1
[2019-03-31 06:19:23] [config] transformer-dropout-ffn: 0.1
[2019-03-31 06:19:23] [config] transformer-ffn-activation: swish
[2019-03-31 06:19:23] [config] transformer-ffn-depth: 2
[2019-03-31 06:19:23] [config] transformer-guided-alignment-layer: last
[2019-03-31 06:19:23] [config] transformer-heads: 16
[2019-03-31 06:19:23] [config] transformer-no-projection: false
[2019-03-31 06:19:23] [config] transformer-postprocess: da
[2019-03-31 06:19:23] [config] transformer-postprocess-emb: d
[2019-03-31 06:19:23] [config] transformer-preprocess: n
[2019-03-31 06:19:23] [config] transformer-tied-layers:
[2019-03-31 06:19:23] [config]   []
[2019-03-31 06:19:23] [config] type: transformer
[2019-03-31 06:19:23] [config] ulr: false
[2019-03-31 06:19:23] [config] ulr-dim-emb: 0
[2019-03-31 06:19:23] [config] ulr-dropout: 0
[2019-03-31 06:19:23] [config] ulr-keys-vectors: ""
[2019-03-31 06:19:23] [config] ulr-query-vectors: ""
[2019-03-31 06:19:23] [config] ulr-softmax-temperature: 1
[2019-03-31 06:19:23] [config] ulr-trainable-transformation: false
[2019-03-31 06:19:23] [config] valid-freq: 5000
[2019-03-31 06:19:23] [config] valid-log: model/valid.log
[2019-03-31 06:19:23] [config] valid-max-length: 1000
[2019-03-31 06:19:23] [config] valid-metrics:
[2019-03-31 06:19:23] [config]   - ce-mean-words
[2019-03-31 06:19:23] [config]   - perplexity
[2019-03-31 06:19:23] [config]   - translation
[2019-03-31 06:19:23] [config] valid-mini-batch: 16
[2019-03-31 06:19:23] [config] valid-script-path: ./val.sh
[2019-03-31 06:19:23] [config] valid-sets:
[2019-03-31 06:19:23] [config]   - corp/newstest2016-encs-src.en.bpe
[2019-03-31 06:19:23] [config]   - corp/newstest2016-encs-ref.cs.bpe
[2019-03-31 06:19:23] [config] version: v1.7.6 9cc5b17 2018-12-14 15:11:34 -0800
[2019-03-31 06:19:23] [config] vocabs:
[2019-03-31 06:19:23] [config]   - corp/vocab.encs.yml
[2019-03-31 06:19:23] [config]   - corp/vocab.encs.yml
[2019-03-31 06:19:23] [config] word-penalty: 0
[2019-03-31 06:19:23] [config] workspace: 8600
[2019-03-31 06:19:23] [config] Loaded model has been created with Marian v1.7.6 9cc5b17 2018-12-14 15:11:34 -0800
[2019-03-31 06:19:23] Using synchronous training
[2019-03-31 06:19:23] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.yml
[2019-03-31 06:19:24] [data] Setting vocabulary size for input 0 to 34028
[2019-03-31 06:19:24] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.yml
[2019-03-31 06:19:24] [data] Setting vocabulary size for input 1 to 34028
[2019-03-31 06:19:24] [sqlite] Creating temporary database in /tmp
[2019-03-31 06:19:28] [sqlite] Inserted 1000000 lines
[2019-03-31 06:19:32] [sqlite] Inserted 2000000 lines
[2019-03-31 06:19:41] [sqlite] Inserted 4000000 lines
[2019-03-31 06:19:57] [sqlite] Inserted 8000000 lines
[2019-03-31 06:20:33] [sqlite] Inserted 16000000 lines
[2019-03-31 06:25:08] [sqlite] Inserted 32000000 lines
[2019-03-31 06:27:12] [sqlite] Inserted 49633032 lines
[2019-03-31 06:27:12] [sqlite] Creating primary index
[2019-03-31 06:36:47] [batching] Collecting statistics for batch fitting with step size 10
[2019-03-31 06:36:47] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-03-31 06:36:53] [memory] Extending reserved space to 8704 MB (device gpu0)
[2019-03-31 06:36:53] Error: CUDA error 2 'out of memory' - /home/big_maggie/usr/marian_spider/marian_1.7.6/marian-dev/src/tensors/gpu/device.cu:38: cudaMalloc(&data_, size)
[2019-03-31 06:36:53] Error: Aborted from virtual void marian::gpu::Device::reserve(size_t) in /home/big_maggie/usr/marian_spider/marian_1.7.6/marian-dev/src/tensors/gpu/device.cu:38

[CALL STACK]
[0xa50f57]                                                            
[0x755b28]                                                            
[0x47ec84]                                                            
[0x505a1a]                                                            
[0x44d72d]                                                            
[0x421b70]                                                            
[0x7f7276fa1b35]    __libc_start_main                                  + 0xf5
[0x44a19c]                                                            

train_bt_encs.sh: line 2: 12343 Aborted                 (core dumped) $marian/marian --model model/model_bt_encz.npz --type transformer --train-sets bt.encz.en.bpe bt.encz.cz.bpe -e $i --max-length 100 --vocabs corp/vocab.encs.yml corp/vocab.encs.yml --mini-batch-fit -w 8600 --mini-batch 1000 --maxi-batch 10000 --valid-freq 5000 --save-freq 5000 --disp-freq 500 --optimizer-delay 4 --valid-metrics ce-mean-words perplexity translation --valid-sets corp/newstest2016-encs-src.en.bpe corp/newstest2016-encs-ref.cs.bpe --valid-script-path ./val.sh --quiet-translation --beam-size 6 --normalize=0.6 --valid-mini-batch 16 --overwrite --keep-best --early-stopping 15 --cost-type=ce-mean-words --log model/bt_encz.log --valid-log model/valid.log --enc-depth 6 --dec-depth 6 --transformer-preprocess n --transformer-postprocess da --tied-embeddings-all --dim-emb 1024 --transformer-dim-ffn 4096 --transformer-heads 16 --transformer-dropout 0.1 --transformer-dropout-attention 0.1 --transformer-dropout-ffn 0.1 --label-smoothing 0.1 --learn-rate 0.0002 --lr-warmup 8000 --lr-decay-inv-sqrt 8000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --devices 0 1 --sync-sgd --seed 0 --no-nccl --exponential-smoothing --sqlite -T /tmp
rm: cannot remove ‘model/model_bt_encz.npz.yml’: No such file or directory
ITERATION 6
[2019-03-31 06:37:05] [marian] Marian v1.7.6 9cc5b17 2018-12-14 15:11:34 -0800
[2019-03-31 06:37:05] [marian] Running on spider3.lingea.cz as process 12604 with command line:
[2019-03-31 06:37:05] [marian] /home/big_maggie/usr/marian_spider/marian_1.7.6/marian-dev/build/marian --model model/model_bt_encz.npz --type transformer --train-sets corpus+paracrawl.2M.en.bpe corpus+paracrawl.2M.cz.bpe -e 6 --max-length 100 --vocabs corp/vocab.encs.yml corp/vocab.encs.yml --mini-batch-fit -w 8600 --mini-batch 1000 --maxi-batch 10000 --valid-freq 5000 --save-freq 5000 --disp-freq 500 --valid-metrics ce-mean-words perplexity translation --valid-sets corp/newstest2016-encs-src.en.bpe corp/newstest2016-encs-ref.cs.bpe --valid-script-path ./val.sh --quiet-translation --beam-size 6 --normalize=0.6 --valid-mini-batch 16 --overwrite --keep-best --optimizer-delay 4 --early-stopping 15 --cost-type=ce-mean-words --log model/bt_encz.log --valid-log model/valid.log --enc-depth 6 --dec-depth 6 --transformer-preprocess n --transformer-postprocess da --tied-embeddings-all --dim-emb 1024 --transformer-dim-ffn 4096 --transformer-heads 16 --transformer-dropout 0.1 --transformer-dropout-attention 0.1 --transformer-dropout-ffn 0.1 --label-smoothing 0.1 --learn-rate 0.0002 --lr-warmup 8000 --lr-decay-inv-sqrt 8000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --devices 0 1 --sync-sgd --seed 0 --no-nccl --exponential-smoothing --sqlite -T /tmp
[2019-03-31 06:37:06] [config] after-batches: 0
[2019-03-31 06:37:06] [config] after-epochs: 6
[2019-03-31 06:37:06] [config] allow-unk: false
[2019-03-31 06:37:06] [config] beam-size: 6
[2019-03-31 06:37:06] [config] best-deep: false
[2019-03-31 06:37:06] [config] clip-gemm: 0
[2019-03-31 06:37:06] [config] clip-norm: 5
[2019-03-31 06:37:06] [config] cost-type: ce-mean-words
[2019-03-31 06:37:06] [config] cpu-threads: 0
[2019-03-31 06:37:06] [config] data-weighting-type: sentence
[2019-03-31 06:37:06] [config] dec-cell: gru
[2019-03-31 06:37:06] [config] dec-cell-base-depth: 2
[2019-03-31 06:37:06] [config] dec-cell-high-depth: 1
[2019-03-31 06:37:06] [config] dec-depth: 6
[2019-03-31 06:37:06] [config] devices:
[2019-03-31 06:37:06] [config]   - 0
[2019-03-31 06:37:06] [config]   - 1
[2019-03-31 06:37:06] [config] dim-emb: 1024
[2019-03-31 06:37:06] [config] dim-rnn: 1024
[2019-03-31 06:37:06] [config] dim-vocabs:
[2019-03-31 06:37:06] [config]   - 34028
[2019-03-31 06:37:06] [config]   - 34028
[2019-03-31 06:37:06] [config] disp-first: 0
[2019-03-31 06:37:06] [config] disp-freq: 500
[2019-03-31 06:37:06] [config] disp-label-counts: false
[2019-03-31 06:37:06] [config] dropout-rnn: 0
[2019-03-31 06:37:06] [config] dropout-src: 0
[2019-03-31 06:37:06] [config] dropout-trg: 0
[2019-03-31 06:37:06] [config] early-stopping: 15
[2019-03-31 06:37:06] [config] embedding-fix-src: false
[2019-03-31 06:37:06] [config] embedding-fix-trg: false
[2019-03-31 06:37:06] [config] embedding-normalization: false
[2019-03-31 06:37:06] [config] enc-cell: gru
[2019-03-31 06:37:06] [config] enc-cell-depth: 1
[2019-03-31 06:37:06] [config] enc-depth: 6
[2019-03-31 06:37:06] [config] enc-type: bidirectional
[2019-03-31 06:37:06] [config] exponential-smoothing: 0.0001
[2019-03-31 06:37:06] [config] grad-dropping-momentum: 0
[2019-03-31 06:37:06] [config] grad-dropping-rate: 0
[2019-03-31 06:37:06] [config] grad-dropping-warmup: 100
[2019-03-31 06:37:06] [config] guided-alignment: none
[2019-03-31 06:37:06] [config] guided-alignment-cost: mse
[2019-03-31 06:37:06] [config] guided-alignment-weight: 0.1
[2019-03-31 06:37:06] [config] ignore-model-config: false
[2019-03-31 06:37:06] [config] interpolate-env-vars: false
[2019-03-31 06:37:06] [config] keep-best: true
[2019-03-31 06:37:06] [config] label-smoothing: 0.1
[2019-03-31 06:37:06] [config] layer-normalization: false
[2019-03-31 06:37:06] [config] learn-rate: 0.0002
[2019-03-31 06:37:06] [config] log: model/bt_encz.log
[2019-03-31 06:37:06] [config] log-level: info
[2019-03-31 06:37:06] [config] lr-decay: 0
[2019-03-31 06:37:06] [config] lr-decay-freq: 50000
[2019-03-31 06:37:06] [config] lr-decay-inv-sqrt: 8000
[2019-03-31 06:37:06] [config] lr-decay-repeat-warmup: false
[2019-03-31 06:37:06] [config] lr-decay-reset-optimizer: false
[2019-03-31 06:37:06] [config] lr-decay-start:
[2019-03-31 06:37:06] [config]   - 10
[2019-03-31 06:37:06] [config]   - 1
[2019-03-31 06:37:06] [config] lr-decay-strategy: epoch+stalled
[2019-03-31 06:37:06] [config] lr-report: true
[2019-03-31 06:37:06] [config] lr-warmup: 8000
[2019-03-31 06:37:06] [config] lr-warmup-at-reload: false
[2019-03-31 06:37:06] [config] lr-warmup-cycle: false
[2019-03-31 06:37:06] [config] lr-warmup-start-rate: 0
[2019-03-31 06:37:06] [config] max-length: 100
[2019-03-31 06:37:06] [config] max-length-crop: false
[2019-03-31 06:37:06] [config] max-length-factor: 3
[2019-03-31 06:37:06] [config] maxi-batch: 10000
[2019-03-31 06:37:06] [config] maxi-batch-sort: trg
[2019-03-31 06:37:06] [config] mini-batch: 1000
[2019-03-31 06:37:06] [config] mini-batch-fit: true
[2019-03-31 06:37:06] [config] mini-batch-fit-step: 10
[2019-03-31 06:37:06] [config] mini-batch-words: 0
[2019-03-31 06:37:06] [config] model: model/model_bt_encz.npz
[2019-03-31 06:37:06] [config] multi-node: false
[2019-03-31 06:37:06] [config] multi-node-overlap: true
[2019-03-31 06:37:06] [config] n-best: false
[2019-03-31 06:37:06] [config] no-nccl: true
[2019-03-31 06:37:06] [config] no-reload: false
[2019-03-31 06:37:06] [config] no-restore-corpus: false
[2019-03-31 06:37:06] [config] no-shuffle: false
[2019-03-31 06:37:06] [config] normalize: 0.6
[2019-03-31 06:37:06] [config] optimizer: adam
[2019-03-31 06:37:06] [config] optimizer-delay: 4
[2019-03-31 06:37:06] [config] optimizer-params:
[2019-03-31 06:37:06] [config]   - 0.9
[2019-03-31 06:37:06] [config]   - 0.98
[2019-03-31 06:37:06] [config]   - 1e-09
[2019-03-31 06:37:06] [config] overwrite: true
[2019-03-31 06:37:06] [config] quiet: false
[2019-03-31 06:37:06] [config] quiet-translation: true
[2019-03-31 06:37:06] [config] relative-paths: false
[2019-03-31 06:37:06] [config] right-left: false
[2019-03-31 06:37:06] [config] save-freq: 5000
[2019-03-31 06:37:06] [config] seed: 0
[2019-03-31 06:37:06] [config] sentencepiece-alphas:
[2019-03-31 06:37:06] [config]   []
[2019-03-31 06:37:06] [config] sentencepiece-max-lines: 10000000
[2019-03-31 06:37:06] [config] sentencepiece-options: ""
[2019-03-31 06:37:06] [config] shuffle-in-ram: false
[2019-03-31 06:37:06] [config] skip: false
[2019-03-31 06:37:06] [config] sqlite: temporary
[2019-03-31 06:37:06] [config] sqlite-drop: false
[2019-03-31 06:37:06] [config] sync-sgd: true
[2019-03-31 06:37:06] [config] tempdir: /tmp
[2019-03-31 06:37:06] [config] tied-embeddings: false
[2019-03-31 06:37:06] [config] tied-embeddings-all: true
[2019-03-31 06:37:06] [config] tied-embeddings-src: false
[2019-03-31 06:37:06] [config] train-sets:
[2019-03-31 06:37:06] [config]   - corpus+paracrawl.2M.en.bpe
[2019-03-31 06:37:06] [config]   - corpus+paracrawl.2M.cz.bpe
[2019-03-31 06:37:06] [config] transformer-aan-activation: swish
[2019-03-31 06:37:06] [config] transformer-aan-depth: 2
[2019-03-31 06:37:06] [config] transformer-aan-nogate: false
[2019-03-31 06:37:06] [config] transformer-decoder-autoreg: self-attention
[2019-03-31 06:37:06] [config] transformer-dim-aan: 2048
[2019-03-31 06:37:06] [config] transformer-dim-ffn: 4096
[2019-03-31 06:37:06] [config] transformer-dropout: 0.1
[2019-03-31 06:37:06] [config] transformer-dropout-attention: 0.1
[2019-03-31 06:37:06] [config] transformer-dropout-ffn: 0.1
[2019-03-31 06:37:06] [config] transformer-ffn-activation: swish
[2019-03-31 06:37:06] [config] transformer-ffn-depth: 2
[2019-03-31 06:37:06] [config] transformer-guided-alignment-layer: last
[2019-03-31 06:37:06] [config] transformer-heads: 16
[2019-03-31 06:37:06] [config] transformer-no-projection: false
[2019-03-31 06:37:06] [config] transformer-postprocess: da
[2019-03-31 06:37:06] [config] transformer-postprocess-emb: d
[2019-03-31 06:37:06] [config] transformer-preprocess: n
[2019-03-31 06:37:06] [config] transformer-tied-layers:
[2019-03-31 06:37:06] [config]   []
[2019-03-31 06:37:06] [config] type: transformer
[2019-03-31 06:37:06] [config] ulr: false
[2019-03-31 06:37:06] [config] ulr-dim-emb: 0
[2019-03-31 06:37:06] [config] ulr-dropout: 0
[2019-03-31 06:37:06] [config] ulr-keys-vectors: ""
[2019-03-31 06:37:06] [config] ulr-query-vectors: ""
[2019-03-31 06:37:06] [config] ulr-softmax-temperature: 1
[2019-03-31 06:37:06] [config] ulr-trainable-transformation: false
[2019-03-31 06:37:06] [config] valid-freq: 5000
[2019-03-31 06:37:06] [config] valid-log: model/valid.log
[2019-03-31 06:37:06] [config] valid-max-length: 1000
[2019-03-31 06:37:06] [config] valid-metrics:
[2019-03-31 06:37:06] [config]   - ce-mean-words
[2019-03-31 06:37:06] [config]   - perplexity
[2019-03-31 06:37:06] [config]   - translation
[2019-03-31 06:37:06] [config] valid-mini-batch: 16
[2019-03-31 06:37:06] [config] valid-script-path: ./val.sh
[2019-03-31 06:37:06] [config] valid-sets:
[2019-03-31 06:37:06] [config]   - corp/newstest2016-encs-src.en.bpe
[2019-03-31 06:37:06] [config]   - corp/newstest2016-encs-ref.cs.bpe
[2019-03-31 06:37:06] [config] version: v1.7.6 9cc5b17 2018-12-14 15:11:34 -0800
[2019-03-31 06:37:06] [config] vocabs:
[2019-03-31 06:37:06] [config]   - corp/vocab.encs.yml
[2019-03-31 06:37:06] [config]   - corp/vocab.encs.yml
[2019-03-31 06:37:06] [config] word-penalty: 0
[2019-03-31 06:37:06] [config] workspace: 8600
[2019-03-31 06:37:06] [config] Loaded model has been created with Marian v1.7.6 9cc5b17 2018-12-14 15:11:34 -0800
[2019-03-31 06:37:06] Using synchronous training
[2019-03-31 06:37:06] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.yml
[2019-03-31 06:37:07] [data] Setting vocabulary size for input 0 to 34028
[2019-03-31 06:37:07] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.yml
[2019-03-31 06:37:07] [data] Setting vocabulary size for input 1 to 34028
[2019-03-31 06:37:07] [sqlite] Creating temporary database in /tmp
[2019-03-31 06:37:10] [sqlite] Inserted 1000000 lines
[2019-03-31 06:37:14] [sqlite] Inserted 2000000 lines
[2019-03-31 06:37:21] [sqlite] Inserted 4000000 lines
[2019-03-31 06:37:35] [sqlite] Inserted 8000000 lines
[2019-03-31 06:38:07] [sqlite] Inserted 16000000 lines
[2019-03-31 06:39:26] [sqlite] Inserted 32000000 lines
[2019-03-31 06:40:09] [sqlite] Inserted 41438108 lines
[2019-03-31 06:40:09] [sqlite] Creating primary index
[2019-03-31 06:42:50] [batching] Collecting statistics for batch fitting with step size 10
[2019-03-31 06:42:50] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-03-31 06:42:54] [memory] Extending reserved space to 8704 MB (device gpu0)
[2019-03-31 06:42:56] [memory] Extending reserved space to 8704 MB (device gpu1)
[2019-03-31 06:42:56] [comm] NCCL communicator overridden
[2019-03-31 06:42:56] [memory] Reserving 805 MB, device gpu0
[2019-03-31 06:42:57] [memory] Reserving 805 MB, device gpu0
[2019-03-31 06:43:08] [batching] Done
[2019-03-31 06:43:08] [memory] Extending reserved space to 8704 MB (device gpu0)
[2019-03-31 06:43:09] [memory] Extending reserved space to 8704 MB (device gpu1)
[2019-03-31 06:43:09] [comm] NCCL communicator overridden
[2019-03-31 06:43:09] Loading model from model/model_bt_encz.npz.orig.npz
[2019-03-31 06:43:19] Loading model from model/model_bt_encz.npz.orig.npz
[2019-03-31 06:43:22] Loading Adam parameters from model/model_bt_encz.npz.optimizer.npz
[2019-03-31 06:43:50] [memory] Reserving 805 MB, device gpu0
[2019-03-31 06:43:51] [memory] Reserving 805 MB, device gpu1
[2019-03-31 06:43:54] [data] Restoring the corpus state to epoch 5, batch 190000
[2019-03-31 06:46:54] [sqlite] Selecting shuffled data
[2019-03-31 07:42:56] Training started
[2019-03-31 07:42:56] [memory] Reserving 805 MB, device gpu0
[2019-03-31 07:42:57] [memory] Reserving 805 MB, device gpu1
[2019-03-31 07:42:57] Loading model from model/model_bt_encz.npz
[2019-03-31 07:43:06] [memory] Reserving 805 MB, device cpu0
[2019-03-31 07:43:07] [memory] Reserving 402 MB, device gpu0
[2019-03-31 07:43:07] [memory] Reserving 402 MB, device gpu1
[2019-03-31 07:43:07] [memory] Reserving 805 MB, device gpu0
[2019-03-31 07:43:07] [memory] Reserving 805 MB, device gpu1
[2019-03-31 07:43:08] [memory] Reserving 402 MB, device gpu0
[2019-03-31 07:43:08] [memory] Reserving 402 MB, device gpu1
[2019-03-31 08:00:53] Ep. 5 : Up. 190500 : Sen. 25,816,231 : Cost 2.97327662 : Time 4664.34s : 1843.45 words/s : L.r. 4.0985e-05
[2019-03-31 08:18:45] Ep. 5 : Up. 191000 : Sen. 26,364,141 : Cost 2.84750581 : Time 1072.37s : 7898.12 words/s : L.r. 4.0932e-05
[2019-03-31 08:36:53] Ep. 5 : Up. 191500 : Sen. 26,882,179 : Cost 2.86152864 : Time 1087.51s : 8002.30 words/s : L.r. 4.0878e-05
[2019-03-31 08:55:07] Ep. 5 : Up. 192000 : Sen. 27,410,409 : Cost 2.85901761 : Time 1094.93s : 7999.80 words/s : L.r. 4.0825e-05
[2019-03-31 09:13:23] Ep. 5 : Up. 192500 : Sen. 27,907,064 : Cost 2.83447289 : Time 1095.69s : 7974.06 words/s : L.r. 4.0772e-05
[2019-03-31 09:31:36] Ep. 5 : Up. 193000 : Sen. 28,415,730 : Cost 2.82105088 : Time 1093.12s : 7984.72 words/s : L.r. 4.0719e-05
[2019-03-31 09:49:49] Ep. 5 : Up. 193500 : Sen. 28,988,240 : Cost 2.83389258 : Time 1092.27s : 7969.82 words/s : L.r. 4.0666e-05
[2019-03-31 10:07:56] Ep. 5 : Up. 194000 : Sen. 29,526,126 : Cost 2.78136325 : Time 1087.16s : 7921.56 words/s : L.r. 4.0614e-05
[2019-03-31 10:26:18] Ep. 5 : Up. 194500 : Sen. 30,082,022 : Cost 2.82409334 : Time 1102.76s : 7982.87 words/s : L.r. 4.0562e-05
[2019-03-31 10:43:48] Ep. 5 : Up. 195000 : Sen. 30,573,799 : Cost 2.80648685 : Time 1049.61s : 7834.68 words/s : L.r. 4.0510e-05
[2019-03-31 10:43:48] Saving model weights and runtime parameters to model/model_bt_encz.npz.orig.npz
[2019-03-31 10:44:01] Saving model weights and runtime parameters to model/model_bt_encz.npz
[2019-03-31 10:44:15] Saving Adam parameters to model/model_bt_encz.npz.optimizer.npz
[2019-03-31 10:44:59] [valid] Ep. 5 : Up. 195000 : ce-mean-words : 1.48961 : stalled 6 times
[2019-03-31 10:45:03] [valid] Ep. 5 : Up. 195000 : perplexity : 4.43537 : stalled 6 times
Detokenizer Version $Revision: 4134 $
Language: en
[2019-03-31 10:47:03] Saving model weights and runtime parameters to model/model_bt_encz.npz.best-translation.npz
[2019-03-31 10:47:16] [valid] Ep. 5 : Up. 195000 : translation : 28.23 : new best
[2019-03-31 11:04:44] Ep. 5 : Up. 195500 : Sen. 31,085,846 : Cost 2.79339981 : Time 1256.24s : 6484.90 words/s : L.r. 4.0458e-05
[2019-03-31 11:16:27] Seen 31407177 samples
[2019-03-31 11:16:27] Starting epoch 6
[2019-03-31 11:16:27] [sqlite] Selecting shuffled data
[2019-03-31 11:43:19] Ep. 6 : Up. 196000 : Sen. 169,406 : Cost 2.77059340 : Time 2315.11s : 3567.15 words/s : L.r. 4.0406e-05
[2019-03-31 12:01:36] Ep. 6 : Up. 196500 : Sen. 698,062 : Cost 2.79172301 : Time 1096.53s : 8005.88 words/s : L.r. 4.0355e-05
[2019-03-31 12:19:50] Ep. 6 : Up. 197000 : Sen. 1,235,866 : Cost 2.78843641 : Time 1094.25s : 8003.51 words/s : L.r. 4.0303e-05
[2019-03-31 12:38:09] Ep. 6 : Up. 197500 : Sen. 1,755,203 : Cost 2.78506684 : Time 1098.56s : 8057.58 words/s : L.r. 4.0252e-05
[2019-03-31 12:56:13] Ep. 6 : Up. 198000 : Sen. 2,251,114 : Cost 2.76563907 : Time 1083.83s : 8028.30 words/s : L.r. 4.0202e-05
[2019-03-31 13:14:05] Ep. 6 : Up. 198500 : Sen. 2,761,948 : Cost 2.78579378 : Time 1072.78s : 7985.94 words/s : L.r. 4.0151e-05
[2019-03-31 13:32:01] Ep. 6 : Up. 199000 : Sen. 3,264,080 : Cost 2.79880714 : Time 1075.59s : 7999.56 words/s : L.r. 4.0100e-05
[2019-03-31 13:50:03] Ep. 6 : Up. 199500 : Sen. 3,779,629 : Cost 2.78057623 : Time 1082.48s : 7985.30 words/s : L.r. 4.0050e-05
[2019-03-31 14:08:19] Ep. 6 : Up. 200000 : Sen. 4,328,466 : Cost 2.80535650 : Time 1095.10s : 7983.52 words/s : L.r. 4.0000e-05
[2019-03-31 14:08:19] Saving model weights and runtime parameters to model/model_bt_encz.npz.orig.npz
[2019-03-31 14:08:32] Saving model weights and runtime parameters to model/model_bt_encz.npz
[2019-03-31 14:08:47] Saving Adam parameters to model/model_bt_encz.npz.optimizer.npz
[2019-03-31 14:09:33] Saving model weights and runtime parameters to model/model_bt_encz.npz.best-ce-mean-words.npz
[2019-03-31 14:09:45] [valid] Ep. 6 : Up. 200000 : ce-mean-words : 1.42376 : new best
[2019-03-31 14:09:49] Saving model weights and runtime parameters to model/model_bt_encz.npz.best-perplexity.npz
[2019-03-31 14:10:02] [valid] Ep. 6 : Up. 200000 : perplexity : 4.15272 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-03-31 14:11:46] Saving model weights and runtime parameters to model/model_bt_encz.npz.best-translation.npz
[2019-03-31 14:11:58] [valid] Ep. 6 : Up. 200000 : translation : 28.76 : new best
[2019-03-31 14:30:06] Ep. 6 : Up. 200500 : Sen. 4,889,826 : Cost 2.76280522 : Time 1307.58s : 6645.00 words/s : L.r. 3.9950e-05
[2019-03-31 14:47:55] Ep. 6 : Up. 201000 : Sen. 5,418,970 : Cost 2.78554773 : Time 1068.58s : 7928.98 words/s : L.r. 3.9900e-05
[2019-03-31 15:05:59] Ep. 6 : Up. 201500 : Sen. 5,971,732 : Cost 2.78119540 : Time 1084.58s : 7982.80 words/s : L.r. 3.9851e-05
[2019-03-31 15:24:11] Ep. 6 : Up. 202000 : Sen. 6,512,515 : Cost 2.76205754 : Time 1091.30s : 7915.28 words/s : L.r. 3.9801e-05
[2019-03-31 15:42:15] Ep. 6 : Up. 202500 : Sen. 7,021,712 : Cost 2.75336289 : Time 1084.70s : 7967.58 words/s : L.r. 3.9752e-05
[2019-03-31 16:00:22] Ep. 6 : Up. 203000 : Sen. 7,543,864 : Cost 2.75344872 : Time 1086.90s : 8011.20 words/s : L.r. 3.9703e-05
[2019-03-31 16:18:14] Ep. 6 : Up. 203500 : Sen. 8,066,573 : Cost 2.73731136 : Time 1071.62s : 7925.37 words/s : L.r. 3.9655e-05
[2019-03-31 16:36:22] Ep. 6 : Up. 204000 : Sen. 8,590,368 : Cost 2.75413799 : Time 1088.60s : 8031.32 words/s : L.r. 3.9606e-05
[2019-03-31 16:54:20] Ep. 6 : Up. 204500 : Sen. 9,119,619 : Cost 2.74137878 : Time 1077.90s : 7994.05 words/s : L.r. 3.9557e-05
[2019-03-31 17:12:25] Ep. 6 : Up. 205000 : Sen. 9,675,052 : Cost 2.74647593 : Time 1084.20s : 7969.14 words/s : L.r. 3.9509e-05
[2019-03-31 17:12:25] Saving model weights and runtime parameters to model/model_bt_encz.npz.orig.npz
[2019-03-31 17:12:37] Saving model weights and runtime parameters to model/model_bt_encz.npz
[2019-03-31 17:12:49] Saving Adam parameters to model/model_bt_encz.npz.optimizer.npz
[2019-03-31 17:13:30] Saving model weights and runtime parameters to model/model_bt_encz.npz.best-ce-mean-words.npz
[2019-03-31 17:13:43] [valid] Ep. 6 : Up. 205000 : ce-mean-words : 1.40108 : new best
[2019-03-31 17:13:47] Saving model weights and runtime parameters to model/model_bt_encz.npz.best-perplexity.npz
[2019-03-31 17:14:00] [valid] Ep. 6 : Up. 205000 : perplexity : 4.05957 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-03-31 17:15:47] Saving model weights and runtime parameters to model/model_bt_encz.npz.best-translation.npz
[2019-03-31 17:15:59] [valid] Ep. 6 : Up. 205000 : translation : 28.92 : new best
[2019-03-31 17:34:05] Ep. 6 : Up. 205500 : Sen. 10,204,147 : Cost 2.75362420 : Time 1300.91s : 6653.10 words/s : L.r. 3.9461e-05
[2019-03-31 17:52:11] Ep. 6 : Up. 206000 : Sen. 10,740,104 : Cost 2.78502393 : Time 1085.34s : 8042.17 words/s : L.r. 3.9413e-05
[2019-03-31 18:10:20] Ep. 6 : Up. 206500 : Sen. 11,280,283 : Cost 2.73175120 : Time 1089.55s : 7959.46 words/s : L.r. 3.9365e-05
[2019-03-31 18:28:23] Ep. 6 : Up. 207000 : Sen. 11,795,191 : Cost 2.76299930 : Time 1082.95s : 7963.73 words/s : L.r. 3.9318e-05
[2019-03-31 18:46:34] Ep. 6 : Up. 207500 : Sen. 12,309,888 : Cost 2.77654433 : Time 1091.21s : 8065.13 words/s : L.r. 3.9270e-05
[2019-03-31 19:04:25] Ep. 6 : Up. 208000 : Sen. 12,807,660 : Cost 2.76021886 : Time 1070.54s : 7975.37 words/s : L.r. 3.9223e-05
[2019-03-31 19:22:40] Ep. 6 : Up. 208500 : Sen. 13,317,015 : Cost 2.73952317 : Time 1094.52s : 8011.76 words/s : L.r. 3.9176e-05
[2019-03-31 19:40:52] Ep. 6 : Up. 209000 : Sen. 13,845,135 : Cost 2.72274828 : Time 1092.12s : 7904.36 words/s : L.r. 3.9129e-05
[2019-03-31 19:58:52] Ep. 6 : Up. 209500 : Sen. 14,354,670 : Cost 2.74576855 : Time 1080.57s : 7927.12 words/s : L.r. 3.9083e-05
[2019-03-31 20:17:06] Ep. 6 : Up. 210000 : Sen. 14,867,594 : Cost 2.74978423 : Time 1093.50s : 8018.51 words/s : L.r. 3.9036e-05
[2019-03-31 20:17:06] Saving model weights and runtime parameters to model/model_bt_encz.npz.orig.npz
[2019-03-31 20:17:18] Saving model weights and runtime parameters to model/model_bt_encz.npz
[2019-03-31 20:17:31] Saving Adam parameters to model/model_bt_encz.npz.optimizer.npz
[2019-03-31 20:18:14] Saving model weights and runtime parameters to model/model_bt_encz.npz.best-ce-mean-words.npz
[2019-03-31 20:18:26] [valid] Ep. 6 : Up. 210000 : ce-mean-words : 1.39516 : new best
[2019-03-31 20:18:30] Saving model weights and runtime parameters to model/model_bt_encz.npz.best-perplexity.npz
[2019-03-31 20:18:43] [valid] Ep. 6 : Up. 210000 : perplexity : 4.03562 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-03-31 20:20:31] [valid] Ep. 6 : Up. 210000 : translation : 28.8 : stalled 1 times
[2019-03-31 20:38:31] Ep. 6 : Up. 210500 : Sen. 15,397,274 : Cost 2.72653842 : Time 1284.96s : 6660.93 words/s : L.r. 3.8990e-05
[2019-03-31 20:56:23] Ep. 6 : Up. 211000 : Sen. 15,930,463 : Cost 2.74287391 : Time 1072.02s : 7881.56 words/s : L.r. 3.8943e-05
[2019-03-31 21:14:32] Ep. 6 : Up. 211500 : Sen. 16,490,710 : Cost 2.74565244 : Time 1089.71s : 7997.42 words/s : L.r. 3.8897e-05
[2019-03-31 21:32:29] Ep. 6 : Up. 212000 : Sen. 17,008,220 : Cost 2.78836012 : Time 1077.06s : 8042.50 words/s : L.r. 3.8851e-05
[2019-03-31 21:50:42] Ep. 6 : Up. 212500 : Sen. 17,552,275 : Cost 2.75903130 : Time 1092.61s : 8114.77 words/s : L.r. 3.8806e-05
[2019-03-31 22:08:52] Ep. 6 : Up. 213000 : Sen. 18,093,811 : Cost 2.77464437 : Time 1090.15s : 8020.80 words/s : L.r. 3.8760e-05
[2019-03-31 22:26:57] Ep. 6 : Up. 213500 : Sen. 18,633,455 : Cost 2.72512603 : Time 1085.02s : 8002.51 words/s : L.r. 3.8715e-05
[2019-03-31 22:45:07] Ep. 6 : Up. 214000 : Sen. 19,158,613 : Cost 2.73220849 : Time 1089.35s : 7994.77 words/s : L.r. 3.8669e-05
[2019-03-31 23:02:53] Ep. 6 : Up. 214500 : Sen. 19,663,789 : Cost 2.76726842 : Time 1066.88s : 7878.86 words/s : L.r. 3.8624e-05
[2019-03-31 23:21:09] Ep. 6 : Up. 215000 : Sen. 20,218,080 : Cost 2.74419022 : Time 1095.04s : 8013.59 words/s : L.r. 3.8579e-05
[2019-03-31 23:21:09] Saving model weights and runtime parameters to model/model_bt_encz.npz.orig.npz
[2019-03-31 23:21:21] Saving model weights and runtime parameters to model/model_bt_encz.npz
[2019-03-31 23:21:34] Saving Adam parameters to model/model_bt_encz.npz.optimizer.npz
[2019-03-31 23:22:13] [valid] Ep. 6 : Up. 215000 : ce-mean-words : 1.39516 : stalled 1 times
[2019-03-31 23:22:17] [valid] Ep. 6 : Up. 215000 : perplexity : 4.03562 : stalled 1 times
Detokenizer Version $Revision: 4134 $
Language: en
[2019-03-31 23:24:04] [valid] Ep. 6 : Up. 215000 : translation : 28.6 : stalled 2 times
[2019-03-31 23:42:06] Ep. 6 : Up. 215500 : Sen. 20,725,206 : Cost 2.74348330 : Time 1257.90s : 6779.45 words/s : L.r. 3.8535e-05
[2019-04-01 00:00:20] Ep. 6 : Up. 216000 : Sen. 21,228,267 : Cost 2.73394012 : Time 1093.12s : 8077.14 words/s : L.r. 3.8490e-05
[2019-04-01 00:18:27] Ep. 6 : Up. 216500 : Sen. 21,768,266 : Cost 2.74939656 : Time 1087.74s : 7971.38 words/s : L.r. 3.8446e-05
[2019-04-01 00:36:34] Ep. 6 : Up. 217000 : Sen. 22,303,565 : Cost 2.75615644 : Time 1086.49s : 7963.71 words/s : L.r. 3.8401e-05
[2019-04-01 00:54:48] Ep. 6 : Up. 217500 : Sen. 22,837,935 : Cost 2.74617243 : Time 1094.31s : 8010.71 words/s : L.r. 3.8357e-05
[2019-04-01 01:12:53] Ep. 6 : Up. 218000 : Sen. 23,361,744 : Cost 2.74774837 : Time 1085.14s : 7919.30 words/s : L.r. 3.8313e-05
[2019-04-01 01:30:58] Ep. 6 : Up. 218500 : Sen. 23,861,693 : Cost 2.70541549 : Time 1084.93s : 8034.32 words/s : L.r. 3.8269e-05
[2019-04-01 01:49:10] Ep. 6 : Up. 219000 : Sen. 24,382,228 : Cost 2.77606916 : Time 1091.48s : 8072.27 words/s : L.r. 3.8225e-05
[2019-04-01 02:07:06] Ep. 6 : Up. 219500 : Sen. 24,909,135 : Cost 2.75526762 : Time 1075.93s : 7943.52 words/s : L.r. 3.8182e-05
[2019-04-01 02:25:03] Ep. 6 : Up. 220000 : Sen. 25,442,236 : Cost 2.73649836 : Time 1077.58s : 7977.53 words/s : L.r. 3.8139e-05
[2019-04-01 02:25:03] Saving model weights and runtime parameters to model/model_bt_encz.npz.orig.npz
[2019-04-01 02:25:16] Saving model weights and runtime parameters to model/model_bt_encz.npz
[2019-04-01 02:25:29] Saving Adam parameters to model/model_bt_encz.npz.optimizer.npz
[2019-04-01 02:26:08] [valid] Ep. 6 : Up. 220000 : ce-mean-words : 1.39702 : stalled 2 times
[2019-04-01 02:26:12] [valid] Ep. 6 : Up. 220000 : perplexity : 4.04312 : stalled 2 times
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-01 02:27:51] [valid] Ep. 6 : Up. 220000 : translation : 28.4 : stalled 3 times
[2019-04-01 02:45:50] Ep. 6 : Up. 220500 : Sen. 25,950,125 : Cost 2.76652145 : Time 1247.31s : 6932.91 words/s : L.r. 3.8095e-05
[2019-04-01 03:03:55] Ep. 6 : Up. 221000 : Sen. 26,492,632 : Cost 2.73518252 : Time 1084.25s : 8011.51 words/s : L.r. 3.8052e-05
[2019-04-01 03:22:13] Ep. 6 : Up. 221500 : Sen. 27,036,738 : Cost 2.75073051 : Time 1098.32s : 8087.26 words/s : L.r. 3.8009e-05
[2019-04-01 03:40:18] Ep. 6 : Up. 222000 : Sen. 27,584,836 : Cost 2.72615814 : Time 1085.23s : 7965.27 words/s : L.r. 3.7966e-05
[2019-04-01 03:58:27] Ep. 6 : Up. 222500 : Sen. 28,133,835 : Cost 2.73935795 : Time 1089.21s : 7967.78 words/s : L.r. 3.7924e-05
[2019-04-01 04:16:31] Ep. 6 : Up. 223000 : Sen. 28,667,345 : Cost 2.72086835 : Time 1083.51s : 7959.60 words/s : L.r. 3.7881e-05
[2019-04-01 04:34:10] Ep. 6 : Up. 223500 : Sen. 29,178,208 : Cost 2.75689316 : Time 1059.18s : 7915.23 words/s : L.r. 3.7839e-05
[2019-04-01 04:52:19] Ep. 6 : Up. 224000 : Sen. 29,716,952 : Cost 2.73948026 : Time 1088.58s : 7964.24 words/s : L.r. 3.7796e-05
[2019-04-01 05:10:34] Ep. 6 : Up. 224500 : Sen. 30,263,130 : Cost 2.75643897 : Time 1094.95s : 7995.96 words/s : L.r. 3.7754e-05
[2019-04-01 05:28:56] Ep. 6 : Up. 225000 : Sen. 30,811,237 : Cost 2.72019935 : Time 1102.54s : 7998.90 words/s : L.r. 3.7712e-05
[2019-04-01 05:28:56] Saving model weights and runtime parameters to model/model_bt_encz.npz.orig.npz
[2019-04-01 05:29:10] Saving model weights and runtime parameters to model/model_bt_encz.npz
[2019-04-01 05:29:23] Saving Adam parameters to model/model_bt_encz.npz.optimizer.npz
[2019-04-01 05:30:03] [valid] Ep. 6 : Up. 225000 : ce-mean-words : 1.39865 : stalled 3 times
[2019-04-01 05:30:07] [valid] Ep. 6 : Up. 225000 : perplexity : 4.04971 : stalled 3 times
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-01 05:31:54] [valid] Ep. 6 : Up. 225000 : translation : 28.18 : stalled 4 times
[2019-04-01 05:50:15] Ep. 6 : Up. 225500 : Sen. 31,338,278 : Cost 2.75697684 : Time 1278.28s : 6913.99 words/s : L.r. 3.7671e-05
[2019-04-01 06:08:21] Ep. 6 : Up. 226000 : Sen. 31,885,351 : Cost 2.73833585 : Time 1086.57s : 7928.82 words/s : L.r. 3.7629e-05
[2019-04-01 06:26:21] Ep. 6 : Up. 226500 : Sen. 32,409,618 : Cost 2.74789071 : Time 1079.59s : 7940.23 words/s : L.r. 3.7587e-05
[2019-04-01 06:44:22] Ep. 6 : Up. 227000 : Sen. 32,940,200 : Cost 2.71519375 : Time 1081.02s : 8016.63 words/s : L.r. 3.7546e-05
[2019-04-01 07:02:17] Ep. 6 : Up. 227500 : Sen. 33,454,931 : Cost 2.72821569 : Time 1075.40s : 7990.79 words/s : L.r. 3.7505e-05
[2019-04-01 07:20:15] Ep. 6 : Up. 228000 : Sen. 33,976,094 : Cost 2.74318695 : Time 1077.95s : 7985.61 words/s : L.r. 3.7463e-05
[2019-04-01 07:38:07] Ep. 6 : Up. 228500 : Sen. 34,498,404 : Cost 2.76275420 : Time 1071.46s : 8056.99 words/s : L.r. 3.7422e-05
[2019-04-01 07:56:02] Ep. 6 : Up. 229000 : Sen. 35,054,539 : Cost 2.75094724 : Time 1075.88s : 8004.33 words/s : L.r. 3.7382e-05
[2019-04-01 08:14:03] Ep. 6 : Up. 229500 : Sen. 35,530,344 : Cost 2.73548961 : Time 1080.42s : 8064.95 words/s : L.r. 3.7341e-05
[2019-04-01 08:32:08] Ep. 6 : Up. 230000 : Sen. 36,061,801 : Cost 2.72558570 : Time 1085.13s : 8027.78 words/s : L.r. 3.7300e-05
[2019-04-01 08:32:08] Saving model weights and runtime parameters to model/model_bt_encz.npz.orig.npz
[2019-04-01 08:32:21] Saving model weights and runtime parameters to model/model_bt_encz.npz
[2019-04-01 08:32:34] Saving Adam parameters to model/model_bt_encz.npz.optimizer.npz
[2019-04-01 08:33:11] [valid] Ep. 6 : Up. 230000 : ce-mean-words : 1.39986 : stalled 4 times
[2019-04-01 08:33:14] [valid] Ep. 6 : Up. 230000 : perplexity : 4.05464 : stalled 4 times
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-01 08:34:55] [valid] Ep. 6 : Up. 230000 : translation : 28.13 : stalled 5 times
[2019-04-01 08:53:05] Ep. 6 : Up. 230500 : Sen. 36,599,147 : Cost 2.75583339 : Time 1256.87s : 6958.75 words/s : L.r. 3.7260e-05
[2019-04-01 09:11:01] Ep. 6 : Up. 231000 : Sen. 37,112,163 : Cost 2.75252414 : Time 1076.52s : 7936.53 words/s : L.r. 3.7219e-05
[2019-04-01 09:29:12] Ep. 6 : Up. 231500 : Sen. 37,629,436 : Cost 2.70968366 : Time 1091.07s : 8015.67 words/s : L.r. 3.7179e-05
[2019-04-01 09:47:18] Ep. 6 : Up. 232000 : Sen. 38,160,535 : Cost 2.72707200 : Time 1086.07s : 7946.63 words/s : L.r. 3.7139e-05
[2019-04-01 10:05:23] Ep. 6 : Up. 232500 : Sen. 38,666,947 : Cost 2.72020888 : Time 1084.92s : 7962.26 words/s : L.r. 3.7099e-05
[2019-04-01 10:23:28] Ep. 6 : Up. 233000 : Sen. 39,194,839 : Cost 2.75627327 : Time 1084.22s : 8001.41 words/s : L.r. 3.7059e-05
[2019-04-01 10:41:30] Ep. 6 : Up. 233500 : Sen. 39,749,692 : Cost 2.74104524 : Time 1082.08s : 7963.40 words/s : L.r. 3.7020e-05
[2019-04-01 10:59:03] Ep. 6 : Up. 234000 : Sen. 40,246,624 : Cost 2.71034980 : Time 1053.09s : 7850.50 words/s : L.r. 3.6980e-05
[2019-04-01 11:16:32] Ep. 6 : Up. 234500 : Sen. 40,740,944 : Cost 2.71625042 : Time 1049.34s : 7861.63 words/s : L.r. 3.6941e-05
[2019-04-01 11:33:46] Ep. 6 : Up. 235000 : Sen. 41,247,166 : Cost 2.76247025 : Time 1034.12s : 7838.33 words/s : L.r. 3.6901e-05
[2019-04-01 11:33:46] Saving model weights and runtime parameters to model/model_bt_encz.npz.orig.npz
[2019-04-01 11:33:59] Saving model weights and runtime parameters to model/model_bt_encz.npz
[2019-04-01 11:34:12] Saving Adam parameters to model/model_bt_encz.npz.optimizer.npz
[2019-04-01 11:34:47] [valid] Ep. 6 : Up. 235000 : ce-mean-words : 1.40085 : stalled 5 times
[2019-04-01 11:34:51] [valid] Ep. 6 : Up. 235000 : perplexity : 4.05865 : stalled 5 times
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-01 11:36:31] [valid] Ep. 6 : Up. 235000 : translation : 28.03 : stalled 6 times
[2019-04-01 11:37:01] Seen 41256827 samples
[2019-04-01 11:37:01] Starting epoch 7
[2019-04-01 11:37:01] Training finished
[2019-04-01 11:37:05] [valid] Ep. 7 : Up. 235014 : ce-mean-words : 1.40086 : stalled 6 times
[2019-04-01 11:37:10] [valid] Ep. 7 : Up. 235014 : perplexity : 4.05867 : stalled 6 times
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-01 11:38:49] [valid] Ep. 7 : Up. 235014 : translation : 28.02 : stalled 7 times
[2019-04-01 11:38:50] Saving model weights and runtime parameters to model/model_bt_encz.npz.orig.npz
[2019-04-01 11:39:02] Saving model weights and runtime parameters to model/model_bt_encz.npz
[2019-04-01 11:39:16] Saving Adam parameters to model/model_bt_encz.npz.optimizer.npz
[2019-04-01 11:39:51] [marian] Marian v1.7.6 9cc5b17 2018-12-14 15:11:34 -0800
[2019-04-01 11:39:51] [marian] Running on spider3.lingea.cz as process 17379 with command line:
[2019-04-01 11:39:51] [marian] /home/big_maggie/usr/marian_spider/marian_1.7.6/marian-dev/build/marian --model model/model_bt_encz.npz --type transformer --train-sets bt.encz.en.bpe bt.encz.cz.bpe -e 7 --max-length 100 --vocabs corp/vocab.encs.yml corp/vocab.encs.yml --mini-batch-fit -w 8600 --mini-batch 1000 --maxi-batch 10000 --valid-freq 5000 --save-freq 5000 --disp-freq 500 --optimizer-delay 4 --valid-metrics ce-mean-words perplexity translation --valid-sets corp/newstest2016-encs-src.en.bpe corp/newstest2016-encs-ref.cs.bpe --valid-script-path ./val.sh --quiet-translation --beam-size 6 --normalize=0.6 --valid-mini-batch 16 --overwrite --keep-best --early-stopping 15 --cost-type=ce-mean-words --log model/bt_encz.log --valid-log model/valid.log --enc-depth 6 --dec-depth 6 --transformer-preprocess n --transformer-postprocess da --tied-embeddings-all --dim-emb 1024 --transformer-dim-ffn 4096 --transformer-heads 16 --transformer-dropout 0.1 --transformer-dropout-attention 0.1 --transformer-dropout-ffn 0.1 --label-smoothing 0.1 --learn-rate 0.0002 --lr-warmup 8000 --lr-decay-inv-sqrt 8000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --devices 0 1 --sync-sgd --seed 0 --no-nccl --exponential-smoothing --sqlite -T /tmp
[2019-04-01 11:39:52] [config] after-batches: 0
[2019-04-01 11:39:52] [config] after-epochs: 7
[2019-04-01 11:39:52] [config] allow-unk: false
[2019-04-01 11:39:52] [config] beam-size: 6
[2019-04-01 11:39:52] [config] best-deep: false
[2019-04-01 11:39:52] [config] clip-gemm: 0
[2019-04-01 11:39:52] [config] clip-norm: 5
[2019-04-01 11:39:52] [config] cost-type: ce-mean-words
[2019-04-01 11:39:52] [config] cpu-threads: 0
[2019-04-01 11:39:52] [config] data-weighting-type: sentence
[2019-04-01 11:39:52] [config] dec-cell: gru
[2019-04-01 11:39:52] [config] dec-cell-base-depth: 2
[2019-04-01 11:39:52] [config] dec-cell-high-depth: 1
[2019-04-01 11:39:52] [config] dec-depth: 6
[2019-04-01 11:39:52] [config] devices:
[2019-04-01 11:39:52] [config]   - 0
[2019-04-01 11:39:52] [config]   - 1
[2019-04-01 11:39:52] [config] dim-emb: 1024
[2019-04-01 11:39:52] [config] dim-rnn: 1024
[2019-04-01 11:39:52] [config] dim-vocabs:
[2019-04-01 11:39:52] [config]   - 34028
[2019-04-01 11:39:52] [config]   - 34028
[2019-04-01 11:39:52] [config] disp-first: 0
[2019-04-01 11:39:52] [config] disp-freq: 500
[2019-04-01 11:39:52] [config] disp-label-counts: false
[2019-04-01 11:39:52] [config] dropout-rnn: 0
[2019-04-01 11:39:52] [config] dropout-src: 0
[2019-04-01 11:39:52] [config] dropout-trg: 0
[2019-04-01 11:39:52] [config] early-stopping: 15
[2019-04-01 11:39:52] [config] embedding-fix-src: false
[2019-04-01 11:39:52] [config] embedding-fix-trg: false
[2019-04-01 11:39:52] [config] embedding-normalization: false
[2019-04-01 11:39:52] [config] enc-cell: gru
[2019-04-01 11:39:52] [config] enc-cell-depth: 1
[2019-04-01 11:39:52] [config] enc-depth: 6
[2019-04-01 11:39:52] [config] enc-type: bidirectional
[2019-04-01 11:39:52] [config] exponential-smoothing: 0.0001
[2019-04-01 11:39:52] [config] grad-dropping-momentum: 0
[2019-04-01 11:39:52] [config] grad-dropping-rate: 0
[2019-04-01 11:39:52] [config] grad-dropping-warmup: 100
[2019-04-01 11:39:52] [config] guided-alignment: none
[2019-04-01 11:39:52] [config] guided-alignment-cost: mse
[2019-04-01 11:39:52] [config] guided-alignment-weight: 0.1
[2019-04-01 11:39:52] [config] ignore-model-config: false
[2019-04-01 11:39:52] [config] interpolate-env-vars: false
[2019-04-01 11:39:52] [config] keep-best: true
[2019-04-01 11:39:52] [config] label-smoothing: 0.1
[2019-04-01 11:39:52] [config] layer-normalization: false
[2019-04-01 11:39:52] [config] learn-rate: 0.0002
[2019-04-01 11:39:52] [config] log: model/bt_encz.log
[2019-04-01 11:39:52] [config] log-level: info
[2019-04-01 11:39:52] [config] lr-decay: 0
[2019-04-01 11:39:52] [config] lr-decay-freq: 50000
[2019-04-01 11:39:52] [config] lr-decay-inv-sqrt: 8000
[2019-04-01 11:39:52] [config] lr-decay-repeat-warmup: false
[2019-04-01 11:39:52] [config] lr-decay-reset-optimizer: false
[2019-04-01 11:39:52] [config] lr-decay-start:
[2019-04-01 11:39:52] [config]   - 10
[2019-04-01 11:39:52] [config]   - 1
[2019-04-01 11:39:52] [config] lr-decay-strategy: epoch+stalled
[2019-04-01 11:39:52] [config] lr-report: true
[2019-04-01 11:39:52] [config] lr-warmup: 8000
[2019-04-01 11:39:52] [config] lr-warmup-at-reload: false
[2019-04-01 11:39:52] [config] lr-warmup-cycle: false
[2019-04-01 11:39:52] [config] lr-warmup-start-rate: 0
[2019-04-01 11:39:52] [config] max-length: 100
[2019-04-01 11:39:52] [config] max-length-crop: false
[2019-04-01 11:39:52] [config] max-length-factor: 3
[2019-04-01 11:39:52] [config] maxi-batch: 10000
[2019-04-01 11:39:52] [config] maxi-batch-sort: trg
[2019-04-01 11:39:52] [config] mini-batch: 1000
[2019-04-01 11:39:52] [config] mini-batch-fit: true
[2019-04-01 11:39:52] [config] mini-batch-fit-step: 10
[2019-04-01 11:39:52] [config] mini-batch-words: 0
[2019-04-01 11:39:52] [config] model: model/model_bt_encz.npz
[2019-04-01 11:39:52] [config] multi-node: false
[2019-04-01 11:39:52] [config] multi-node-overlap: true
[2019-04-01 11:39:52] [config] n-best: false
[2019-04-01 11:39:52] [config] no-nccl: true
[2019-04-01 11:39:52] [config] no-reload: false
[2019-04-01 11:39:52] [config] no-restore-corpus: false
[2019-04-01 11:39:52] [config] no-shuffle: false
[2019-04-01 11:39:52] [config] normalize: 0.6
[2019-04-01 11:39:52] [config] optimizer: adam
[2019-04-01 11:39:52] [config] optimizer-delay: 4
[2019-04-01 11:39:52] [config] optimizer-params:
[2019-04-01 11:39:52] [config]   - 0.9
[2019-04-01 11:39:52] [config]   - 0.98
[2019-04-01 11:39:52] [config]   - 1e-09
[2019-04-01 11:39:52] [config] overwrite: true
[2019-04-01 11:39:52] [config] quiet: false
[2019-04-01 11:39:52] [config] quiet-translation: true
[2019-04-01 11:39:52] [config] relative-paths: false
[2019-04-01 11:39:52] [config] right-left: false
[2019-04-01 11:39:52] [config] save-freq: 5000
[2019-04-01 11:39:52] [config] seed: 0
[2019-04-01 11:39:52] [config] sentencepiece-alphas:
[2019-04-01 11:39:52] [config]   []
[2019-04-01 11:39:52] [config] sentencepiece-max-lines: 10000000
[2019-04-01 11:39:52] [config] sentencepiece-options: ""
[2019-04-01 11:39:52] [config] shuffle-in-ram: false
[2019-04-01 11:39:52] [config] skip: false
[2019-04-01 11:39:52] [config] sqlite: temporary
[2019-04-01 11:39:52] [config] sqlite-drop: false
[2019-04-01 11:39:52] [config] sync-sgd: true
[2019-04-01 11:39:52] [config] tempdir: /tmp
[2019-04-01 11:39:52] [config] tied-embeddings: false
[2019-04-01 11:39:52] [config] tied-embeddings-all: true
[2019-04-01 11:39:52] [config] tied-embeddings-src: false
[2019-04-01 11:39:52] [config] train-sets:
[2019-04-01 11:39:52] [config]   - bt.encz.en.bpe
[2019-04-01 11:39:52] [config]   - bt.encz.cz.bpe
[2019-04-01 11:39:52] [config] transformer-aan-activation: swish
[2019-04-01 11:39:52] [config] transformer-aan-depth: 2
[2019-04-01 11:39:52] [config] transformer-aan-nogate: false
[2019-04-01 11:39:52] [config] transformer-decoder-autoreg: self-attention
[2019-04-01 11:39:52] [config] transformer-dim-aan: 2048
[2019-04-01 11:39:52] [config] transformer-dim-ffn: 4096
[2019-04-01 11:39:52] [config] transformer-dropout: 0.1
[2019-04-01 11:39:52] [config] transformer-dropout-attention: 0.1
[2019-04-01 11:39:52] [config] transformer-dropout-ffn: 0.1
[2019-04-01 11:39:52] [config] transformer-ffn-activation: swish
[2019-04-01 11:39:52] [config] transformer-ffn-depth: 2
[2019-04-01 11:39:52] [config] transformer-guided-alignment-layer: last
[2019-04-01 11:39:52] [config] transformer-heads: 16
[2019-04-01 11:39:52] [config] transformer-no-projection: false
[2019-04-01 11:39:52] [config] transformer-postprocess: da
[2019-04-01 11:39:52] [config] transformer-postprocess-emb: d
[2019-04-01 11:39:52] [config] transformer-preprocess: n
[2019-04-01 11:39:52] [config] transformer-tied-layers:
[2019-04-01 11:39:52] [config]   []
[2019-04-01 11:39:52] [config] type: transformer
[2019-04-01 11:39:52] [config] ulr: false
[2019-04-01 11:39:52] [config] ulr-dim-emb: 0
[2019-04-01 11:39:52] [config] ulr-dropout: 0
[2019-04-01 11:39:52] [config] ulr-keys-vectors: ""
[2019-04-01 11:39:52] [config] ulr-query-vectors: ""
[2019-04-01 11:39:52] [config] ulr-softmax-temperature: 1
[2019-04-01 11:39:52] [config] ulr-trainable-transformation: false
[2019-04-01 11:39:52] [config] valid-freq: 5000
[2019-04-01 11:39:52] [config] valid-log: model/valid.log
[2019-04-01 11:39:52] [config] valid-max-length: 1000
[2019-04-01 11:39:52] [config] valid-metrics:
[2019-04-01 11:39:52] [config]   - ce-mean-words
[2019-04-01 11:39:52] [config]   - perplexity
[2019-04-01 11:39:52] [config]   - translation
[2019-04-01 11:39:52] [config] valid-mini-batch: 16
[2019-04-01 11:39:52] [config] valid-script-path: ./val.sh
[2019-04-01 11:39:52] [config] valid-sets:
[2019-04-01 11:39:52] [config]   - corp/newstest2016-encs-src.en.bpe
[2019-04-01 11:39:52] [config]   - corp/newstest2016-encs-ref.cs.bpe
[2019-04-01 11:39:52] [config] version: v1.7.6 9cc5b17 2018-12-14 15:11:34 -0800
[2019-04-01 11:39:52] [config] vocabs:
[2019-04-01 11:39:52] [config]   - corp/vocab.encs.yml
[2019-04-01 11:39:52] [config]   - corp/vocab.encs.yml
[2019-04-01 11:39:52] [config] word-penalty: 0
[2019-04-01 11:39:52] [config] workspace: 8600
[2019-04-01 11:39:52] [config] Loaded model has been created with Marian v1.7.6 9cc5b17 2018-12-14 15:11:34 -0800
[2019-04-01 11:39:52] Using synchronous training
[2019-04-01 11:39:52] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.yml
[2019-04-01 11:39:53] [data] Setting vocabulary size for input 0 to 34028
[2019-04-01 11:39:53] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.yml
[2019-04-01 11:39:53] [data] Setting vocabulary size for input 1 to 34028
[2019-04-01 11:39:53] [sqlite] Creating temporary database in /tmp
[2019-04-01 11:39:57] [sqlite] Inserted 1000000 lines
[2019-04-01 11:40:01] [sqlite] Inserted 2000000 lines
[2019-04-01 11:40:09] [sqlite] Inserted 4000000 lines
[2019-04-01 11:40:25] [sqlite] Inserted 8000000 lines
[2019-04-01 11:40:56] [sqlite] Inserted 16000000 lines
[2019-04-01 11:42:01] [sqlite] Inserted 32000000 lines
[2019-04-01 11:43:15] [sqlite] Inserted 49633032 lines
[2019-04-01 11:43:15] [sqlite] Creating primary index
[2019-04-01 11:45:12] [batching] Collecting statistics for batch fitting with step size 10
[2019-04-01 11:45:12] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-04-01 11:45:18] [memory] Extending reserved space to 8704 MB (device gpu0)
[2019-04-01 11:45:19] [memory] Extending reserved space to 8704 MB (device gpu1)
[2019-04-01 11:45:20] [comm] NCCL communicator overridden
[2019-04-01 11:45:20] [memory] Reserving 805 MB, device gpu0
[2019-04-01 11:45:20] [memory] Reserving 805 MB, device gpu0
[2019-04-01 11:45:32] [batching] Done
[2019-04-01 11:45:32] [memory] Extending reserved space to 8704 MB (device gpu0)
[2019-04-01 11:45:32] [memory] Extending reserved space to 8704 MB (device gpu1)
[2019-04-01 11:45:32] [comm] NCCL communicator overridden
[2019-04-01 11:45:32] Loading model from model/model_bt_encz.npz.orig.npz
[2019-04-01 11:45:42] Loading model from model/model_bt_encz.npz.orig.npz
[2019-04-01 11:45:44] Loading Adam parameters from model/model_bt_encz.npz.optimizer.npz
[2019-04-01 11:46:06] [memory] Reserving 805 MB, device gpu0
[2019-04-01 11:46:07] [memory] Reserving 805 MB, device gpu1
[2019-04-01 11:46:08] [data] Restoring the corpus state to epoch 7, batch 235014
[2019-04-01 11:50:12] [sqlite] Selecting shuffled data
[2019-04-01 11:50:12] Training started
[2019-04-01 12:02:53] [memory] Reserving 805 MB, device gpu0
[2019-04-01 12:02:53] [memory] Reserving 805 MB, device gpu1
[2019-04-01 12:02:53] Loading model from model/model_bt_encz.npz
[2019-04-01 12:03:02] [memory] Reserving 805 MB, device cpu0
[2019-04-01 12:03:03] [memory] Reserving 402 MB, device gpu0
[2019-04-01 12:03:03] [memory] Reserving 402 MB, device gpu1
[2019-04-01 12:03:03] [memory] Reserving 805 MB, device gpu0
[2019-04-01 12:03:03] [memory] Reserving 805 MB, device gpu1
[2019-04-01 12:03:04] [memory] Reserving 402 MB, device gpu0
[2019-04-01 12:03:04] [memory] Reserving 402 MB, device gpu1
[2019-04-01 12:21:11] Ep. 7 : Up. 235500 : Sen. 357,938 : Cost 2.20425415 : Time 2139.10s : 4338.17 words/s : L.r. 3.6862e-05
[2019-04-01 12:40:01] Ep. 7 : Up. 236000 : Sen. 749,767 : Cost 2.13086939 : Time 1129.91s : 8306.14 words/s : L.r. 3.6823e-05
[2019-04-01 12:58:57] Ep. 7 : Up. 236500 : Sen. 1,141,893 : Cost 2.11836433 : Time 1135.56s : 8312.75 words/s : L.r. 3.6784e-05
[2019-04-01 13:17:44] Ep. 7 : Up. 237000 : Sen. 1,524,821 : Cost 2.09611654 : Time 1126.93s : 8248.03 words/s : L.r. 3.6745e-05
[2019-04-01 13:36:43] Ep. 7 : Up. 237500 : Sen. 1,916,351 : Cost 2.09103942 : Time 1139.64s : 8327.56 words/s : L.r. 3.6707e-05
[2019-04-01 13:55:30] Ep. 7 : Up. 238000 : Sen. 2,297,927 : Cost 2.07833123 : Time 1126.99s : 8296.98 words/s : L.r. 3.6668e-05
[2019-04-01 14:14:16] Ep. 7 : Up. 238500 : Sen. 2,677,722 : Cost 2.08038521 : Time 1126.04s : 8222.38 words/s : L.r. 3.6629e-05
[2019-04-01 14:33:13] Ep. 7 : Up. 239000 : Sen. 3,053,709 : Cost 2.08035660 : Time 1136.63s : 8277.60 words/s : L.r. 3.6591e-05
[2019-04-01 14:52:07] Ep. 7 : Up. 239500 : Sen. 3,421,131 : Cost 2.07201600 : Time 1134.20s : 8231.45 words/s : L.r. 3.6553e-05
[2019-04-01 15:11:11] Ep. 7 : Up. 240000 : Sen. 3,809,688 : Cost 2.06945443 : Time 1144.31s : 8275.77 words/s : L.r. 3.6515e-05
[2019-04-01 15:11:11] Saving model weights and runtime parameters to model/model_bt_encz.npz.orig.npz
[2019-04-01 15:11:26] Saving model weights and runtime parameters to model/model_bt_encz.npz
[2019-04-01 15:11:41] Saving Adam parameters to model/model_bt_encz.npz.optimizer.npz
[2019-04-01 15:35:05] Saving model weights and runtime parameters to model/model_bt_encz.npz.best-ce-mean-words.npz
[2019-04-01 15:35:17] [valid] Ep. 7 : Up. 240000 : ce-mean-words : 1.39233 : new best
[2019-04-01 15:35:20] Saving model weights and runtime parameters to model/model_bt_encz.npz.best-perplexity.npz
[2019-04-01 15:35:32] [valid] Ep. 7 : Up. 240000 : perplexity : 4.02423 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-01 15:37:15] Saving model weights and runtime parameters to model/model_bt_encz.npz.best-translation.npz
[2019-04-01 15:37:26] [valid] Ep. 7 : Up. 240000 : translation : 29.12 : new best
[2019-04-01 15:56:38] Ep. 7 : Up. 240500 : Sen. 4,198,885 : Cost 2.06408715 : Time 2726.25s : 3448.90 words/s : L.r. 3.6477e-05
[2019-04-01 16:16:02] Ep. 7 : Up. 241000 : Sen. 4,594,030 : Cost 2.06270003 : Time 1164.80s : 8199.68 words/s : L.r. 3.6439e-05
[2019-04-01 16:35:24] Ep. 7 : Up. 241500 : Sen. 4,982,110 : Cost 2.06009269 : Time 1161.62s : 8186.64 words/s : L.r. 3.6401e-05
[2019-04-01 16:54:14] Ep. 7 : Up. 242000 : Sen. 5,360,583 : Cost 2.05667853 : Time 1129.93s : 8127.42 words/s : L.r. 3.6364e-05
[2019-04-01 17:13:26] Ep. 7 : Up. 242500 : Sen. 5,744,377 : Cost 2.05615759 : Time 1151.69s : 8208.82 words/s : L.r. 3.6326e-05
[2019-04-01 17:32:46] Ep. 7 : Up. 243000 : Sen. 6,115,967 : Cost 2.05905223 : Time 1160.23s : 8083.40 words/s : L.r. 3.6289e-05
[2019-04-01 17:51:57] Ep. 7 : Up. 243500 : Sen. 6,493,279 : Cost 2.04829049 : Time 1151.21s : 8063.98 words/s : L.r. 3.6251e-05
[2019-04-01 18:11:26] Ep. 7 : Up. 244000 : Sen. 6,862,931 : Cost 2.05244303 : Time 1168.29s : 8126.73 words/s : L.r. 3.6214e-05
[2019-04-01 18:30:44] Ep. 7 : Up. 244500 : Sen. 7,234,527 : Cost 2.04802155 : Time 1158.73s : 8097.84 words/s : L.r. 3.6177e-05
[2019-04-01 18:50:01] Ep. 7 : Up. 245000 : Sen. 7,630,611 : Cost 2.04852247 : Time 1156.30s : 8060.64 words/s : L.r. 3.6140e-05
[2019-04-01 18:50:01] Saving model weights and runtime parameters to model/model_bt_encz.npz.orig.npz
[2019-04-01 18:50:16] Saving model weights and runtime parameters to model/model_bt_encz.npz
[2019-04-01 18:50:31] Saving Adam parameters to model/model_bt_encz.npz.optimizer.npz
[2019-04-01 18:53:54] [valid] Ep. 7 : Up. 245000 : ce-mean-words : 1.43602 : stalled 1 times
[2019-04-01 18:53:58] [valid] Ep. 7 : Up. 245000 : perplexity : 4.20391 : stalled 1 times
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-01 18:55:40] [valid] Ep. 7 : Up. 245000 : translation : 28.72 : stalled 1 times
[2019-04-01 19:15:30] Ep. 7 : Up. 245500 : Sen. 8,007,554 : Cost 2.04077482 : Time 1529.93s : 6147.49 words/s : L.r. 3.6103e-05
[2019-04-01 19:35:16] Ep. 7 : Up. 246000 : Sen. 8,381,620 : Cost 2.04558468 : Time 1185.57s : 7987.89 words/s : L.r. 3.6067e-05
[2019-04-01 19:54:50] Ep. 7 : Up. 246500 : Sen. 8,745,511 : Cost 2.04418039 : Time 1173.93s : 7970.67 words/s : L.r. 3.6030e-05
[2019-04-01 20:14:15] Ep. 7 : Up. 247000 : Sen. 9,118,545 : Cost 2.04572630 : Time 1164.99s : 8034.75 words/s : L.r. 3.5994e-05
[2019-04-01 20:33:48] Ep. 7 : Up. 247500 : Sen. 9,491,457 : Cost 2.04449391 : Time 1172.94s : 8103.24 words/s : L.r. 3.5957e-05
[2019-04-01 20:53:27] Ep. 7 : Up. 248000 : Sen. 9,884,496 : Cost 2.04150820 : Time 1178.89s : 8143.13 words/s : L.r. 3.5921e-05
[2019-04-01 21:12:49] Ep. 7 : Up. 248500 : Sen. 10,255,537 : Cost 2.03982925 : Time 1161.71s : 8166.30 words/s : L.r. 3.5885e-05
[2019-04-01 21:31:55] Ep. 7 : Up. 249000 : Sen. 10,654,740 : Cost 2.03268766 : Time 1146.41s : 8246.10 words/s : L.r. 3.5849e-05
[2019-04-01 21:50:55] Ep. 7 : Up. 249500 : Sen. 11,028,964 : Cost 2.03433728 : Time 1140.24s : 8276.19 words/s : L.r. 3.5813e-05
[2019-04-01 22:10:06] Ep. 7 : Up. 250000 : Sen. 11,435,509 : Cost 2.03441644 : Time 1150.83s : 8268.99 words/s : L.r. 3.5777e-05
[2019-04-01 22:10:06] Saving model weights and runtime parameters to model/model_bt_encz.npz.orig.npz
[2019-04-01 22:10:23] Saving model weights and runtime parameters to model/model_bt_encz.npz
[2019-04-01 22:10:39] Saving Adam parameters to model/model_bt_encz.npz.optimizer.npz
[2019-04-01 22:16:37] [valid] Ep. 7 : Up. 250000 : ce-mean-words : 1.4883 : stalled 2 times
[2019-04-01 22:16:41] [valid] Ep. 7 : Up. 250000 : perplexity : 4.42957 : stalled 2 times
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-01 22:18:24] [valid] Ep. 7 : Up. 250000 : translation : 28.52 : stalled 2 times
[2019-04-01 22:37:56] Ep. 7 : Up. 250500 : Sen. 11,801,218 : Cost 2.03117108 : Time 1669.64s : 5636.86 words/s : L.r. 3.5741e-05
[2019-04-01 22:57:30] Ep. 7 : Up. 251000 : Sen. 12,188,860 : Cost 2.03662276 : Time 1174.84s : 8083.11 words/s : L.r. 3.5706e-05
[2019-04-01 23:16:57] Ep. 7 : Up. 251500 : Sen. 12,585,887 : Cost 2.03234220 : Time 1167.03s : 8038.13 words/s : L.r. 3.5670e-05
[2019-04-01 23:36:31] Ep. 7 : Up. 252000 : Sen. 12,973,057 : Cost 2.02428961 : Time 1173.56s : 8094.61 words/s : L.r. 3.5635e-05
[2019-04-01 23:55:49] Ep. 7 : Up. 252500 : Sen. 13,355,069 : Cost 2.03252840 : Time 1158.21s : 8074.26 words/s : L.r. 3.5600e-05
[2019-04-02 00:15:03] Ep. 7 : Up. 253000 : Sen. 13,724,792 : Cost 2.02978992 : Time 1153.92s : 8085.45 words/s : L.r. 3.5564e-05
[2019-04-02 00:34:21] Ep. 7 : Up. 253500 : Sen. 14,085,075 : Cost 2.02345181 : Time 1157.40s : 8087.06 words/s : L.r. 3.5529e-05
[2019-04-02 00:53:32] Ep. 7 : Up. 254000 : Sen. 14,454,237 : Cost 2.02979207 : Time 1151.68s : 8095.15 words/s : L.r. 3.5494e-05
[2019-04-02 01:12:35] Ep. 7 : Up. 254500 : Sen. 14,836,226 : Cost 2.03287411 : Time 1143.18s : 8102.15 words/s : L.r. 3.5459e-05
[2019-04-02 01:31:43] Ep. 7 : Up. 255000 : Sen. 15,243,540 : Cost 2.02283454 : Time 1147.60s : 8097.40 words/s : L.r. 3.5425e-05
[2019-04-02 01:31:43] Saving model weights and runtime parameters to model/model_bt_encz.npz.orig.npz
[2019-04-02 01:31:56] Saving model weights and runtime parameters to model/model_bt_encz.npz
[2019-04-02 01:32:09] Saving Adam parameters to model/model_bt_encz.npz.optimizer.npz
[2019-04-02 01:32:52] [valid] Ep. 7 : Up. 255000 : ce-mean-words : 1.53371 : stalled 3 times
[2019-04-02 01:32:56] [valid] Ep. 7 : Up. 255000 : perplexity : 4.63534 : stalled 3 times
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-02 01:34:46] [valid] Ep. 7 : Up. 255000 : translation : 28.06 : stalled 3 times
[2019-04-02 01:53:56] Ep. 7 : Up. 255500 : Sen. 15,627,409 : Cost 2.02511930 : Time 1332.63s : 7057.76 words/s : L.r. 3.5390e-05
[2019-04-02 02:13:12] Ep. 7 : Up. 256000 : Sen. 16,012,846 : Cost 2.03424048 : Time 1156.29s : 8165.03 words/s : L.r. 3.5355e-05
[2019-04-02 02:32:20] Ep. 7 : Up. 256500 : Sen. 16,387,111 : Cost 2.03074932 : Time 1148.00s : 8160.30 words/s : L.r. 3.5321e-05
[2019-04-02 02:51:33] Ep. 7 : Up. 257000 : Sen. 16,773,420 : Cost 2.02621484 : Time 1152.53s : 8201.94 words/s : L.r. 3.5286e-05
[2019-04-02 03:10:44] Ep. 7 : Up. 257500 : Sen. 17,171,261 : Cost 2.02008057 : Time 1151.26s : 8122.50 words/s : L.r. 3.5252e-05
[2019-04-02 03:29:54] Ep. 7 : Up. 258000 : Sen. 17,535,149 : Cost 2.01853538 : Time 1150.40s : 8108.72 words/s : L.r. 3.5218e-05
[2019-04-02 03:49:19] Ep. 7 : Up. 258500 : Sen. 17,894,510 : Cost 2.02652597 : Time 1164.62s : 8167.01 words/s : L.r. 3.5184e-05
[2019-04-02 04:08:35] Ep. 7 : Up. 259000 : Sen. 18,270,021 : Cost 2.02139735 : Time 1156.04s : 8177.68 words/s : L.r. 3.5150e-05
[2019-04-02 04:27:48] Ep. 7 : Up. 259500 : Sen. 18,654,394 : Cost 2.02465129 : Time 1152.87s : 8159.74 words/s : L.r. 3.5116e-05
[2019-04-02 04:47:00] Ep. 7 : Up. 260000 : Sen. 19,030,930 : Cost 2.01884985 : Time 1152.70s : 8133.66 words/s : L.r. 3.5082e-05
[2019-04-02 04:47:00] Saving model weights and runtime parameters to model/model_bt_encz.npz.orig.npz
[2019-04-02 04:47:17] Saving model weights and runtime parameters to model/model_bt_encz.npz
[2019-04-02 04:47:31] Saving Adam parameters to model/model_bt_encz.npz.optimizer.npz
[2019-04-02 04:57:00] [valid] Ep. 7 : Up. 260000 : ce-mean-words : 1.56878 : stalled 4 times
[2019-04-02 04:57:04] [valid] Ep. 7 : Up. 260000 : perplexity : 4.80078 : stalled 4 times
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-02 04:58:52] [valid] Ep. 7 : Up. 260000 : translation : 27.89 : stalled 4 times
[2019-04-02 05:18:32] Ep. 7 : Up. 260500 : Sen. 19,406,096 : Cost 2.02067494 : Time 1891.34s : 5024.54 words/s : L.r. 3.5049e-05
[2019-04-02 05:37:56] Ep. 7 : Up. 261000 : Sen. 19,780,384 : Cost 2.02590632 : Time 1163.96s : 8087.01 words/s : L.r. 3.5015e-05
[2019-04-02 05:57:13] Ep. 7 : Up. 261500 : Sen. 20,153,030 : Cost 2.01499653 : Time 1157.07s : 8004.14 words/s : L.r. 3.4982e-05
[2019-04-02 06:16:30] Ep. 7 : Up. 262000 : Sen. 20,533,797 : Cost 2.01336360 : Time 1157.36s : 8161.42 words/s : L.r. 3.4948e-05
[2019-04-02 06:35:49] Ep. 7 : Up. 262500 : Sen. 20,920,999 : Cost 2.01844358 : Time 1158.66s : 8235.63 words/s : L.r. 3.4915e-05
[2019-04-02 06:54:42] Ep. 7 : Up. 263000 : Sen. 21,287,923 : Cost 2.01940632 : Time 1133.06s : 8124.24 words/s : L.r. 3.4882e-05
[2019-04-02 07:13:57] Ep. 7 : Up. 263500 : Sen. 21,664,200 : Cost 2.01048851 : Time 1154.98s : 8180.12 words/s : L.r. 3.4849e-05
[2019-04-02 07:33:06] Ep. 7 : Up. 264000 : Sen. 22,036,173 : Cost 2.01518369 : Time 1148.85s : 8155.36 words/s : L.r. 3.4816e-05
[2019-04-02 07:52:27] Ep. 7 : Up. 264500 : Sen. 22,401,997 : Cost 2.01853418 : Time 1160.86s : 8178.49 words/s : L.r. 3.4783e-05
[2019-04-02 08:11:46] Ep. 7 : Up. 265000 : Sen. 22,807,185 : Cost 2.01720405 : Time 1159.28s : 8165.88 words/s : L.r. 3.4750e-05
[2019-04-02 08:11:46] Saving model weights and runtime parameters to model/model_bt_encz.npz.orig.npz
[2019-04-02 08:12:03] Saving model weights and runtime parameters to model/model_bt_encz.npz
[2019-04-02 08:12:19] Saving Adam parameters to model/model_bt_encz.npz.optimizer.npz
[2019-04-02 08:13:12] [valid] Ep. 7 : Up. 265000 : ce-mean-words : 1.59453 : stalled 5 times
[2019-04-02 08:13:16] [valid] Ep. 7 : Up. 265000 : perplexity : 4.92604 : stalled 5 times
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-02 08:15:07] [valid] Ep. 7 : Up. 265000 : translation : 27.78 : stalled 5 times
[2019-04-02 08:34:30] Ep. 7 : Up. 265500 : Sen. 23,210,176 : Cost 2.01506066 : Time 1364.27s : 6899.97 words/s : L.r. 3.4717e-05
[2019-04-02 08:53:45] Ep. 7 : Up. 266000 : Sen. 23,592,002 : Cost 2.01930571 : Time 1155.39s : 8093.62 words/s : L.r. 3.4684e-05
[2019-04-02 09:13:06] Ep. 7 : Up. 266500 : Sen. 23,961,985 : Cost 2.01332736 : Time 1160.57s : 8097.57 words/s : L.r. 3.4652e-05
[2019-04-02 09:32:16] Ep. 7 : Up. 267000 : Sen. 24,324,770 : Cost 2.00550747 : Time 1150.35s : 8050.96 words/s : L.r. 3.4619e-05
[2019-04-02 09:51:32] Ep. 7 : Up. 267500 : Sen. 24,690,483 : Cost 2.01518941 : Time 1155.92s : 8139.39 words/s : L.r. 3.4587e-05
[2019-04-02 10:10:40] Ep. 7 : Up. 268000 : Sen. 25,079,520 : Cost 2.01313734 : Time 1147.92s : 8116.21 words/s : L.r. 3.4555e-05
[2019-04-02 10:29:53] Ep. 7 : Up. 268500 : Sen. 25,474,633 : Cost 2.00459623 : Time 1153.08s : 8055.61 words/s : L.r. 3.4523e-05
[2019-04-02 10:49:04] Ep. 7 : Up. 269000 : Sen. 25,849,595 : Cost 2.01231170 : Time 1150.65s : 8199.13 words/s : L.r. 3.4490e-05
[2019-04-02 11:08:23] Ep. 7 : Up. 269500 : Sen. 26,224,118 : Cost 2.01464319 : Time 1158.56s : 8218.08 words/s : L.r. 3.4458e-05
[2019-04-02 11:27:34] Ep. 7 : Up. 270000 : Sen. 26,605,801 : Cost 2.01648235 : Time 1151.12s : 8133.04 words/s : L.r. 3.4427e-05
[2019-04-02 11:27:34] Saving model weights and runtime parameters to model/model_bt_encz.npz.orig.npz
[2019-04-02 11:27:49] Saving model weights and runtime parameters to model/model_bt_encz.npz
[2019-04-02 11:28:03] Saving Adam parameters to model/model_bt_encz.npz.optimizer.npz
[2019-04-02 11:28:40] [valid] Ep. 7 : Up. 270000 : ce-mean-words : 1.6132 : stalled 6 times
[2019-04-02 11:28:44] [valid] Ep. 7 : Up. 270000 : perplexity : 5.01886 : stalled 6 times
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-02 11:30:27] [valid] Ep. 7 : Up. 270000 : translation : 27.65 : stalled 6 times
[2019-04-02 11:49:37] Ep. 7 : Up. 270500 : Sen. 26,987,340 : Cost 2.00856209 : Time 1323.25s : 7032.56 words/s : L.r. 3.4395e-05
[2019-04-02 12:08:57] Ep. 7 : Up. 271000 : Sen. 27,377,761 : Cost 2.01088047 : Time 1160.01s : 8139.02 words/s : L.r. 3.4363e-05
[2019-04-02 12:28:18] Ep. 7 : Up. 271500 : Sen. 27,763,649 : Cost 2.00819707 : Time 1160.69s : 8157.67 words/s : L.r. 3.4331e-05
[2019-04-02 12:47:26] Ep. 7 : Up. 272000 : Sen. 28,147,450 : Cost 2.00902510 : Time 1148.71s : 8112.54 words/s : L.r. 3.4300e-05
[2019-04-02 13:06:53] Ep. 7 : Up. 272500 : Sen. 28,537,490 : Cost 2.01513886 : Time 1166.69s : 8188.76 words/s : L.r. 3.4268e-05
[2019-04-02 13:26:07] Ep. 7 : Up. 273000 : Sen. 28,910,498 : Cost 2.01125407 : Time 1154.30s : 8082.92 words/s : L.r. 3.4237e-05
[2019-04-02 13:45:35] Ep. 7 : Up. 273500 : Sen. 29,291,722 : Cost 2.00414348 : Time 1167.51s : 8024.27 words/s : L.r. 3.4206e-05
[2019-04-02 14:05:13] Ep. 7 : Up. 274000 : Sen. 29,668,298 : Cost 2.00486398 : Time 1178.26s : 8073.91 words/s : L.r. 3.4174e-05
[2019-04-02 14:24:35] Ep. 7 : Up. 274500 : Sen. 30,029,600 : Cost 2.02024078 : Time 1162.06s : 8176.20 words/s : L.r. 3.4143e-05
[2019-04-02 14:43:39] Ep. 7 : Up. 275000 : Sen. 30,417,312 : Cost 2.00284839 : Time 1143.75s : 8138.78 words/s : L.r. 3.4112e-05
[2019-04-02 14:43:39] Saving model weights and runtime parameters to model/model_bt_encz.npz.orig.npz
[2019-04-02 14:43:54] Saving model weights and runtime parameters to model/model_bt_encz.npz
[2019-04-02 14:44:08] Saving Adam parameters to model/model_bt_encz.npz.optimizer.npz
[2019-04-02 14:44:48] [valid] Ep. 7 : Up. 275000 : ce-mean-words : 1.62602 : stalled 7 times
[2019-04-02 14:44:52] [valid] Ep. 7 : Up. 275000 : perplexity : 5.08362 : stalled 7 times
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-02 14:46:39] [valid] Ep. 7 : Up. 275000 : translation : 27.51 : stalled 7 times
[2019-04-02 15:05:40] Ep. 7 : Up. 275500 : Sen. 30,798,129 : Cost 2.00730538 : Time 1320.70s : 7162.99 words/s : L.r. 3.4081e-05
[2019-04-02 15:24:50] Ep. 7 : Up. 276000 : Sen. 31,186,185 : Cost 2.00536251 : Time 1150.51s : 8252.64 words/s : L.r. 3.4050e-05
[2019-04-02 15:43:53] Ep. 7 : Up. 276500 : Sen. 31,566,999 : Cost 1.99949598 : Time 1142.92s : 8224.49 words/s : L.r. 3.4019e-05
[2019-04-02 16:03:00] Ep. 7 : Up. 277000 : Sen. 31,940,466 : Cost 2.00928617 : Time 1147.10s : 8141.31 words/s : L.r. 3.3989e-05
[2019-04-02 16:22:55] Ep. 7 : Up. 277500 : Sen. 32,318,953 : Cost 2.00404286 : Time 1194.50s : 7926.42 words/s : L.r. 3.3958e-05
[2019-04-02 16:42:32] Ep. 7 : Up. 278000 : Sen. 32,685,431 : Cost 2.00110364 : Time 1177.13s : 7941.97 words/s : L.r. 3.3928e-05
[2019-04-02 17:02:10] Ep. 7 : Up. 278500 : Sen. 33,059,095 : Cost 2.01181817 : Time 1177.80s : 8049.18 words/s : L.r. 3.3897e-05
[2019-04-02 17:21:39] Ep. 7 : Up. 279000 : Sen. 33,435,338 : Cost 2.00178814 : Time 1169.00s : 7972.99 words/s : L.r. 3.3867e-05
[2019-04-02 17:41:02] Ep. 7 : Up. 279500 : Sen. 33,812,018 : Cost 2.00538564 : Time 1162.77s : 8010.20 words/s : L.r. 3.3836e-05
[2019-04-02 18:00:34] Ep. 7 : Up. 280000 : Sen. 34,192,506 : Cost 2.00406456 : Time 1172.52s : 8106.66 words/s : L.r. 3.3806e-05
[2019-04-02 18:00:34] Saving model weights and runtime parameters to model/model_bt_encz.npz.orig.npz
[2019-04-02 18:00:49] Saving model weights and runtime parameters to model/model_bt_encz.npz
[2019-04-02 18:01:11] Saving Adam parameters to model/model_bt_encz.npz.optimizer.npz
[2019-04-02 18:03:07] [valid] Ep. 7 : Up. 280000 : ce-mean-words : 1.63575 : stalled 8 times
[2019-04-02 18:03:12] [valid] Ep. 7 : Up. 280000 : perplexity : 5.13329 : stalled 8 times
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-02 18:04:59] [valid] Ep. 7 : Up. 280000 : translation : 27.5 : stalled 8 times
[2019-04-02 18:25:03] Ep. 7 : Up. 280500 : Sen. 34,573,277 : Cost 2.00458670 : Time 1469.04s : 6440.81 words/s : L.r. 3.3776e-05
[2019-04-02 18:44:46] Ep. 7 : Up. 281000 : Sen. 34,967,528 : Cost 2.00496030 : Time 1182.97s : 7843.34 words/s : L.r. 3.3746e-05
[2019-04-02 19:04:33] Ep. 7 : Up. 281500 : Sen. 35,359,567 : Cost 2.00106072 : Time 1187.18s : 7928.81 words/s : L.r. 3.3716e-05
[2019-04-02 19:24:07] Ep. 7 : Up. 282000 : Sen. 35,716,164 : Cost 2.00735235 : Time 1173.97s : 7941.99 words/s : L.r. 3.3686e-05
[2019-04-02 19:43:45] Ep. 7 : Up. 282500 : Sen. 36,084,950 : Cost 2.00332332 : Time 1178.03s : 8014.50 words/s : L.r. 3.3656e-05
[2019-04-02 20:03:23] Ep. 7 : Up. 283000 : Sen. 36,457,158 : Cost 1.99806154 : Time 1177.72s : 8020.61 words/s : L.r. 3.3627e-05
[2019-04-02 20:23:05] Ep. 7 : Up. 283500 : Sen. 36,848,684 : Cost 1.99828362 : Time 1182.17s : 8049.58 words/s : L.r. 3.3597e-05
[2019-04-02 20:42:31] Ep. 7 : Up. 284000 : Sen. 37,231,341 : Cost 2.00449300 : Time 1165.48s : 8044.10 words/s : L.r. 3.3567e-05
[2019-04-02 21:01:53] Ep. 7 : Up. 284500 : Sen. 37,608,945 : Cost 1.99648225 : Time 1162.45s : 7989.60 words/s : L.r. 3.3538e-05
[2019-04-02 21:21:23] Ep. 7 : Up. 285000 : Sen. 37,997,280 : Cost 2.00956273 : Time 1169.58s : 8113.41 words/s : L.r. 3.3508e-05
[2019-04-02 21:21:23] Saving model weights and runtime parameters to model/model_bt_encz.npz.orig.npz
[2019-04-02 21:21:38] Saving model weights and runtime parameters to model/model_bt_encz.npz
[2019-04-02 21:21:52] Saving Adam parameters to model/model_bt_encz.npz.optimizer.npz
[2019-04-02 21:22:44] [valid] Ep. 7 : Up. 285000 : ce-mean-words : 1.64338 : stalled 9 times
[2019-04-02 21:22:48] [valid] Ep. 7 : Up. 285000 : perplexity : 5.17263 : stalled 9 times
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-02 21:24:41] [valid] Ep. 7 : Up. 285000 : translation : 27.54 : stalled 9 times
[2019-04-02 21:44:18] Ep. 7 : Up. 285500 : Sen. 38,369,736 : Cost 2.00172448 : Time 1374.94s : 6849.06 words/s : L.r. 3.3479e-05
[2019-04-02 22:03:53] Ep. 7 : Up. 286000 : Sen. 38,742,130 : Cost 1.99457681 : Time 1175.35s : 8024.88 words/s : L.r. 3.3450e-05
[2019-04-02 22:23:16] Ep. 7 : Up. 286500 : Sen. 39,136,145 : Cost 2.00894403 : Time 1163.49s : 7986.21 words/s : L.r. 3.3420e-05
[2019-04-02 22:42:56] Ep. 7 : Up. 287000 : Sen. 39,534,306 : Cost 1.99414194 : Time 1179.90s : 8005.49 words/s : L.r. 3.3391e-05
[2019-04-02 23:02:17] Ep. 7 : Up. 287500 : Sen. 39,913,368 : Cost 1.99770617 : Time 1160.50s : 7992.14 words/s : L.r. 3.3362e-05
[2019-04-02 23:21:46] Ep. 7 : Up. 288000 : Sen. 40,282,764 : Cost 2.00611758 : Time 1168.82s : 8028.15 words/s : L.r. 3.3333e-05
[2019-04-02 23:41:17] Ep. 7 : Up. 288500 : Sen. 40,672,230 : Cost 1.99946749 : Time 1171.12s : 8025.12 words/s : L.r. 3.3304e-05
[2019-04-03 00:00:45] Ep. 7 : Up. 289000 : Sen. 41,061,534 : Cost 1.99837708 : Time 1167.85s : 8095.47 words/s : L.r. 3.3276e-05
[2019-04-03 00:20:00] Ep. 7 : Up. 289500 : Sen. 41,433,350 : Cost 1.99179566 : Time 1155.01s : 8046.29 words/s : L.r. 3.3247e-05
[2019-04-03 00:39:16] Ep. 7 : Up. 290000 : Sen. 41,832,503 : Cost 1.99343216 : Time 1155.91s : 8061.53 words/s : L.r. 3.3218e-05
[2019-04-03 00:39:16] Saving model weights and runtime parameters to model/model_bt_encz.npz.orig.npz
[2019-04-03 00:39:29] Saving model weights and runtime parameters to model/model_bt_encz.npz
[2019-04-03 00:39:44] Saving Adam parameters to model/model_bt_encz.npz.optimizer.npz
[2019-04-03 00:40:33] [valid] Ep. 7 : Up. 290000 : ce-mean-words : 1.64941 : stalled 10 times
[2019-04-03 00:40:37] [valid] Ep. 7 : Up. 290000 : perplexity : 5.20393 : stalled 10 times
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-03 00:42:22] [valid] Ep. 7 : Up. 290000 : translation : 27.55 : stalled 10 times
[2019-04-03 01:01:57] Ep. 7 : Up. 290500 : Sen. 42,209,294 : Cost 2.00190568 : Time 1361.40s : 6959.20 words/s : L.r. 3.3190e-05
[2019-04-03 01:21:23] Ep. 7 : Up. 291000 : Sen. 42,592,064 : Cost 1.99609196 : Time 1166.29s : 8022.99 words/s : L.r. 3.3161e-05
[2019-04-03 01:40:52] Ep. 7 : Up. 291500 : Sen. 42,965,657 : Cost 1.99461210 : Time 1168.83s : 8040.58 words/s : L.r. 3.3133e-05
[2019-04-03 02:00:23] Ep. 7 : Up. 292000 : Sen. 43,350,131 : Cost 1.99121869 : Time 1170.93s : 8073.15 words/s : L.r. 3.3104e-05
[2019-04-03 02:19:41] Ep. 7 : Up. 292500 : Sen. 43,748,319 : Cost 1.99747193 : Time 1157.76s : 8035.48 words/s : L.r. 3.3076e-05
[2019-04-03 02:39:06] Ep. 7 : Up. 293000 : Sen. 44,118,523 : Cost 1.99261642 : Time 1165.18s : 8033.75 words/s : L.r. 3.3048e-05
[2019-04-03 02:58:31] Ep. 7 : Up. 293500 : Sen. 44,505,283 : Cost 1.99466252 : Time 1164.59s : 8140.30 words/s : L.r. 3.3020e-05
[2019-04-03 03:17:42] Ep. 7 : Up. 294000 : Sen. 44,896,182 : Cost 1.99491858 : Time 1151.82s : 8055.35 words/s : L.r. 3.2991e-05
[2019-04-03 03:37:10] Ep. 7 : Up. 294500 : Sen. 45,267,343 : Cost 1.99636543 : Time 1167.24s : 8117.76 words/s : L.r. 3.2963e-05
[2019-04-03 03:56:25] Ep. 7 : Up. 295000 : Sen. 45,638,820 : Cost 2.00263882 : Time 1155.11s : 8159.75 words/s : L.r. 3.2935e-05
[2019-04-03 03:56:25] Saving model weights and runtime parameters to model/model_bt_encz.npz.orig.npz
[2019-04-03 03:56:45] Saving model weights and runtime parameters to model/model_bt_encz.npz
[2019-04-03 03:56:59] Saving Adam parameters to model/model_bt_encz.npz.optimizer.npz
[2019-04-03 04:04:07] [valid] Ep. 7 : Up. 295000 : ce-mean-words : 1.65389 : stalled 11 times
[2019-04-03 04:04:11] [valid] Ep. 7 : Up. 295000 : perplexity : 5.22729 : stalled 11 times
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-03 04:06:00] [valid] Ep. 7 : Up. 295000 : translation : 27.59 : stalled 11 times
[2019-04-03 04:26:06] Ep. 7 : Up. 295500 : Sen. 46,032,363 : Cost 1.99407291 : Time 1781.60s : 5351.29 words/s : L.r. 3.2908e-05
[2019-04-03 04:45:55] Ep. 7 : Up. 296000 : Sen. 46,404,133 : Cost 1.99253607 : Time 1188.67s : 7931.39 words/s : L.r. 3.2880e-05
[2019-04-03 05:05:41] Ep. 7 : Up. 296500 : Sen. 46,795,144 : Cost 1.99023056 : Time 1186.15s : 7950.70 words/s : L.r. 3.2852e-05
[2019-04-03 05:25:19] Ep. 7 : Up. 297000 : Sen. 47,157,472 : Cost 1.99852443 : Time 1177.80s : 8030.70 words/s : L.r. 3.2824e-05
[2019-04-03 05:44:46] Ep. 7 : Up. 297500 : Sen. 47,512,513 : Cost 2.00284481 : Time 1167.50s : 8045.54 words/s : L.r. 3.2797e-05
[2019-04-03 06:04:12] Ep. 7 : Up. 298000 : Sen. 47,892,745 : Cost 1.99277639 : Time 1165.56s : 8050.76 words/s : L.r. 3.2769e-05
[2019-04-03 06:23:38] Ep. 7 : Up. 298500 : Sen. 48,272,081 : Cost 2.00063109 : Time 1166.44s : 8029.57 words/s : L.r. 3.2742e-05
[2019-04-03 06:43:08] Ep. 7 : Up. 299000 : Sen. 48,653,996 : Cost 1.98702359 : Time 1169.28s : 7992.26 words/s : L.r. 3.2714e-05
[2019-04-03 07:02:27] Ep. 7 : Up. 299500 : Sen. 49,029,405 : Cost 1.99547946 : Time 1159.05s : 7994.34 words/s : L.r. 3.2687e-05
[2019-04-03 07:22:01] Ep. 7 : Up. 300000 : Sen. 49,403,721 : Cost 1.98464000 : Time 1173.93s : 8055.13 words/s : L.r. 3.2660e-05
[2019-04-03 07:22:01] Saving model weights and runtime parameters to model/model_bt_encz.npz.orig.npz
[2019-04-03 07:22:13] Saving model weights and runtime parameters to model/model_bt_encz.npz
[2019-04-03 07:22:25] Saving Adam parameters to model/model_bt_encz.npz.optimizer.npz
[2019-04-03 07:23:37] [valid] Ep. 7 : Up. 300000 : ce-mean-words : 1.65723 : stalled 12 times
[2019-04-03 07:23:41] [valid] Ep. 7 : Up. 300000 : perplexity : 5.24474 : stalled 12 times
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-03 07:25:32] [valid] Ep. 7 : Up. 300000 : translation : 27.53 : stalled 12 times
[2019-04-03 07:31:07] Seen 49518769 samples
[2019-04-03 07:31:07] Starting epoch 8
[2019-04-03 07:31:07] Training finished
[2019-04-03 07:31:11] [valid] Ep. 8 : Up. 300142 : ce-mean-words : 1.65732 : stalled 13 times
[2019-04-03 07:31:16] [valid] Ep. 8 : Up. 300142 : perplexity : 5.24522 : stalled 13 times
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-03 07:33:06] [valid] Ep. 8 : Up. 300142 : translation : 27.51 : stalled 13 times
[2019-04-03 07:33:07] Saving model weights and runtime parameters to model/model_bt_encz.npz.orig.npz
[2019-04-03 07:33:19] Saving model weights and runtime parameters to model/model_bt_encz.npz
[2019-04-03 07:33:32] Saving Adam parameters to model/model_bt_encz.npz.optimizer.npz
ITERATION 7
[2019-04-03 07:34:09] [marian] Marian v1.7.6 9cc5b17 2018-12-14 15:11:34 -0800
[2019-04-03 07:34:09] [marian] Running on spider3.lingea.cz as process 20963 with command line:
[2019-04-03 07:34:09] [marian] /home/big_maggie/usr/marian_spider/marian_1.7.6/marian-dev/build/marian --model model/model_bt_encz.npz --type transformer --train-sets corpus+paracrawl.2M.en.bpe corpus+paracrawl.2M.cz.bpe -e 7 --max-length 100 --vocabs corp/vocab.encs.yml corp/vocab.encs.yml --mini-batch-fit -w 8600 --mini-batch 1000 --maxi-batch 10000 --valid-freq 5000 --save-freq 5000 --disp-freq 500 --valid-metrics ce-mean-words perplexity translation --valid-sets corp/newstest2016-encs-src.en.bpe corp/newstest2016-encs-ref.cs.bpe --valid-script-path ./val.sh --quiet-translation --beam-size 6 --normalize=0.6 --valid-mini-batch 16 --overwrite --keep-best --optimizer-delay 4 --early-stopping 15 --cost-type=ce-mean-words --log model/bt_encz.log --valid-log model/valid.log --enc-depth 6 --dec-depth 6 --transformer-preprocess n --transformer-postprocess da --tied-embeddings-all --dim-emb 1024 --transformer-dim-ffn 4096 --transformer-heads 16 --transformer-dropout 0.1 --transformer-dropout-attention 0.1 --transformer-dropout-ffn 0.1 --label-smoothing 0.1 --learn-rate 0.0002 --lr-warmup 8000 --lr-decay-inv-sqrt 8000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --devices 0 1 --sync-sgd --seed 0 --no-nccl --exponential-smoothing --sqlite -T /tmp
[2019-04-03 07:34:11] [config] after-batches: 0
[2019-04-03 07:34:11] [config] after-epochs: 7
[2019-04-03 07:34:11] [config] allow-unk: false
[2019-04-03 07:34:11] [config] beam-size: 6
[2019-04-03 07:34:11] [config] best-deep: false
[2019-04-03 07:34:11] [config] clip-gemm: 0
[2019-04-03 07:34:11] [config] clip-norm: 5
[2019-04-03 07:34:11] [config] cost-type: ce-mean-words
[2019-04-03 07:34:11] [config] cpu-threads: 0
[2019-04-03 07:34:11] [config] data-weighting-type: sentence
[2019-04-03 07:34:11] [config] dec-cell: gru
[2019-04-03 07:34:11] [config] dec-cell-base-depth: 2
[2019-04-03 07:34:11] [config] dec-cell-high-depth: 1
[2019-04-03 07:34:11] [config] dec-depth: 6
[2019-04-03 07:34:11] [config] devices:
[2019-04-03 07:34:11] [config]   - 0
[2019-04-03 07:34:11] [config]   - 1
[2019-04-03 07:34:11] [config] dim-emb: 1024
[2019-04-03 07:34:11] [config] dim-rnn: 1024
[2019-04-03 07:34:11] [config] dim-vocabs:
[2019-04-03 07:34:11] [config]   - 34028
[2019-04-03 07:34:11] [config]   - 34028
[2019-04-03 07:34:11] [config] disp-first: 0
[2019-04-03 07:34:11] [config] disp-freq: 500
[2019-04-03 07:34:11] [config] disp-label-counts: false
[2019-04-03 07:34:11] [config] dropout-rnn: 0
[2019-04-03 07:34:11] [config] dropout-src: 0
[2019-04-03 07:34:11] [config] dropout-trg: 0
[2019-04-03 07:34:11] [config] early-stopping: 15
[2019-04-03 07:34:11] [config] embedding-fix-src: false
[2019-04-03 07:34:11] [config] embedding-fix-trg: false
[2019-04-03 07:34:11] [config] embedding-normalization: false
[2019-04-03 07:34:11] [config] enc-cell: gru
[2019-04-03 07:34:11] [config] enc-cell-depth: 1
[2019-04-03 07:34:11] [config] enc-depth: 6
[2019-04-03 07:34:11] [config] enc-type: bidirectional
[2019-04-03 07:34:11] [config] exponential-smoothing: 0.0001
[2019-04-03 07:34:11] [config] grad-dropping-momentum: 0
[2019-04-03 07:34:11] [config] grad-dropping-rate: 0
[2019-04-03 07:34:11] [config] grad-dropping-warmup: 100
[2019-04-03 07:34:11] [config] guided-alignment: none
[2019-04-03 07:34:11] [config] guided-alignment-cost: mse
[2019-04-03 07:34:11] [config] guided-alignment-weight: 0.1
[2019-04-03 07:34:11] [config] ignore-model-config: false
[2019-04-03 07:34:11] [config] interpolate-env-vars: false
[2019-04-03 07:34:11] [config] keep-best: true
[2019-04-03 07:34:11] [config] label-smoothing: 0.1
[2019-04-03 07:34:11] [config] layer-normalization: false
[2019-04-03 07:34:11] [config] learn-rate: 0.0002
[2019-04-03 07:34:11] [config] log: model/bt_encz.log
[2019-04-03 07:34:11] [config] log-level: info
[2019-04-03 07:34:11] [config] lr-decay: 0
[2019-04-03 07:34:11] [config] lr-decay-freq: 50000
[2019-04-03 07:34:11] [config] lr-decay-inv-sqrt: 8000
[2019-04-03 07:34:11] [config] lr-decay-repeat-warmup: false
[2019-04-03 07:34:11] [config] lr-decay-reset-optimizer: false
[2019-04-03 07:34:11] [config] lr-decay-start:
[2019-04-03 07:34:11] [config]   - 10
[2019-04-03 07:34:11] [config]   - 1
[2019-04-03 07:34:11] [config] lr-decay-strategy: epoch+stalled
[2019-04-03 07:34:11] [config] lr-report: true
[2019-04-03 07:34:11] [config] lr-warmup: 8000
[2019-04-03 07:34:11] [config] lr-warmup-at-reload: false
[2019-04-03 07:34:11] [config] lr-warmup-cycle: false
[2019-04-03 07:34:11] [config] lr-warmup-start-rate: 0
[2019-04-03 07:34:11] [config] max-length: 100
[2019-04-03 07:34:11] [config] max-length-crop: false
[2019-04-03 07:34:11] [config] max-length-factor: 3
[2019-04-03 07:34:11] [config] maxi-batch: 10000
[2019-04-03 07:34:11] [config] maxi-batch-sort: trg
[2019-04-03 07:34:11] [config] mini-batch: 1000
[2019-04-03 07:34:11] [config] mini-batch-fit: true
[2019-04-03 07:34:11] [config] mini-batch-fit-step: 10
[2019-04-03 07:34:11] [config] mini-batch-words: 0
[2019-04-03 07:34:11] [config] model: model/model_bt_encz.npz
[2019-04-03 07:34:11] [config] multi-node: false
[2019-04-03 07:34:11] [config] multi-node-overlap: true
[2019-04-03 07:34:11] [config] n-best: false
[2019-04-03 07:34:11] [config] no-nccl: true
[2019-04-03 07:34:11] [config] no-reload: false
[2019-04-03 07:34:11] [config] no-restore-corpus: false
[2019-04-03 07:34:11] [config] no-shuffle: false
[2019-04-03 07:34:11] [config] normalize: 0.6
[2019-04-03 07:34:11] [config] optimizer: adam
[2019-04-03 07:34:11] [config] optimizer-delay: 4
[2019-04-03 07:34:11] [config] optimizer-params:
[2019-04-03 07:34:11] [config]   - 0.9
[2019-04-03 07:34:11] [config]   - 0.98
[2019-04-03 07:34:11] [config]   - 1e-09
[2019-04-03 07:34:11] [config] overwrite: true
[2019-04-03 07:34:11] [config] quiet: false
[2019-04-03 07:34:11] [config] quiet-translation: true
[2019-04-03 07:34:11] [config] relative-paths: false
[2019-04-03 07:34:11] [config] right-left: false
[2019-04-03 07:34:11] [config] save-freq: 5000
[2019-04-03 07:34:11] [config] seed: 0
[2019-04-03 07:34:11] [config] sentencepiece-alphas:
[2019-04-03 07:34:11] [config]   []
[2019-04-03 07:34:11] [config] sentencepiece-max-lines: 10000000
[2019-04-03 07:34:11] [config] sentencepiece-options: ""
[2019-04-03 07:34:11] [config] shuffle-in-ram: false
[2019-04-03 07:34:11] [config] skip: false
[2019-04-03 07:34:11] [config] sqlite: temporary
[2019-04-03 07:34:11] [config] sqlite-drop: false
[2019-04-03 07:34:11] [config] sync-sgd: true
[2019-04-03 07:34:11] [config] tempdir: /tmp
[2019-04-03 07:34:11] [config] tied-embeddings: false
[2019-04-03 07:34:11] [config] tied-embeddings-all: true
[2019-04-03 07:34:11] [config] tied-embeddings-src: false
[2019-04-03 07:34:11] [config] train-sets:
[2019-04-03 07:34:11] [config]   - corpus+paracrawl.2M.en.bpe
[2019-04-03 07:34:11] [config]   - corpus+paracrawl.2M.cz.bpe
[2019-04-03 07:34:11] [config] transformer-aan-activation: swish
[2019-04-03 07:34:11] [config] transformer-aan-depth: 2
[2019-04-03 07:34:11] [config] transformer-aan-nogate: false
[2019-04-03 07:34:11] [config] transformer-decoder-autoreg: self-attention
[2019-04-03 07:34:11] [config] transformer-dim-aan: 2048
[2019-04-03 07:34:11] [config] transformer-dim-ffn: 4096
[2019-04-03 07:34:11] [config] transformer-dropout: 0.1
[2019-04-03 07:34:11] [config] transformer-dropout-attention: 0.1
[2019-04-03 07:34:11] [config] transformer-dropout-ffn: 0.1
[2019-04-03 07:34:11] [config] transformer-ffn-activation: swish
[2019-04-03 07:34:11] [config] transformer-ffn-depth: 2
[2019-04-03 07:34:11] [config] transformer-guided-alignment-layer: last
[2019-04-03 07:34:11] [config] transformer-heads: 16
[2019-04-03 07:34:11] [config] transformer-no-projection: false
[2019-04-03 07:34:11] [config] transformer-postprocess: da
[2019-04-03 07:34:11] [config] transformer-postprocess-emb: d
[2019-04-03 07:34:11] [config] transformer-preprocess: n
[2019-04-03 07:34:11] [config] transformer-tied-layers:
[2019-04-03 07:34:11] [config]   []
[2019-04-03 07:34:11] [config] type: transformer
[2019-04-03 07:34:11] [config] ulr: false
[2019-04-03 07:34:11] [config] ulr-dim-emb: 0
[2019-04-03 07:34:11] [config] ulr-dropout: 0
[2019-04-03 07:34:11] [config] ulr-keys-vectors: ""
[2019-04-03 07:34:11] [config] ulr-query-vectors: ""
[2019-04-03 07:34:11] [config] ulr-softmax-temperature: 1
[2019-04-03 07:34:11] [config] ulr-trainable-transformation: false
[2019-04-03 07:34:11] [config] valid-freq: 5000
[2019-04-03 07:34:11] [config] valid-log: model/valid.log
[2019-04-03 07:34:11] [config] valid-max-length: 1000
[2019-04-03 07:34:11] [config] valid-metrics:
[2019-04-03 07:34:11] [config]   - ce-mean-words
[2019-04-03 07:34:11] [config]   - perplexity
[2019-04-03 07:34:11] [config]   - translation
[2019-04-03 07:34:11] [config] valid-mini-batch: 16
[2019-04-03 07:34:11] [config] valid-script-path: ./val.sh
[2019-04-03 07:34:11] [config] valid-sets:
[2019-04-03 07:34:11] [config]   - corp/newstest2016-encs-src.en.bpe
[2019-04-03 07:34:11] [config]   - corp/newstest2016-encs-ref.cs.bpe
[2019-04-03 07:34:11] [config] version: v1.7.6 9cc5b17 2018-12-14 15:11:34 -0800
[2019-04-03 07:34:11] [config] vocabs:
[2019-04-03 07:34:11] [config]   - corp/vocab.encs.yml
[2019-04-03 07:34:11] [config]   - corp/vocab.encs.yml
[2019-04-03 07:34:11] [config] word-penalty: 0
[2019-04-03 07:34:11] [config] workspace: 8600
[2019-04-03 07:34:11] [config] Loaded model has been created with Marian v1.7.6 9cc5b17 2018-12-14 15:11:34 -0800
[2019-04-03 07:34:11] Using synchronous training
[2019-04-03 07:34:11] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.yml
[2019-04-03 07:34:11] [data] Setting vocabulary size for input 0 to 34028
[2019-04-03 07:34:11] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.yml
[2019-04-03 07:34:12] [data] Setting vocabulary size for input 1 to 34028
[2019-04-03 07:34:12] [sqlite] Creating temporary database in /tmp
[2019-04-03 07:34:15] [sqlite] Inserted 1000000 lines
[2019-04-03 07:34:18] [sqlite] Inserted 2000000 lines
[2019-04-03 07:34:25] [sqlite] Inserted 4000000 lines
[2019-04-03 07:34:39] [sqlite] Inserted 8000000 lines
[2019-04-03 07:35:08] [sqlite] Inserted 16000000 lines
[2019-04-03 07:36:09] [sqlite] Inserted 32000000 lines
[2019-04-03 07:36:49] [sqlite] Inserted 41438108 lines
[2019-04-03 07:36:49] [sqlite] Creating primary index
[2019-04-03 07:37:43] [batching] Collecting statistics for batch fitting with step size 10
[2019-04-03 07:37:43] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-04-03 07:37:47] [memory] Extending reserved space to 8704 MB (device gpu0)
[2019-04-03 07:37:48] [memory] Extending reserved space to 8704 MB (device gpu1)
[2019-04-03 07:37:49] [comm] NCCL communicator overridden
[2019-04-03 07:37:49] [memory] Reserving 805 MB, device gpu0
[2019-04-03 07:37:49] [memory] Reserving 805 MB, device gpu0
[2019-04-03 07:38:01] [batching] Done
[2019-04-03 07:38:01] [memory] Extending reserved space to 8704 MB (device gpu0)
[2019-04-03 07:38:01] [memory] Extending reserved space to 8704 MB (device gpu1)
[2019-04-03 07:38:01] [comm] NCCL communicator overridden
[2019-04-03 07:38:01] Loading model from model/model_bt_encz.npz.orig.npz
[2019-04-03 07:38:13] Loading model from model/model_bt_encz.npz.orig.npz
[2019-04-03 07:38:16] Loading Adam parameters from model/model_bt_encz.npz.optimizer.npz
[2019-04-03 07:38:39] [memory] Reserving 805 MB, device gpu0
[2019-04-03 07:38:39] [memory] Reserving 805 MB, device gpu1
[2019-04-03 07:38:42] [data] Restoring the corpus state to epoch 8, batch 300142
[2019-04-03 07:42:42] [sqlite] Selecting shuffled data
[2019-04-03 07:42:42] Training started
[2019-04-03 07:42:42] Training finished
rm: cannot remove ‘model/model_bt_encz.npz.yml’: No such file or directory
[2019-04-03 07:42:46] [marian] Marian v1.7.6 9cc5b17 2018-12-14 15:11:34 -0800
[2019-04-03 07:42:46] [marian] Running on spider3.lingea.cz as process 21082 with command line:
[2019-04-03 07:42:46] [marian] /home/big_maggie/usr/marian_spider/marian_1.7.6/marian-dev/build/marian --model model/model_bt_encz.npz --type transformer --train-sets bt.encz.en.bpe bt.encz.cz.bpe -e 8 --max-length 100 --vocabs corp/vocab.encs.yml corp/vocab.encs.yml --mini-batch-fit -w 8600 --mini-batch 1000 --maxi-batch 10000 --valid-freq 5000 --save-freq 5000 --disp-freq 500 --optimizer-delay 4 --valid-metrics ce-mean-words perplexity translation --valid-sets corp/newstest2016-encs-src.en.bpe corp/newstest2016-encs-ref.cs.bpe --valid-script-path ./val.sh --quiet-translation --beam-size 6 --normalize=0.6 --valid-mini-batch 16 --overwrite --keep-best --early-stopping 15 --cost-type=ce-mean-words --log model/bt_encz.log --valid-log model/valid.log --enc-depth 6 --dec-depth 6 --transformer-preprocess n --transformer-postprocess da --tied-embeddings-all --dim-emb 1024 --transformer-dim-ffn 4096 --transformer-heads 16 --transformer-dropout 0.1 --transformer-dropout-attention 0.1 --transformer-dropout-ffn 0.1 --label-smoothing 0.1 --learn-rate 0.0002 --lr-warmup 8000 --lr-decay-inv-sqrt 8000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --devices 0 1 --sync-sgd --seed 0 --no-nccl --exponential-smoothing --sqlite -T /tmp
[2019-04-03 07:42:48] [config] after-batches: 0
[2019-04-03 07:42:48] [config] after-epochs: 8
[2019-04-03 07:42:48] [config] allow-unk: false
[2019-04-03 07:42:48] [config] beam-size: 6
[2019-04-03 07:42:48] [config] best-deep: false
[2019-04-03 07:42:48] [config] clip-gemm: 0
[2019-04-03 07:42:48] [config] clip-norm: 5
[2019-04-03 07:42:48] [config] cost-type: ce-mean-words
[2019-04-03 07:42:48] [config] cpu-threads: 0
[2019-04-03 07:42:48] [config] data-weighting-type: sentence
[2019-04-03 07:42:48] [config] dec-cell: gru
[2019-04-03 07:42:48] [config] dec-cell-base-depth: 2
[2019-04-03 07:42:48] [config] dec-cell-high-depth: 1
[2019-04-03 07:42:48] [config] dec-depth: 6
[2019-04-03 07:42:48] [config] devices:
[2019-04-03 07:42:48] [config]   - 0
[2019-04-03 07:42:48] [config]   - 1
[2019-04-03 07:42:48] [config] dim-emb: 1024
[2019-04-03 07:42:48] [config] dim-rnn: 1024
[2019-04-03 07:42:48] [config] dim-vocabs:
[2019-04-03 07:42:48] [config]   - 34028
[2019-04-03 07:42:48] [config]   - 34028
[2019-04-03 07:42:48] [config] disp-first: 0
[2019-04-03 07:42:48] [config] disp-freq: 500
[2019-04-03 07:42:48] [config] disp-label-counts: false
[2019-04-03 07:42:48] [config] dropout-rnn: 0
[2019-04-03 07:42:48] [config] dropout-src: 0
[2019-04-03 07:42:48] [config] dropout-trg: 0
[2019-04-03 07:42:48] [config] early-stopping: 15
[2019-04-03 07:42:48] [config] embedding-fix-src: false
[2019-04-03 07:42:48] [config] embedding-fix-trg: false
[2019-04-03 07:42:48] [config] embedding-normalization: false
[2019-04-03 07:42:48] [config] enc-cell: gru
[2019-04-03 07:42:48] [config] enc-cell-depth: 1
[2019-04-03 07:42:48] [config] enc-depth: 6
[2019-04-03 07:42:48] [config] enc-type: bidirectional
[2019-04-03 07:42:48] [config] exponential-smoothing: 0.0001
[2019-04-03 07:42:48] [config] grad-dropping-momentum: 0
[2019-04-03 07:42:48] [config] grad-dropping-rate: 0
[2019-04-03 07:42:48] [config] grad-dropping-warmup: 100
[2019-04-03 07:42:48] [config] guided-alignment: none
[2019-04-03 07:42:48] [config] guided-alignment-cost: mse
[2019-04-03 07:42:48] [config] guided-alignment-weight: 0.1
[2019-04-03 07:42:48] [config] ignore-model-config: false
[2019-04-03 07:42:48] [config] interpolate-env-vars: false
[2019-04-03 07:42:48] [config] keep-best: true
[2019-04-03 07:42:48] [config] label-smoothing: 0.1
[2019-04-03 07:42:48] [config] layer-normalization: false
[2019-04-03 07:42:48] [config] learn-rate: 0.0002
[2019-04-03 07:42:48] [config] log: model/bt_encz.log
[2019-04-03 07:42:48] [config] log-level: info
[2019-04-03 07:42:48] [config] lr-decay: 0
[2019-04-03 07:42:48] [config] lr-decay-freq: 50000
[2019-04-03 07:42:48] [config] lr-decay-inv-sqrt: 8000
[2019-04-03 07:42:48] [config] lr-decay-repeat-warmup: false
[2019-04-03 07:42:48] [config] lr-decay-reset-optimizer: false
[2019-04-03 07:42:48] [config] lr-decay-start:
[2019-04-03 07:42:48] [config]   - 10
[2019-04-03 07:42:48] [config]   - 1
[2019-04-03 07:42:48] [config] lr-decay-strategy: epoch+stalled
[2019-04-03 07:42:48] [config] lr-report: true
[2019-04-03 07:42:48] [config] lr-warmup: 8000
[2019-04-03 07:42:48] [config] lr-warmup-at-reload: false
[2019-04-03 07:42:48] [config] lr-warmup-cycle: false
[2019-04-03 07:42:48] [config] lr-warmup-start-rate: 0
[2019-04-03 07:42:48] [config] max-length: 100
[2019-04-03 07:42:48] [config] max-length-crop: false
[2019-04-03 07:42:48] [config] max-length-factor: 3
[2019-04-03 07:42:48] [config] maxi-batch: 10000
[2019-04-03 07:42:48] [config] maxi-batch-sort: trg
[2019-04-03 07:42:48] [config] mini-batch: 1000
[2019-04-03 07:42:48] [config] mini-batch-fit: true
[2019-04-03 07:42:48] [config] mini-batch-fit-step: 10
[2019-04-03 07:42:48] [config] mini-batch-words: 0
[2019-04-03 07:42:48] [config] model: model/model_bt_encz.npz
[2019-04-03 07:42:48] [config] multi-node: false
[2019-04-03 07:42:48] [config] multi-node-overlap: true
[2019-04-03 07:42:48] [config] n-best: false
[2019-04-03 07:42:48] [config] no-nccl: true
[2019-04-03 07:42:48] [config] no-reload: false
[2019-04-03 07:42:48] [config] no-restore-corpus: false
[2019-04-03 07:42:48] [config] no-shuffle: false
[2019-04-03 07:42:48] [config] normalize: 0.6
[2019-04-03 07:42:48] [config] optimizer: adam
[2019-04-03 07:42:48] [config] optimizer-delay: 4
[2019-04-03 07:42:48] [config] optimizer-params:
[2019-04-03 07:42:48] [config]   - 0.9
[2019-04-03 07:42:48] [config]   - 0.98
[2019-04-03 07:42:48] [config]   - 1e-09
[2019-04-03 07:42:48] [config] overwrite: true
[2019-04-03 07:42:48] [config] quiet: false
[2019-04-03 07:42:48] [config] quiet-translation: true
[2019-04-03 07:42:48] [config] relative-paths: false
[2019-04-03 07:42:48] [config] right-left: false
[2019-04-03 07:42:48] [config] save-freq: 5000
[2019-04-03 07:42:48] [config] seed: 0
[2019-04-03 07:42:48] [config] sentencepiece-alphas:
[2019-04-03 07:42:48] [config]   []
[2019-04-03 07:42:48] [config] sentencepiece-max-lines: 10000000
[2019-04-03 07:42:48] [config] sentencepiece-options: ""
[2019-04-03 07:42:48] [config] shuffle-in-ram: false
[2019-04-03 07:42:48] [config] skip: false
[2019-04-03 07:42:48] [config] sqlite: temporary
[2019-04-03 07:42:48] [config] sqlite-drop: false
[2019-04-03 07:42:48] [config] sync-sgd: true
[2019-04-03 07:42:48] [config] tempdir: /tmp
[2019-04-03 07:42:48] [config] tied-embeddings: false
[2019-04-03 07:42:48] [config] tied-embeddings-all: true
[2019-04-03 07:42:48] [config] tied-embeddings-src: false
[2019-04-03 07:42:48] [config] train-sets:
[2019-04-03 07:42:48] [config]   - bt.encz.en.bpe
[2019-04-03 07:42:48] [config]   - bt.encz.cz.bpe
[2019-04-03 07:42:48] [config] transformer-aan-activation: swish
[2019-04-03 07:42:48] [config] transformer-aan-depth: 2
[2019-04-03 07:42:48] [config] transformer-aan-nogate: false
[2019-04-03 07:42:48] [config] transformer-decoder-autoreg: self-attention
[2019-04-03 07:42:48] [config] transformer-dim-aan: 2048
[2019-04-03 07:42:48] [config] transformer-dim-ffn: 4096
[2019-04-03 07:42:48] [config] transformer-dropout: 0.1
[2019-04-03 07:42:48] [config] transformer-dropout-attention: 0.1
[2019-04-03 07:42:48] [config] transformer-dropout-ffn: 0.1
[2019-04-03 07:42:48] [config] transformer-ffn-activation: swish
[2019-04-03 07:42:48] [config] transformer-ffn-depth: 2
[2019-04-03 07:42:48] [config] transformer-guided-alignment-layer: last
[2019-04-03 07:42:48] [config] transformer-heads: 16
[2019-04-03 07:42:48] [config] transformer-no-projection: false
[2019-04-03 07:42:48] [config] transformer-postprocess: da
[2019-04-03 07:42:48] [config] transformer-postprocess-emb: d
[2019-04-03 07:42:48] [config] transformer-preprocess: n
[2019-04-03 07:42:48] [config] transformer-tied-layers:
[2019-04-03 07:42:48] [config]   []
[2019-04-03 07:42:48] [config] type: transformer
[2019-04-03 07:42:48] [config] ulr: false
[2019-04-03 07:42:48] [config] ulr-dim-emb: 0
[2019-04-03 07:42:48] [config] ulr-dropout: 0
[2019-04-03 07:42:48] [config] ulr-keys-vectors: ""
[2019-04-03 07:42:48] [config] ulr-query-vectors: ""
[2019-04-03 07:42:48] [config] ulr-softmax-temperature: 1
[2019-04-03 07:42:48] [config] ulr-trainable-transformation: false
[2019-04-03 07:42:48] [config] valid-freq: 5000
[2019-04-03 07:42:48] [config] valid-log: model/valid.log
[2019-04-03 07:42:48] [config] valid-max-length: 1000
[2019-04-03 07:42:48] [config] valid-metrics:
[2019-04-03 07:42:48] [config]   - ce-mean-words
[2019-04-03 07:42:48] [config]   - perplexity
[2019-04-03 07:42:48] [config]   - translation
[2019-04-03 07:42:48] [config] valid-mini-batch: 16
[2019-04-03 07:42:48] [config] valid-script-path: ./val.sh
[2019-04-03 07:42:48] [config] valid-sets:
[2019-04-03 07:42:48] [config]   - corp/newstest2016-encs-src.en.bpe
[2019-04-03 07:42:48] [config]   - corp/newstest2016-encs-ref.cs.bpe
[2019-04-03 07:42:48] [config] version: v1.7.6 9cc5b17 2018-12-14 15:11:34 -0800
[2019-04-03 07:42:48] [config] vocabs:
[2019-04-03 07:42:48] [config]   - corp/vocab.encs.yml
[2019-04-03 07:42:48] [config]   - corp/vocab.encs.yml
[2019-04-03 07:42:48] [config] word-penalty: 0
[2019-04-03 07:42:48] [config] workspace: 8600
[2019-04-03 07:42:48] [config] Loaded model has been created with Marian v1.7.6 9cc5b17 2018-12-14 15:11:34 -0800
[2019-04-03 07:42:48] Using synchronous training
[2019-04-03 07:42:48] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.yml
[2019-04-03 07:42:49] [data] Setting vocabulary size for input 0 to 34028
[2019-04-03 07:42:49] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.yml
[2019-04-03 07:42:49] [data] Setting vocabulary size for input 1 to 34028
[2019-04-03 07:42:49] [sqlite] Creating temporary database in /tmp
[2019-04-03 07:42:53] [sqlite] Inserted 1000000 lines
[2019-04-03 07:42:57] [sqlite] Inserted 2000000 lines
[2019-04-03 07:43:04] [sqlite] Inserted 4000000 lines
[2019-04-03 07:43:21] [sqlite] Inserted 8000000 lines
[2019-04-03 07:43:58] [sqlite] Inserted 16000000 lines
[2019-04-03 07:45:17] [sqlite] Inserted 32000000 lines
[2019-04-03 07:46:43] [sqlite] Inserted 49633032 lines
[2019-04-03 07:46:43] [sqlite] Creating primary index
[2019-04-03 07:49:36] [batching] Collecting statistics for batch fitting with step size 10
[2019-04-03 07:49:36] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-04-03 07:49:39] [memory] Extending reserved space to 8704 MB (device gpu0)
[2019-04-03 07:49:40] [memory] Extending reserved space to 8704 MB (device gpu1)
[2019-04-03 07:49:40] [comm] NCCL communicator overridden
[2019-04-03 07:49:40] [memory] Reserving 805 MB, device gpu0
[2019-04-03 07:49:41] [memory] Reserving 805 MB, device gpu0
[2019-04-03 07:49:52] [batching] Done
[2019-04-03 07:49:52] [memory] Extending reserved space to 8704 MB (device gpu0)
[2019-04-03 07:49:53] [memory] Extending reserved space to 8704 MB (device gpu1)
[2019-04-03 07:49:53] [comm] NCCL communicator overridden
[2019-04-03 07:49:53] Loading model from model/model_bt_encz.npz.orig.npz
[2019-04-03 07:49:57] Loading model from model/model_bt_encz.npz.orig.npz
[2019-04-03 07:50:01] Loading Adam parameters from model/model_bt_encz.npz.optimizer.npz
[2019-04-03 07:50:24] [memory] Reserving 805 MB, device gpu0
[2019-04-03 07:50:24] [memory] Reserving 805 MB, device gpu1
[2019-04-03 07:50:26] [data] Restoring the corpus state to epoch 8, batch 300142
[2019-04-03 07:55:15] [sqlite] Selecting shuffled data
[2019-04-03 07:55:15] Training started
[2019-04-03 08:09:56] [memory] Reserving 805 MB, device gpu0
[2019-04-03 08:09:57] [memory] Reserving 805 MB, device gpu1
[2019-04-03 08:09:58] Loading model from model/model_bt_encz.npz
[2019-04-03 08:10:07] [memory] Reserving 805 MB, device cpu0
[2019-04-03 08:10:09] [memory] Reserving 402 MB, device gpu0
[2019-04-03 08:10:09] [memory] Reserving 402 MB, device gpu1
[2019-04-03 08:10:09] [memory] Reserving 805 MB, device gpu0
[2019-04-03 08:10:09] [memory] Reserving 805 MB, device gpu1
[2019-04-03 08:10:10] [memory] Reserving 402 MB, device gpu0
[2019-04-03 08:10:10] [memory] Reserving 402 MB, device gpu1
[2019-04-03 08:23:27] Ep. 8 : Up. 300500 : Sen. 276,498 : Cost 1.98699403 : Time 2014.80s : 4686.01 words/s : L.r. 3.2633e-05
[2019-04-03 08:42:21] Ep. 8 : Up. 301000 : Sen. 650,319 : Cost 1.98408115 : Time 1134.43s : 8362.63 words/s : L.r. 3.2606e-05
[2019-04-03 09:01:13] Ep. 8 : Up. 301500 : Sen. 1,044,342 : Cost 1.98401725 : Time 1131.14s : 8269.14 words/s : L.r. 3.2579e-05
[2019-04-03 09:20:04] Ep. 8 : Up. 302000 : Sen. 1,425,794 : Cost 1.98446894 : Time 1131.14s : 8288.40 words/s : L.r. 3.2552e-05
[2019-04-03 09:38:54] Ep. 8 : Up. 302500 : Sen. 1,808,367 : Cost 1.98228049 : Time 1130.33s : 8215.17 words/s : L.r. 3.2525e-05
[2019-04-03 09:57:46] Ep. 8 : Up. 303000 : Sen. 2,190,520 : Cost 1.98561525 : Time 1131.81s : 8328.28 words/s : L.r. 3.2498e-05
[2019-04-03 10:16:38] Ep. 8 : Up. 303500 : Sen. 2,560,996 : Cost 1.98860145 : Time 1132.34s : 8347.50 words/s : L.r. 3.2471e-05
[2019-04-03 10:36:18] Ep. 8 : Up. 304000 : Sen. 2,936,153 : Cost 1.98411536 : Time 1179.51s : 8020.88 words/s : L.r. 3.2444e-05
[2019-04-03 10:56:02] Ep. 8 : Up. 304500 : Sen. 3,314,753 : Cost 1.98406100 : Time 1184.67s : 7917.99 words/s : L.r. 3.2418e-05
[2019-04-03 11:15:37] Ep. 8 : Up. 305000 : Sen. 3,689,478 : Cost 1.97991240 : Time 1174.93s : 7943.86 words/s : L.r. 3.2391e-05
[2019-04-03 11:15:37] Saving model weights and runtime parameters to model/model_bt_encz.npz.orig.npz
[2019-04-03 11:15:50] Saving model weights and runtime parameters to model/model_bt_encz.npz
[2019-04-03 11:16:01] Saving Adam parameters to model/model_bt_encz.npz.optimizer.npz
[2019-04-03 11:21:28] [valid] Ep. 8 : Up. 305000 : ce-mean-words : 1.66135 : stalled 14 times
[2019-04-03 11:21:32] [valid] Ep. 8 : Up. 305000 : perplexity : 5.2664 : stalled 14 times
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-03 11:23:23] [valid] Ep. 8 : Up. 305000 : translation : 27.54 : stalled 14 times
[2019-04-03 11:43:36] Ep. 8 : Up. 305500 : Sen. 4,052,661 : Cost 1.98425961 : Time 1678.56s : 5536.94 words/s : L.r. 3.2365e-05
[2019-04-03 12:03:42] Ep. 8 : Up. 306000 : Sen. 4,427,645 : Cost 1.97995782 : Time 1206.36s : 7750.65 words/s : L.r. 3.2338e-05
[2019-04-03 12:23:50] Ep. 8 : Up. 306500 : Sen. 4,806,264 : Cost 1.98493934 : Time 1207.87s : 7924.75 words/s : L.r. 3.2312e-05
[2019-04-03 12:43:27] Ep. 8 : Up. 307000 : Sen. 5,182,808 : Cost 1.97935987 : Time 1177.29s : 7952.63 words/s : L.r. 3.2285e-05
[2019-04-03 13:03:03] Ep. 8 : Up. 307500 : Sen. 5,560,482 : Cost 1.99733412 : Time 1175.77s : 8063.81 words/s : L.r. 3.2259e-05
[2019-04-03 13:22:44] Ep. 8 : Up. 308000 : Sen. 5,961,544 : Cost 1.98125041 : Time 1180.36s : 8008.64 words/s : L.r. 3.2233e-05
[2019-04-03 13:42:15] Ep. 8 : Up. 308500 : Sen. 6,351,736 : Cost 1.98716581 : Time 1171.14s : 8090.77 words/s : L.r. 3.2207e-05
[2019-04-03 14:01:34] Ep. 8 : Up. 309000 : Sen. 6,745,512 : Cost 1.97741795 : Time 1159.38s : 8014.26 words/s : L.r. 3.2181e-05
[2019-04-03 14:20:56] Ep. 8 : Up. 309500 : Sen. 7,102,491 : Cost 1.98132420 : Time 1161.65s : 8057.79 words/s : L.r. 3.2155e-05
[2019-04-03 14:40:29] Ep. 8 : Up. 310000 : Sen. 7,488,561 : Cost 1.98193300 : Time 1173.56s : 8107.11 words/s : L.r. 3.2129e-05
[2019-04-03 14:40:29] Saving model weights and runtime parameters to model/model_bt_encz.npz.orig.npz
[2019-04-03 14:40:42] Saving model weights and runtime parameters to model/model_bt_encz.npz
[2019-04-03 14:40:53] Saving Adam parameters to model/model_bt_encz.npz.optimizer.npz
[2019-04-03 14:46:03] [valid] Ep. 8 : Up. 310000 : ce-mean-words : 1.66463 : stalled 15 times
[2019-04-03 14:46:07] [valid] Ep. 8 : Up. 310000 : perplexity : 5.28373 : stalled 15 times
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-03 14:47:56] [valid] Ep. 8 : Up. 310000 : translation : 27.53 : stalled 15 times
[2019-04-03 14:47:57] Training finished
[2019-04-03 14:47:58] Saving model weights and runtime parameters to model/model_bt_encz.npz.orig.npz
[2019-04-03 14:48:08] Saving model weights and runtime parameters to model/model_bt_encz.npz
[2019-04-03 14:48:20] Saving Adam parameters to model/model_bt_encz.npz.optimizer.npz
ITERATION 8
[2019-04-03 14:48:58] [marian] Marian v1.7.6 9cc5b17 2018-12-14 15:11:34 -0800
[2019-04-03 14:48:58] [marian] Running on spider3.lingea.cz as process 2296 with command line:
[2019-04-03 14:48:58] [marian] /home/big_maggie/usr/marian_spider/marian_1.7.6/marian-dev/build/marian --model model/model_bt_encz.npz --type transformer --train-sets corpus+paracrawl.2M.en.bpe corpus+paracrawl.2M.cz.bpe -e 8 --max-length 100 --vocabs corp/vocab.encs.yml corp/vocab.encs.yml --mini-batch-fit -w 8600 --mini-batch 1000 --maxi-batch 10000 --valid-freq 5000 --save-freq 5000 --disp-freq 500 --valid-metrics ce-mean-words perplexity translation --valid-sets corp/newstest2016-encs-src.en.bpe corp/newstest2016-encs-ref.cs.bpe --valid-script-path ./val.sh --quiet-translation --beam-size 6 --normalize=0.6 --valid-mini-batch 16 --overwrite --keep-best --optimizer-delay 4 --early-stopping 15 --cost-type=ce-mean-words --log model/bt_encz.log --valid-log model/valid.log --enc-depth 6 --dec-depth 6 --transformer-preprocess n --transformer-postprocess da --tied-embeddings-all --dim-emb 1024 --transformer-dim-ffn 4096 --transformer-heads 16 --transformer-dropout 0.1 --transformer-dropout-attention 0.1 --transformer-dropout-ffn 0.1 --label-smoothing 0.1 --learn-rate 0.0002 --lr-warmup 8000 --lr-decay-inv-sqrt 8000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --devices 0 1 --sync-sgd --seed 0 --no-nccl --exponential-smoothing --sqlite -T /tmp
[2019-04-03 14:48:59] [config] after-batches: 0
[2019-04-03 14:48:59] [config] after-epochs: 8
[2019-04-03 14:48:59] [config] allow-unk: false
[2019-04-03 14:48:59] [config] beam-size: 6
[2019-04-03 14:48:59] [config] best-deep: false
[2019-04-03 14:48:59] [config] clip-gemm: 0
[2019-04-03 14:48:59] [config] clip-norm: 5
[2019-04-03 14:48:59] [config] cost-type: ce-mean-words
[2019-04-03 14:48:59] [config] cpu-threads: 0
[2019-04-03 14:48:59] [config] data-weighting-type: sentence
[2019-04-03 14:48:59] [config] dec-cell: gru
[2019-04-03 14:48:59] [config] dec-cell-base-depth: 2
[2019-04-03 14:48:59] [config] dec-cell-high-depth: 1
[2019-04-03 14:48:59] [config] dec-depth: 6
[2019-04-03 14:48:59] [config] devices:
[2019-04-03 14:48:59] [config]   - 0
[2019-04-03 14:48:59] [config]   - 1
[2019-04-03 14:48:59] [config] dim-emb: 1024
[2019-04-03 14:48:59] [config] dim-rnn: 1024
[2019-04-03 14:48:59] [config] dim-vocabs:
[2019-04-03 14:48:59] [config]   - 34028
[2019-04-03 14:48:59] [config]   - 34028
[2019-04-03 14:48:59] [config] disp-first: 0
[2019-04-03 14:48:59] [config] disp-freq: 500
[2019-04-03 14:48:59] [config] disp-label-counts: false
[2019-04-03 14:48:59] [config] dropout-rnn: 0
[2019-04-03 14:48:59] [config] dropout-src: 0
[2019-04-03 14:48:59] [config] dropout-trg: 0
[2019-04-03 14:48:59] [config] early-stopping: 15
[2019-04-03 14:48:59] [config] embedding-fix-src: false
[2019-04-03 14:48:59] [config] embedding-fix-trg: false
[2019-04-03 14:48:59] [config] embedding-normalization: false
[2019-04-03 14:48:59] [config] enc-cell: gru
[2019-04-03 14:48:59] [config] enc-cell-depth: 1
[2019-04-03 14:48:59] [config] enc-depth: 6
[2019-04-03 14:48:59] [config] enc-type: bidirectional
[2019-04-03 14:48:59] [config] exponential-smoothing: 0.0001
[2019-04-03 14:48:59] [config] grad-dropping-momentum: 0
[2019-04-03 14:48:59] [config] grad-dropping-rate: 0
[2019-04-03 14:48:59] [config] grad-dropping-warmup: 100
[2019-04-03 14:48:59] [config] guided-alignment: none
[2019-04-03 14:48:59] [config] guided-alignment-cost: mse
[2019-04-03 14:48:59] [config] guided-alignment-weight: 0.1
[2019-04-03 14:48:59] [config] ignore-model-config: false
[2019-04-03 14:48:59] [config] interpolate-env-vars: false
[2019-04-03 14:48:59] [config] keep-best: true
[2019-04-03 14:48:59] [config] label-smoothing: 0.1
[2019-04-03 14:48:59] [config] layer-normalization: false
[2019-04-03 14:48:59] [config] learn-rate: 0.0002
[2019-04-03 14:48:59] [config] log: model/bt_encz.log
[2019-04-03 14:48:59] [config] log-level: info
[2019-04-03 14:48:59] [config] lr-decay: 0
[2019-04-03 14:48:59] [config] lr-decay-freq: 50000
[2019-04-03 14:48:59] [config] lr-decay-inv-sqrt: 8000
[2019-04-03 14:48:59] [config] lr-decay-repeat-warmup: false
[2019-04-03 14:48:59] [config] lr-decay-reset-optimizer: false
[2019-04-03 14:48:59] [config] lr-decay-start:
[2019-04-03 14:48:59] [config]   - 10
[2019-04-03 14:48:59] [config]   - 1
[2019-04-03 14:48:59] [config] lr-decay-strategy: epoch+stalled
[2019-04-03 14:48:59] [config] lr-report: true
[2019-04-03 14:48:59] [config] lr-warmup: 8000
[2019-04-03 14:48:59] [config] lr-warmup-at-reload: false
[2019-04-03 14:48:59] [config] lr-warmup-cycle: false
[2019-04-03 14:48:59] [config] lr-warmup-start-rate: 0
[2019-04-03 14:48:59] [config] max-length: 100
[2019-04-03 14:48:59] [config] max-length-crop: false
[2019-04-03 14:48:59] [config] max-length-factor: 3
[2019-04-03 14:48:59] [config] maxi-batch: 10000
[2019-04-03 14:48:59] [config] maxi-batch-sort: trg
[2019-04-03 14:48:59] [config] mini-batch: 1000
[2019-04-03 14:48:59] [config] mini-batch-fit: true
[2019-04-03 14:48:59] [config] mini-batch-fit-step: 10
[2019-04-03 14:48:59] [config] mini-batch-words: 0
[2019-04-03 14:48:59] [config] model: model/model_bt_encz.npz
[2019-04-03 14:48:59] [config] multi-node: false
[2019-04-03 14:48:59] [config] multi-node-overlap: true
[2019-04-03 14:48:59] [config] n-best: false
[2019-04-03 14:48:59] [config] no-nccl: true
[2019-04-03 14:48:59] [config] no-reload: false
[2019-04-03 14:48:59] [config] no-restore-corpus: false
[2019-04-03 14:48:59] [config] no-shuffle: false
[2019-04-03 14:48:59] [config] normalize: 0.6
[2019-04-03 14:48:59] [config] optimizer: adam
[2019-04-03 14:48:59] [config] optimizer-delay: 4
[2019-04-03 14:48:59] [config] optimizer-params:
[2019-04-03 14:48:59] [config]   - 0.9
[2019-04-03 14:48:59] [config]   - 0.98
[2019-04-03 14:48:59] [config]   - 1e-09
[2019-04-03 14:48:59] [config] overwrite: true
[2019-04-03 14:48:59] [config] quiet: false
[2019-04-03 14:48:59] [config] quiet-translation: true
[2019-04-03 14:48:59] [config] relative-paths: false
[2019-04-03 14:48:59] [config] right-left: false
[2019-04-03 14:48:59] [config] save-freq: 5000
[2019-04-03 14:48:59] [config] seed: 0
[2019-04-03 14:48:59] [config] sentencepiece-alphas:
[2019-04-03 14:48:59] [config]   []
[2019-04-03 14:48:59] [config] sentencepiece-max-lines: 10000000
[2019-04-03 14:48:59] [config] sentencepiece-options: ""
[2019-04-03 14:48:59] [config] shuffle-in-ram: false
[2019-04-03 14:48:59] [config] skip: false
[2019-04-03 14:48:59] [config] sqlite: temporary
[2019-04-03 14:48:59] [config] sqlite-drop: false
[2019-04-03 14:48:59] [config] sync-sgd: true
[2019-04-03 14:48:59] [config] tempdir: /tmp
[2019-04-03 14:48:59] [config] tied-embeddings: false
[2019-04-03 14:48:59] [config] tied-embeddings-all: true
[2019-04-03 14:48:59] [config] tied-embeddings-src: false
[2019-04-03 14:48:59] [config] train-sets:
[2019-04-03 14:48:59] [config]   - corpus+paracrawl.2M.en.bpe
[2019-04-03 14:48:59] [config]   - corpus+paracrawl.2M.cz.bpe
[2019-04-03 14:48:59] [config] transformer-aan-activation: swish
[2019-04-03 14:48:59] [config] transformer-aan-depth: 2
[2019-04-03 14:48:59] [config] transformer-aan-nogate: false
[2019-04-03 14:48:59] [config] transformer-decoder-autoreg: self-attention
[2019-04-03 14:48:59] [config] transformer-dim-aan: 2048
[2019-04-03 14:48:59] [config] transformer-dim-ffn: 4096
[2019-04-03 14:48:59] [config] transformer-dropout: 0.1
[2019-04-03 14:48:59] [config] transformer-dropout-attention: 0.1
[2019-04-03 14:48:59] [config] transformer-dropout-ffn: 0.1
[2019-04-03 14:48:59] [config] transformer-ffn-activation: swish
[2019-04-03 14:48:59] [config] transformer-ffn-depth: 2
[2019-04-03 14:48:59] [config] transformer-guided-alignment-layer: last
[2019-04-03 14:48:59] [config] transformer-heads: 16
[2019-04-03 14:48:59] [config] transformer-no-projection: false
[2019-04-03 14:48:59] [config] transformer-postprocess: da
[2019-04-03 14:48:59] [config] transformer-postprocess-emb: d
[2019-04-03 14:48:59] [config] transformer-preprocess: n
[2019-04-03 14:48:59] [config] transformer-tied-layers:
[2019-04-03 14:48:59] [config]   []
[2019-04-03 14:48:59] [config] type: transformer
[2019-04-03 14:48:59] [config] ulr: false
[2019-04-03 14:48:59] [config] ulr-dim-emb: 0
[2019-04-03 14:48:59] [config] ulr-dropout: 0
[2019-04-03 14:48:59] [config] ulr-keys-vectors: ""
[2019-04-03 14:48:59] [config] ulr-query-vectors: ""
[2019-04-03 14:48:59] [config] ulr-softmax-temperature: 1
[2019-04-03 14:48:59] [config] ulr-trainable-transformation: false
[2019-04-03 14:48:59] [config] valid-freq: 5000
[2019-04-03 14:48:59] [config] valid-log: model/valid.log
[2019-04-03 14:48:59] [config] valid-max-length: 1000
[2019-04-03 14:48:59] [config] valid-metrics:
[2019-04-03 14:48:59] [config]   - ce-mean-words
[2019-04-03 14:48:59] [config]   - perplexity
[2019-04-03 14:48:59] [config]   - translation
[2019-04-03 14:48:59] [config] valid-mini-batch: 16
[2019-04-03 14:48:59] [config] valid-script-path: ./val.sh
[2019-04-03 14:48:59] [config] valid-sets:
[2019-04-03 14:48:59] [config]   - corp/newstest2016-encs-src.en.bpe
[2019-04-03 14:48:59] [config]   - corp/newstest2016-encs-ref.cs.bpe
[2019-04-03 14:48:59] [config] version: v1.7.6 9cc5b17 2018-12-14 15:11:34 -0800
[2019-04-03 14:48:59] [config] vocabs:
[2019-04-03 14:48:59] [config]   - corp/vocab.encs.yml
[2019-04-03 14:48:59] [config]   - corp/vocab.encs.yml
[2019-04-03 14:48:59] [config] word-penalty: 0
[2019-04-03 14:48:59] [config] workspace: 8600
[2019-04-03 14:48:59] [config] Loaded model has been created with Marian v1.7.6 9cc5b17 2018-12-14 15:11:34 -0800
[2019-04-03 14:48:59] Using synchronous training
[2019-04-03 14:48:59] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.yml
[2019-04-03 14:49:00] [data] Setting vocabulary size for input 0 to 34028
[2019-04-03 14:49:00] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.yml
[2019-04-03 14:49:00] [data] Setting vocabulary size for input 1 to 34028
[2019-04-03 14:49:00] [sqlite] Creating temporary database in /tmp
[2019-04-03 14:49:03] [sqlite] Inserted 1000000 lines
[2019-04-03 14:49:07] [sqlite] Inserted 2000000 lines
[2019-04-03 14:49:13] [sqlite] Inserted 4000000 lines
[2019-04-03 14:49:27] [sqlite] Inserted 8000000 lines
[2019-04-03 14:49:57] [sqlite] Inserted 16000000 lines
[2019-04-03 14:50:56] [sqlite] Inserted 32000000 lines
[2019-04-03 14:51:33] [sqlite] Inserted 41438108 lines
[2019-04-03 14:51:33] [sqlite] Creating primary index
[2019-04-03 14:52:29] [batching] Collecting statistics for batch fitting with step size 10
[2019-04-03 14:52:29] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-04-03 14:52:33] [memory] Extending reserved space to 8704 MB (device gpu0)
[2019-04-03 14:52:34] [memory] Extending reserved space to 8704 MB (device gpu1)
[2019-04-03 14:52:34] [comm] NCCL communicator overridden
[2019-04-03 14:52:34] [memory] Reserving 805 MB, device gpu0
[2019-04-03 14:52:34] [memory] Reserving 805 MB, device gpu0
[2019-04-03 14:52:46] [batching] Done
[2019-04-03 14:52:46] [memory] Extending reserved space to 8704 MB (device gpu0)
[2019-04-03 14:52:46] [memory] Extending reserved space to 8704 MB (device gpu1)
[2019-04-03 14:52:46] [comm] NCCL communicator overridden
[2019-04-03 14:52:46] Loading model from model/model_bt_encz.npz.orig.npz
[2019-04-03 14:52:55] Loading model from model/model_bt_encz.npz.orig.npz
[2019-04-03 14:52:58] Loading Adam parameters from model/model_bt_encz.npz.optimizer.npz
[2019-04-03 14:53:21] [memory] Reserving 805 MB, device gpu0
[2019-04-03 14:53:22] [memory] Reserving 805 MB, device gpu1
[2019-04-03 14:53:23] [data] Restoring the corpus state to epoch 8, batch 310000
[2019-04-03 14:57:24] [sqlite] Selecting shuffled data
[2019-04-03 15:12:04] Training started
[2019-04-03 15:12:04] Training finished
rm: cannot remove ‘model/model_bt_encz.npz.yml’: No such file or directory
[2019-04-03 15:12:08] [marian] Marian v1.7.6 9cc5b17 2018-12-14 15:11:34 -0800
[2019-04-03 15:12:08] [marian] Running on spider3.lingea.cz as process 2568 with command line:
[2019-04-03 15:12:08] [marian] /home/big_maggie/usr/marian_spider/marian_1.7.6/marian-dev/build/marian --model model/model_bt_encz.npz --type transformer --train-sets bt.encz.en.bpe bt.encz.cz.bpe -e 9 --max-length 100 --vocabs corp/vocab.encs.yml corp/vocab.encs.yml --mini-batch-fit -w 8600 --mini-batch 1000 --maxi-batch 10000 --valid-freq 5000 --save-freq 5000 --disp-freq 500 --optimizer-delay 4 --valid-metrics ce-mean-words perplexity translation --valid-sets corp/newstest2016-encs-src.en.bpe corp/newstest2016-encs-ref.cs.bpe --valid-script-path ./val.sh --quiet-translation --beam-size 6 --normalize=0.6 --valid-mini-batch 16 --overwrite --keep-best --early-stopping 15 --cost-type=ce-mean-words --log model/bt_encz.log --valid-log model/valid.log --enc-depth 6 --dec-depth 6 --transformer-preprocess n --transformer-postprocess da --tied-embeddings-all --dim-emb 1024 --transformer-dim-ffn 4096 --transformer-heads 16 --transformer-dropout 0.1 --transformer-dropout-attention 0.1 --transformer-dropout-ffn 0.1 --label-smoothing 0.1 --learn-rate 0.0002 --lr-warmup 8000 --lr-decay-inv-sqrt 8000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --devices 0 1 --sync-sgd --seed 0 --no-nccl --exponential-smoothing --sqlite -T /tmp
[2019-04-03 15:12:09] [config] after-batches: 0
[2019-04-03 15:12:09] [config] after-epochs: 9
[2019-04-03 15:12:09] [config] allow-unk: false
[2019-04-03 15:12:09] [config] beam-size: 6
[2019-04-03 15:12:09] [config] best-deep: false
[2019-04-03 15:12:09] [config] clip-gemm: 0
[2019-04-03 15:12:09] [config] clip-norm: 5
[2019-04-03 15:12:09] [config] cost-type: ce-mean-words
[2019-04-03 15:12:09] [config] cpu-threads: 0
[2019-04-03 15:12:09] [config] data-weighting-type: sentence
[2019-04-03 15:12:09] [config] dec-cell: gru
[2019-04-03 15:12:09] [config] dec-cell-base-depth: 2
[2019-04-03 15:12:09] [config] dec-cell-high-depth: 1
[2019-04-03 15:12:09] [config] dec-depth: 6
[2019-04-03 15:12:09] [config] devices:
[2019-04-03 15:12:09] [config]   - 0
[2019-04-03 15:12:09] [config]   - 1
[2019-04-03 15:12:09] [config] dim-emb: 1024
[2019-04-03 15:12:09] [config] dim-rnn: 1024
[2019-04-03 15:12:09] [config] dim-vocabs:
[2019-04-03 15:12:09] [config]   - 34028
[2019-04-03 15:12:09] [config]   - 34028
[2019-04-03 15:12:09] [config] disp-first: 0
[2019-04-03 15:12:09] [config] disp-freq: 500
[2019-04-03 15:12:09] [config] disp-label-counts: false
[2019-04-03 15:12:09] [config] dropout-rnn: 0
[2019-04-03 15:12:09] [config] dropout-src: 0
[2019-04-03 15:12:09] [config] dropout-trg: 0
[2019-04-03 15:12:09] [config] early-stopping: 15
[2019-04-03 15:12:09] [config] embedding-fix-src: false
[2019-04-03 15:12:09] [config] embedding-fix-trg: false
[2019-04-03 15:12:09] [config] embedding-normalization: false
[2019-04-03 15:12:09] [config] enc-cell: gru
[2019-04-03 15:12:09] [config] enc-cell-depth: 1
[2019-04-03 15:12:09] [config] enc-depth: 6
[2019-04-03 15:12:09] [config] enc-type: bidirectional
[2019-04-03 15:12:09] [config] exponential-smoothing: 0.0001
[2019-04-03 15:12:09] [config] grad-dropping-momentum: 0
[2019-04-03 15:12:09] [config] grad-dropping-rate: 0
[2019-04-03 15:12:09] [config] grad-dropping-warmup: 100
[2019-04-03 15:12:09] [config] guided-alignment: none
[2019-04-03 15:12:09] [config] guided-alignment-cost: mse
[2019-04-03 15:12:09] [config] guided-alignment-weight: 0.1
[2019-04-03 15:12:09] [config] ignore-model-config: false
[2019-04-03 15:12:09] [config] interpolate-env-vars: false
[2019-04-03 15:12:09] [config] keep-best: true
[2019-04-03 15:12:09] [config] label-smoothing: 0.1
[2019-04-03 15:12:09] [config] layer-normalization: false
[2019-04-03 15:12:09] [config] learn-rate: 0.0002
[2019-04-03 15:12:09] [config] log: model/bt_encz.log
[2019-04-03 15:12:09] [config] log-level: info
[2019-04-03 15:12:09] [config] lr-decay: 0
[2019-04-03 15:12:09] [config] lr-decay-freq: 50000
[2019-04-03 15:12:09] [config] lr-decay-inv-sqrt: 8000
[2019-04-03 15:12:09] [config] lr-decay-repeat-warmup: false
[2019-04-03 15:12:09] [config] lr-decay-reset-optimizer: false
[2019-04-03 15:12:09] [config] lr-decay-start:
[2019-04-03 15:12:09] [config]   - 10
[2019-04-03 15:12:09] [config]   - 1
[2019-04-03 15:12:09] [config] lr-decay-strategy: epoch+stalled
[2019-04-03 15:12:09] [config] lr-report: true
[2019-04-03 15:12:09] [config] lr-warmup: 8000
[2019-04-03 15:12:09] [config] lr-warmup-at-reload: false
[2019-04-03 15:12:09] [config] lr-warmup-cycle: false
[2019-04-03 15:12:09] [config] lr-warmup-start-rate: 0
[2019-04-03 15:12:09] [config] max-length: 100
[2019-04-03 15:12:09] [config] max-length-crop: false
[2019-04-03 15:12:09] [config] max-length-factor: 3
[2019-04-03 15:12:09] [config] maxi-batch: 10000
[2019-04-03 15:12:09] [config] maxi-batch-sort: trg
[2019-04-03 15:12:09] [config] mini-batch: 1000
[2019-04-03 15:12:09] [config] mini-batch-fit: true
[2019-04-03 15:12:09] [config] mini-batch-fit-step: 10
[2019-04-03 15:12:09] [config] mini-batch-words: 0
[2019-04-03 15:12:09] [config] model: model/model_bt_encz.npz
[2019-04-03 15:12:09] [config] multi-node: false
[2019-04-03 15:12:09] [config] multi-node-overlap: true
[2019-04-03 15:12:09] [config] n-best: false
[2019-04-03 15:12:09] [config] no-nccl: true
[2019-04-03 15:12:09] [config] no-reload: false
[2019-04-03 15:12:09] [config] no-restore-corpus: false
[2019-04-03 15:12:09] [config] no-shuffle: false
[2019-04-03 15:12:09] [config] normalize: 0.6
[2019-04-03 15:12:09] [config] optimizer: adam
[2019-04-03 15:12:09] [config] optimizer-delay: 4
[2019-04-03 15:12:09] [config] optimizer-params:
[2019-04-03 15:12:09] [config]   - 0.9
[2019-04-03 15:12:09] [config]   - 0.98
[2019-04-03 15:12:09] [config]   - 1e-09
[2019-04-03 15:12:09] [config] overwrite: true
[2019-04-03 15:12:09] [config] quiet: false
[2019-04-03 15:12:09] [config] quiet-translation: true
[2019-04-03 15:12:09] [config] relative-paths: false
[2019-04-03 15:12:09] [config] right-left: false
[2019-04-03 15:12:09] [config] save-freq: 5000
[2019-04-03 15:12:09] [config] seed: 0
[2019-04-03 15:12:09] [config] sentencepiece-alphas:
[2019-04-03 15:12:09] [config]   []
[2019-04-03 15:12:09] [config] sentencepiece-max-lines: 10000000
[2019-04-03 15:12:09] [config] sentencepiece-options: ""
[2019-04-03 15:12:09] [config] shuffle-in-ram: false
[2019-04-03 15:12:09] [config] skip: false
[2019-04-03 15:12:09] [config] sqlite: temporary
[2019-04-03 15:12:09] [config] sqlite-drop: false
[2019-04-03 15:12:09] [config] sync-sgd: true
[2019-04-03 15:12:09] [config] tempdir: /tmp
[2019-04-03 15:12:09] [config] tied-embeddings: false
[2019-04-03 15:12:09] [config] tied-embeddings-all: true
[2019-04-03 15:12:09] [config] tied-embeddings-src: false
[2019-04-03 15:12:09] [config] train-sets:
[2019-04-03 15:12:09] [config]   - bt.encz.en.bpe
[2019-04-03 15:12:09] [config]   - bt.encz.cz.bpe
[2019-04-03 15:12:09] [config] transformer-aan-activation: swish
[2019-04-03 15:12:09] [config] transformer-aan-depth: 2
[2019-04-03 15:12:09] [config] transformer-aan-nogate: false
[2019-04-03 15:12:09] [config] transformer-decoder-autoreg: self-attention
[2019-04-03 15:12:09] [config] transformer-dim-aan: 2048
[2019-04-03 15:12:09] [config] transformer-dim-ffn: 4096
[2019-04-03 15:12:09] [config] transformer-dropout: 0.1
[2019-04-03 15:12:09] [config] transformer-dropout-attention: 0.1
[2019-04-03 15:12:09] [config] transformer-dropout-ffn: 0.1
[2019-04-03 15:12:09] [config] transformer-ffn-activation: swish
[2019-04-03 15:12:09] [config] transformer-ffn-depth: 2
[2019-04-03 15:12:09] [config] transformer-guided-alignment-layer: last
[2019-04-03 15:12:09] [config] transformer-heads: 16
[2019-04-03 15:12:09] [config] transformer-no-projection: false
[2019-04-03 15:12:09] [config] transformer-postprocess: da
[2019-04-03 15:12:09] [config] transformer-postprocess-emb: d
[2019-04-03 15:12:09] [config] transformer-preprocess: n
[2019-04-03 15:12:09] [config] transformer-tied-layers:
[2019-04-03 15:12:09] [config]   []
[2019-04-03 15:12:09] [config] type: transformer
[2019-04-03 15:12:09] [config] ulr: false
[2019-04-03 15:12:09] [config] ulr-dim-emb: 0
[2019-04-03 15:12:09] [config] ulr-dropout: 0
[2019-04-03 15:12:09] [config] ulr-keys-vectors: ""
[2019-04-03 15:12:09] [config] ulr-query-vectors: ""
[2019-04-03 15:12:09] [config] ulr-softmax-temperature: 1
[2019-04-03 15:12:09] [config] ulr-trainable-transformation: false
[2019-04-03 15:12:09] [config] valid-freq: 5000
[2019-04-03 15:12:09] [config] valid-log: model/valid.log
[2019-04-03 15:12:09] [config] valid-max-length: 1000
[2019-04-03 15:12:09] [config] valid-metrics:
[2019-04-03 15:12:09] [config]   - ce-mean-words
[2019-04-03 15:12:09] [config]   - perplexity
[2019-04-03 15:12:09] [config]   - translation
[2019-04-03 15:12:09] [config] valid-mini-batch: 16
[2019-04-03 15:12:09] [config] valid-script-path: ./val.sh
[2019-04-03 15:12:09] [config] valid-sets:
[2019-04-03 15:12:09] [config]   - corp/newstest2016-encs-src.en.bpe
[2019-04-03 15:12:09] [config]   - corp/newstest2016-encs-ref.cs.bpe
[2019-04-03 15:12:09] [config] version: v1.7.6 9cc5b17 2018-12-14 15:11:34 -0800
[2019-04-03 15:12:09] [config] vocabs:
[2019-04-03 15:12:09] [config]   - corp/vocab.encs.yml
[2019-04-03 15:12:09] [config]   - corp/vocab.encs.yml
[2019-04-03 15:12:09] [config] word-penalty: 0
[2019-04-03 15:12:09] [config] workspace: 8600
[2019-04-03 15:12:09] [config] Loaded model has been created with Marian v1.7.6 9cc5b17 2018-12-14 15:11:34 -0800
[2019-04-03 15:12:09] Using synchronous training
[2019-04-03 15:12:09] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.yml
[2019-04-03 15:12:10] [data] Setting vocabulary size for input 0 to 34028
[2019-04-03 15:12:10] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.yml
[2019-04-03 15:12:10] [data] Setting vocabulary size for input 1 to 34028
[2019-04-03 15:12:10] [sqlite] Creating temporary database in /tmp
[2019-04-03 15:12:14] [sqlite] Inserted 1000000 lines
[2019-04-03 15:12:18] [sqlite] Inserted 2000000 lines
[2019-04-03 15:12:27] [sqlite] Inserted 4000000 lines
[2019-04-03 15:12:44] [sqlite] Inserted 8000000 lines
[2019-04-03 15:13:22] [sqlite] Inserted 16000000 lines
[2019-04-03 15:14:34] [sqlite] Inserted 32000000 lines
[2019-04-03 15:15:56] [sqlite] Inserted 49633032 lines
[2019-04-03 15:15:56] [sqlite] Creating primary index
[2019-04-03 15:18:41] [batching] Collecting statistics for batch fitting with step size 10
[2019-04-03 15:18:42] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-04-03 15:18:46] [memory] Extending reserved space to 8704 MB (device gpu0)
[2019-04-03 15:18:47] [memory] Extending reserved space to 8704 MB (device gpu1)
[2019-04-03 15:18:47] [comm] NCCL communicator overridden
[2019-04-03 15:18:48] [memory] Reserving 805 MB, device gpu0
[2019-04-03 15:18:48] [memory] Reserving 805 MB, device gpu0
[2019-04-03 15:18:59] [batching] Done
[2019-04-03 15:19:00] [memory] Extending reserved space to 8704 MB (device gpu0)
[2019-04-03 15:19:00] [memory] Extending reserved space to 8704 MB (device gpu1)
[2019-04-03 15:19:00] [comm] NCCL communicator overridden
[2019-04-03 15:19:00] Loading model from model/model_bt_encz.npz.orig.npz
[2019-04-03 15:19:12] Loading model from model/model_bt_encz.npz.orig.npz
[2019-04-03 15:19:15] Loading Adam parameters from model/model_bt_encz.npz.optimizer.npz
[2019-04-03 15:19:40] [memory] Reserving 805 MB, device gpu0
[2019-04-03 15:19:40] [memory] Reserving 805 MB, device gpu1
[2019-04-03 15:19:41] [data] Restoring the corpus state to epoch 8, batch 310000
[2019-04-03 15:24:31] [sqlite] Selecting shuffled data
[2019-04-03 15:39:46] Training started
[2019-04-03 15:39:46] Training finished
rm: cannot remove ‘model/model_bt_encz.npz.yml’: No such file or directory
ITERATION 9
[2019-04-03 15:39:50] [marian] Marian v1.7.6 9cc5b17 2018-12-14 15:11:34 -0800
[2019-04-03 15:39:50] [marian] Running on spider3.lingea.cz as process 2869 with command line:
[2019-04-03 15:39:50] [marian] /home/big_maggie/usr/marian_spider/marian_1.7.6/marian-dev/build/marian --model model/model_bt_encz.npz --type transformer --train-sets corpus+paracrawl.2M.en.bpe corpus+paracrawl.2M.cz.bpe -e 9 --max-length 100 --vocabs corp/vocab.encs.yml corp/vocab.encs.yml --mini-batch-fit -w 8600 --mini-batch 1000 --maxi-batch 10000 --valid-freq 5000 --save-freq 5000 --disp-freq 500 --valid-metrics ce-mean-words perplexity translation --valid-sets corp/newstest2016-encs-src.en.bpe corp/newstest2016-encs-ref.cs.bpe --valid-script-path ./val.sh --quiet-translation --beam-size 6 --normalize=0.6 --valid-mini-batch 16 --overwrite --keep-best --optimizer-delay 4 --early-stopping 15 --cost-type=ce-mean-words --log model/bt_encz.log --valid-log model/valid.log --enc-depth 6 --dec-depth 6 --transformer-preprocess n --transformer-postprocess da --tied-embeddings-all --dim-emb 1024 --transformer-dim-ffn 4096 --transformer-heads 16 --transformer-dropout 0.1 --transformer-dropout-attention 0.1 --transformer-dropout-ffn 0.1 --label-smoothing 0.1 --learn-rate 0.0002 --lr-warmup 8000 --lr-decay-inv-sqrt 8000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --devices 0 1 --sync-sgd --seed 0 --no-nccl --exponential-smoothing --sqlite -T /tmp
[2019-04-03 15:39:51] [config] after-batches: 0
[2019-04-03 15:39:51] [config] after-epochs: 9
[2019-04-03 15:39:51] [config] allow-unk: false
[2019-04-03 15:39:51] [config] beam-size: 6
[2019-04-03 15:39:51] [config] best-deep: false
[2019-04-03 15:39:51] [config] clip-gemm: 0
[2019-04-03 15:39:51] [config] clip-norm: 5
[2019-04-03 15:39:51] [config] cost-type: ce-mean-words
[2019-04-03 15:39:51] [config] cpu-threads: 0
[2019-04-03 15:39:51] [config] data-weighting-type: sentence
[2019-04-03 15:39:51] [config] dec-cell: gru
[2019-04-03 15:39:51] [config] dec-cell-base-depth: 2
[2019-04-03 15:39:51] [config] dec-cell-high-depth: 1
[2019-04-03 15:39:51] [config] dec-depth: 6
[2019-04-03 15:39:51] [config] devices:
[2019-04-03 15:39:51] [config]   - 0
[2019-04-03 15:39:51] [config]   - 1
[2019-04-03 15:39:51] [config] dim-emb: 1024
[2019-04-03 15:39:51] [config] dim-rnn: 1024
[2019-04-03 15:39:51] [config] dim-vocabs:
[2019-04-03 15:39:51] [config]   - 34028
[2019-04-03 15:39:51] [config]   - 34028
[2019-04-03 15:39:51] [config] disp-first: 0
[2019-04-03 15:39:51] [config] disp-freq: 500
[2019-04-03 15:39:51] [config] disp-label-counts: false
[2019-04-03 15:39:51] [config] dropout-rnn: 0
[2019-04-03 15:39:51] [config] dropout-src: 0
[2019-04-03 15:39:51] [config] dropout-trg: 0
[2019-04-03 15:39:51] [config] early-stopping: 15
[2019-04-03 15:39:51] [config] embedding-fix-src: false
[2019-04-03 15:39:51] [config] embedding-fix-trg: false
[2019-04-03 15:39:51] [config] embedding-normalization: false
[2019-04-03 15:39:51] [config] enc-cell: gru
[2019-04-03 15:39:51] [config] enc-cell-depth: 1
[2019-04-03 15:39:51] [config] enc-depth: 6
[2019-04-03 15:39:51] [config] enc-type: bidirectional
[2019-04-03 15:39:51] [config] exponential-smoothing: 0.0001
[2019-04-03 15:39:51] [config] grad-dropping-momentum: 0
[2019-04-03 15:39:51] [config] grad-dropping-rate: 0
[2019-04-03 15:39:51] [config] grad-dropping-warmup: 100
[2019-04-03 15:39:51] [config] guided-alignment: none
[2019-04-03 15:39:51] [config] guided-alignment-cost: mse
[2019-04-03 15:39:51] [config] guided-alignment-weight: 0.1
[2019-04-03 15:39:51] [config] ignore-model-config: false
[2019-04-03 15:39:51] [config] interpolate-env-vars: false
[2019-04-03 15:39:51] [config] keep-best: true
[2019-04-03 15:39:51] [config] label-smoothing: 0.1
[2019-04-03 15:39:51] [config] layer-normalization: false
[2019-04-03 15:39:51] [config] learn-rate: 0.0002
[2019-04-03 15:39:51] [config] log: model/bt_encz.log
[2019-04-03 15:39:51] [config] log-level: info
[2019-04-03 15:39:51] [config] lr-decay: 0
[2019-04-03 15:39:51] [config] lr-decay-freq: 50000
[2019-04-03 15:39:51] [config] lr-decay-inv-sqrt: 8000
[2019-04-03 15:39:51] [config] lr-decay-repeat-warmup: false
[2019-04-03 15:39:51] [config] lr-decay-reset-optimizer: false
[2019-04-03 15:39:51] [config] lr-decay-start:
[2019-04-03 15:39:51] [config]   - 10
[2019-04-03 15:39:51] [config]   - 1
[2019-04-03 15:39:51] [config] lr-decay-strategy: epoch+stalled
[2019-04-03 15:39:51] [config] lr-report: true
[2019-04-03 15:39:51] [config] lr-warmup: 8000
[2019-04-03 15:39:51] [config] lr-warmup-at-reload: false
[2019-04-03 15:39:51] [config] lr-warmup-cycle: false
[2019-04-03 15:39:51] [config] lr-warmup-start-rate: 0
[2019-04-03 15:39:51] [config] max-length: 100
[2019-04-03 15:39:51] [config] max-length-crop: false
[2019-04-03 15:39:51] [config] max-length-factor: 3
[2019-04-03 15:39:51] [config] maxi-batch: 10000
[2019-04-03 15:39:51] [config] maxi-batch-sort: trg
[2019-04-03 15:39:51] [config] mini-batch: 1000
[2019-04-03 15:39:51] [config] mini-batch-fit: true
[2019-04-03 15:39:51] [config] mini-batch-fit-step: 10
[2019-04-03 15:39:51] [config] mini-batch-words: 0
[2019-04-03 15:39:51] [config] model: model/model_bt_encz.npz
[2019-04-03 15:39:51] [config] multi-node: false
[2019-04-03 15:39:51] [config] multi-node-overlap: true
[2019-04-03 15:39:51] [config] n-best: false
[2019-04-03 15:39:51] [config] no-nccl: true
[2019-04-03 15:39:51] [config] no-reload: false
[2019-04-03 15:39:51] [config] no-restore-corpus: false
[2019-04-03 15:39:51] [config] no-shuffle: false
[2019-04-03 15:39:51] [config] normalize: 0.6
[2019-04-03 15:39:51] [config] optimizer: adam
[2019-04-03 15:39:51] [config] optimizer-delay: 4
[2019-04-03 15:39:51] [config] optimizer-params:
[2019-04-03 15:39:51] [config]   - 0.9
[2019-04-03 15:39:51] [config]   - 0.98
[2019-04-03 15:39:51] [config]   - 1e-09
[2019-04-03 15:39:51] [config] overwrite: true
[2019-04-03 15:39:51] [config] quiet: false
[2019-04-03 15:39:51] [config] quiet-translation: true
[2019-04-03 15:39:51] [config] relative-paths: false
[2019-04-03 15:39:51] [config] right-left: false
[2019-04-03 15:39:51] [config] save-freq: 5000
[2019-04-03 15:39:51] [config] seed: 0
[2019-04-03 15:39:51] [config] sentencepiece-alphas:
[2019-04-03 15:39:51] [config]   []
[2019-04-03 15:39:51] [config] sentencepiece-max-lines: 10000000
[2019-04-03 15:39:51] [config] sentencepiece-options: ""
[2019-04-03 15:39:51] [config] shuffle-in-ram: false
[2019-04-03 15:39:51] [config] skip: false
[2019-04-03 15:39:51] [config] sqlite: temporary
[2019-04-03 15:39:51] [config] sqlite-drop: false
[2019-04-03 15:39:51] [config] sync-sgd: true
[2019-04-03 15:39:51] [config] tempdir: /tmp
[2019-04-03 15:39:51] [config] tied-embeddings: false
[2019-04-03 15:39:51] [config] tied-embeddings-all: true
[2019-04-03 15:39:51] [config] tied-embeddings-src: false
[2019-04-03 15:39:51] [config] train-sets:
[2019-04-03 15:39:51] [config]   - corpus+paracrawl.2M.en.bpe
[2019-04-03 15:39:51] [config]   - corpus+paracrawl.2M.cz.bpe
[2019-04-03 15:39:51] [config] transformer-aan-activation: swish
[2019-04-03 15:39:51] [config] transformer-aan-depth: 2
[2019-04-03 15:39:51] [config] transformer-aan-nogate: false
[2019-04-03 15:39:51] [config] transformer-decoder-autoreg: self-attention
[2019-04-03 15:39:51] [config] transformer-dim-aan: 2048
[2019-04-03 15:39:51] [config] transformer-dim-ffn: 4096
[2019-04-03 15:39:51] [config] transformer-dropout: 0.1
[2019-04-03 15:39:51] [config] transformer-dropout-attention: 0.1
[2019-04-03 15:39:51] [config] transformer-dropout-ffn: 0.1
[2019-04-03 15:39:51] [config] transformer-ffn-activation: swish
[2019-04-03 15:39:51] [config] transformer-ffn-depth: 2
[2019-04-03 15:39:51] [config] transformer-guided-alignment-layer: last
[2019-04-03 15:39:51] [config] transformer-heads: 16
[2019-04-03 15:39:51] [config] transformer-no-projection: false
[2019-04-03 15:39:51] [config] transformer-postprocess: da
[2019-04-03 15:39:51] [config] transformer-postprocess-emb: d
[2019-04-03 15:39:51] [config] transformer-preprocess: n
[2019-04-03 15:39:51] [config] transformer-tied-layers:
[2019-04-03 15:39:51] [config]   []
[2019-04-03 15:39:51] [config] type: transformer
[2019-04-03 15:39:51] [config] ulr: false
[2019-04-03 15:39:51] [config] ulr-dim-emb: 0
[2019-04-03 15:39:51] [config] ulr-dropout: 0
[2019-04-03 15:39:51] [config] ulr-keys-vectors: ""
[2019-04-03 15:39:51] [config] ulr-query-vectors: ""
[2019-04-03 15:39:51] [config] ulr-softmax-temperature: 1
[2019-04-03 15:39:51] [config] ulr-trainable-transformation: false
[2019-04-03 15:39:51] [config] valid-freq: 5000
[2019-04-03 15:39:51] [config] valid-log: model/valid.log
[2019-04-03 15:39:51] [config] valid-max-length: 1000
[2019-04-03 15:39:51] [config] valid-metrics:
[2019-04-03 15:39:51] [config]   - ce-mean-words
[2019-04-03 15:39:51] [config]   - perplexity
[2019-04-03 15:39:51] [config]   - translation
[2019-04-03 15:39:51] [config] valid-mini-batch: 16
[2019-04-03 15:39:51] [config] valid-script-path: ./val.sh
[2019-04-03 15:39:51] [config] valid-sets:
[2019-04-03 15:39:51] [config]   - corp/newstest2016-encs-src.en.bpe
[2019-04-03 15:39:51] [config]   - corp/newstest2016-encs-ref.cs.bpe
[2019-04-03 15:39:51] [config] version: v1.7.6 9cc5b17 2018-12-14 15:11:34 -0800
[2019-04-03 15:39:51] [config] vocabs:
[2019-04-03 15:39:51] [config]   - corp/vocab.encs.yml
[2019-04-03 15:39:51] [config]   - corp/vocab.encs.yml
[2019-04-03 15:39:51] [config] word-penalty: 0
[2019-04-03 15:39:51] [config] workspace: 8600
[2019-04-03 15:39:51] [config] Loaded model has been created with Marian v1.7.6 9cc5b17 2018-12-14 15:11:34 -0800
[2019-04-03 15:39:51] Using synchronous training
[2019-04-03 15:39:51] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.yml
[2019-04-03 15:39:52] [data] Setting vocabulary size for input 0 to 34028
[2019-04-03 15:39:52] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.yml
[2019-04-03 15:39:52] [data] Setting vocabulary size for input 1 to 34028
[2019-04-03 15:39:52] [sqlite] Creating temporary database in /tmp
[2019-04-03 15:39:56] [sqlite] Inserted 1000000 lines
[2019-04-03 15:39:59] [sqlite] Inserted 2000000 lines
[2019-04-03 15:40:06] [sqlite] Inserted 4000000 lines
[2019-04-03 15:40:21] [sqlite] Inserted 8000000 lines
[2019-04-03 15:40:52] [sqlite] Inserted 16000000 lines
[2019-04-03 15:41:55] [sqlite] Inserted 32000000 lines
[2019-04-03 15:42:36] [sqlite] Inserted 41438108 lines
[2019-04-03 15:42:36] [sqlite] Creating primary index
[2019-04-03 15:43:31] [batching] Collecting statistics for batch fitting with step size 10
[2019-04-03 15:43:31] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-04-03 15:43:35] [memory] Extending reserved space to 8704 MB (device gpu0)
[2019-04-03 15:43:36] [memory] Extending reserved space to 8704 MB (device gpu1)
[2019-04-03 15:43:36] [comm] NCCL communicator overridden
[2019-04-03 15:43:36] [memory] Reserving 805 MB, device gpu0
[2019-04-03 15:43:36] [memory] Reserving 805 MB, device gpu0
[2019-04-03 15:43:48] [batching] Done
[2019-04-03 15:43:48] [memory] Extending reserved space to 8704 MB (device gpu0)
[2019-04-03 15:43:48] [memory] Extending reserved space to 8704 MB (device gpu1)
[2019-04-03 15:43:48] [comm] NCCL communicator overridden
[2019-04-03 15:43:48] Loading model from model/model_bt_encz.npz.orig.npz
[2019-04-03 15:43:57] Loading model from model/model_bt_encz.npz.orig.npz
[2019-04-03 15:43:59] Loading Adam parameters from model/model_bt_encz.npz.optimizer.npz
[2019-04-03 15:44:22] [memory] Reserving 805 MB, device gpu0
[2019-04-03 15:44:22] [memory] Reserving 805 MB, device gpu1
[2019-04-03 15:44:24] [data] Restoring the corpus state to epoch 8, batch 310000
[2019-04-03 15:48:22] [sqlite] Selecting shuffled data
[2019-04-03 16:02:58] Training started
[2019-04-03 16:02:58] Training finished
rm: cannot remove ‘model/model_bt_encz.npz.yml’: No such file or directory
[2019-04-03 16:03:02] [marian] Marian v1.7.6 9cc5b17 2018-12-14 15:11:34 -0800
[2019-04-03 16:03:02] [marian] Running on spider3.lingea.cz as process 3141 with command line:
[2019-04-03 16:03:02] [marian] /home/big_maggie/usr/marian_spider/marian_1.7.6/marian-dev/build/marian --model model/model_bt_encz.npz --type transformer --train-sets bt.encz.en.bpe bt.encz.cz.bpe -e 10 --max-length 100 --vocabs corp/vocab.encs.yml corp/vocab.encs.yml --mini-batch-fit -w 8600 --mini-batch 1000 --maxi-batch 10000 --valid-freq 5000 --save-freq 5000 --disp-freq 500 --optimizer-delay 4 --valid-metrics ce-mean-words perplexity translation --valid-sets corp/newstest2016-encs-src.en.bpe corp/newstest2016-encs-ref.cs.bpe --valid-script-path ./val.sh --quiet-translation --beam-size 6 --normalize=0.6 --valid-mini-batch 16 --overwrite --keep-best --early-stopping 15 --cost-type=ce-mean-words --log model/bt_encz.log --valid-log model/valid.log --enc-depth 6 --dec-depth 6 --transformer-preprocess n --transformer-postprocess da --tied-embeddings-all --dim-emb 1024 --transformer-dim-ffn 4096 --transformer-heads 16 --transformer-dropout 0.1 --transformer-dropout-attention 0.1 --transformer-dropout-ffn 0.1 --label-smoothing 0.1 --learn-rate 0.0002 --lr-warmup 8000 --lr-decay-inv-sqrt 8000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --devices 0 1 --sync-sgd --seed 0 --no-nccl --exponential-smoothing --sqlite -T /tmp
[2019-04-03 16:03:04] [config] after-batches: 0
[2019-04-03 16:03:04] [config] after-epochs: 10
[2019-04-03 16:03:04] [config] allow-unk: false
[2019-04-03 16:03:04] [config] beam-size: 6
[2019-04-03 16:03:04] [config] best-deep: false
[2019-04-03 16:03:04] [config] clip-gemm: 0
[2019-04-03 16:03:04] [config] clip-norm: 5
[2019-04-03 16:03:04] [config] cost-type: ce-mean-words
[2019-04-03 16:03:04] [config] cpu-threads: 0
[2019-04-03 16:03:04] [config] data-weighting-type: sentence
[2019-04-03 16:03:04] [config] dec-cell: gru
[2019-04-03 16:03:04] [config] dec-cell-base-depth: 2
[2019-04-03 16:03:04] [config] dec-cell-high-depth: 1
[2019-04-03 16:03:04] [config] dec-depth: 6
[2019-04-03 16:03:04] [config] devices:
[2019-04-03 16:03:04] [config]   - 0
[2019-04-03 16:03:04] [config]   - 1
[2019-04-03 16:03:04] [config] dim-emb: 1024
[2019-04-03 16:03:04] [config] dim-rnn: 1024
[2019-04-03 16:03:04] [config] dim-vocabs:
[2019-04-03 16:03:04] [config]   - 34028
[2019-04-03 16:03:04] [config]   - 34028
[2019-04-03 16:03:04] [config] disp-first: 0
[2019-04-03 16:03:04] [config] disp-freq: 500
[2019-04-03 16:03:04] [config] disp-label-counts: false
[2019-04-03 16:03:04] [config] dropout-rnn: 0
[2019-04-03 16:03:04] [config] dropout-src: 0
[2019-04-03 16:03:04] [config] dropout-trg: 0
[2019-04-03 16:03:04] [config] early-stopping: 15
[2019-04-03 16:03:04] [config] embedding-fix-src: false
[2019-04-03 16:03:04] [config] embedding-fix-trg: false
[2019-04-03 16:03:04] [config] embedding-normalization: false
[2019-04-03 16:03:04] [config] enc-cell: gru
[2019-04-03 16:03:04] [config] enc-cell-depth: 1
[2019-04-03 16:03:04] [config] enc-depth: 6
[2019-04-03 16:03:04] [config] enc-type: bidirectional
[2019-04-03 16:03:04] [config] exponential-smoothing: 0.0001
[2019-04-03 16:03:04] [config] grad-dropping-momentum: 0
[2019-04-03 16:03:04] [config] grad-dropping-rate: 0
[2019-04-03 16:03:04] [config] grad-dropping-warmup: 100
[2019-04-03 16:03:04] [config] guided-alignment: none
[2019-04-03 16:03:04] [config] guided-alignment-cost: mse
[2019-04-03 16:03:04] [config] guided-alignment-weight: 0.1
[2019-04-03 16:03:04] [config] ignore-model-config: false
[2019-04-03 16:03:04] [config] interpolate-env-vars: false
[2019-04-03 16:03:04] [config] keep-best: true
[2019-04-03 16:03:04] [config] label-smoothing: 0.1
[2019-04-03 16:03:04] [config] layer-normalization: false
[2019-04-03 16:03:04] [config] learn-rate: 0.0002
[2019-04-03 16:03:04] [config] log: model/bt_encz.log
[2019-04-03 16:03:04] [config] log-level: info
[2019-04-03 16:03:04] [config] lr-decay: 0
[2019-04-03 16:03:04] [config] lr-decay-freq: 50000
[2019-04-03 16:03:04] [config] lr-decay-inv-sqrt: 8000
[2019-04-03 16:03:04] [config] lr-decay-repeat-warmup: false
[2019-04-03 16:03:04] [config] lr-decay-reset-optimizer: false
[2019-04-03 16:03:04] [config] lr-decay-start:
[2019-04-03 16:03:04] [config]   - 10
[2019-04-03 16:03:04] [config]   - 1
[2019-04-03 16:03:04] [config] lr-decay-strategy: epoch+stalled
[2019-04-03 16:03:04] [config] lr-report: true
[2019-04-03 16:03:04] [config] lr-warmup: 8000
[2019-04-03 16:03:04] [config] lr-warmup-at-reload: false
[2019-04-03 16:03:04] [config] lr-warmup-cycle: false
[2019-04-03 16:03:04] [config] lr-warmup-start-rate: 0
[2019-04-03 16:03:04] [config] max-length: 100
[2019-04-03 16:03:04] [config] max-length-crop: false
[2019-04-03 16:03:04] [config] max-length-factor: 3
[2019-04-03 16:03:04] [config] maxi-batch: 10000
[2019-04-03 16:03:04] [config] maxi-batch-sort: trg
[2019-04-03 16:03:04] [config] mini-batch: 1000
[2019-04-03 16:03:04] [config] mini-batch-fit: true
[2019-04-03 16:03:04] [config] mini-batch-fit-step: 10
[2019-04-03 16:03:04] [config] mini-batch-words: 0
[2019-04-03 16:03:04] [config] model: model/model_bt_encz.npz
[2019-04-03 16:03:04] [config] multi-node: false
[2019-04-03 16:03:04] [config] multi-node-overlap: true
[2019-04-03 16:03:04] [config] n-best: false
[2019-04-03 16:03:04] [config] no-nccl: true
[2019-04-03 16:03:04] [config] no-reload: false
[2019-04-03 16:03:04] [config] no-restore-corpus: false
[2019-04-03 16:03:04] [config] no-shuffle: false
[2019-04-03 16:03:04] [config] normalize: 0.6
[2019-04-03 16:03:04] [config] optimizer: adam
[2019-04-03 16:03:04] [config] optimizer-delay: 4
[2019-04-03 16:03:04] [config] optimizer-params:
[2019-04-03 16:03:04] [config]   - 0.9
[2019-04-03 16:03:04] [config]   - 0.98
[2019-04-03 16:03:04] [config]   - 1e-09
[2019-04-03 16:03:04] [config] overwrite: true
[2019-04-03 16:03:04] [config] quiet: false
[2019-04-03 16:03:04] [config] quiet-translation: true
[2019-04-03 16:03:04] [config] relative-paths: false
[2019-04-03 16:03:04] [config] right-left: false
[2019-04-03 16:03:04] [config] save-freq: 5000
[2019-04-03 16:03:04] [config] seed: 0
[2019-04-03 16:03:04] [config] sentencepiece-alphas:
[2019-04-03 16:03:04] [config]   []
[2019-04-03 16:03:04] [config] sentencepiece-max-lines: 10000000
[2019-04-03 16:03:04] [config] sentencepiece-options: ""
[2019-04-03 16:03:04] [config] shuffle-in-ram: false
[2019-04-03 16:03:04] [config] skip: false
[2019-04-03 16:03:04] [config] sqlite: temporary
[2019-04-03 16:03:04] [config] sqlite-drop: false
[2019-04-03 16:03:04] [config] sync-sgd: true
[2019-04-03 16:03:04] [config] tempdir: /tmp
[2019-04-03 16:03:04] [config] tied-embeddings: false
[2019-04-03 16:03:04] [config] tied-embeddings-all: true
[2019-04-03 16:03:04] [config] tied-embeddings-src: false
[2019-04-03 16:03:04] [config] train-sets:
[2019-04-03 16:03:04] [config]   - bt.encz.en.bpe
[2019-04-03 16:03:04] [config]   - bt.encz.cz.bpe
[2019-04-03 16:03:04] [config] transformer-aan-activation: swish
[2019-04-03 16:03:04] [config] transformer-aan-depth: 2
[2019-04-03 16:03:04] [config] transformer-aan-nogate: false
[2019-04-03 16:03:04] [config] transformer-decoder-autoreg: self-attention
[2019-04-03 16:03:04] [config] transformer-dim-aan: 2048
[2019-04-03 16:03:04] [config] transformer-dim-ffn: 4096
[2019-04-03 16:03:04] [config] transformer-dropout: 0.1
[2019-04-03 16:03:04] [config] transformer-dropout-attention: 0.1
[2019-04-03 16:03:04] [config] transformer-dropout-ffn: 0.1
[2019-04-03 16:03:04] [config] transformer-ffn-activation: swish
[2019-04-03 16:03:04] [config] transformer-ffn-depth: 2
[2019-04-03 16:03:04] [config] transformer-guided-alignment-layer: last
[2019-04-03 16:03:04] [config] transformer-heads: 16
[2019-04-03 16:03:04] [config] transformer-no-projection: false
[2019-04-03 16:03:04] [config] transformer-postprocess: da
[2019-04-03 16:03:04] [config] transformer-postprocess-emb: d
[2019-04-03 16:03:04] [config] transformer-preprocess: n
[2019-04-03 16:03:04] [config] transformer-tied-layers:
[2019-04-03 16:03:04] [config]   []
[2019-04-03 16:03:04] [config] type: transformer
[2019-04-03 16:03:04] [config] ulr: false
[2019-04-03 16:03:04] [config] ulr-dim-emb: 0
[2019-04-03 16:03:04] [config] ulr-dropout: 0
[2019-04-03 16:03:04] [config] ulr-keys-vectors: ""
[2019-04-03 16:03:04] [config] ulr-query-vectors: ""
[2019-04-03 16:03:04] [config] ulr-softmax-temperature: 1
[2019-04-03 16:03:04] [config] ulr-trainable-transformation: false
[2019-04-03 16:03:04] [config] valid-freq: 5000
[2019-04-03 16:03:04] [config] valid-log: model/valid.log
[2019-04-03 16:03:04] [config] valid-max-length: 1000
[2019-04-03 16:03:04] [config] valid-metrics:
[2019-04-03 16:03:04] [config]   - ce-mean-words
[2019-04-03 16:03:04] [config]   - perplexity
[2019-04-03 16:03:04] [config]   - translation
[2019-04-03 16:03:04] [config] valid-mini-batch: 16
[2019-04-03 16:03:04] [config] valid-script-path: ./val.sh
[2019-04-03 16:03:04] [config] valid-sets:
[2019-04-03 16:03:04] [config]   - corp/newstest2016-encs-src.en.bpe
[2019-04-03 16:03:04] [config]   - corp/newstest2016-encs-ref.cs.bpe
[2019-04-03 16:03:04] [config] version: v1.7.6 9cc5b17 2018-12-14 15:11:34 -0800
[2019-04-03 16:03:04] [config] vocabs:
[2019-04-03 16:03:04] [config]   - corp/vocab.encs.yml
[2019-04-03 16:03:04] [config]   - corp/vocab.encs.yml
[2019-04-03 16:03:04] [config] word-penalty: 0
[2019-04-03 16:03:04] [config] workspace: 8600
[2019-04-03 16:03:04] [config] Loaded model has been created with Marian v1.7.6 9cc5b17 2018-12-14 15:11:34 -0800
[2019-04-03 16:03:04] Using synchronous training
[2019-04-03 16:03:04] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.yml
[2019-04-03 16:03:04] [data] Setting vocabulary size for input 0 to 34028
[2019-04-03 16:03:04] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.yml
[2019-04-03 16:03:04] [data] Setting vocabulary size for input 1 to 34028
[2019-04-03 16:03:04] [sqlite] Creating temporary database in /tmp
[2019-04-03 16:03:08] [sqlite] Inserted 1000000 lines
[2019-04-03 16:03:12] [sqlite] Inserted 2000000 lines
[2019-04-03 16:03:21] [sqlite] Inserted 4000000 lines
[2019-04-03 16:03:39] [sqlite] Inserted 8000000 lines
[2019-04-03 16:04:14] [sqlite] Inserted 16000000 lines
[2019-04-03 16:05:29] [sqlite] Inserted 32000000 lines
[2019-04-03 16:06:50] [sqlite] Inserted 49633032 lines
[2019-04-03 16:06:50] [sqlite] Creating primary index
[2019-04-03 16:09:32] [batching] Collecting statistics for batch fitting with step size 10
[2019-04-03 16:09:32] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-04-03 16:09:37] [memory] Extending reserved space to 8704 MB (device gpu0)
[2019-04-03 16:09:38] [memory] Extending reserved space to 8704 MB (device gpu1)
[2019-04-03 16:09:38] [comm] NCCL communicator overridden
[2019-04-03 16:09:38] [memory] Reserving 805 MB, device gpu0
[2019-04-03 16:09:39] [memory] Reserving 805 MB, device gpu0
[2019-04-03 16:09:50] [batching] Done
[2019-04-03 16:09:50] [memory] Extending reserved space to 8704 MB (device gpu0)
[2019-04-03 16:09:51] [memory] Extending reserved space to 8704 MB (device gpu1)
[2019-04-03 16:09:51] [comm] NCCL communicator overridden
[2019-04-03 16:09:51] Loading model from model/model_bt_encz.npz.orig.npz
[2019-04-03 16:10:02] Loading model from model/model_bt_encz.npz.orig.npz
[2019-04-03 16:10:06] Loading Adam parameters from model/model_bt_encz.npz.optimizer.npz
[2019-04-03 16:10:30] [memory] Reserving 805 MB, device gpu0
[2019-04-03 16:10:31] [memory] Reserving 805 MB, device gpu1
[2019-04-03 16:10:32] [data] Restoring the corpus state to epoch 8, batch 310000
[2019-04-03 16:15:22] [sqlite] Selecting shuffled data
[2019-04-03 16:30:41] Training started
[2019-04-03 16:30:41] Training finished
rm: cannot remove ‘model/model_bt_encz.npz.yml’: No such file or directory
ITERATION 10
[2019-04-03 16:30:46] [marian] Marian v1.7.6 9cc5b17 2018-12-14 15:11:34 -0800
[2019-04-03 16:30:46] [marian] Running on spider3.lingea.cz as process 3439 with command line:
[2019-04-03 16:30:46] [marian] /home/big_maggie/usr/marian_spider/marian_1.7.6/marian-dev/build/marian --model model/model_bt_encz.npz --type transformer --train-sets corpus+paracrawl.2M.en.bpe corpus+paracrawl.2M.cz.bpe -e 10 --max-length 100 --vocabs corp/vocab.encs.yml corp/vocab.encs.yml --mini-batch-fit -w 8600 --mini-batch 1000 --maxi-batch 10000 --valid-freq 5000 --save-freq 5000 --disp-freq 500 --valid-metrics ce-mean-words perplexity translation --valid-sets corp/newstest2016-encs-src.en.bpe corp/newstest2016-encs-ref.cs.bpe --valid-script-path ./val.sh --quiet-translation --beam-size 6 --normalize=0.6 --valid-mini-batch 16 --overwrite --keep-best --optimizer-delay 4 --early-stopping 15 --cost-type=ce-mean-words --log model/bt_encz.log --valid-log model/valid.log --enc-depth 6 --dec-depth 6 --transformer-preprocess n --transformer-postprocess da --tied-embeddings-all --dim-emb 1024 --transformer-dim-ffn 4096 --transformer-heads 16 --transformer-dropout 0.1 --transformer-dropout-attention 0.1 --transformer-dropout-ffn 0.1 --label-smoothing 0.1 --learn-rate 0.0002 --lr-warmup 8000 --lr-decay-inv-sqrt 8000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --devices 0 1 --sync-sgd --seed 0 --no-nccl --exponential-smoothing --sqlite -T /tmp
[2019-04-03 16:30:47] [config] after-batches: 0
[2019-04-03 16:30:47] [config] after-epochs: 10
[2019-04-03 16:30:47] [config] allow-unk: false
[2019-04-03 16:30:47] [config] beam-size: 6
[2019-04-03 16:30:47] [config] best-deep: false
[2019-04-03 16:30:47] [config] clip-gemm: 0
[2019-04-03 16:30:47] [config] clip-norm: 5
[2019-04-03 16:30:47] [config] cost-type: ce-mean-words
[2019-04-03 16:30:47] [config] cpu-threads: 0
[2019-04-03 16:30:47] [config] data-weighting-type: sentence
[2019-04-03 16:30:47] [config] dec-cell: gru
[2019-04-03 16:30:47] [config] dec-cell-base-depth: 2
[2019-04-03 16:30:47] [config] dec-cell-high-depth: 1
[2019-04-03 16:30:47] [config] dec-depth: 6
[2019-04-03 16:30:47] [config] devices:
[2019-04-03 16:30:47] [config]   - 0
[2019-04-03 16:30:47] [config]   - 1
[2019-04-03 16:30:47] [config] dim-emb: 1024
[2019-04-03 16:30:47] [config] dim-rnn: 1024
[2019-04-03 16:30:47] [config] dim-vocabs:
[2019-04-03 16:30:47] [config]   - 34028
[2019-04-03 16:30:47] [config]   - 34028
[2019-04-03 16:30:47] [config] disp-first: 0
[2019-04-03 16:30:47] [config] disp-freq: 500
[2019-04-03 16:30:47] [config] disp-label-counts: false
[2019-04-03 16:30:47] [config] dropout-rnn: 0
[2019-04-03 16:30:47] [config] dropout-src: 0
[2019-04-03 16:30:47] [config] dropout-trg: 0
[2019-04-03 16:30:47] [config] early-stopping: 15
[2019-04-03 16:30:47] [config] embedding-fix-src: false
[2019-04-03 16:30:47] [config] embedding-fix-trg: false
[2019-04-03 16:30:47] [config] embedding-normalization: false
[2019-04-03 16:30:47] [config] enc-cell: gru
[2019-04-03 16:30:47] [config] enc-cell-depth: 1
[2019-04-03 16:30:47] [config] enc-depth: 6
[2019-04-03 16:30:47] [config] enc-type: bidirectional
[2019-04-03 16:30:47] [config] exponential-smoothing: 0.0001
[2019-04-03 16:30:47] [config] grad-dropping-momentum: 0
[2019-04-03 16:30:47] [config] grad-dropping-rate: 0
[2019-04-03 16:30:47] [config] grad-dropping-warmup: 100
[2019-04-03 16:30:47] [config] guided-alignment: none
[2019-04-03 16:30:47] [config] guided-alignment-cost: mse
[2019-04-03 16:30:47] [config] guided-alignment-weight: 0.1
[2019-04-03 16:30:47] [config] ignore-model-config: false
[2019-04-03 16:30:47] [config] interpolate-env-vars: false
[2019-04-03 16:30:47] [config] keep-best: true
[2019-04-03 16:30:47] [config] label-smoothing: 0.1
[2019-04-03 16:30:47] [config] layer-normalization: false
[2019-04-03 16:30:47] [config] learn-rate: 0.0002
[2019-04-03 16:30:47] [config] log: model/bt_encz.log
[2019-04-03 16:30:47] [config] log-level: info
[2019-04-03 16:30:47] [config] lr-decay: 0
[2019-04-03 16:30:47] [config] lr-decay-freq: 50000
[2019-04-03 16:30:47] [config] lr-decay-inv-sqrt: 8000
[2019-04-03 16:30:47] [config] lr-decay-repeat-warmup: false
[2019-04-03 16:30:47] [config] lr-decay-reset-optimizer: false
[2019-04-03 16:30:47] [config] lr-decay-start:
[2019-04-03 16:30:47] [config]   - 10
[2019-04-03 16:30:47] [config]   - 1
[2019-04-03 16:30:47] [config] lr-decay-strategy: epoch+stalled
[2019-04-03 16:30:47] [config] lr-report: true
[2019-04-03 16:30:47] [config] lr-warmup: 8000
[2019-04-03 16:30:47] [config] lr-warmup-at-reload: false
[2019-04-03 16:30:47] [config] lr-warmup-cycle: false
[2019-04-03 16:30:47] [config] lr-warmup-start-rate: 0
[2019-04-03 16:30:47] [config] max-length: 100
[2019-04-03 16:30:47] [config] max-length-crop: false
[2019-04-03 16:30:47] [config] max-length-factor: 3
[2019-04-03 16:30:47] [config] maxi-batch: 10000
[2019-04-03 16:30:47] [config] maxi-batch-sort: trg
[2019-04-03 16:30:47] [config] mini-batch: 1000
[2019-04-03 16:30:47] [config] mini-batch-fit: true
[2019-04-03 16:30:47] [config] mini-batch-fit-step: 10
[2019-04-03 16:30:47] [config] mini-batch-words: 0
[2019-04-03 16:30:47] [config] model: model/model_bt_encz.npz
[2019-04-03 16:30:47] [config] multi-node: false
[2019-04-03 16:30:47] [config] multi-node-overlap: true
[2019-04-03 16:30:47] [config] n-best: false
[2019-04-03 16:30:47] [config] no-nccl: true
[2019-04-03 16:30:47] [config] no-reload: false
[2019-04-03 16:30:47] [config] no-restore-corpus: false
[2019-04-03 16:30:47] [config] no-shuffle: false
[2019-04-03 16:30:47] [config] normalize: 0.6
[2019-04-03 16:30:47] [config] optimizer: adam
[2019-04-03 16:30:47] [config] optimizer-delay: 4
[2019-04-03 16:30:47] [config] optimizer-params:
[2019-04-03 16:30:47] [config]   - 0.9
[2019-04-03 16:30:47] [config]   - 0.98
[2019-04-03 16:30:47] [config]   - 1e-09
[2019-04-03 16:30:47] [config] overwrite: true
[2019-04-03 16:30:47] [config] quiet: false
[2019-04-03 16:30:47] [config] quiet-translation: true
[2019-04-03 16:30:47] [config] relative-paths: false
[2019-04-03 16:30:47] [config] right-left: false
[2019-04-03 16:30:47] [config] save-freq: 5000
[2019-04-03 16:30:47] [config] seed: 0
[2019-04-03 16:30:47] [config] sentencepiece-alphas:
[2019-04-03 16:30:47] [config]   []
[2019-04-03 16:30:47] [config] sentencepiece-max-lines: 10000000
[2019-04-03 16:30:47] [config] sentencepiece-options: ""
[2019-04-03 16:30:47] [config] shuffle-in-ram: false
[2019-04-03 16:30:47] [config] skip: false
[2019-04-03 16:30:47] [config] sqlite: temporary
[2019-04-03 16:30:47] [config] sqlite-drop: false
[2019-04-03 16:30:47] [config] sync-sgd: true
[2019-04-03 16:30:47] [config] tempdir: /tmp
[2019-04-03 16:30:47] [config] tied-embeddings: false
[2019-04-03 16:30:47] [config] tied-embeddings-all: true
[2019-04-03 16:30:47] [config] tied-embeddings-src: false
[2019-04-03 16:30:47] [config] train-sets:
[2019-04-03 16:30:47] [config]   - corpus+paracrawl.2M.en.bpe
[2019-04-03 16:30:47] [config]   - corpus+paracrawl.2M.cz.bpe
[2019-04-03 16:30:47] [config] transformer-aan-activation: swish
[2019-04-03 16:30:47] [config] transformer-aan-depth: 2
[2019-04-03 16:30:47] [config] transformer-aan-nogate: false
[2019-04-03 16:30:47] [config] transformer-decoder-autoreg: self-attention
[2019-04-03 16:30:47] [config] transformer-dim-aan: 2048
[2019-04-03 16:30:47] [config] transformer-dim-ffn: 4096
[2019-04-03 16:30:47] [config] transformer-dropout: 0.1
[2019-04-03 16:30:47] [config] transformer-dropout-attention: 0.1
[2019-04-03 16:30:47] [config] transformer-dropout-ffn: 0.1
[2019-04-03 16:30:47] [config] transformer-ffn-activation: swish
[2019-04-03 16:30:47] [config] transformer-ffn-depth: 2
[2019-04-03 16:30:47] [config] transformer-guided-alignment-layer: last
[2019-04-03 16:30:47] [config] transformer-heads: 16
[2019-04-03 16:30:47] [config] transformer-no-projection: false
[2019-04-03 16:30:47] [config] transformer-postprocess: da
[2019-04-03 16:30:47] [config] transformer-postprocess-emb: d
[2019-04-03 16:30:47] [config] transformer-preprocess: n
[2019-04-03 16:30:47] [config] transformer-tied-layers:
[2019-04-03 16:30:47] [config]   []
[2019-04-03 16:30:47] [config] type: transformer
[2019-04-03 16:30:47] [config] ulr: false
[2019-04-03 16:30:47] [config] ulr-dim-emb: 0
[2019-04-03 16:30:47] [config] ulr-dropout: 0
[2019-04-03 16:30:47] [config] ulr-keys-vectors: ""
[2019-04-03 16:30:47] [config] ulr-query-vectors: ""
[2019-04-03 16:30:47] [config] ulr-softmax-temperature: 1
[2019-04-03 16:30:47] [config] ulr-trainable-transformation: false
[2019-04-03 16:30:47] [config] valid-freq: 5000
[2019-04-03 16:30:47] [config] valid-log: model/valid.log
[2019-04-03 16:30:47] [config] valid-max-length: 1000
[2019-04-03 16:30:47] [config] valid-metrics:
[2019-04-03 16:30:47] [config]   - ce-mean-words
[2019-04-03 16:30:47] [config]   - perplexity
[2019-04-03 16:30:47] [config]   - translation
[2019-04-03 16:30:47] [config] valid-mini-batch: 16
[2019-04-03 16:30:47] [config] valid-script-path: ./val.sh
[2019-04-03 16:30:47] [config] valid-sets:
[2019-04-03 16:30:47] [config]   - corp/newstest2016-encs-src.en.bpe
[2019-04-03 16:30:47] [config]   - corp/newstest2016-encs-ref.cs.bpe
[2019-04-03 16:30:47] [config] version: v1.7.6 9cc5b17 2018-12-14 15:11:34 -0800
[2019-04-03 16:30:47] [config] vocabs:
[2019-04-03 16:30:47] [config]   - corp/vocab.encs.yml
[2019-04-03 16:30:47] [config]   - corp/vocab.encs.yml
[2019-04-03 16:30:47] [config] word-penalty: 0
[2019-04-03 16:30:47] [config] workspace: 8600
[2019-04-03 16:30:47] [config] Loaded model has been created with Marian v1.7.6 9cc5b17 2018-12-14 15:11:34 -0800
[2019-04-03 16:30:47] Using synchronous training
[2019-04-03 16:30:47] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.yml
[2019-04-03 16:30:47] [data] Setting vocabulary size for input 0 to 34028
[2019-04-03 16:30:47] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.yml
[2019-04-03 16:30:48] [data] Setting vocabulary size for input 1 to 34028
[2019-04-03 16:30:48] [sqlite] Creating temporary database in /tmp
[2019-04-03 16:30:51] [sqlite] Inserted 1000000 lines
[2019-04-03 16:30:54] [sqlite] Inserted 2000000 lines
[2019-04-03 16:31:00] [sqlite] Inserted 4000000 lines
[2019-04-03 16:31:14] [sqlite] Inserted 8000000 lines
[2019-04-03 16:31:46] [sqlite] Inserted 16000000 lines
[2019-04-03 16:32:49] [sqlite] Inserted 32000000 lines
[2019-04-03 16:33:26] [sqlite] Inserted 41438108 lines
[2019-04-03 16:33:26] [sqlite] Creating primary index
[2019-04-03 16:34:21] [batching] Collecting statistics for batch fitting with step size 10
[2019-04-03 16:34:21] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-04-03 16:34:25] [memory] Extending reserved space to 8704 MB (device gpu0)
[2019-04-03 16:34:27] [memory] Extending reserved space to 8704 MB (device gpu1)
[2019-04-03 16:34:27] [comm] NCCL communicator overridden
[2019-04-03 16:34:27] [memory] Reserving 805 MB, device gpu0
[2019-04-03 16:34:28] [memory] Reserving 805 MB, device gpu0
[2019-04-03 16:34:39] [batching] Done
[2019-04-03 16:34:39] [memory] Extending reserved space to 8704 MB (device gpu0)
[2019-04-03 16:34:39] [memory] Extending reserved space to 8704 MB (device gpu1)
[2019-04-03 16:34:40] [comm] NCCL communicator overridden
[2019-04-03 16:34:40] Loading model from model/model_bt_encz.npz.orig.npz
[2019-04-03 16:34:48] Loading model from model/model_bt_encz.npz.orig.npz
[2019-04-03 16:34:50] Loading Adam parameters from model/model_bt_encz.npz.optimizer.npz
[2019-04-03 16:35:14] [memory] Reserving 805 MB, device gpu0
[2019-04-03 16:35:14] [memory] Reserving 805 MB, device gpu1
[2019-04-03 16:35:16] [data] Restoring the corpus state to epoch 8, batch 310000
[2019-04-03 16:39:12] [sqlite] Selecting shuffled data
[2019-04-03 16:53:56] Training started
[2019-04-03 16:53:56] Training finished
rm: cannot remove ‘model/model_bt_encz.npz.yml’: No such file or directory
[2019-04-03 16:54:01] [marian] Marian v1.7.6 9cc5b17 2018-12-14 15:11:34 -0800
[2019-04-03 16:54:01] [marian] Running on spider3.lingea.cz as process 3674 with command line:
[2019-04-03 16:54:01] [marian] /home/big_maggie/usr/marian_spider/marian_1.7.6/marian-dev/build/marian --model model/model_bt_encz.npz --type transformer --train-sets bt.encz.en.bpe bt.encz.cz.bpe -e 11 --max-length 100 --vocabs corp/vocab.encs.yml corp/vocab.encs.yml --mini-batch-fit -w 8600 --mini-batch 1000 --maxi-batch 10000 --valid-freq 5000 --save-freq 5000 --disp-freq 500 --optimizer-delay 4 --valid-metrics ce-mean-words perplexity translation --valid-sets corp/newstest2016-encs-src.en.bpe corp/newstest2016-encs-ref.cs.bpe --valid-script-path ./val.sh --quiet-translation --beam-size 6 --normalize=0.6 --valid-mini-batch 16 --overwrite --keep-best --early-stopping 15 --cost-type=ce-mean-words --log model/bt_encz.log --valid-log model/valid.log --enc-depth 6 --dec-depth 6 --transformer-preprocess n --transformer-postprocess da --tied-embeddings-all --dim-emb 1024 --transformer-dim-ffn 4096 --transformer-heads 16 --transformer-dropout 0.1 --transformer-dropout-attention 0.1 --transformer-dropout-ffn 0.1 --label-smoothing 0.1 --learn-rate 0.0002 --lr-warmup 8000 --lr-decay-inv-sqrt 8000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --devices 0 1 --sync-sgd --seed 0 --no-nccl --exponential-smoothing --sqlite -T /tmp
[2019-04-03 16:54:02] [config] after-batches: 0
[2019-04-03 16:54:02] [config] after-epochs: 11
[2019-04-03 16:54:02] [config] allow-unk: false
[2019-04-03 16:54:02] [config] beam-size: 6
[2019-04-03 16:54:02] [config] best-deep: false
[2019-04-03 16:54:02] [config] clip-gemm: 0
[2019-04-03 16:54:02] [config] clip-norm: 5
[2019-04-03 16:54:02] [config] cost-type: ce-mean-words
[2019-04-03 16:54:02] [config] cpu-threads: 0
[2019-04-03 16:54:02] [config] data-weighting-type: sentence
[2019-04-03 16:54:02] [config] dec-cell: gru
[2019-04-03 16:54:02] [config] dec-cell-base-depth: 2
[2019-04-03 16:54:02] [config] dec-cell-high-depth: 1
[2019-04-03 16:54:02] [config] dec-depth: 6
[2019-04-03 16:54:02] [config] devices:
[2019-04-03 16:54:02] [config]   - 0
[2019-04-03 16:54:02] [config]   - 1
[2019-04-03 16:54:02] [config] dim-emb: 1024
[2019-04-03 16:54:02] [config] dim-rnn: 1024
[2019-04-03 16:54:02] [config] dim-vocabs:
[2019-04-03 16:54:02] [config]   - 34028
[2019-04-03 16:54:02] [config]   - 34028
[2019-04-03 16:54:02] [config] disp-first: 0
[2019-04-03 16:54:02] [config] disp-freq: 500
[2019-04-03 16:54:02] [config] disp-label-counts: false
[2019-04-03 16:54:02] [config] dropout-rnn: 0
[2019-04-03 16:54:02] [config] dropout-src: 0
[2019-04-03 16:54:02] [config] dropout-trg: 0
[2019-04-03 16:54:02] [config] early-stopping: 15
[2019-04-03 16:54:02] [config] embedding-fix-src: false
[2019-04-03 16:54:02] [config] embedding-fix-trg: false
[2019-04-03 16:54:02] [config] embedding-normalization: false
[2019-04-03 16:54:02] [config] enc-cell: gru
[2019-04-03 16:54:02] [config] enc-cell-depth: 1
[2019-04-03 16:54:02] [config] enc-depth: 6
[2019-04-03 16:54:02] [config] enc-type: bidirectional
[2019-04-03 16:54:02] [config] exponential-smoothing: 0.0001
[2019-04-03 16:54:02] [config] grad-dropping-momentum: 0
[2019-04-03 16:54:02] [config] grad-dropping-rate: 0
[2019-04-03 16:54:02] [config] grad-dropping-warmup: 100
[2019-04-03 16:54:02] [config] guided-alignment: none
[2019-04-03 16:54:02] [config] guided-alignment-cost: mse
[2019-04-03 16:54:02] [config] guided-alignment-weight: 0.1
[2019-04-03 16:54:02] [config] ignore-model-config: false
[2019-04-03 16:54:02] [config] interpolate-env-vars: false
[2019-04-03 16:54:02] [config] keep-best: true
[2019-04-03 16:54:02] [config] label-smoothing: 0.1
[2019-04-03 16:54:02] [config] layer-normalization: false
[2019-04-03 16:54:02] [config] learn-rate: 0.0002
[2019-04-03 16:54:02] [config] log: model/bt_encz.log
[2019-04-03 16:54:02] [config] log-level: info
[2019-04-03 16:54:02] [config] lr-decay: 0
[2019-04-03 16:54:02] [config] lr-decay-freq: 50000
[2019-04-03 16:54:02] [config] lr-decay-inv-sqrt: 8000
[2019-04-03 16:54:02] [config] lr-decay-repeat-warmup: false
[2019-04-03 16:54:02] [config] lr-decay-reset-optimizer: false
[2019-04-03 16:54:02] [config] lr-decay-start:
[2019-04-03 16:54:02] [config]   - 10
[2019-04-03 16:54:02] [config]   - 1
[2019-04-03 16:54:02] [config] lr-decay-strategy: epoch+stalled
[2019-04-03 16:54:02] [config] lr-report: true
[2019-04-03 16:54:02] [config] lr-warmup: 8000
[2019-04-03 16:54:02] [config] lr-warmup-at-reload: false
[2019-04-03 16:54:02] [config] lr-warmup-cycle: false
[2019-04-03 16:54:02] [config] lr-warmup-start-rate: 0
[2019-04-03 16:54:02] [config] max-length: 100
[2019-04-03 16:54:02] [config] max-length-crop: false
[2019-04-03 16:54:02] [config] max-length-factor: 3
[2019-04-03 16:54:02] [config] maxi-batch: 10000
[2019-04-03 16:54:02] [config] maxi-batch-sort: trg
[2019-04-03 16:54:02] [config] mini-batch: 1000
[2019-04-03 16:54:02] [config] mini-batch-fit: true
[2019-04-03 16:54:02] [config] mini-batch-fit-step: 10
[2019-04-03 16:54:02] [config] mini-batch-words: 0
[2019-04-03 16:54:02] [config] model: model/model_bt_encz.npz
[2019-04-03 16:54:02] [config] multi-node: false
[2019-04-03 16:54:02] [config] multi-node-overlap: true
[2019-04-03 16:54:02] [config] n-best: false
[2019-04-03 16:54:02] [config] no-nccl: true
[2019-04-03 16:54:02] [config] no-reload: false
[2019-04-03 16:54:02] [config] no-restore-corpus: false
[2019-04-03 16:54:02] [config] no-shuffle: false
[2019-04-03 16:54:02] [config] normalize: 0.6
[2019-04-03 16:54:02] [config] optimizer: adam
[2019-04-03 16:54:02] [config] optimizer-delay: 4
[2019-04-03 16:54:02] [config] optimizer-params:
[2019-04-03 16:54:02] [config]   - 0.9
[2019-04-03 16:54:02] [config]   - 0.98
[2019-04-03 16:54:02] [config]   - 1e-09
[2019-04-03 16:54:02] [config] overwrite: true
[2019-04-03 16:54:02] [config] quiet: false
[2019-04-03 16:54:02] [config] quiet-translation: true
[2019-04-03 16:54:02] [config] relative-paths: false
[2019-04-03 16:54:02] [config] right-left: false
[2019-04-03 16:54:02] [config] save-freq: 5000
[2019-04-03 16:54:02] [config] seed: 0
[2019-04-03 16:54:02] [config] sentencepiece-alphas:
[2019-04-03 16:54:02] [config]   []
[2019-04-03 16:54:02] [config] sentencepiece-max-lines: 10000000
[2019-04-03 16:54:02] [config] sentencepiece-options: ""
[2019-04-03 16:54:02] [config] shuffle-in-ram: false
[2019-04-03 16:54:02] [config] skip: false
[2019-04-03 16:54:02] [config] sqlite: temporary
[2019-04-03 16:54:02] [config] sqlite-drop: false
[2019-04-03 16:54:02] [config] sync-sgd: true
[2019-04-03 16:54:02] [config] tempdir: /tmp
[2019-04-03 16:54:02] [config] tied-embeddings: false
[2019-04-03 16:54:02] [config] tied-embeddings-all: true
[2019-04-03 16:54:02] [config] tied-embeddings-src: false
[2019-04-03 16:54:02] [config] train-sets:
[2019-04-03 16:54:02] [config]   - bt.encz.en.bpe
[2019-04-03 16:54:02] [config]   - bt.encz.cz.bpe
[2019-04-03 16:54:02] [config] transformer-aan-activation: swish
[2019-04-03 16:54:02] [config] transformer-aan-depth: 2
[2019-04-03 16:54:02] [config] transformer-aan-nogate: false
[2019-04-03 16:54:02] [config] transformer-decoder-autoreg: self-attention
[2019-04-03 16:54:02] [config] transformer-dim-aan: 2048
[2019-04-03 16:54:02] [config] transformer-dim-ffn: 4096
[2019-04-03 16:54:02] [config] transformer-dropout: 0.1
[2019-04-03 16:54:02] [config] transformer-dropout-attention: 0.1
[2019-04-03 16:54:02] [config] transformer-dropout-ffn: 0.1
[2019-04-03 16:54:02] [config] transformer-ffn-activation: swish
[2019-04-03 16:54:02] [config] transformer-ffn-depth: 2
[2019-04-03 16:54:02] [config] transformer-guided-alignment-layer: last
[2019-04-03 16:54:02] [config] transformer-heads: 16
[2019-04-03 16:54:02] [config] transformer-no-projection: false
[2019-04-03 16:54:02] [config] transformer-postprocess: da
[2019-04-03 16:54:02] [config] transformer-postprocess-emb: d
[2019-04-03 16:54:02] [config] transformer-preprocess: n
[2019-04-03 16:54:02] [config] transformer-tied-layers:
[2019-04-03 16:54:02] [config]   []
[2019-04-03 16:54:02] [config] type: transformer
[2019-04-03 16:54:02] [config] ulr: false
[2019-04-03 16:54:02] [config] ulr-dim-emb: 0
[2019-04-03 16:54:02] [config] ulr-dropout: 0
[2019-04-03 16:54:02] [config] ulr-keys-vectors: ""
[2019-04-03 16:54:02] [config] ulr-query-vectors: ""
[2019-04-03 16:54:02] [config] ulr-softmax-temperature: 1
[2019-04-03 16:54:02] [config] ulr-trainable-transformation: false
[2019-04-03 16:54:02] [config] valid-freq: 5000
[2019-04-03 16:54:02] [config] valid-log: model/valid.log
[2019-04-03 16:54:02] [config] valid-max-length: 1000
[2019-04-03 16:54:02] [config] valid-metrics:
[2019-04-03 16:54:02] [config]   - ce-mean-words
[2019-04-03 16:54:02] [config]   - perplexity
[2019-04-03 16:54:02] [config]   - translation
[2019-04-03 16:54:02] [config] valid-mini-batch: 16
[2019-04-03 16:54:02] [config] valid-script-path: ./val.sh
[2019-04-03 16:54:02] [config] valid-sets:
[2019-04-03 16:54:02] [config]   - corp/newstest2016-encs-src.en.bpe
[2019-04-03 16:54:02] [config]   - corp/newstest2016-encs-ref.cs.bpe
[2019-04-03 16:54:02] [config] version: v1.7.6 9cc5b17 2018-12-14 15:11:34 -0800
[2019-04-03 16:54:02] [config] vocabs:
[2019-04-03 16:54:02] [config]   - corp/vocab.encs.yml
[2019-04-03 16:54:02] [config]   - corp/vocab.encs.yml
[2019-04-03 16:54:02] [config] word-penalty: 0
[2019-04-03 16:54:02] [config] workspace: 8600
[2019-04-03 16:54:02] [config] Loaded model has been created with Marian v1.7.6 9cc5b17 2018-12-14 15:11:34 -0800
[2019-04-03 16:54:02] Using synchronous training
[2019-04-03 16:54:02] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.yml
[2019-04-03 16:54:02] [data] Setting vocabulary size for input 0 to 34028
[2019-04-03 16:54:02] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.yml
[2019-04-03 16:54:03] [data] Setting vocabulary size for input 1 to 34028
[2019-04-03 16:54:03] [sqlite] Creating temporary database in /tmp
[2019-04-03 16:54:06] [sqlite] Inserted 1000000 lines
[2019-04-03 16:54:10] [sqlite] Inserted 2000000 lines
[2019-04-03 16:54:19] [sqlite] Inserted 4000000 lines
[2019-04-03 16:54:36] [sqlite] Inserted 8000000 lines
[2019-04-03 16:55:12] [sqlite] Inserted 16000000 lines
[2019-04-03 16:56:26] [sqlite] Inserted 32000000 lines
[2019-04-03 16:57:47] [sqlite] Inserted 49633032 lines
[2019-04-03 16:57:47] [sqlite] Creating primary index
[2019-04-03 17:00:32] [batching] Collecting statistics for batch fitting with step size 10
[2019-04-03 17:00:33] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-04-03 17:00:37] [memory] Extending reserved space to 8704 MB (device gpu0)
[2019-04-03 17:00:38] [memory] Extending reserved space to 8704 MB (device gpu1)
[2019-04-03 17:00:38] [comm] NCCL communicator overridden
[2019-04-03 17:00:38] [memory] Reserving 805 MB, device gpu0
[2019-04-03 17:00:39] [memory] Reserving 805 MB, device gpu0
[2019-04-03 17:00:50] [batching] Done
[2019-04-03 17:00:50] [memory] Extending reserved space to 8704 MB (device gpu0)
[2019-04-03 17:00:50] [memory] Extending reserved space to 8704 MB (device gpu1)
[2019-04-03 17:00:50] [comm] NCCL communicator overridden
[2019-04-03 17:00:50] Loading model from model/model_bt_encz.npz.orig.npz
[2019-04-03 17:01:02] Loading model from model/model_bt_encz.npz.orig.npz
[2019-04-03 17:01:06] Loading Adam parameters from model/model_bt_encz.npz.optimizer.npz
[2019-04-03 17:01:29] [memory] Reserving 805 MB, device gpu0
[2019-04-03 17:01:30] [memory] Reserving 805 MB, device gpu1
[2019-04-03 17:01:32] [data] Restoring the corpus state to epoch 8, batch 310000
[2019-04-03 17:06:27] [sqlite] Selecting shuffled data
[2019-04-03 17:20:23] Training started
[2019-04-03 17:20:23] Training finished
rm: cannot remove ‘model/model_bt_encz.npz.yml’: No such file or directory
