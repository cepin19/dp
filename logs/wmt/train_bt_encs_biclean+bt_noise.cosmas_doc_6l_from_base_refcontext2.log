[2019-04-17 05:29:57] [marian] Marian v1.7.8 1e91cce 2019-04-04 17:46:39 +0200
[2019-04-17 05:29:57] [marian] Running on cosmas.lingea.cz as process 110096 with command line:
[2019-04-17 05:29:57] [marian] /home/large/data/models/marian/marian-doc/doc-marian-cosmas/build/marian --model model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext2.npz --pretrained-model model/model_base_encz2.npz --type transformer-context --train-sets corpus.docs.cs.bpe corpus.docs.en.bpe.src corpus.docs.cs.bpe -e 1 --max-length 95 --vocabs corp/vocab.encs.yml corp/vocab.encs.yml corp/vocab.encs.yml --mini-batch-fit -w 9000 --mini-batch 1000 --maxi-batch 1000 --freeze --valid-freq 2000 --save-freq 2000 --disp-freq 100 --embedding-fix-src --embedding-fix-trg --valid-metrics ce-mean-words perplexity translation --valid-sets newstest2016.docs.cs.bpe newstest2016.docs.src newstest2016.docs.cs.bpe --valid-script-path ./val.sh --quiet-translation --beam-size 6 --normalize=0.6 --valid-mini-batch 16 --overwrite --keep-best --early-stopping 15 --cost-type=ce-mean-words --log model/bt_encz.log --valid-log model/valid.log --transformer-heads 8 --enc-depth 6 --dec-depth 6 --context-enc-depth 6 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --optimizer-delay 4 --devices 2 3 --sync-sgd --seed 1111 --exponential-smoothing
[2019-04-17 05:29:57] [config] after-batches: 0
[2019-04-17 05:29:57] [config] after-epochs: 1
[2019-04-17 05:29:57] [config] allow-unk: false
[2019-04-17 05:29:57] [config] beam-size: 6
[2019-04-17 05:29:57] [config] bert-class-symbol: "[CLS]"
[2019-04-17 05:29:57] [config] bert-mask-symbol: "[MASK]"
[2019-04-17 05:29:57] [config] bert-masking-fraction: 0.15
[2019-04-17 05:29:57] [config] bert-sep-symbol: "[SEP]"
[2019-04-17 05:29:57] [config] bert-train-type-embeddings: true
[2019-04-17 05:29:57] [config] bert-type-vocab-size: 2
[2019-04-17 05:29:57] [config] best-deep: false
[2019-04-17 05:29:57] [config] clip-gemm: 0
[2019-04-17 05:29:57] [config] clip-norm: 5
[2019-04-17 05:29:57] [config] context-enc-depth: 6
[2019-04-17 05:29:57] [config] cost-type: ce-mean-words
[2019-04-17 05:29:57] [config] cpu-threads: 0
[2019-04-17 05:29:57] [config] data-weighting: ""
[2019-04-17 05:29:57] [config] data-weighting-type: sentence
[2019-04-17 05:29:57] [config] dec-cell: gru
[2019-04-17 05:29:57] [config] dec-cell-base-depth: 2
[2019-04-17 05:29:57] [config] dec-cell-high-depth: 1
[2019-04-17 05:29:57] [config] dec-depth: 6
[2019-04-17 05:29:57] [config] devices:
[2019-04-17 05:29:57] [config]   - 2
[2019-04-17 05:29:57] [config]   - 3
[2019-04-17 05:29:57] [config] dim-emb: 512
[2019-04-17 05:29:57] [config] dim-rnn: 1024
[2019-04-17 05:29:57] [config] dim-vocabs:
[2019-04-17 05:29:57] [config]   - 0
[2019-04-17 05:29:57] [config]   - 0
[2019-04-17 05:29:57] [config] disp-first: 0
[2019-04-17 05:29:57] [config] disp-freq: 100
[2019-04-17 05:29:57] [config] disp-label-counts: false
[2019-04-17 05:29:57] [config] dropout-rnn: 0
[2019-04-17 05:29:57] [config] dropout-src: 0
[2019-04-17 05:29:57] [config] dropout-trg: 0
[2019-04-17 05:29:57] [config] dump-config: ""
[2019-04-17 05:29:57] [config] early-stopping: 15
[2019-04-17 05:29:57] [config] embedding-fix-src: true
[2019-04-17 05:29:57] [config] embedding-fix-trg: true
[2019-04-17 05:29:57] [config] embedding-normalization: false
[2019-04-17 05:29:57] [config] embedding-vectors:
[2019-04-17 05:29:57] [config]   []
[2019-04-17 05:29:57] [config] enc-cell: gru
[2019-04-17 05:29:57] [config] enc-cell-depth: 1
[2019-04-17 05:29:57] [config] enc-depth: 6
[2019-04-17 05:29:57] [config] enc-type: bidirectional
[2019-04-17 05:29:57] [config] exponential-smoothing: 0.0001
[2019-04-17 05:29:57] [config] freeze: true
[2019-04-17 05:29:57] [config] grad-dropping-momentum: 0
[2019-04-17 05:29:57] [config] grad-dropping-rate: 0
[2019-04-17 05:29:57] [config] grad-dropping-warmup: 100
[2019-04-17 05:29:57] [config] guided-alignment: none
[2019-04-17 05:29:57] [config] guided-alignment-cost: mse
[2019-04-17 05:29:57] [config] guided-alignment-weight: 0.1
[2019-04-17 05:29:57] [config] hier-att: false
[2019-04-17 05:29:57] [config] ignore-model-config: false
[2019-04-17 05:29:57] [config] input-types:
[2019-04-17 05:29:57] [config]   []
[2019-04-17 05:29:57] [config] interpolate-env-vars: false
[2019-04-17 05:29:57] [config] keep-best: true
[2019-04-17 05:29:57] [config] label-smoothing: 0.1
[2019-04-17 05:29:57] [config] layer-normalization: false
[2019-04-17 05:29:57] [config] learn-rate: 0.0003
[2019-04-17 05:29:57] [config] log: model/bt_encz.log
[2019-04-17 05:29:57] [config] log-level: info
[2019-04-17 05:29:57] [config] log-time-zone: ""
[2019-04-17 05:29:57] [config] lr-decay: 0
[2019-04-17 05:29:57] [config] lr-decay-freq: 50000
[2019-04-17 05:29:57] [config] lr-decay-inv-sqrt:
[2019-04-17 05:29:57] [config]   - 16000
[2019-04-17 05:29:57] [config] lr-decay-repeat-warmup: false
[2019-04-17 05:29:57] [config] lr-decay-reset-optimizer: false
[2019-04-17 05:29:57] [config] lr-decay-start:
[2019-04-17 05:29:57] [config]   - 10
[2019-04-17 05:29:57] [config]   - 1
[2019-04-17 05:29:57] [config] lr-decay-strategy: epoch+stalled
[2019-04-17 05:29:57] [config] lr-report: true
[2019-04-17 05:29:57] [config] lr-warmup: 16000
[2019-04-17 05:29:57] [config] lr-warmup-at-reload: false
[2019-04-17 05:29:57] [config] lr-warmup-cycle: false
[2019-04-17 05:29:57] [config] lr-warmup-start-rate: 0
[2019-04-17 05:29:57] [config] max-length: 95
[2019-04-17 05:29:57] [config] max-length-crop: false
[2019-04-17 05:29:57] [config] max-length-factor: 3
[2019-04-17 05:29:57] [config] maxi-batch: 1000
[2019-04-17 05:29:57] [config] maxi-batch-sort: trg
[2019-04-17 05:29:57] [config] mini-batch: 1000
[2019-04-17 05:29:57] [config] mini-batch-fit: true
[2019-04-17 05:29:57] [config] mini-batch-fit-step: 10
[2019-04-17 05:29:57] [config] mini-batch-overstuff: 1
[2019-04-17 05:29:57] [config] mini-batch-track-lr: false
[2019-04-17 05:29:57] [config] mini-batch-understuff: 1
[2019-04-17 05:29:57] [config] mini-batch-warmup: 0
[2019-04-17 05:29:57] [config] mini-batch-words: 0
[2019-04-17 05:29:57] [config] mini-batch-words-ref: 0
[2019-04-17 05:29:57] [config] model: model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext2.npz
[2019-04-17 05:29:57] [config] multi-loss-type: sum
[2019-04-17 05:29:57] [config] multi-node: false
[2019-04-17 05:29:57] [config] multi-node-overlap: true
[2019-04-17 05:29:57] [config] n-best: false
[2019-04-17 05:29:57] [config] no-nccl: false
[2019-04-17 05:29:57] [config] no-reload: false
[2019-04-17 05:29:57] [config] no-restore-corpus: false
[2019-04-17 05:29:57] [config] no-shuffle: false
[2019-04-17 05:29:57] [config] normalize: 0.6
[2019-04-17 05:29:57] [config] num-devices: 0
[2019-04-17 05:29:57] [config] optimizer: adam
[2019-04-17 05:29:57] [config] optimizer-delay: 4
[2019-04-17 05:29:57] [config] optimizer-params:
[2019-04-17 05:29:57] [config]   - 0.9
[2019-04-17 05:29:57] [config]   - 0.98
[2019-04-17 05:29:57] [config]   - 1e-09
[2019-04-17 05:29:57] [config] overwrite: true
[2019-04-17 05:29:57] [config] pretrained-model: model/model_base_encz2.npz
[2019-04-17 05:29:57] [config] quiet: false
[2019-04-17 05:29:57] [config] quiet-translation: true
[2019-04-17 05:29:57] [config] relative-paths: false
[2019-04-17 05:29:57] [config] right-left: false
[2019-04-17 05:29:57] [config] save-freq: 2000
[2019-04-17 05:29:57] [config] seed: 1111
[2019-04-17 05:29:57] [config] shuffle-in-ram: false
[2019-04-17 05:29:57] [config] skip: false
[2019-04-17 05:29:57] [config] sqlite: ""
[2019-04-17 05:29:57] [config] sqlite-drop: false
[2019-04-17 05:29:57] [config] sync-sgd: true
[2019-04-17 05:29:57] [config] tempdir: /tmp
[2019-04-17 05:29:57] [config] tied-embeddings: false
[2019-04-17 05:29:57] [config] tied-embeddings-all: true
[2019-04-17 05:29:57] [config] tied-embeddings-src: false
[2019-04-17 05:29:57] [config] train-sets:
[2019-04-17 05:29:57] [config]   - corpus.docs.cs.bpe
[2019-04-17 05:29:57] [config]   - corpus.docs.en.bpe.src
[2019-04-17 05:29:57] [config]   - corpus.docs.cs.bpe
[2019-04-17 05:29:57] [config] transformer-aan-activation: swish
[2019-04-17 05:29:57] [config] transformer-aan-depth: 2
[2019-04-17 05:29:57] [config] transformer-aan-nogate: false
[2019-04-17 05:29:57] [config] transformer-decoder-autoreg: self-attention
[2019-04-17 05:29:57] [config] transformer-dim-aan: 2048
[2019-04-17 05:29:57] [config] transformer-dim-ffn: 2048
[2019-04-17 05:29:57] [config] transformer-dropout: 0.1
[2019-04-17 05:29:57] [config] transformer-dropout-attention: 0
[2019-04-17 05:29:57] [config] transformer-dropout-ffn: 0
[2019-04-17 05:29:57] [config] transformer-ffn-activation: swish
[2019-04-17 05:29:57] [config] transformer-ffn-depth: 2
[2019-04-17 05:29:57] [config] transformer-guided-alignment-layer: last
[2019-04-17 05:29:57] [config] transformer-heads: 8
[2019-04-17 05:29:57] [config] transformer-no-projection: false
[2019-04-17 05:29:57] [config] transformer-postprocess: dan
[2019-04-17 05:29:57] [config] transformer-postprocess-emb: d
[2019-04-17 05:29:57] [config] transformer-preprocess: ""
[2019-04-17 05:29:57] [config] transformer-tied-layers:
[2019-04-17 05:29:57] [config]   []
[2019-04-17 05:29:57] [config] transformer-train-position-embeddings: false
[2019-04-17 05:29:57] [config] type: transformer-context
[2019-04-17 05:29:57] [config] ulr: false
[2019-04-17 05:29:57] [config] ulr-dim-emb: 0
[2019-04-17 05:29:57] [config] ulr-dropout: 0
[2019-04-17 05:29:57] [config] ulr-keys-vectors: ""
[2019-04-17 05:29:57] [config] ulr-query-vectors: ""
[2019-04-17 05:29:57] [config] ulr-softmax-temperature: 1
[2019-04-17 05:29:57] [config] ulr-trainable-transformation: false
[2019-04-17 05:29:57] [config] valid-freq: 2000
[2019-04-17 05:29:57] [config] valid-log: model/valid.log
[2019-04-17 05:29:57] [config] valid-max-length: 1000
[2019-04-17 05:29:57] [config] valid-metrics:
[2019-04-17 05:29:57] [config]   - ce-mean-words
[2019-04-17 05:29:57] [config]   - perplexity
[2019-04-17 05:29:57] [config]   - translation
[2019-04-17 05:29:57] [config] valid-mini-batch: 16
[2019-04-17 05:29:57] [config] valid-script-path: ./val.sh
[2019-04-17 05:29:57] [config] valid-sets:
[2019-04-17 05:29:57] [config]   - newstest2016.docs.cs.bpe
[2019-04-17 05:29:57] [config]   - newstest2016.docs.src
[2019-04-17 05:29:57] [config]   - newstest2016.docs.cs.bpe
[2019-04-17 05:29:57] [config] valid-translation-output: ""
[2019-04-17 05:29:57] [config] vocabs:
[2019-04-17 05:29:57] [config]   - corp/vocab.encs.yml
[2019-04-17 05:29:57] [config]   - corp/vocab.encs.yml
[2019-04-17 05:29:57] [config]   - corp/vocab.encs.yml
[2019-04-17 05:29:57] [config] word-penalty: 0
[2019-04-17 05:29:57] [config] workspace: 9000
[2019-04-17 05:29:57] [config] Model is being created with Marian v1.7.8 1e91cce 2019-04-04 17:46:39 +0200
[2019-04-17 05:29:57] Using synchronous training
[2019-04-17 05:29:57] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.yml
[2019-04-17 05:29:57] [data] Setting vocabulary size for input 0 to 34028
[2019-04-17 05:29:57] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.yml
[2019-04-17 05:29:58] [data] Setting vocabulary size for input 1 to 34028
[2019-04-17 05:29:58] [data] Loading vocabulary from JSON/Yaml file corp/vocab.encs.yml
[2019-04-17 05:29:58] [data] Setting vocabulary size for input 2 to 34028
[2019-04-17 05:29:58] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-04-17 05:29:58] [batching] Collecting statistics for batch fitting with step size 10
[2019-04-17 05:30:00] [memory] Extending reserved space to 9088 MB (device gpu2)
[2019-04-17 05:30:00] [memory] Extending reserved space to 9088 MB (device gpu3)
[2019-04-17 05:30:00] [comm] Using NCCL 2.4.2 for GPU communication
[2019-04-17 05:30:00] [comm] NCCLCommunicator constructed successfully.
[2019-04-17 05:30:00] [training] Using 2 GPUs
[2019-04-17 05:30:00] [memory] Reserving 379 MB, device gpu2
[2019-04-17 05:30:00] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-04-17 05:30:01] [memory] Reserving 379 MB, device gpu2
[2019-04-17 05:30:13] [batching] Done. Typical MB size is 29080 target words
[2019-04-17 05:30:13] [memory] Extending reserved space to 9088 MB (device gpu2)
[2019-04-17 05:30:13] [memory] Extending reserved space to 9088 MB (device gpu3)
[2019-04-17 05:30:13] [comm] Using NCCL 2.4.2 for GPU communication
[2019-04-17 05:30:13] [comm] NCCLCommunicator constructed successfully.
[2019-04-17 05:30:13] [training] Using 2 GPUs
[2019-04-17 05:30:13] [training] Initializing model weights with the pre-trained model model/model_base_encz2.npz
[2019-04-17 05:30:13] Loading model from model/model_base_encz2.npz
[2019-04-17 05:30:14] Loading model from model/model_base_encz2.npz
[2019-04-17 05:30:14] Training started
[2019-04-17 05:30:14] [data] Shuffling data
tcmalloc: large alloc 1073741824 bytes == 0x1be2b8000 @ 
tcmalloc: large alloc 2147483648 bytes == 0x7f3fceafa000 @ 
tcmalloc: large alloc 2147483648 bytes == 0x7f3f4eafa000 @ 
tcmalloc: large alloc 2147483648 bytes == 0x7f3ea4000000 @ 
[2019-04-17 05:30:35] [data] Done reading 57951104 sentences
[2019-04-17 05:33:59] [data] Done shuffling 57951104 sentences to temp files
[2019-04-17 05:34:28] [training] Batches are processed as 1 process(es) x 2 devices/process
[2019-04-17 05:34:28] [memory] Reserving 379 MB, device gpu2
[2019-04-17 05:34:28] [memory] Reserving 379 MB, device gpu3
[2019-04-17 05:34:28] [memory] Reserving 379 MB, device gpu3
[2019-04-17 05:34:28] [memory] Reserving 379 MB, device gpu2
[2019-04-17 05:34:28] [memory] Reserving 189 MB, device gpu2
[2019-04-17 05:34:28] [memory] Reserving 189 MB, device gpu3
[2019-04-17 05:34:29] [memory] Reserving 379 MB, device gpu2
[2019-04-17 05:34:29] [memory] Reserving 379 MB, device gpu3
[2019-04-17 05:36:46] Ep. 1 : Up. 100 : Sen. 138,106 : Cost 9.74977398 : Time 408.01s : 5187.43 words/s : L.r. 1.8750e-06
[2019-04-17 05:39:13] Ep. 1 : Up. 200 : Sen. 281,773 : Cost 8.84782696 : Time 146.77s : 14743.02 words/s : L.r. 3.7500e-06
[2019-04-17 05:41:36] Ep. 1 : Up. 300 : Sen. 424,144 : Cost 8.53457069 : Time 142.94s : 14677.35 words/s : L.r. 5.6250e-06
[2019-04-17 05:43:56] Ep. 1 : Up. 400 : Sen. 568,312 : Cost 8.15885544 : Time 140.87s : 14675.59 words/s : L.r. 7.5000e-06
[2019-04-17 05:46:24] Ep. 1 : Up. 500 : Sen. 706,967 : Cost 7.91806793 : Time 147.28s : 14809.05 words/s : L.r. 9.3750e-06
[2019-04-17 05:48:47] Ep. 1 : Up. 600 : Sen. 850,308 : Cost 7.21902657 : Time 143.02s : 14692.06 words/s : L.r. 1.1250e-05
[2019-04-17 05:51:07] Ep. 1 : Up. 700 : Sen. 976,325 : Cost 6.30764389 : Time 139.84s : 14748.63 words/s : L.r. 1.3125e-05
[2019-04-17 05:53:29] Ep. 1 : Up. 800 : Sen. 1,114,493 : Cost 5.73826742 : Time 141.97s : 14767.48 words/s : L.r. 1.5000e-05
[2019-04-17 05:55:48] Ep. 1 : Up. 900 : Sen. 1,254,737 : Cost 5.38690948 : Time 139.88s : 14912.12 words/s : L.r. 1.6875e-05
[2019-04-17 05:58:11] Ep. 1 : Up. 1000 : Sen. 1,390,130 : Cost 4.77830172 : Time 142.37s : 14812.41 words/s : L.r. 1.8750e-05
[2019-04-17 06:00:31] Ep. 1 : Up. 1100 : Sen. 1,529,372 : Cost 3.86612463 : Time 140.70s : 14729.51 words/s : L.r. 2.0625e-05
[2019-04-17 06:02:54] Ep. 1 : Up. 1200 : Sen. 1,665,563 : Cost 3.36745119 : Time 142.79s : 14714.87 words/s : L.r. 2.2500e-05
[2019-04-17 06:05:26] Ep. 1 : Up. 1300 : Sen. 1,811,704 : Cost 3.17858887 : Time 151.51s : 14825.51 words/s : L.r. 2.4375e-05
[2019-04-17 06:07:47] Ep. 1 : Up. 1400 : Sen. 1,949,919 : Cost 3.06587029 : Time 140.71s : 14601.04 words/s : L.r. 2.6250e-05
[2019-04-17 06:10:09] Ep. 1 : Up. 1500 : Sen. 2,071,832 : Cost 2.96326947 : Time 142.98s : 14622.99 words/s : L.r. 2.8125e-05
[2019-04-17 06:12:28] Ep. 1 : Up. 1600 : Sen. 2,204,214 : Cost 2.94753933 : Time 138.93s : 14638.68 words/s : L.r. 3.0000e-05
[2019-04-17 06:14:53] Ep. 1 : Up. 1700 : Sen. 2,340,786 : Cost 2.91629505 : Time 144.16s : 14721.30 words/s : L.r. 3.1875e-05
[2019-04-17 06:17:21] Ep. 1 : Up. 1800 : Sen. 2,489,736 : Cost 2.86927986 : Time 148.27s : 14803.34 words/s : L.r. 3.3750e-05
[2019-04-17 06:19:45] Ep. 1 : Up. 1900 : Sen. 2,623,976 : Cost 2.87198138 : Time 143.69s : 14883.83 words/s : L.r. 3.5625e-05
[2019-04-17 06:22:10] Ep. 1 : Up. 2000 : Sen. 2,764,907 : Cost 2.84866881 : Time 145.40s : 14696.72 words/s : L.r. 3.7500e-05
[2019-04-17 06:22:10] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext2.npz.orig.npz
[2019-04-17 06:22:12] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext2.npz
[2019-04-17 06:22:15] Saving Adam parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext2.npz.optimizer.npz
[2019-04-17 06:22:22] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext2.npz.best-ce-mean-words.npz
[2019-04-17 06:22:24] [valid] Ep. 1 : Up. 2000 : ce-mean-words : 1.63732 : new best
[2019-04-17 06:22:27] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext2.npz.best-perplexity.npz
[2019-04-17 06:22:28] [valid] Ep. 1 : Up. 2000 : perplexity : 5.14135 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-17 06:23:11] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext2.npz.best-translation.npz
[2019-04-17 06:23:12] [valid] Ep. 1 : Up. 2000 : translation : 25.66 : new best
[2019-04-17 06:25:36] Ep. 1 : Up. 2100 : Sen. 2,912,278 : Cost 2.81705379 : Time 206.44s : 10215.39 words/s : L.r. 3.9375e-05
[2019-04-17 06:28:00] Ep. 1 : Up. 2200 : Sen. 3,055,421 : Cost 2.84494662 : Time 143.31s : 14541.22 words/s : L.r. 4.1250e-05
[2019-04-17 06:30:23] Ep. 1 : Up. 2300 : Sen. 3,199,380 : Cost 2.82436061 : Time 143.76s : 14637.05 words/s : L.r. 4.3125e-05
[2019-04-17 06:32:50] Ep. 1 : Up. 2400 : Sen. 3,334,883 : Cost 2.76258755 : Time 146.20s : 14807.38 words/s : L.r. 4.5000e-05
[2019-04-17 06:35:07] Ep. 1 : Up. 2500 : Sen. 3,485,622 : Cost 2.84030914 : Time 137.05s : 14751.69 words/s : L.r. 4.6875e-05
[2019-04-17 06:37:35] Ep. 1 : Up. 2600 : Sen. 3,629,860 : Cost 2.72229004 : Time 148.34s : 14761.29 words/s : L.r. 4.8750e-05
[2019-04-17 06:40:03] Ep. 1 : Up. 2700 : Sen. 3,780,056 : Cost 2.72351837 : Time 147.97s : 14698.16 words/s : L.r. 5.0625e-05
[2019-04-17 06:42:22] Ep. 1 : Up. 2800 : Sen. 3,903,741 : Cost 2.73942971 : Time 138.68s : 14531.92 words/s : L.r. 5.2500e-05
[2019-04-17 06:44:45] Ep. 1 : Up. 2900 : Sen. 4,038,659 : Cost 2.77394629 : Time 143.48s : 14840.21 words/s : L.r. 5.4375e-05
[2019-04-17 06:47:08] Ep. 1 : Up. 3000 : Sen. 4,166,200 : Cost 2.74248862 : Time 142.95s : 14612.96 words/s : L.r. 5.6250e-05
[2019-04-17 06:49:31] Ep. 1 : Up. 3100 : Sen. 4,279,286 : Cost 2.65758109 : Time 143.13s : 14502.17 words/s : L.r. 5.8125e-05
[2019-04-17 06:51:59] Ep. 1 : Up. 3200 : Sen. 4,425,529 : Cost 2.70842934 : Time 147.72s : 14911.03 words/s : L.r. 6.0000e-05
[2019-04-17 06:54:23] Ep. 1 : Up. 3300 : Sen. 4,568,484 : Cost 2.69900370 : Time 143.72s : 14682.10 words/s : L.r. 6.1875e-05
[2019-04-17 06:56:51] Ep. 1 : Up. 3400 : Sen. 4,712,759 : Cost 2.68944860 : Time 148.81s : 14879.33 words/s : L.r. 6.3750e-05
[2019-04-17 06:59:10] Ep. 1 : Up. 3500 : Sen. 4,842,315 : Cost 2.65852666 : Time 138.56s : 14417.71 words/s : L.r. 6.5625e-05
[2019-04-17 07:01:33] Ep. 1 : Up. 3600 : Sen. 5,004,048 : Cost 2.68951964 : Time 143.26s : 14721.00 words/s : L.r. 6.7500e-05
[2019-04-17 07:04:00] Ep. 1 : Up. 3700 : Sen. 5,143,564 : Cost 2.68310213 : Time 146.57s : 14956.98 words/s : L.r. 6.9375e-05
[2019-04-17 07:06:28] Ep. 1 : Up. 3800 : Sen. 5,278,783 : Cost 2.65967894 : Time 148.03s : 14856.08 words/s : L.r. 7.1250e-05
[2019-04-17 07:08:49] Ep. 1 : Up. 3900 : Sen. 5,410,282 : Cost 2.66131759 : Time 140.99s : 14545.76 words/s : L.r. 7.3125e-05
[2019-04-17 07:11:18] Ep. 1 : Up. 4000 : Sen. 5,551,008 : Cost 2.60890031 : Time 149.12s : 14612.90 words/s : L.r. 7.5000e-05
[2019-04-17 07:11:18] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext2.npz.orig.npz
[2019-04-17 07:11:21] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext2.npz
[2019-04-17 07:11:24] Saving Adam parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext2.npz.optimizer.npz
[2019-04-17 07:11:33] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext2.npz.best-ce-mean-words.npz
[2019-04-17 07:11:35] [valid] Ep. 1 : Up. 4000 : ce-mean-words : 1.5282 : new best
[2019-04-17 07:11:38] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext2.npz.best-perplexity.npz
[2019-04-17 07:11:40] [valid] Ep. 1 : Up. 4000 : perplexity : 4.60987 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-17 07:12:24] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext2.npz.best-translation.npz
[2019-04-17 07:12:27] [valid] Ep. 1 : Up. 4000 : translation : 26.54 : new best
[2019-04-17 07:14:50] Ep. 1 : Up. 4100 : Sen. 5,683,929 : Cost 2.66436839 : Time 211.76s : 9727.40 words/s : L.r. 7.6875e-05
[2019-04-17 07:17:12] Ep. 1 : Up. 4200 : Sen. 5,826,461 : Cost 2.66984582 : Time 142.52s : 14493.99 words/s : L.r. 7.8750e-05
[2019-04-17 07:19:33] Ep. 1 : Up. 4300 : Sen. 5,973,104 : Cost 2.61794925 : Time 141.08s : 14678.20 words/s : L.r. 8.0625e-05
[2019-04-17 07:21:57] Ep. 1 : Up. 4400 : Sen. 6,129,153 : Cost 2.54953575 : Time 143.92s : 14562.35 words/s : L.r. 8.2500e-05
[2019-04-17 07:24:23] Ep. 1 : Up. 4500 : Sen. 6,262,133 : Cost 2.61705947 : Time 145.74s : 14752.86 words/s : L.r. 8.4375e-05
[2019-04-17 07:26:52] Ep. 1 : Up. 4600 : Sen. 6,396,928 : Cost 2.60161138 : Time 149.12s : 14830.63 words/s : L.r. 8.6250e-05
[2019-04-17 07:29:10] Ep. 1 : Up. 4700 : Sen. 6,529,247 : Cost 2.63618207 : Time 138.00s : 14498.89 words/s : L.r. 8.8125e-05
[2019-04-17 07:31:34] Ep. 1 : Up. 4800 : Sen. 6,651,330 : Cost 2.62230682 : Time 143.47s : 14723.36 words/s : L.r. 9.0000e-05
[2019-04-17 07:34:00] Ep. 1 : Up. 4900 : Sen. 6,795,866 : Cost 2.57599616 : Time 146.17s : 14613.87 words/s : L.r. 9.1875e-05
[2019-04-17 07:36:26] Ep. 1 : Up. 5000 : Sen. 6,959,625 : Cost 2.59798503 : Time 146.04s : 14633.16 words/s : L.r. 9.3750e-05
[2019-04-17 07:38:47] Ep. 1 : Up. 5100 : Sen. 7,075,870 : Cost 2.61477542 : Time 141.28s : 14615.33 words/s : L.r. 9.5625e-05
[2019-04-17 07:41:10] Ep. 1 : Up. 5200 : Sen. 7,218,943 : Cost 2.56465578 : Time 142.66s : 14639.42 words/s : L.r. 9.7500e-05
[2019-04-17 07:43:36] Ep. 1 : Up. 5300 : Sen. 7,362,864 : Cost 2.54542494 : Time 146.71s : 14616.11 words/s : L.r. 9.9375e-05
[2019-04-17 07:46:01] Ep. 1 : Up. 5400 : Sen. 7,502,833 : Cost 2.58414459 : Time 144.74s : 14805.47 words/s : L.r. 1.0125e-04
[2019-04-17 07:48:23] Ep. 1 : Up. 5500 : Sen. 7,649,564 : Cost 2.58263731 : Time 141.96s : 14804.94 words/s : L.r. 1.0313e-04
[2019-04-17 07:50:44] Ep. 1 : Up. 5600 : Sen. 7,768,863 : Cost 2.52483869 : Time 140.39s : 14600.71 words/s : L.r. 1.0500e-04
[2019-04-17 07:53:08] Ep. 1 : Up. 5700 : Sen. 7,922,942 : Cost 2.54844093 : Time 144.69s : 14744.31 words/s : L.r. 1.0687e-04
[2019-04-17 07:55:36] Ep. 1 : Up. 5800 : Sen. 8,068,488 : Cost 2.54093838 : Time 148.05s : 14725.72 words/s : L.r. 1.0875e-04
[2019-04-17 07:57:56] Ep. 1 : Up. 5900 : Sen. 8,198,412 : Cost 2.56240988 : Time 140.06s : 14394.80 words/s : L.r. 1.1063e-04
[2019-04-17 08:00:12] Ep. 1 : Up. 6000 : Sen. 8,351,676 : Cost 2.48947287 : Time 135.23s : 14526.43 words/s : L.r. 1.1250e-04
[2019-04-17 08:00:12] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext2.npz.orig.npz
[2019-04-17 08:00:15] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext2.npz
[2019-04-17 08:00:18] Saving Adam parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext2.npz.optimizer.npz
[2019-04-17 08:00:27] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext2.npz.best-ce-mean-words.npz
[2019-04-17 08:00:29] [valid] Ep. 1 : Up. 6000 : ce-mean-words : 1.45797 : new best
[2019-04-17 08:00:32] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext2.npz.best-perplexity.npz
[2019-04-17 08:00:34] [valid] Ep. 1 : Up. 6000 : perplexity : 4.29724 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-17 08:01:16] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext2.npz.best-translation.npz
[2019-04-17 08:01:18] [valid] Ep. 1 : Up. 6000 : translation : 28.14 : new best
[2019-04-17 08:03:48] Ep. 1 : Up. 6100 : Sen. 8,467,841 : Cost 2.51869130 : Time 216.52s : 10168.13 words/s : L.r. 1.1438e-04
[2019-04-17 08:06:16] Ep. 1 : Up. 6200 : Sen. 8,616,249 : Cost 2.52619886 : Time 147.61s : 14779.39 words/s : L.r. 1.1625e-04
[2019-04-17 08:08:38] Ep. 1 : Up. 6300 : Sen. 8,748,053 : Cost 2.51859784 : Time 142.38s : 14704.14 words/s : L.r. 1.1813e-04
[2019-04-17 08:11:02] Ep. 1 : Up. 6400 : Sen. 8,889,746 : Cost 2.50607920 : Time 143.89s : 14546.21 words/s : L.r. 1.2000e-04
[2019-04-17 08:13:25] Ep. 1 : Up. 6500 : Sen. 9,027,468 : Cost 2.53656530 : Time 142.63s : 14791.09 words/s : L.r. 1.2188e-04
[2019-04-17 08:15:55] Ep. 1 : Up. 6600 : Sen. 9,176,064 : Cost 2.46521544 : Time 150.54s : 14625.58 words/s : L.r. 1.2375e-04
[2019-04-17 08:18:11] Ep. 1 : Up. 6700 : Sen. 9,311,119 : Cost 2.52971387 : Time 136.22s : 14527.00 words/s : L.r. 1.2562e-04
[2019-04-17 08:20:40] Ep. 1 : Up. 6800 : Sen. 9,449,408 : Cost 2.48377085 : Time 148.66s : 14806.16 words/s : L.r. 1.2750e-04
[2019-04-17 08:23:03] Ep. 1 : Up. 6900 : Sen. 9,583,052 : Cost 2.45527840 : Time 142.47s : 14645.57 words/s : L.r. 1.2938e-04
[2019-04-17 08:25:28] Ep. 1 : Up. 7000 : Sen. 9,722,178 : Cost 2.51033640 : Time 145.00s : 14783.69 words/s : L.r. 1.3125e-04
[2019-04-17 08:27:51] Ep. 1 : Up. 7100 : Sen. 9,861,039 : Cost 2.49056172 : Time 143.74s : 14708.96 words/s : L.r. 1.3313e-04
[2019-04-17 08:30:15] Ep. 1 : Up. 7200 : Sen. 10,010,688 : Cost 2.51526570 : Time 143.54s : 14618.08 words/s : L.r. 1.3500e-04
[2019-04-17 08:32:42] Ep. 1 : Up. 7300 : Sen. 10,145,093 : Cost 2.49538565 : Time 147.00s : 14767.18 words/s : L.r. 1.3688e-04
[2019-04-17 08:35:04] Ep. 1 : Up. 7400 : Sen. 10,268,730 : Cost 2.45828319 : Time 142.46s : 14711.30 words/s : L.r. 1.3875e-04
[2019-04-17 08:37:28] Ep. 1 : Up. 7500 : Sen. 10,422,037 : Cost 2.44916201 : Time 143.81s : 14679.88 words/s : L.r. 1.4063e-04
[2019-04-17 08:39:54] Ep. 1 : Up. 7600 : Sen. 10,570,193 : Cost 2.45323372 : Time 145.67s : 14647.27 words/s : L.r. 1.4250e-04
[2019-04-17 08:42:18] Ep. 1 : Up. 7700 : Sen. 10,721,432 : Cost 2.46939015 : Time 143.83s : 14563.44 words/s : L.r. 1.4438e-04
[2019-04-17 08:44:39] Ep. 1 : Up. 7800 : Sen. 10,858,305 : Cost 2.42802739 : Time 141.49s : 14732.46 words/s : L.r. 1.4625e-04
[2019-04-17 08:47:02] Ep. 1 : Up. 7900 : Sen. 10,985,460 : Cost 2.43663144 : Time 142.64s : 14575.83 words/s : L.r. 1.4813e-04
[2019-04-17 08:49:30] Ep. 1 : Up. 8000 : Sen. 11,126,799 : Cost 2.37603807 : Time 148.02s : 14626.29 words/s : L.r. 1.5000e-04
[2019-04-17 08:49:30] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext2.npz.orig.npz
[2019-04-17 08:49:33] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext2.npz
[2019-04-17 08:49:36] Saving Adam parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext2.npz.optimizer.npz
[2019-04-17 08:49:45] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext2.npz.best-ce-mean-words.npz
[2019-04-17 08:49:47] [valid] Ep. 1 : Up. 8000 : ce-mean-words : 1.40311 : new best
[2019-04-17 08:49:50] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext2.npz.best-perplexity.npz
[2019-04-17 08:49:52] [valid] Ep. 1 : Up. 8000 : perplexity : 4.06783 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-17 08:50:33] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext2.npz.best-translation.npz
[2019-04-17 08:50:35] [valid] Ep. 1 : Up. 8000 : translation : 29.88 : new best
[2019-04-17 08:53:01] Ep. 1 : Up. 8100 : Sen. 11,256,265 : Cost 2.44605327 : Time 211.06s : 10199.17 words/s : L.r. 1.5188e-04
[2019-04-17 08:55:28] Ep. 1 : Up. 8200 : Sen. 11,381,872 : Cost 2.39571667 : Time 147.16s : 14766.72 words/s : L.r. 1.5375e-04
[2019-04-17 08:57:53] Ep. 1 : Up. 8300 : Sen. 11,528,711 : Cost 2.28742671 : Time 144.87s : 14668.54 words/s : L.r. 1.5563e-04
[2019-04-17 09:00:11] Ep. 1 : Up. 8400 : Sen. 11,664,537 : Cost 2.32895684 : Time 138.42s : 14445.34 words/s : L.r. 1.5750e-04
[2019-04-17 09:02:32] Ep. 1 : Up. 8500 : Sen. 11,801,314 : Cost 2.28036094 : Time 141.04s : 14511.74 words/s : L.r. 1.5938e-04
[2019-04-17 09:04:59] Ep. 1 : Up. 8600 : Sen. 11,960,610 : Cost 2.20543504 : Time 146.55s : 14621.81 words/s : L.r. 1.6125e-04
[2019-04-17 09:07:23] Ep. 1 : Up. 8700 : Sen. 12,093,505 : Cost 2.21556330 : Time 144.61s : 14762.55 words/s : L.r. 1.6313e-04
[2019-04-17 09:09:48] Ep. 1 : Up. 8800 : Sen. 12,238,268 : Cost 2.21504807 : Time 144.75s : 14889.43 words/s : L.r. 1.6500e-04
[2019-04-17 09:12:11] Ep. 1 : Up. 8900 : Sen. 12,363,455 : Cost 2.21392417 : Time 142.98s : 14631.21 words/s : L.r. 1.6688e-04
[2019-04-17 09:14:37] Ep. 1 : Up. 9000 : Sen. 12,496,609 : Cost 2.11264253 : Time 145.65s : 14742.63 words/s : L.r. 1.6875e-04
[2019-04-17 09:16:58] Ep. 1 : Up. 9100 : Sen. 12,616,320 : Cost 2.15492272 : Time 141.36s : 14517.08 words/s : L.r. 1.7063e-04
[2019-04-17 09:19:22] Ep. 1 : Up. 9200 : Sen. 12,788,229 : Cost 1.96580625 : Time 144.30s : 14672.06 words/s : L.r. 1.7250e-04
[2019-04-17 09:21:48] Ep. 1 : Up. 9300 : Sen. 12,931,355 : Cost 2.04702640 : Time 145.68s : 14893.17 words/s : L.r. 1.7438e-04
[2019-04-17 09:24:10] Ep. 1 : Up. 9400 : Sen. 13,071,077 : Cost 2.06100583 : Time 142.33s : 14691.62 words/s : L.r. 1.7625e-04
[2019-04-17 09:26:30] Ep. 1 : Up. 9500 : Sen. 13,197,851 : Cost 2.08373809 : Time 139.88s : 14580.24 words/s : L.r. 1.7813e-04
[2019-04-17 09:28:55] Ep. 1 : Up. 9600 : Sen. 13,325,805 : Cost 2.00295949 : Time 144.48s : 14769.36 words/s : L.r. 1.8000e-04
[2019-04-17 09:31:22] Ep. 1 : Up. 9700 : Sen. 13,456,604 : Cost 1.99109948 : Time 147.17s : 14921.15 words/s : L.r. 1.8188e-04
[2019-04-17 09:33:44] Ep. 1 : Up. 9800 : Sen. 13,598,089 : Cost 1.89916682 : Time 142.02s : 14735.08 words/s : L.r. 1.8375e-04
[2019-04-17 09:36:05] Ep. 1 : Up. 9900 : Sen. 13,744,605 : Cost 1.96363151 : Time 141.38s : 14588.22 words/s : L.r. 1.8563e-04
[2019-04-17 09:38:32] Ep. 1 : Up. 10000 : Sen. 13,914,613 : Cost 1.86952949 : Time 147.02s : 14675.18 words/s : L.r. 1.8750e-04
[2019-04-17 09:38:32] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext2.npz.orig.npz
[2019-04-17 09:38:36] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext2.npz
[2019-04-17 09:38:39] Saving Adam parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext2.npz.optimizer.npz
[2019-04-17 09:38:48] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext2.npz.best-ce-mean-words.npz
[2019-04-17 09:38:50] [valid] Ep. 1 : Up. 10000 : ce-mean-words : 0.884064 : new best
[2019-04-17 09:38:53] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext2.npz.best-perplexity.npz
[2019-04-17 09:38:55] [valid] Ep. 1 : Up. 10000 : perplexity : 2.42072 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-17 09:39:34] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext2.npz.best-translation.npz
[2019-04-17 09:39:36] [valid] Ep. 1 : Up. 10000 : translation : 51.73 : new best
[2019-04-17 09:42:01] Ep. 1 : Up. 10100 : Sen. 14,045,687 : Cost 1.95637536 : Time 209.09s : 10185.65 words/s : L.r. 1.8938e-04
[2019-04-17 09:44:27] Ep. 1 : Up. 10200 : Sen. 14,191,445 : Cost 1.87370789 : Time 145.82s : 14667.16 words/s : L.r. 1.9125e-04
[2019-04-17 09:46:47] Ep. 1 : Up. 10300 : Sen. 14,334,844 : Cost 1.82531762 : Time 139.89s : 14560.77 words/s : L.r. 1.9313e-04
[2019-04-17 09:49:16] Ep. 1 : Up. 10400 : Sen. 14,474,578 : Cost 1.83773482 : Time 149.22s : 14807.27 words/s : L.r. 1.9500e-04
[2019-04-17 09:51:39] Ep. 1 : Up. 10500 : Sen. 14,611,980 : Cost 1.81559587 : Time 142.26s : 14537.09 words/s : L.r. 1.9688e-04
[2019-04-17 09:54:07] Ep. 1 : Up. 10600 : Sen. 14,753,604 : Cost 1.79139245 : Time 148.07s : 14808.06 words/s : L.r. 1.9875e-04
[2019-04-17 09:56:28] Ep. 1 : Up. 10700 : Sen. 14,888,292 : Cost 1.79240513 : Time 140.95s : 14629.11 words/s : L.r. 2.0062e-04
[2019-04-17 09:58:53] Ep. 1 : Up. 10800 : Sen. 15,026,936 : Cost 1.76553464 : Time 145.75s : 14893.42 words/s : L.r. 2.0250e-04
[2019-04-17 10:01:15] Ep. 1 : Up. 10900 : Sen. 15,172,391 : Cost 1.71735775 : Time 141.28s : 14527.68 words/s : L.r. 2.0437e-04
[2019-04-17 10:03:41] Ep. 1 : Up. 11000 : Sen. 15,310,533 : Cost 1.74386144 : Time 146.10s : 14919.67 words/s : L.r. 2.0625e-04
[2019-04-17 10:06:01] Ep. 1 : Up. 11100 : Sen. 15,453,897 : Cost 1.71367598 : Time 140.38s : 14616.42 words/s : L.r. 2.0813e-04
[2019-04-17 10:08:21] Ep. 1 : Up. 11200 : Sen. 15,594,674 : Cost 1.74535644 : Time 139.82s : 14537.95 words/s : L.r. 2.1000e-04
[2019-04-17 10:10:48] Ep. 1 : Up. 11300 : Sen. 15,732,218 : Cost 1.71786213 : Time 146.69s : 14894.12 words/s : L.r. 2.1188e-04
[2019-04-17 10:13:15] Ep. 1 : Up. 11400 : Sen. 15,841,557 : Cost 1.71784186 : Time 146.91s : 14702.65 words/s : L.r. 2.1375e-04
[2019-04-17 10:15:40] Ep. 1 : Up. 11500 : Sen. 16,001,648 : Cost 1.63657677 : Time 145.29s : 14829.44 words/s : L.r. 2.1563e-04
[2019-04-17 10:18:01] Ep. 1 : Up. 11600 : Sen. 16,146,083 : Cost 1.64411688 : Time 141.28s : 14821.91 words/s : L.r. 2.1750e-04
[2019-04-17 10:20:28] Ep. 1 : Up. 11700 : Sen. 16,282,572 : Cost 1.61854994 : Time 146.71s : 14756.36 words/s : L.r. 2.1938e-04
[2019-04-17 10:22:49] Ep. 1 : Up. 11800 : Sen. 16,403,868 : Cost 1.64573050 : Time 140.70s : 14475.74 words/s : L.r. 2.2125e-04
[2019-04-17 10:25:14] Ep. 1 : Up. 11900 : Sen. 16,564,723 : Cost 1.62148106 : Time 145.66s : 14837.62 words/s : L.r. 2.2312e-04
[2019-04-17 10:27:45] Ep. 1 : Up. 12000 : Sen. 16,715,779 : Cost 1.61680901 : Time 150.67s : 14872.88 words/s : L.r. 2.2500e-04
[2019-04-17 10:27:45] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext2.npz.orig.npz
[2019-04-17 10:27:48] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext2.npz
[2019-04-17 10:27:51] Saving Adam parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext2.npz.optimizer.npz
[2019-04-17 10:28:00] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext2.npz.best-ce-mean-words.npz
[2019-04-17 10:28:02] [valid] Ep. 1 : Up. 12000 : ce-mean-words : 0.272613 : new best
[2019-04-17 10:28:05] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext2.npz.best-perplexity.npz
[2019-04-17 10:28:07] [valid] Ep. 1 : Up. 12000 : perplexity : 1.31339 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-17 10:28:46] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext2.npz.best-translation.npz
[2019-04-17 10:28:48] [valid] Ep. 1 : Up. 12000 : translation : 85.09 : new best
[2019-04-17 10:31:10] Ep. 1 : Up. 12100 : Sen. 16,845,883 : Cost 1.61981547 : Time 205.49s : 10068.85 words/s : L.r. 2.2688e-04
[2019-04-17 10:33:31] Ep. 1 : Up. 12200 : Sen. 16,973,669 : Cost 1.59670794 : Time 140.12s : 14476.03 words/s : L.r. 2.2875e-04
[2019-04-17 10:36:02] Ep. 1 : Up. 12300 : Sen. 17,129,311 : Cost 1.56748843 : Time 151.10s : 14774.44 words/s : L.r. 2.3063e-04
[2019-04-17 10:38:23] Ep. 1 : Up. 12400 : Sen. 17,264,661 : Cost 1.56836295 : Time 141.25s : 14538.93 words/s : L.r. 2.3250e-04
[2019-04-17 10:40:46] Ep. 1 : Up. 12500 : Sen. 17,406,981 : Cost 1.58249879 : Time 142.69s : 14633.05 words/s : L.r. 2.3438e-04
[2019-04-17 10:43:09] Ep. 1 : Up. 12600 : Sen. 17,523,020 : Cost 1.59799206 : Time 143.69s : 14855.51 words/s : L.r. 2.3625e-04
[2019-04-17 10:45:29] Ep. 1 : Up. 12700 : Sen. 17,663,909 : Cost 1.55660713 : Time 139.97s : 14683.46 words/s : L.r. 2.3813e-04
[2019-04-17 10:47:50] Ep. 1 : Up. 12800 : Sen. 17,811,498 : Cost 1.56253147 : Time 140.59s : 14448.26 words/s : L.r. 2.4000e-04
[2019-04-17 10:50:17] Ep. 1 : Up. 12900 : Sen. 17,946,617 : Cost 1.55305099 : Time 147.24s : 14606.71 words/s : L.r. 2.4188e-04
[2019-04-17 10:52:47] Ep. 1 : Up. 13000 : Sen. 18,103,882 : Cost 1.51947343 : Time 149.64s : 14887.25 words/s : L.r. 2.4375e-04
[2019-04-17 10:55:12] Ep. 1 : Up. 13100 : Sen. 18,251,504 : Cost 1.54276311 : Time 144.76s : 14431.56 words/s : L.r. 2.4563e-04
[2019-04-17 10:57:37] Ep. 1 : Up. 13200 : Sen. 18,373,791 : Cost 1.53550541 : Time 145.32s : 14712.09 words/s : L.r. 2.4750e-04
[2019-04-17 11:00:01] Ep. 1 : Up. 13300 : Sen. 18,502,355 : Cost 1.53619933 : Time 144.49s : 14819.43 words/s : L.r. 2.4938e-04
[2019-04-17 11:02:20] Ep. 1 : Up. 13400 : Sen. 18,626,859 : Cost 1.53133881 : Time 139.00s : 14377.46 words/s : L.r. 2.5125e-04
[2019-04-17 11:04:46] Ep. 1 : Up. 13500 : Sen. 18,765,546 : Cost 1.52054298 : Time 145.70s : 14683.85 words/s : L.r. 2.5313e-04
[2019-04-17 11:07:11] Ep. 1 : Up. 13600 : Sen. 18,913,768 : Cost 1.53093040 : Time 144.56s : 14559.94 words/s : L.r. 2.5500e-04
[2019-04-17 11:09:28] Ep. 1 : Up. 13700 : Sen. 19,055,516 : Cost 1.51616490 : Time 137.22s : 14700.72 words/s : L.r. 2.5688e-04
[2019-04-17 11:11:51] Ep. 1 : Up. 13800 : Sen. 19,192,860 : Cost 1.52014434 : Time 142.75s : 14532.98 words/s : L.r. 2.5875e-04
[2019-04-17 11:14:14] Ep. 1 : Up. 13900 : Sen. 19,322,965 : Cost 1.52060521 : Time 143.27s : 14658.97 words/s : L.r. 2.6063e-04
[2019-04-17 11:16:40] Ep. 1 : Up. 14000 : Sen. 19,485,123 : Cost 1.49811399 : Time 145.87s : 14753.06 words/s : L.r. 2.6250e-04
[2019-04-17 11:16:40] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext2.npz.orig.npz
[2019-04-17 11:16:43] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext2.npz
[2019-04-17 11:16:46] Saving Adam parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext2.npz.optimizer.npz
[2019-04-17 11:16:55] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext2.npz.best-ce-mean-words.npz
[2019-04-17 11:16:57] [valid] Ep. 1 : Up. 14000 : ce-mean-words : 0.0948363 : new best
[2019-04-17 11:17:00] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext2.npz.best-perplexity.npz
[2019-04-17 11:17:02] [valid] Ep. 1 : Up. 14000 : perplexity : 1.09948 : new best
Detokenizer Version $Revision: 4134 $
Language: en
[2019-04-17 11:17:40] Saving model weights and runtime parameters to model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext2.npz.best-translation.npz
[2019-04-17 11:17:42] [valid] Ep. 1 : Up. 14000 : translation : 95.47 : new best
[2019-04-17 11:20:02] Ep. 1 : Up. 14100 : Sen. 19,617,602 : Cost 1.51711214 : Time 202.71s : 10163.05 words/s : L.r. 2.6438e-04
[2019-04-17 11:22:26] Ep. 1 : Up. 14200 : Sen. 19,771,454 : Cost 1.50102007 : Time 143.34s : 14755.14 words/s : L.r. 2.6625e-04
[2019-04-17 11:24:55] Ep. 1 : Up. 14300 : Sen. 19,894,666 : Cost 1.49334538 : Time 148.89s : 14916.69 words/s : L.r. 2.6813e-04
[2019-04-17 11:27:22] Ep. 1 : Up. 14400 : Sen. 20,032,945 : Cost 1.49780989 : Time 147.74s : 14848.11 words/s : L.r. 2.7000e-04
[2019-04-17 11:29:41] Ep. 1 : Up. 14500 : Sen. 20,176,457 : Cost 1.48927867 : Time 138.89s : 14611.44 words/s : L.r. 2.7188e-04
[2019-04-17 11:32:07] Ep. 1 : Up. 14600 : Sen. 20,318,101 : Cost 1.48653030 : Time 145.69s : 14694.33 words/s : L.r. 2.7375e-04
[2019-04-17 11:34:37] Ep. 1 : Up. 14700 : Sen. 20,465,841 : Cost 1.48815572 : Time 149.82s : 14945.77 words/s : L.r. 2.7563e-04
[2019-04-17 11:37:03] Ep. 1 : Up. 14800 : Sen. 20,599,871 : Cost 1.49007320 : Time 146.05s : 15006.90 words/s : L.r. 2.7750e-04
[2019-04-17 11:39:26] Ep. 1 : Up. 14900 : Sen. 20,720,717 : Cost 1.48628116 : Time 143.54s : 14673.17 words/s : L.r. 2.7938e-04
[2019-04-17 11:41:53] Ep. 1 : Up. 15000 : Sen. 20,847,507 : Cost 1.48050892 : Time 146.40s : 14868.75 words/s : L.r. 2.8125e-04
[2019-04-17 11:44:09] Ep. 1 : Up. 15100 : Sen. 21,011,480 : Cost 1.47955704 : Time 136.72s : 14378.83 words/s : L.r. 2.8313e-04
[2019-04-17 11:46:33] Ep. 1 : Up. 15200 : Sen. 21,155,063 : Cost 1.49136019 : Time 143.48s : 14769.42 words/s : L.r. 2.8500e-04
train_bt_encs_biclean+bt_noise.cosmas_doc_6l_from_base_refcontext.sh: line 29: 110096 Terminated              $marian/marian --model model/model_bt_noise_encz_bicleaner_cosmas_doc_from_base_refcontext2.npz --pretrained-model model/model_base_encz2.npz --type transformer-context --train-sets corpus.docs.cs.bpe corpus.docs.en.bpe.src corpus.docs.cs.bpe -e 1 --max-length 95 --vocabs corp/vocab.encs.yml corp/vocab.encs.yml corp/vocab.encs.yml --mini-batch-fit -w 9000 --mini-batch 1000 --maxi-batch 1000 --freeze --valid-freq 2000 --save-freq 2000 --disp-freq 100 --embedding-fix-src --embedding-fix-trg --valid-metrics ce-mean-words perplexity translation --valid-sets newstest2016.docs.cs.bpe newstest2016.docs.src newstest2016.docs.cs.bpe --valid-script-path ./val.sh --quiet-translation --beam-size 6 --normalize=0.6 --valid-mini-batch 16 --overwrite --keep-best --early-stopping 15 --cost-type=ce-mean-words --log model/bt_encz.log --valid-log model/valid.log --transformer-heads 8 --enc-depth 6 --dec-depth 6 --context-enc-depth 6 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --optimizer-delay 4 --devices 2 3 --sync-sgd --seed 1111 --exponential-smoothing
